{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Soften - Old nets policy notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "cmCpRMBKgvDB",
        "wuDM6Ydokv05",
        "bvD4EPGJLNZn",
        "jICRWSARLUuD"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manuelemacchia/incremental-learning-image-classification/blob/master/dist_targets_analisys_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NzqxHIh4OCdW"
      },
      "source": [
        "# Incremental learning on image classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAmDjtS9LyH2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "fb9d780e-5d4c-4aa4-c1ec-714ffd28563c"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Jun 29 12:09:43 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wBHSznCZxpNB"
      },
      "source": [
        "## Libraries and packages\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4eQ6O12jxMFf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        },
        "outputId": "afdf9124-f744-4f56-a418-addd5bed93ff"
      },
      "source": [
        "!pip3 install 'torch==1.4.0'\n",
        "!pip3 install 'torchvision==0.5.0'\n",
        "!pip3 install 'Pillow-SIMD'\n",
        "!pip3 install 'tqdm'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==1.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/19/4804aea17cd136f1705a5e98a00618cb8f6ccc375ad8bfa437408e09d058/torch-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (753.4MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4MB 20kB/s \n",
            "\u001b[31mERROR: torchvision 0.6.1+cu101 has requirement torch==1.5.1, but you'll have torch 1.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "  Found existing installation: torch 1.5.1+cu101\n",
            "    Uninstalling torch-1.5.1+cu101:\n",
            "      Successfully uninstalled torch-1.5.1+cu101\n",
            "Successfully installed torch-1.4.0\n",
            "Collecting torchvision==0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/90/6141bf41f5655c78e24f40f710fdd4f8a8aff6c8b7c6f0328240f649bdbe/torchvision-0.5.0-cp36-cp36m-manylinux1_x86_64.whl (4.0MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (7.0.0)\n",
            "Requirement already satisfied: torch==1.4.0 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (1.4.0)\n",
            "Installing collected packages: torchvision\n",
            "  Found existing installation: torchvision 0.6.1+cu101\n",
            "    Uninstalling torchvision-0.6.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.6.1+cu101\n",
            "Successfully installed torchvision-0.5.0\n",
            "Collecting Pillow-SIMD\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/6a/30d21c886293cca3755b8e55de34137a5068b77eba1c0644d3632080516b/Pillow-SIMD-7.0.0.post3.tar.gz (630kB)\n",
            "\u001b[K     |████████████████████████████████| 634kB 2.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: Pillow-SIMD\n",
            "  Building wheel for Pillow-SIMD (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Pillow-SIMD: filename=Pillow_SIMD-7.0.0.post3-cp36-cp36m-linux_x86_64.whl size=1110260 sha256=873134b3e9f559ec2086f035de6666f41560f733277347958300212b70e38193\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/ac/4f/4cdf8febba528e5f1b09fc58d5181e1c12ed1e8655dcd583b8\n",
            "Successfully built Pillow-SIMD\n",
            "Installing collected packages: Pillow-SIMD\n",
            "Successfully installed Pillow-SIMD-7.0.0.post3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xAYXtIdpx0Yy",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import urllib\n",
        "import logging\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, Subset, DataLoader, ConcatDataset\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.models import resnet34\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "from copy import deepcopy\n",
        "\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "09iWc_oCotu2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "outputId": "513f2663-b4a7-433d-d407-93248fe06fc2"
      },
      "source": [
        "# GitHub credentials for cloning private repository\n",
        "username = 'LilMowgli'\n",
        "password = '_Kora3030_'\n",
        "\n",
        "# Download packages from repository\n",
        "password = urllib.parse.quote(password)\n",
        "!git clone https://$username:$password@github.com/manuelemacchia/incremental-learning-image-classification.git\n",
        "password = ''\n",
        "\n",
        "!mv -v incremental-learning-image-classification/* .\n",
        "!rm -rf incremental-learning-image-classification README.md"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'incremental-learning-image-classification'...\n",
            "remote: Enumerating objects: 59, done.\u001b[K\n",
            "remote: Counting objects: 100% (59/59), done.\u001b[K\n",
            "remote: Compressing objects: 100% (56/56), done.\u001b[K\n",
            "remote: Total 948 (delta 32), reused 5 (delta 3), pack-reused 889\u001b[K\n",
            "Receiving objects: 100% (948/948), 4.35 MiB | 21.53 MiB/s, done.\n",
            "Resolving deltas: 100% (533/533), done.\n",
            "renamed 'incremental-learning-image-classification/data' -> './data'\n",
            "renamed 'incremental-learning-image-classification/dist_targets_analisys_notebook.ipynb' -> './dist_targets_analisys_notebook.ipynb'\n",
            "renamed 'incremental-learning-image-classification/icarlSVM.ipynb' -> './icarlSVM.ipynb'\n",
            "renamed 'incremental-learning-image-classification/joint_training.ipynb' -> './joint_training.ipynb'\n",
            "renamed 'incremental-learning-image-classification/losses' -> './losses'\n",
            "renamed 'incremental-learning-image-classification/lwf_confmat_targets.pkl' -> './lwf_confmat_targets.pkl'\n",
            "renamed 'incremental-learning-image-classification/model' -> './model'\n",
            "renamed 'incremental-learning-image-classification/notebook.ipynb' -> './notebook.ipynb'\n",
            "renamed 'incremental-learning-image-classification/point5_notebook.ipynb' -> './point5_notebook.ipynb'\n",
            "renamed 'incremental-learning-image-classification/README.md' -> './README.md'\n",
            "renamed 'incremental-learning-image-classification/report' -> './report'\n",
            "renamed 'incremental-learning-image-classification/results' -> './results'\n",
            "renamed 'incremental-learning-image-classification/studies-classifier.ipynb' -> './studies-classifier.ipynb'\n",
            "renamed 'incremental-learning-image-classification/utils' -> './utils'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QPLViftqtC3I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "7110c70f-bec3-4506-db0b-61b4435c52fa"
      },
      "source": [
        "from data.cifar100 import Cifar100\n",
        "from model.resnet_cifar import resnet32\n",
        "from model.manager import Manager\n",
        "from model.icarl import Exemplars\n",
        "# from model.icarl import iCaRL\n",
        "from utils import plot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j12pgffMR6Qv"
      },
      "source": [
        "## Arguments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JwE0x8gkSisn",
        "colab": {}
      },
      "source": [
        "# Directories\n",
        "DATA_DIR = 'data'       # Directory where the dataset will be downloaded\n",
        "\n",
        "# Settings\n",
        "DEVICE = 'cuda'\n",
        "\n",
        "# Dataset\n",
        "\n",
        "RANDOM_STATE = None\n",
        "\n",
        "RANDOM_STATES = [658, 423, 422]      # For reproducibility of results                        \n",
        "                                     # Note: different random states give very different\n",
        "                                     # splits and therefore very different results.\n",
        "\n",
        "NUM_CLASSES = 100       # Total number of classes\n",
        "NUM_BATCHES = 10\n",
        "CLASS_BATCH_SIZE = 10   # Size of batch of classes for incremental learning\n",
        "\n",
        "VAL_SIZE = 0.1          # Proportion of validation set with respect to training set (between 0 and 1)\n",
        "\n",
        "# Training\n",
        "BATCH_SIZE = 64         # Batch size (iCaRL sets this to 128)\n",
        "LR = 2                  # Initial learning rate\n",
        "                       \n",
        "MOMENTUM = 0.9          # Momentum for stochastic gradient descent (SGD)\n",
        "WEIGHT_DECAY = 1e-5     # Weight decay from iCaRL\n",
        "\n",
        "NUM_RUNS = 3            # Number of runs of every method\n",
        "                        # Note: this should be at least 3 to have a fair benchmark\n",
        "\n",
        "NUM_EPOCHS = 70         # Total number of training epochs\n",
        "MILESTONES = [49, 63]   # Step down policy from iCaRL (MultiStepLR)\n",
        "                        # Decrease the learning rate by gamma at each milestone\n",
        "GAMMA = 0.2             # Gamma factor from iCaRL"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7B6CcDcDlMf_",
        "colab_type": "text"
      },
      "source": [
        "## iCaRL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF0ypxGognNR",
        "colab_type": "text"
      },
      "source": [
        "### Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4mf04UjEgmPG",
        "colab": {}
      },
      "source": [
        "# Transformations for Learning Without Forgetting\n",
        "train_transform = transforms.Compose([transforms.RandomCrop(32, padding=4),\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.ToTensor(), # Turn PIL Image to torch.Tensor\n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))                                    \n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y9Oq44dxgmPN",
        "colab": {}
      },
      "source": [
        "train_subsets = [[] for i in range(NUM_RUNS)]\n",
        "val_subsets = [[] for i in range(NUM_RUNS)]\n",
        "test_subsets = [[] for i in range(NUM_RUNS)]\n",
        "\n",
        "for run_i in range(NUM_RUNS):\n",
        "    for split_i in range(CLASS_BATCH_SIZE):\n",
        "        if run_i+split_i == 0: # Download dataset only at first instantiation\n",
        "            download = True\n",
        "        else:\n",
        "            download = False\n",
        "\n",
        "        # Create CIFAR100 dataset\n",
        "        train_dataset = Cifar100(DATA_DIR, train=True, download=download, random_state=RANDOM_STATES[run_i], transform=train_transform)\n",
        "        test_dataset = Cifar100(DATA_DIR, train=False, download=False, random_state=RANDOM_STATES[run_i], transform=test_transform)\n",
        "    \n",
        "        # Subspace of CIFAR100 of 10 classes\n",
        "        train_dataset.set_classes_batch(train_dataset.batch_splits[split_i]) \n",
        "        test_dataset.set_classes_batch([test_dataset.batch_splits[i] for i in range(0, split_i+1)])\n",
        "\n",
        "        # Define train and validation indices\n",
        "        train_indices, val_indices = train_dataset.train_val_split(VAL_SIZE, RANDOM_STATES[run_i])\n",
        "\n",
        "        # Define subsets\n",
        "        train_subsets[run_i].append(Subset(train_dataset, train_indices))\n",
        "        val_subsets[run_i].append(Subset(train_dataset, val_indices))\n",
        "        test_subsets[run_i].append(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwyiPrAZw3L9",
        "colab_type": "text"
      },
      "source": [
        "### iCaRL for Distillation targets analisys"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1h-Fy3D0xAqt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import numpy as np\n",
        "import numpy.ma as ma\n",
        "from math import floor\n",
        "from copy import deepcopy\n",
        "import random\n",
        "\n",
        "sigmoid = nn.Sigmoid() # Sigmoid function\n",
        "\n",
        "NUM_EXAM_EXEMPLARS = 10\n",
        "\n",
        "class Exemplars(torch.utils.data.Dataset):\n",
        "    def __init__(self, exemplars, transform=None):\n",
        "        # exemplars = [\n",
        "        #     [ex0_class0, ex1_class0, ex2_class0, ...],\n",
        "        #     [ex0_class1, ex1_class1, ex2_class1, ...],\n",
        "        #     ...\n",
        "        #     [ex0_classN, ex1_classN, ex2_classN, ...]\n",
        "        # ]\n",
        "\n",
        "        self.dataset = []\n",
        "        self.targets = []\n",
        "\n",
        "        for y, exemplar_y in enumerate(exemplars):\n",
        "            self.dataset.extend(exemplar_y)\n",
        "            self.targets.extend([y] * len(exemplar_y))\n",
        "\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        image = self.dataset[index]\n",
        "        target = self.targets[index]\n",
        "\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.targets)\n",
        "\n",
        "class iCaRL:\n",
        "    \"\"\"Implement iCaRL, a strategy for simultaneously learning classifiers and a\n",
        "    feature representation in the class-incremental setting.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, device, net, lr, momentum, weight_decay, milestones, gamma, num_epochs, batch_size, train_transform, test_transform):\n",
        "        self.device = device\n",
        "        self.net = net\n",
        "\n",
        "        # Set hyper-parameters\n",
        "        self.LR = lr\n",
        "        self.MOMENTUM = momentum\n",
        "        self.WEIGHT_DECAY = weight_decay\n",
        "        self.MILESTONES = milestones\n",
        "        self.GAMMA = gamma\n",
        "        self.NUM_EPOCHS = num_epochs\n",
        "        self.BATCH_SIZE = batch_size\n",
        "        \n",
        "        # Set transformations\n",
        "        self.train_transform = train_transform\n",
        "        self.test_transform = test_transform\n",
        "\n",
        "        # List of exemplar sets. Each set contains memory_size/num_classes exemplars\n",
        "        # with num_classes the number of classes seen until now by the network.\n",
        "        self.exemplars = []\n",
        "\n",
        "        # @DEBUG\n",
        "        self.exemplars_rand = []\n",
        "\n",
        "        # Initialize the copy of the old network, used to compute outputs of the\n",
        "        # previous network for the distillation loss, to None. This is useful to\n",
        "        # correctly apply the first function when training the network for the\n",
        "        # first time.\n",
        "        self.old_net = None\n",
        "        self.old_nets = []\n",
        "\n",
        "        # store saved features in a dictionary where key = split,\n",
        "        # value = [last_net_features, old_nets_features]\n",
        "        self.examined_exemplars_loader = None\n",
        "        self.examined_exemplars_features = dict()\n",
        "\n",
        "        # Maximum number of exemplars\n",
        "        self.memory_size = 2000\n",
        "    \n",
        "        # Loss function\n",
        "        self.criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "        # If True, test on the best model found (e.g., minimize loss). If False,\n",
        "        # test on the last model build (of the last epoch).\n",
        "        self.VALIDATE = False\n",
        "\n",
        "    def classify(self, batch, train_dataset=None):\n",
        "        \"\"\"Mean-of-exemplars classifier used to classify images into the set of\n",
        "        classes observed so far.\n",
        "\n",
        "        Args:\n",
        "            batch (torch.tensor): batch to classify\n",
        "        Returns:\n",
        "            label (int): class label assigned to the image\n",
        "        \"\"\"\n",
        "\n",
        "        batch_features = self.extract_features(batch) # (batch size, 64)\n",
        "        for i in range(batch_features.size(0)):\n",
        "            batch_features[i] = batch_features[i]/batch_features[i].norm() # Normalize sample feature representation\n",
        "        batch_features = batch_features.to(self.device)\n",
        "\n",
        "        if self.cached_means is None:\n",
        "            print(\"Computing mean of exemplars... \", end=\"\")\n",
        "\n",
        "            self.cached_means = []\n",
        "\n",
        "            # Number of known classes\n",
        "            num_classes = len(self.exemplars)\n",
        "\n",
        "            # Compute the means of classes with all the data available,\n",
        "            # including training data which contains samples belonging to\n",
        "            # the latest 10 classes. This will remove noise from the mean\n",
        "            # estimate, improving the results.\n",
        "            if train_dataset is not None:\n",
        "                train_features_list = [[] for _ in range(10)]\n",
        "\n",
        "                for train_sample, label in train_dataset:\n",
        "                    features = self.extract_features(train_sample, batch=False, transform=self.test_transform)\n",
        "                    features = features/features.norm()\n",
        "                    train_features_list[label % 10].append(features)\n",
        "\n",
        "            # Compute means of exemplars for all known classes\n",
        "            for y in range(num_classes):\n",
        "                if (train_dataset is not None) and (y in range(num_classes-10, num_classes)):\n",
        "                    features_list = train_features_list[y % 10]\n",
        "                else:\n",
        "                    features_list = []\n",
        "\n",
        "                for exemplar in self.exemplars[y]:\n",
        "                    features = self.extract_features(exemplar, batch=False, transform=self.test_transform)\n",
        "                    features = features/features.norm() # Normalize the feature representation of the exemplar\n",
        "                    features_list.append(features)\n",
        "                \n",
        "                features_list = torch.stack(features_list)\n",
        "                class_means = features_list.mean(dim=0)\n",
        "                class_means = class_means/class_means.norm() # Normalize the class means\n",
        "\n",
        "                self.cached_means.append(class_means)\n",
        "            \n",
        "            self.cached_means = torch.stack(self.cached_means).to(self.device)\n",
        "            print(\"done\")\n",
        "\n",
        "        preds = []\n",
        "        for i in range(batch_features.size(0)):\n",
        "            f_arg = torch.norm(batch_features[i] - self.cached_means, dim=1)\n",
        "            preds.append(torch.argmin(f_arg))\n",
        "        \n",
        "        return torch.stack(preds)\n",
        "    \n",
        "    # @DEBUG\n",
        "    def classify_rand(self, batch, train_dataset=None):\n",
        "        \"\"\"Mean-of-exemplars classifier used to classify images into the set of\n",
        "        classes observed so far.\n",
        "\n",
        "        Args:\n",
        "            batch (torch.tensor): batch to classify\n",
        "        Returns:\n",
        "            label (int): class label assigned to the image\n",
        "        \"\"\"\n",
        "\n",
        "        batch_features = self.extract_features(batch) # (batch size, 64)\n",
        "        for i in range(batch_features.size(0)):\n",
        "            batch_features[i] = batch_features[i]/batch_features[i].norm() # Normalize sample feature representation\n",
        "        batch_features = batch_features.to(self.device)\n",
        "\n",
        "        if self.cached_means is None:\n",
        "            print(\"Computing mean of exemplars... \", end=\"\")\n",
        "\n",
        "            self.cached_means = []\n",
        "\n",
        "            # Number of known classes\n",
        "            num_classes = len(self.exemplars_rand)\n",
        "\n",
        "            # Compute the means of classes with all the data available,\n",
        "            # including training data which contains samples belonging to\n",
        "            # the latest 10 classes. This will remove noise from the mean\n",
        "            # estimate, improving the results.\n",
        "            if train_dataset is not None:\n",
        "                train_features_list = [[] for _ in range(10)]\n",
        "\n",
        "                for train_sample, label in train_dataset:\n",
        "                    features = self.extract_features(train_sample, batch=False, transform=self.test_transform)\n",
        "                    features = features/features.norm()\n",
        "                    train_features_list[label % 10].append(features)\n",
        "\n",
        "            # Compute means of exemplars for all known classes\n",
        "            for y in range(num_classes):\n",
        "                if (train_dataset is not None) and (y in range(num_classes-10, num_classes)):\n",
        "                    features_list = train_features_list[y % 10]\n",
        "                else:\n",
        "                    features_list = []\n",
        "\n",
        "                for exemplar in self.exemplars_rand[y]:\n",
        "                    features = self.extract_features(exemplar, batch=False, transform=self.test_transform)\n",
        "                    features = features/features.norm() # Normalize the feature representation of the exemplar\n",
        "                    features_list.append(features)\n",
        "                \n",
        "                features_list = torch.stack(features_list)\n",
        "                class_means = features_list.mean(dim=0)\n",
        "                class_means = class_means/class_means.norm() # Normalize the class means\n",
        "\n",
        "                self.cached_means.append(class_means)\n",
        "            \n",
        "            self.cached_means = torch.stack(self.cached_means).to(self.device)\n",
        "            print(\"done\")\n",
        "\n",
        "        preds = []\n",
        "        for i in range(batch_features.size(0)):\n",
        "            f_arg = torch.norm(batch_features[i] - self.cached_means, dim=1)\n",
        "            preds.append(torch.argmin(f_arg))\n",
        "        \n",
        "        return torch.stack(preds)\n",
        "    \n",
        "    def extract_features(self, sample, batch=True, transform=None):\n",
        "        \"\"\"Extract features from single sample or from batch.\n",
        "        \n",
        "        Args:\n",
        "            sample (PIL image or torch.tensor): sample(s) from which to\n",
        "                extract features\n",
        "            batch (bool): if True, sample is a torch.tensor containing a batch\n",
        "                of images with dimensions (batch_size, 3, 32, 32)\n",
        "            transform: transformations to apply to the PIL image before\n",
        "                processing\n",
        "        Returns:\n",
        "            features: torch.tensor, 1-D of dimension 64 for single samples or\n",
        "                2-D of dimension (batch_size, 64) for batch\n",
        "        \"\"\"\n",
        "\n",
        "        assert not (batch is False and transform is None), \"if a PIL image is passed to extract_features, a transform must be defined\"\n",
        "\n",
        "        self.net.train(False)\n",
        "        if self.best_net is not None: self.best_net.train(False)\n",
        "        if self.old_net is not None: \n",
        "          self.old_net.train(False)\n",
        "          for i in range(len(self.old_nets)):\n",
        "            self.old_nets[i] = self.old_nets[i].train(False)\n",
        "\n",
        "\n",
        "        if batch is False: # Treat sample as single PIL image\n",
        "            sample = transform(sample)\n",
        "            sample = sample.unsqueeze(0) # https://stackoverflow.com/a/59566009/6486336\n",
        "\n",
        "        sample = sample.to(self.device)\n",
        "\n",
        "        if self.VALIDATE:\n",
        "            features = self.best_net.features(sample)\n",
        "        else:\n",
        "            features = self.net.features(sample)\n",
        "\n",
        "        if batch is False:\n",
        "            features = features[0]\n",
        "\n",
        "        return features\n",
        "\n",
        "    def incremental_train(self, split, train_dataset, val_dataset):\n",
        "        \"\"\"Adjust internal knowledge based on the additional information\n",
        "        available in the new observations.\n",
        "\n",
        "        Args:\n",
        "            split (int): current split number, counting from zero\n",
        "            train_dataset: dataset for training the model\n",
        "            val_dataset: dataset for validating the model\n",
        "        Returns:\n",
        "            train_logs: tuple of four metrics (train_loss, train_accuracy,\n",
        "            val_loss, val_accuracy) obtained during network training\n",
        "        \"\"\"\n",
        "\n",
        "        self.split = split\n",
        "\n",
        "        if split is not 0:\n",
        "            # Increment the number of output nodes for the new network by 10\n",
        "            self.increment_classes(10)\n",
        "            last_net_preds, old_nets_preds= self.save_exemplars_features()\n",
        "            # update features dictionary for analisys\n",
        "            self.examined_exemplars_features[self.split] = [last_net_preds, old_nets_preds]\n",
        "\n",
        "        # Improve network parameters upon receiving new classes. Effectively\n",
        "        # train a new network starting from the current network parameters.\n",
        "        train_logs = self.update_representation(train_dataset, val_dataset)\n",
        "\n",
        "        # Compute the number of exemplars per class\n",
        "        num_classes = self.output_neurons_count()\n",
        "        m = floor(self.memory_size / num_classes)\n",
        "\n",
        "        print(f\"Target number of exemplars per class: {m}\")\n",
        "        print(f\"Target total number of exemplars: {m*num_classes}\")\n",
        "\n",
        "        # Reduce pre-existing exemplar sets in order to fit new exemplars\n",
        "        for y in range(len(self.exemplars)):\n",
        "            self.exemplars[y] = self.reduce_exemplar_set(self.exemplars[y], m)\n",
        "\n",
        "        # @DEBUG\n",
        "        for y in range(len(self.exemplars_rand)):\n",
        "            self.exemplars_rand[y] = self.reduce_exemplar_set(self.exemplars[y], m)\n",
        "\n",
        "        # Construct exemplar set for new classes\n",
        "        new_exemplars = self.construct_exemplar_set(train_dataset, m)\n",
        "        self.exemplars.extend(new_exemplars)\n",
        "        \n",
        "\n",
        "        # @DEBUG\n",
        "        new_exemplars = self.construct_exemplar_set_rand(train_dataset, m)\n",
        "        self.exemplars_rand.extend(new_exemplars)\n",
        "\n",
        "        return train_logs\n",
        "\n",
        "\n",
        "    def save_exemplars_features(self):\n",
        "      # Take predictions on old_classes (num_classes-10) with\n",
        "      # 1. self.old_net\n",
        "      # 2. self.old_nets, keeping prediction of each net over the classes it's been trained on\n",
        "      # Predictions are taken on exemplars of a single class, self.examined_exemplas, which are the same\n",
        "      # across all the training procedure from split 0 to split 9\n",
        "      # Predictions must be passed into a sigmoid since we want to compare the targets seen by the\n",
        "      # currently trained net\n",
        "\n",
        "      dataiter = iter(self.examined_exemplars_loader)\n",
        "      images, _ = dataiter.next()\n",
        "      images = images.to(self.device)\n",
        "\n",
        "      last_net_preds = sigmoid(self.old_net(images))\n",
        "\n",
        "      old_nets_preds = sigmoid(self.old_nets[0](images))\n",
        "      \n",
        "      for i in range(1, len(self.old_nets[1:])):\n",
        "        old_nets_preds = torch.cat( (old_nets_preds, sigmoid(self.old_nets[i](images))[:, i*10:] ), dim=1)\n",
        "      \n",
        "      if(old_nets_preds.size() != last_net_preds.size()):\n",
        "        print(\"Error: The two predictions matrices must be of the same size\")\n",
        "\n",
        "\n",
        "      return last_net_preds, old_nets_preds\n",
        "      \n",
        "\n",
        "    def update_representation(self, train_dataset, val_dataset):\n",
        "        \"\"\"Update the parameters of the network.\n",
        "\n",
        "        Args:\n",
        "            train_dataset: dataset for training the model\n",
        "            val_dataset: dataset for validating the model\n",
        "        Returns:\n",
        "            train_logs: tuple of four metrics (train_loss, train_accuracy,\n",
        "            val_loss, val_accuracy) obtained during network training\n",
        "        \"\"\"\n",
        "\n",
        "        # Combine the new training data with existing exemplars.\n",
        "        print(f\"Length of exemplars set: {sum([len(self.exemplars[y]) for y in range(len(self.exemplars))])}\")\n",
        "        exemplars_dataset = Exemplars(self.exemplars, self.train_transform)\n",
        "        train_dataset_with_exemplars = ConcatDataset([exemplars_dataset, train_dataset])\n",
        "\n",
        "        # Train the network on combined dataset\n",
        "        train_logs = self.train(train_dataset_with_exemplars, val_dataset) # @todo: include exemplars in validation set?\n",
        "\n",
        "        # Keep a copy of the current network in order to compute its outputs for\n",
        "        # the distillation loss while the new network is being trained.\n",
        "        self.old_net = deepcopy(self.net)\n",
        "        self.old_nets.append(self.old_net)\n",
        "\n",
        "\n",
        "        return train_logs\n",
        "\n",
        "    def construct_exemplar_set(self, dataset, m):\n",
        "        \"\"\"...\n",
        "\n",
        "        Args:\n",
        "            dataset: dataset containing a split (samples from 10 classes) from\n",
        "                which to take exemplars\n",
        "            m (int): target number of exemplars per class\n",
        "        Returns:\n",
        "            exemplars: list of samples extracted from the dataset\n",
        "        \"\"\"\n",
        "\n",
        "        dataset.dataset.disable_transform()\n",
        "\n",
        "        samples = [[] for _ in range(10)]\n",
        "        for image, label in dataset:\n",
        "            label = label % 10 # Map labels to 0-9 range\n",
        "            samples[label].append(image)\n",
        "\n",
        "        dataset.dataset.enable_transform()\n",
        "\n",
        "        # Initialize exemplar sets\n",
        "        exemplars = [[] for _ in range(10)]\n",
        "\n",
        "        # Iterate over classes\n",
        "        for y in range(10):\n",
        "            print(f\"Extracting exemplars from class {y} of current split... \", end=\"\")\n",
        "\n",
        "\n",
        "            # Transform samples to tensors and apply normalization\n",
        "            transformed_samples = torch.zeros((len(samples[y]), 3, 32, 32)).to(self.device)\n",
        "            for i in range(len(transformed_samples)):\n",
        "                transformed_samples[i] = self.test_transform(samples[y][i])\n",
        "\n",
        "            # Extract features from samples\n",
        "            samples_features = self.extract_features(transformed_samples).to(self.device)\n",
        "\n",
        "            # Compute the feature mean of the current class\n",
        "            features_mean = samples_features.mean(dim=0)\n",
        "\n",
        "            # Initializes indices vector, containing the index of each exemplar chosen\n",
        "            idx = []\n",
        "\n",
        "            # See iCaRL algorithm 4\n",
        "            for k in range(1, m+1): # k = 1, ..., m -- Choose m exemplars\n",
        "                if k == 1: # No exemplars chosen yet, sum to 0 vector\n",
        "                    f_sum = torch.zeros(64).to(self.device)\n",
        "                else: # Sum of features of all exemplars chosen until now (j = 1, ..., k-1)\n",
        "                    f_sum = samples_features[idx].sum(dim=0)\n",
        "\n",
        "                # Compute argument of argmin function\n",
        "                f_arg = torch.norm(features_mean - 1/k * samples_features + f_sum, dim=1)\n",
        "\n",
        "                # Mask exemplars that were already taken, as we do not want to store the\n",
        "                # same exemplar more than once\n",
        "                mask = np.zeros(len(f_arg), int)\n",
        "                mask[idx] = 1\n",
        "                f_arg_masked = ma.masked_array(f_arg.cpu().detach().numpy(), mask=mask)\n",
        "\n",
        "                # Compute the nearest available exemplar\n",
        "                exemplar_idx = np.argmin(f_arg_masked)\n",
        "\n",
        "                idx.append(exemplar_idx)\n",
        "            \n",
        "            # Save exemplars to exemplar set\n",
        "            for i in idx:\n",
        "                exemplars[y].append(samples[y][i])\n",
        "\n",
        "            print(f\"Extracted {len(exemplars[y])} exemplars.\")\n",
        "                \n",
        "            # take first ten exemplars of first class, only once during the\n",
        "            # whole incremental training procedure\n",
        "            if self.split == 0 and y == 0:\n",
        "              examined_exemplars = [exemplars[y][:NUM_EXAM_EXEMPLARS]] # add a dimension\n",
        "\n",
        "              examined_exemplars_dataset = Exemplars(examined_exemplars, self.train_transform)\n",
        "              self.examined_exemplars_loader = DataLoader(examined_exemplars_dataset,\n",
        "                                                          batch_size = NUM_EXAM_EXEMPLARS)\n",
        "              print(\"Saved {} exemplars for features analysis\".format(len(examined_exemplars[0])))\n",
        "                \n",
        "            \n",
        "            \n",
        "        return exemplars\n",
        "\n",
        "    def construct_exemplar_set_rand(self, dataset, m):\n",
        "        \"\"\"Randomly sample m elements from a dataset without replacement.\n",
        "\n",
        "        Args:\n",
        "            dataset: dataset containing a split (samples from 10 classes) from\n",
        "                which to take exemplars\n",
        "            m (int): target number of exemplars per class\n",
        "        Returns:\n",
        "            exemplars: list of samples extracted from the dataset\n",
        "        \"\"\"\n",
        "\n",
        "        dataset.dataset.disable_transform()\n",
        "\n",
        "        samples = [[] for _ in range(10)]\n",
        "        for image, label in dataset:\n",
        "            label = label % 10 # Map labels to 0-9 range\n",
        "            samples[label].append(image)\n",
        "\n",
        "        dataset.dataset.enable_transform()\n",
        "\n",
        "        exemplars = [[] for _ in range(10)]\n",
        "\n",
        "        for y in range(10):\n",
        "            print(f\"Randomly extracting exemplars from class {y} of current split... \", end=\"\")\n",
        "\n",
        "            # Randomly choose m samples from samples[y] without replacement\n",
        "            exemplars[y] = random.sample(samples[y], m)\n",
        "\n",
        "            print(f\"Extracted {len(exemplars[y])} exemplars.\")\n",
        "\n",
        "        return exemplars\n",
        "\n",
        "    def reduce_exemplar_set(self, exemplar_set, m):\n",
        "        \"\"\"Procedure for removing exemplars from a given set.\n",
        "\n",
        "        Args:\n",
        "            exemplar_set (set): set of exemplars belonging to a certain class\n",
        "            m (int): target number of exemplars\n",
        "        Returns:\n",
        "            exemplar_set: reduced exemplar set\n",
        "        \"\"\"\n",
        "\n",
        "        return exemplar_set[:m]\n",
        "\n",
        "    def train(self, train_dataset, val_dataset):\n",
        "        \"\"\"Train the network for a specified number of epochs, and save\n",
        "        the best performing model on the validation set.\n",
        "        \n",
        "        Args:\n",
        "            train_dataset: dataset for training the model\n",
        "            val_dataset: dataset for validating the model\n",
        "        Returns: train_logs: tuple of four metrics (train_loss, train_accuracy,\n",
        "            val_loss, val_accuracy) obtained during network training. If\n",
        "            validation is enabled, return scores of the best epoch, otherwise\n",
        "            return scores of the last epoch.\n",
        "        \"\"\"\n",
        "\n",
        "        # Define the optimization algorithm\n",
        "        parameters_to_optimize = self.net.parameters()\n",
        "        self.optimizer = optim.SGD(parameters_to_optimize, \n",
        "                                   lr=self.LR,\n",
        "                                   momentum=self.MOMENTUM,\n",
        "                                   weight_decay=self.WEIGHT_DECAY)\n",
        "        \n",
        "        # Define the learning rate decaying policy\n",
        "        self.scheduler = optim.lr_scheduler.MultiStepLR(self.optimizer,\n",
        "                                                        milestones=self.MILESTONES,\n",
        "                                                        gamma=self.GAMMA)\n",
        "\n",
        "        # Create DataLoaders for training and validation\n",
        "        self.train_dataloader = DataLoader(train_dataset, batch_size=self.BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
        "        self.val_dataloader = DataLoader(val_dataset, batch_size=self.BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
        "\n",
        "        # Send networks to chosen device\n",
        "        self.net = self.net.to(self.device)\n",
        "        if self.old_net is not None: \n",
        "          self.old_net = self.old_net.to(self.device)\n",
        "          for i in range(len(self.old_nets)):\n",
        "            self.old_nets[i] = self.old_nets[i].to(self.device)\n",
        "\n",
        "        cudnn.benchmark  # Calling this optimizes runtime\n",
        "\n",
        "        self.best_val_loss = float('inf')\n",
        "        self.best_val_accuracy = 0\n",
        "        self.best_train_loss = float('inf')\n",
        "        self.best_train_accuracy = 0\n",
        "        \n",
        "        self.best_net = None\n",
        "        self.best_epoch = -1\n",
        "\n",
        "        for epoch in range(self.NUM_EPOCHS):\n",
        "            # Run an epoch (start counting form 1)\n",
        "            train_loss, train_accuracy = self.do_epoch(epoch+1)\n",
        "        \n",
        "            # Validate after each epoch \n",
        "            val_loss, val_accuracy = self.validate()    \n",
        "\n",
        "            # Validation criterion: best net is the one that minimizes the loss\n",
        "            # on the validation set.\n",
        "            if self.VALIDATE and val_loss < self.best_val_loss:\n",
        "                self.best_val_loss = val_loss\n",
        "                self.best_val_accuracy = val_accuracy\n",
        "                self.best_train_loss = train_loss\n",
        "                self.best_train_accuracy = train_accuracy\n",
        "\n",
        "                self.best_net = deepcopy(self.net)\n",
        "                self.best_epoch = epoch\n",
        "                print(\"Best model updated\")\n",
        "\n",
        "        if self.VALIDATE:\n",
        "            val_loss = self.best_val_loss\n",
        "            val_accuracy = self.best_val_accuracy\n",
        "            train_loss = self.best_train_loss\n",
        "            train_accuracy = self.best_train_accuracy\n",
        "\n",
        "            print(f\"Best model found at epoch {self.best_epoch+1}\")\n",
        "\n",
        "        return train_loss, train_accuracy, val_loss, val_accuracy\n",
        "    \n",
        "    def do_epoch(self, current_epoch):\n",
        "        \"\"\"Trains model for one epoch.\n",
        "        \n",
        "        Args:\n",
        "            current_epoch (int): current epoch number (begins from 1)\n",
        "        Returns:\n",
        "            train_loss: average training loss over all batches of the\n",
        "                current epoch.\n",
        "            train_accuracy: training accuracy of the current epoch over\n",
        "                all samples.\n",
        "        \"\"\"\n",
        "\n",
        "        # Set the current network in training mode\n",
        "        self.net.train()\n",
        "        if self.old_net is not None: \n",
        "          self.old_net.train(False)\n",
        "          for i in range(len(self.old_nets)):\n",
        "            self.old_nets[i] = self.old_nets[i].train(False)\n",
        "        if self.best_net is not None: self.best_net.train(False)\n",
        "\n",
        "        running_train_loss = 0\n",
        "        running_corrects = 0\n",
        "        total = 0\n",
        "        batch_idx = 0\n",
        "\n",
        "        print(f\"Epoch: {current_epoch}, LR: {self.scheduler.get_last_lr()}\")\n",
        "\n",
        "        for images, labels in self.train_dataloader:\n",
        "            loss, corrects = self.do_batch(images, labels)\n",
        "\n",
        "            running_train_loss += loss.item()\n",
        "            running_corrects += corrects\n",
        "            total += labels.size(0)\n",
        "            batch_idx += 1\n",
        "\n",
        "        self.scheduler.step()\n",
        "\n",
        "        # Calculate average scores\n",
        "        train_loss = running_train_loss / batch_idx # Average over all batches\n",
        "        train_accuracy = running_corrects / float(total) # Average over all samples\n",
        "\n",
        "        print(f\"Train loss: {train_loss}, Train accuracy: {train_accuracy}\")\n",
        "\n",
        "        return train_loss, train_accuracy\n",
        "\n",
        "    def do_batch(self, batch, labels):\n",
        "        \"\"\"Train network for a batch. Loss is applied here.\n",
        "\n",
        "        Args:\n",
        "            batch: batch of data used for training the network\n",
        "            labels: targets of the batch\n",
        "        Returns:\n",
        "            loss: output of the criterion applied\n",
        "            running_corrects: number of correctly classified elements\n",
        "        \"\"\"\n",
        "        batch = batch.to(self.device)\n",
        "        labels = labels.to(self.device)\n",
        "\n",
        "        # Zero-ing the gradients\n",
        "        self.optimizer.zero_grad()\n",
        "        \n",
        "        # One-hot encoding of labels of the new training data (new classes)\n",
        "        # Size: batch size (rows) by number of classes seen until now (columns)\n",
        "        #\n",
        "        # e.g., suppose we have four images in a batch, and each incremental\n",
        "        #   step adds three new classes. At the second step, the one-hot\n",
        "        #   encoding may return the following tensor:\n",
        "        #\n",
        "        #       tensor([[0., 0., 0., 1., 0., 0.],   # image 0 (label 3)\n",
        "        #               [0., 0., 0., 0., 1., 0.],   # image 1 (label 4)\n",
        "        #               [0., 0., 0., 0., 0., 1.],   # image 2 (label 5)\n",
        "        #               [0., 0., 0., 0., 1., 0.]])  # image 3 (label 4)\n",
        "        #\n",
        "        #   The first three elements of each vector will always be 0, as the\n",
        "        #   new training batch does not contain images belonging to classes\n",
        "        #   already seen in previous steps.\n",
        "        #\n",
        "        #   The last three elements of each vector will contain the actual\n",
        "        #   information about the class of each image (one-hot encoding of the\n",
        "        #   label). Therefore, we slice the tensor and remove the columns \n",
        "        #   related to old classes (all zeros).\n",
        "        num_classes = self.output_neurons_count() # Number of classes seen until now, including new classes\n",
        "        one_hot_labels = self.to_onehot(labels)[:, num_classes-10:num_classes]\n",
        "\n",
        "        if self.old_net is None:\n",
        "            # Network is training for the first time, so we only apply the\n",
        "            # classification loss.\n",
        "            targets = one_hot_labels\n",
        "\n",
        "        else:\n",
        "            # Old net forward pass. We compute the outputs of the old network\n",
        "            # and apply a sigmoid function. These are used in the distillation\n",
        "            # loss. We discard the output of the new neurons, as they are not\n",
        "            # considered in the distillation loss.\n",
        "            old_net_outputs = sigmoid(self.old_net(batch))[:, :num_classes-10]\n",
        "\n",
        "\n",
        "            # Concatenate the outputs of the old network and the one-hot encoded\n",
        "            # labels along dimension 1 (columns).\n",
        "            # \n",
        "            # Each row refers to an image in the training set, and contains:\n",
        "            # - the output of the old network for that image, used by the\n",
        "            #   distillation loss\n",
        "            # - the one-hot label of the image, used by the classification loss\n",
        "            targets = torch.cat((old_net_outputs, one_hot_labels), dim=1)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = self.net(batch)\n",
        "        loss = self.criterion(outputs, targets)\n",
        "\n",
        "        # Get predictions\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "        # Accuracy over NEW IMAGES, not over all images\n",
        "        running_corrects = torch.sum(preds == labels.data).data.item() \n",
        "\n",
        "        # Backward pass: computes gradients\n",
        "        loss.backward()\n",
        "\n",
        "        self.optimizer.step()\n",
        "\n",
        "        return loss, running_corrects\n",
        "\n",
        "    def validate(self):\n",
        "        \"\"\"Validate the model.\n",
        "        \n",
        "        Returns:\n",
        "            val_loss: average loss function computed on the network outputs\n",
        "                of the validation set (val_dataloader).\n",
        "            val_accuracy: accuracy computed on the validation set.\n",
        "        \"\"\"\n",
        "\n",
        "        self.net.train(False)\n",
        "        if self.old_net is not None: self.old_net.train(False)\n",
        "        if self.best_net is not None: self.best_net.train(False)\n",
        "\n",
        "        running_val_loss = 0\n",
        "        running_corrects = 0\n",
        "        total = 0\n",
        "        batch_idx = 0\n",
        "\n",
        "        for images, labels in self.val_dataloader:\n",
        "            images = images.to(self.device)\n",
        "            labels = labels.to(self.device)\n",
        "            total += labels.size(0)\n",
        "\n",
        "            # One hot encoding of new task labels \n",
        "            one_hot_labels = self.to_onehot(labels)\n",
        "\n",
        "            # New net forward pass\n",
        "            outputs = self.net(images)  \n",
        "            loss = self.criterion(outputs, one_hot_labels) # BCE Loss with sigmoids over outputs\n",
        "\n",
        "            running_val_loss += loss.item()\n",
        "\n",
        "            # Get predictions\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "            # Update the number of correctly classified validation samples\n",
        "            running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "            batch_idx += 1\n",
        "\n",
        "        # Calculate scores\n",
        "        val_loss = running_val_loss / batch_idx\n",
        "        val_accuracy = running_corrects / float(total)\n",
        "\n",
        "        print(f\"Validation loss: {val_loss}, Validation accuracy: {val_accuracy}\")\n",
        "\n",
        "        return val_loss, val_accuracy\n",
        "\n",
        "    def test(self, test_dataset, train_dataset=None):\n",
        "        \"\"\"Test the model.\n",
        "\n",
        "        Args:\n",
        "            test_dataset: dataset on which to test the network\n",
        "            train_dataset: training set used to train the last split, if\n",
        "                available\n",
        "        Returns:\n",
        "            accuracy (float): accuracy of the model on the test set\n",
        "        \"\"\"\n",
        "\n",
        "        self.net.train(False)\n",
        "        if self.best_net is not None: self.best_net.train(False)  # Set Network to evaluation mode\n",
        "        if self.old_net is not None: self.old_net.train(False)\n",
        "\n",
        "        self.test_dataloader = DataLoader(test_dataset, batch_size=self.BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "\n",
        "        running_corrects = 0\n",
        "        total = 0\n",
        "\n",
        "        # To store all predictions\n",
        "        all_preds = torch.tensor([])\n",
        "        all_preds = all_preds.type(torch.LongTensor)\n",
        "\n",
        "        # Clear mean of exemplars cache\n",
        "        self.cached_means = None\n",
        "        \n",
        "        # Disable transformations for train_dataset, if available, as we will\n",
        "        # need original PIL images from which to extract features.\n",
        "        if train_dataset is not None: train_dataset.dataset.disable_transform()\n",
        "\n",
        "        for images, labels in self.test_dataloader:\n",
        "            images = images.to(self.device)\n",
        "            labels = labels.to(self.device)\n",
        "\n",
        "            total += labels.size(0)\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                preds = self.classify(images, train_dataset)\n",
        "\n",
        "            running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "            all_preds = torch.cat(\n",
        "                (all_preds.to(self.device), preds.to(self.device)), dim=0\n",
        "            )\n",
        "\n",
        "        if train_dataset is not None: train_dataset.dataset.enable_transform()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        accuracy = running_corrects / float(total)  \n",
        "\n",
        "        print(f\"Test accuracy (iCaRL): {accuracy} \", end=\"\")\n",
        "\n",
        "        if train_dataset is None:\n",
        "            print(\"(only exemplars)\")\n",
        "        else:\n",
        "            print(\"(exemplars and training data)\")\n",
        "\n",
        "        return accuracy, all_preds\n",
        "\n",
        "    # @DEBUG\n",
        "    def test_rand(self, test_dataset, train_dataset=None):\n",
        "        \"\"\"Test the model.\n",
        "\n",
        "        Args:\n",
        "            test_dataset: dataset on which to test the network\n",
        "            train_dataset: training set used to train the last split, if\n",
        "                available\n",
        "        Returns:\n",
        "            accuracy (float): accuracy of the model on the test set\n",
        "        \"\"\"\n",
        "\n",
        "        self.net.train(False)\n",
        "        if self.best_net is not None: self.best_net.train(False)  # Set Network to evaluation mode\n",
        "        if self.old_net is not None: self.old_net.train(False)\n",
        "\n",
        "        self.test_dataloader = DataLoader(test_dataset, batch_size=self.BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "\n",
        "        running_corrects = 0\n",
        "        total = 0\n",
        "\n",
        "        # To store all predictions\n",
        "        all_preds = torch.tensor([])\n",
        "        all_preds = all_preds.type(torch.LongTensor)\n",
        "\n",
        "        # Clear mean of exemplars cache\n",
        "        self.cached_means = None\n",
        "        \n",
        "        # Disable transformations for train_dataset, if available, as we will\n",
        "        # need original PIL images from which to extract features.\n",
        "        if train_dataset is not None: train_dataset.dataset.disable_transform()\n",
        "\n",
        "        for images, labels in self.test_dataloader:\n",
        "            images = images.to(self.device)\n",
        "            labels = labels.to(self.device)\n",
        "\n",
        "            total += labels.size(0)\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                preds = self.classify_rand(images, train_dataset)\n",
        "\n",
        "            running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "            all_preds = torch.cat(\n",
        "                (all_preds.to(self.device), preds.to(self.device)), dim=0\n",
        "            )\n",
        "\n",
        "        if train_dataset is not None: train_dataset.dataset.enable_transform()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        accuracy = running_corrects / float(total)  \n",
        "\n",
        "        print(f\"Test accuracy (iCaRL): {accuracy} \", end=\"\")\n",
        "\n",
        "        if train_dataset is None:\n",
        "            print(\"(only exemplars)\")\n",
        "        else:\n",
        "            print(\"(exemplars and training data)\")\n",
        "\n",
        "        return accuracy, all_preds\n",
        "\n",
        "    def test_without_classifier(self, test_dataset):\n",
        "        \"\"\"Test the model without classifier, using the outputs of the\n",
        "        network instead.\n",
        "\n",
        "        Args:\n",
        "            test_dataset: dataset on which to test the network\n",
        "        Returns:\n",
        "            accuracy (float): accuracy of the model on the test set\n",
        "        \"\"\"\n",
        "\n",
        "        self.net.train(False)\n",
        "        if self.best_net is not None: self.best_net.train(False) # Set Network to evaluation mode\n",
        "        if self.old_net is not None: self.old_net.train(False)\n",
        "\n",
        "        self.test_dataloader = DataLoader(test_dataset, batch_size=self.BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "\n",
        "        running_corrects = 0\n",
        "        total = 0\n",
        "\n",
        "        all_preds = torch.tensor([]) # to store all predictions\n",
        "        all_preds = all_preds.type(torch.LongTensor)\n",
        "        \n",
        "        for images, labels in self.test_dataloader:\n",
        "            images = images.to(self.device)\n",
        "            labels = labels.to(self.device)\n",
        "            total += labels.size(0)\n",
        "\n",
        "            # Forward Pass\n",
        "            with torch.no_grad():\n",
        "                if self.VALIDATE:\n",
        "                    outputs = self.best_net(images)\n",
        "                else:\n",
        "                    outputs = self.net(images)\n",
        "\n",
        "            # Get predictions\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "            # Update Corrects\n",
        "            running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "            # Append batch predictions\n",
        "            all_preds = torch.cat(\n",
        "                (all_preds.to(self.device), preds.to(self.device)), dim=0\n",
        "            )\n",
        "\n",
        "        # Calculate accuracy\n",
        "        accuracy = running_corrects / float(total)  \n",
        "\n",
        "        print(f\"Test accuracy (hybrid1): {accuracy}\")\n",
        "\n",
        "        return accuracy, all_preds\n",
        "    \n",
        "    def increment_classes(self, n=10):\n",
        "        \"\"\"Add n classes in the final fully connected layer.\"\"\"\n",
        "\n",
        "        in_features = self.net.fc.in_features  # size of each input sample\n",
        "        out_features = self.net.fc.out_features  # size of each output sample\n",
        "        weight = self.net.fc.weight.data\n",
        "\n",
        "        self.net.fc = nn.Linear(in_features, out_features+n)\n",
        "        self.net.fc.weight.data[:out_features] = weight\n",
        "    \n",
        "    def output_neurons_count(self):\n",
        "        \"\"\"Return the number of output neurons of the current network.\"\"\"\n",
        "\n",
        "        return self.net.fc.out_features\n",
        "    \n",
        "    def feature_neurons_count(self):\n",
        "        \"\"\"Return the number of neurons of the last layer of the feature extractor.\"\"\"\n",
        "\n",
        "        return self.net.fc.in_features\n",
        "    \n",
        "    def to_onehot(self, targets):\n",
        "        \"\"\"Convert targets to one-hot encoding (for BCE loss).\n",
        "\n",
        "        Args:\n",
        "            targets: dataloader.dataset.targets of the new task images\n",
        "        \"\"\"\n",
        "        num_classes = self.net.fc.out_features\n",
        "        one_hot_targets = torch.eye(num_classes)[targets]\n",
        "\n",
        "        return one_hot_targets.to(self.device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmCpRMBKgvDB",
        "colab_type": "text"
      },
      "source": [
        "### Execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nRU--zYjmZT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# iCaRL hyperparameters\n",
        "LR = 2\n",
        "MOMENTUM = 0.9\n",
        "WEIGHT_DECAY = 0.00001\n",
        "MILESTONES = [49, 63]\n",
        "GAMMA = 0.2\n",
        "NUM_EPOCHS = 70\n",
        "BATCH_SIZE = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mcTQUN7VLPF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2aa7d144-84df-4917-99a5-bc91f88b346f"
      },
      "source": [
        "\n",
        "\n",
        "# Define what tests to run\n",
        "TEST_ICARL = True # Run test with iCaRL (exemplars + train dataset)\n",
        "TEST_HYBRID1 = False # Run test with hybrid1\n",
        "\n",
        "# Initialize logs\n",
        "logs_icarl = [[] for _ in range(NUM_RUNS)]\n",
        "logs_icarl_rand = [[] for _ in range(NUM_RUNS)] # @DEBUG\n",
        "logs_hybrid1 = [[] for _ in range(NUM_RUNS)]\n",
        "logs_analisys = [[] for _ in range(NUM_RUNS)]\n",
        "logs_analisys_split = [dict() for _ in range(NUM_RUNS)]\n",
        "\n",
        "for run_i in range(NUM_RUNS):\n",
        "    net = resnet32()\n",
        "    icarl = iCaRL(DEVICE, net, LR, MOMENTUM, WEIGHT_DECAY, MILESTONES, GAMMA, NUM_EPOCHS, BATCH_SIZE, train_transform, test_transform)\n",
        "\n",
        "    for split_i in range(10):\n",
        "        print(f\"## Split {split_i} of run {run_i} ##\")\n",
        "        \n",
        "        train_logs = icarl.incremental_train(split_i, train_subsets[run_i][split_i], val_subsets[run_i][split_i])\n",
        "\n",
        "        all_targets = torch.stack([label[0] for _, label in DataLoader(test_subsets[run_i][split_i])])\n",
        "\n",
        "        if TEST_ICARL:\n",
        "            logs_icarl[run_i].append({})\n",
        "            logs_icarl_rand[run_i].append({}) # @DEBUG\n",
        "              #  print(\"Herding:\")\n",
        "              #  acc, all_preds = icarl.test(test_subsets[run_i][split_i], train_subsets[run_i][split_i])\n",
        "           \n",
        "\n",
        "            print(\"Random:\") # @DEBUG\n",
        "            acc_rand, _ = icarl.test_rand(test_subsets[run_i][split_i], train_subsets[run_i][split_i]) # @DEBUG\n",
        "\n",
        "            logs_icarl_rand[run_i][split_i]['accuracy'] = acc_rand # @DEBUG\n",
        "\n",
        "            # if split_i > 0:\n",
        "            #   logs_analisys_split[run_i][split_i] = icarl.examined_exemplars_features[split_i]\n",
        "\n",
        "            # logs_icarl[run_i][split_i]['accuracy'] = acc\n",
        "            # logs_icarl[run_i][split_i]['conf_mat'] = confusion_matrix(all_targets.to('cpu'), all_preds.to('cpu'))\n",
        "\n",
        "            logs_icarl[run_i][split_i]['train_loss'] = train_logs[0]\n",
        "            logs_icarl[run_i][split_i]['train_accuracy'] = train_logs[1]\n",
        "            logs_icarl[run_i][split_i]['val_loss'] = train_logs[2]\n",
        "            logs_icarl[run_i][split_i]['val_accuracy'] = train_logs[3]\n",
        "\n",
        "        if TEST_HYBRID1:\n",
        "            logs_hybrid1[run_i].append({})\n",
        "\n",
        "            acc, all_preds = icarl.test_without_classifier(test_subsets[run_i][split_i])\n",
        "\n",
        "            logs_hybrid1[run_i][split_i]['accuracy'] = acc\n",
        "\n",
        "    # logs_analisys[run_i] = icarl.examined_exemplars_features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "## Split 0 of run 0 ##\n",
            "Length of exemplars set: 0\n",
            "Epoch: 1, LR: [2]\n",
            "Train loss: 0.37516499970640454, Train accuracy: 0.11584821428571429\n",
            "Validation loss: 0.3228461061205183, Validation accuracy: 0.09598214285714286\n",
            "Epoch: 2, LR: [2]\n",
            "Train loss: 0.32389820643833706, Train accuracy: 0.11830357142857142\n",
            "Validation loss: 0.3224814363888332, Validation accuracy: 0.14285714285714285\n",
            "Epoch: 3, LR: [2]\n",
            "Train loss: 0.323296018583434, Train accuracy: 0.11629464285714286\n",
            "Validation loss: 0.3191903957298824, Validation accuracy: 0.15178571428571427\n",
            "Epoch: 4, LR: [2]\n",
            "Train loss: 0.31907734530312676, Train accuracy: 0.13392857142857142\n",
            "Validation loss: 0.3145141048090799, Validation accuracy: 0.19196428571428573\n",
            "Epoch: 5, LR: [2]\n",
            "Train loss: 0.3176531323364803, Train accuracy: 0.14910714285714285\n",
            "Validation loss: 0.3095556029251644, Validation accuracy: 0.15401785714285715\n",
            "Epoch: 6, LR: [2]\n",
            "Train loss: 0.3162459407533918, Train accuracy: 0.15200892857142856\n",
            "Validation loss: 0.3134803218500955, Validation accuracy: 0.15848214285714285\n",
            "Epoch: 7, LR: [2]\n",
            "Train loss: 0.313584218280656, Train accuracy: 0.1747767857142857\n",
            "Validation loss: 0.31011284249169485, Validation accuracy: 0.22767857142857142\n",
            "Epoch: 8, LR: [2]\n",
            "Train loss: 0.3116292425564357, Train accuracy: 0.1859375\n",
            "Validation loss: 0.3126887721674783, Validation accuracy: 0.20758928571428573\n",
            "Epoch: 9, LR: [2]\n",
            "Train loss: 0.3029868768794196, Train accuracy: 0.2328125\n",
            "Validation loss: 0.30056269254003254, Validation accuracy: 0.265625\n",
            "Epoch: 10, LR: [2]\n",
            "Train loss: 0.28995222577026913, Train accuracy: 0.2825892857142857\n",
            "Validation loss: 0.32134588275636944, Validation accuracy: 0.2611607142857143\n",
            "Epoch: 11, LR: [2]\n",
            "Train loss: 0.28321346172264644, Train accuracy: 0.31138392857142855\n",
            "Validation loss: 0.2922535070351192, Validation accuracy: 0.2857142857142857\n",
            "Epoch: 12, LR: [2]\n",
            "Train loss: 0.27160652961049764, Train accuracy: 0.3600446428571429\n",
            "Validation loss: 0.2785776810986655, Validation accuracy: 0.3080357142857143\n",
            "Epoch: 13, LR: [2]\n",
            "Train loss: 0.2597183012536594, Train accuracy: 0.4095982142857143\n",
            "Validation loss: 0.24036705493927002, Validation accuracy: 0.453125\n",
            "Epoch: 14, LR: [2]\n",
            "Train loss: 0.2476030198591096, Train accuracy: 0.45669642857142856\n",
            "Validation loss: 0.3314186632633209, Validation accuracy: 0.26339285714285715\n",
            "Epoch: 15, LR: [2]\n",
            "Train loss: 0.2282696076801845, Train accuracy: 0.4941964285714286\n",
            "Validation loss: 0.23064861127308436, Validation accuracy: 0.4799107142857143\n",
            "Epoch: 16, LR: [2]\n",
            "Train loss: 0.21223024470465524, Train accuracy: 0.5484375\n",
            "Validation loss: 0.21156384263719832, Validation accuracy: 0.5290178571428571\n",
            "Epoch: 17, LR: [2]\n",
            "Train loss: 0.20317624977656773, Train accuracy: 0.5709821428571429\n",
            "Validation loss: 0.20662072513784682, Validation accuracy: 0.546875\n",
            "Epoch: 18, LR: [2]\n",
            "Train loss: 0.19050679526158742, Train accuracy: 0.6015625\n",
            "Validation loss: 0.18490036683423178, Validation accuracy: 0.6026785714285714\n",
            "Epoch: 19, LR: [2]\n",
            "Train loss: 0.18247002086469105, Train accuracy: 0.61875\n",
            "Validation loss: 0.18213325526033128, Validation accuracy: 0.6316964285714286\n",
            "Epoch: 20, LR: [2]\n",
            "Train loss: 0.17274917417338917, Train accuracy: 0.6410714285714286\n",
            "Validation loss: 0.18055772994245803, Validation accuracy: 0.6316964285714286\n",
            "Epoch: 21, LR: [2]\n",
            "Train loss: 0.16285710952111654, Train accuracy: 0.6642857142857143\n",
            "Validation loss: 0.15943838868822371, Validation accuracy: 0.6651785714285714\n",
            "Epoch: 22, LR: [2]\n",
            "Train loss: 0.1571683102420398, Train accuracy: 0.6852678571428571\n",
            "Validation loss: 0.18663201800414495, Validation accuracy: 0.609375\n",
            "Epoch: 23, LR: [2]\n",
            "Train loss: 0.14911574774554798, Train accuracy: 0.7033482142857143\n",
            "Validation loss: 0.1620400164808546, Validation accuracy: 0.6852678571428571\n",
            "Epoch: 24, LR: [2]\n",
            "Train loss: 0.14354488253593445, Train accuracy: 0.7131696428571429\n",
            "Validation loss: 0.16871483836855208, Validation accuracy: 0.6919642857142857\n",
            "Epoch: 25, LR: [2]\n",
            "Train loss: 0.13821180696998323, Train accuracy: 0.7292410714285714\n",
            "Validation loss: 0.15674257384879248, Validation accuracy: 0.7120535714285714\n",
            "Epoch: 26, LR: [2]\n",
            "Train loss: 0.13497799092105456, Train accuracy: 0.7388392857142857\n",
            "Validation loss: 0.13631085732153483, Validation accuracy: 0.7455357142857143\n",
            "Epoch: 27, LR: [2]\n",
            "Train loss: 0.1258296761661768, Train accuracy: 0.7627232142857143\n",
            "Validation loss: 0.1317538619041443, Validation accuracy: 0.7142857142857143\n",
            "Epoch: 28, LR: [2]\n",
            "Train loss: 0.1217840878026826, Train accuracy: 0.7625\n",
            "Validation loss: 0.15423021678413665, Validation accuracy: 0.6964285714285714\n",
            "Epoch: 29, LR: [2]\n",
            "Train loss: 0.12062264372195516, Train accuracy: 0.7674107142857143\n",
            "Validation loss: 0.19418229162693024, Validation accuracy: 0.625\n",
            "Epoch: 30, LR: [2]\n",
            "Train loss: 0.1125980899802276, Train accuracy: 0.78125\n",
            "Validation loss: 0.11999442215476717, Validation accuracy: 0.78125\n",
            "Epoch: 31, LR: [2]\n",
            "Train loss: 0.10780539427484785, Train accuracy: 0.790625\n",
            "Validation loss: 0.12026592876229968, Validation accuracy: 0.765625\n",
            "Epoch: 32, LR: [2]\n",
            "Train loss: 0.10251104874270303, Train accuracy: 0.8058035714285714\n",
            "Validation loss: 0.1571712749344962, Validation accuracy: 0.703125\n",
            "Epoch: 33, LR: [2]\n",
            "Train loss: 0.10587359251720564, Train accuracy: 0.7977678571428571\n",
            "Validation loss: 0.1104563804609435, Validation accuracy: 0.78125\n",
            "Epoch: 34, LR: [2]\n",
            "Train loss: 0.09736574238964489, Train accuracy: 0.8180803571428571\n",
            "Validation loss: 0.1028616332582065, Validation accuracy: 0.8013392857142857\n",
            "Epoch: 35, LR: [2]\n",
            "Train loss: 0.09528173921363695, Train accuracy: 0.8191964285714286\n",
            "Validation loss: 0.13122173505170004, Validation accuracy: 0.7544642857142857\n",
            "Epoch: 36, LR: [2]\n",
            "Train loss: 0.09454113819769451, Train accuracy: 0.8229910714285714\n",
            "Validation loss: 0.12756884204489843, Validation accuracy: 0.7700892857142857\n",
            "Epoch: 37, LR: [2]\n",
            "Train loss: 0.08714977582650525, Train accuracy: 0.8345982142857142\n",
            "Validation loss: 0.0937754288315773, Validation accuracy: 0.8236607142857143\n",
            "Epoch: 38, LR: [2]\n",
            "Train loss: 0.08142701467233045, Train accuracy: 0.8482142857142857\n",
            "Validation loss: 0.1408607949103628, Validation accuracy: 0.7611607142857143\n",
            "Epoch: 39, LR: [2]\n",
            "Train loss: 0.0861359076840537, Train accuracy: 0.8419642857142857\n",
            "Validation loss: 0.11648213118314743, Validation accuracy: 0.796875\n",
            "Epoch: 40, LR: [2]\n",
            "Train loss: 0.07667789906263352, Train accuracy: 0.8573660714285715\n",
            "Validation loss: 0.11086850932666234, Validation accuracy: 0.7879464285714286\n",
            "Epoch: 41, LR: [2]\n",
            "Train loss: 0.08162181036812918, Train accuracy: 0.8462053571428572\n",
            "Validation loss: 0.10612726105110985, Validation accuracy: 0.8125\n",
            "Epoch: 42, LR: [2]\n",
            "Train loss: 0.07807157156722887, Train accuracy: 0.8526785714285714\n",
            "Validation loss: 0.08842432871460915, Validation accuracy: 0.8325892857142857\n",
            "Epoch: 43, LR: [2]\n",
            "Train loss: 0.07085749214248997, Train accuracy: 0.8738839285714286\n",
            "Validation loss: 0.10082811117172241, Validation accuracy: 0.8125\n",
            "Epoch: 44, LR: [2]\n",
            "Train loss: 0.06807994672230312, Train accuracy: 0.8745535714285714\n",
            "Validation loss: 0.09005192773682731, Validation accuracy: 0.828125\n",
            "Epoch: 45, LR: [2]\n",
            "Train loss: 0.06604740396142006, Train accuracy: 0.8792410714285714\n",
            "Validation loss: 0.08540597770895277, Validation accuracy: 0.8571428571428571\n",
            "Epoch: 46, LR: [2]\n",
            "Train loss: 0.06635711906211716, Train accuracy: 0.8772321428571429\n",
            "Validation loss: 0.09601228258439473, Validation accuracy: 0.828125\n",
            "Epoch: 47, LR: [2]\n",
            "Train loss: 0.06763813091175896, Train accuracy: 0.8770089285714285\n",
            "Validation loss: 0.09470457849758011, Validation accuracy: 0.8415178571428571\n",
            "Epoch: 48, LR: [2]\n",
            "Train loss: 0.0681546999407666, Train accuracy: 0.8785714285714286\n",
            "Validation loss: 0.08979474327393941, Validation accuracy: 0.8705357142857143\n",
            "Epoch: 49, LR: [2]\n",
            "Train loss: 0.05938103161752224, Train accuracy: 0.8948660714285714\n",
            "Validation loss: 0.0907491317817143, Validation accuracy: 0.8370535714285714\n",
            "Epoch: 50, LR: [0.4]\n",
            "Train loss: 0.04254690081413303, Train accuracy: 0.9294642857142857\n",
            "Validation loss: 0.05268422381154129, Validation accuracy: 0.90625\n",
            "Epoch: 51, LR: [0.4]\n",
            "Train loss: 0.03443207935030971, Train accuracy: 0.9473214285714285\n",
            "Validation loss: 0.05819733680358955, Validation accuracy: 0.8973214285714286\n",
            "Epoch: 52, LR: [0.4]\n",
            "Train loss: 0.03341224611337696, Train accuracy: 0.9470982142857143\n",
            "Validation loss: 0.06200176743524415, Validation accuracy: 0.8973214285714286\n",
            "Epoch: 53, LR: [0.4]\n",
            "Train loss: 0.028970751339303595, Train accuracy: 0.9560267857142857\n",
            "Validation loss: 0.050857545009681156, Validation accuracy: 0.9196428571428571\n",
            "Epoch: 54, LR: [0.4]\n",
            "Train loss: 0.025209430365690164, Train accuracy: 0.9602678571428571\n",
            "Validation loss: 0.060812106622116904, Validation accuracy: 0.8928571428571429\n",
            "Epoch: 55, LR: [0.4]\n",
            "Train loss: 0.024708196953205124, Train accuracy: 0.9602678571428571\n",
            "Validation loss: 0.049146052449941635, Validation accuracy: 0.9151785714285714\n",
            "Epoch: 56, LR: [0.4]\n",
            "Train loss: 0.024745934390063798, Train accuracy: 0.9622767857142858\n",
            "Validation loss: 0.0486060016389404, Validation accuracy: 0.921875\n",
            "Epoch: 57, LR: [0.4]\n",
            "Train loss: 0.023474258317479065, Train accuracy: 0.9609375\n",
            "Validation loss: 0.06463130457060677, Validation accuracy: 0.8973214285714286\n",
            "Epoch: 58, LR: [0.4]\n",
            "Train loss: 0.022846295232219354, Train accuracy: 0.9649553571428572\n",
            "Validation loss: 0.06420994097633022, Validation accuracy: 0.9017857142857143\n",
            "Epoch: 59, LR: [0.4]\n",
            "Train loss: 0.021723106849406447, Train accuracy: 0.965625\n",
            "Validation loss: 0.06407323160341807, Validation accuracy: 0.8883928571428571\n",
            "Epoch: 60, LR: [0.4]\n",
            "Train loss: 0.0204091794123607, Train accuracy: 0.9696428571428571\n",
            "Validation loss: 0.05049727378146989, Validation accuracy: 0.9129464285714286\n",
            "Epoch: 61, LR: [0.4]\n",
            "Train loss: 0.020002509992835777, Train accuracy: 0.9700892857142858\n",
            "Validation loss: 0.06169678909437997, Validation accuracy: 0.9040178571428571\n",
            "Epoch: 62, LR: [0.4]\n",
            "Train loss: 0.01973086345408644, Train accuracy: 0.9700892857142858\n",
            "Validation loss: 0.05886651442519256, Validation accuracy: 0.9040178571428571\n",
            "Epoch: 63, LR: [0.4]\n",
            "Train loss: 0.018902593955863266, Train accuracy: 0.9703125\n",
            "Validation loss: 0.05632222284163747, Validation accuracy: 0.9040178571428571\n",
            "Epoch: 64, LR: [0.08000000000000002]\n",
            "Train loss: 0.015581177880189248, Train accuracy: 0.9763392857142857\n",
            "Validation loss: 0.049719538273555894, Validation accuracy: 0.9107142857142857\n",
            "Epoch: 65, LR: [0.08000000000000002]\n",
            "Train loss: 0.013558386153142367, Train accuracy: 0.9823660714285715\n",
            "Validation loss: 0.049155945756605694, Validation accuracy: 0.9151785714285714\n",
            "Epoch: 66, LR: [0.08000000000000002]\n",
            "Train loss: 0.013945870909706823, Train accuracy: 0.9794642857142857\n",
            "Validation loss: 0.05507692348744188, Validation accuracy: 0.9084821428571429\n",
            "Epoch: 67, LR: [0.08000000000000002]\n",
            "Train loss: 0.01460886711387762, Train accuracy: 0.98125\n",
            "Validation loss: 0.0502674574298518, Validation accuracy: 0.9129464285714286\n",
            "Epoch: 68, LR: [0.08000000000000002]\n",
            "Train loss: 0.012952418399176427, Train accuracy: 0.9834821428571429\n",
            "Validation loss: 0.05172166680651052, Validation accuracy: 0.9151785714285714\n",
            "Epoch: 69, LR: [0.08000000000000002]\n",
            "Train loss: 0.011875194018440588, Train accuracy: 0.9841517857142857\n",
            "Validation loss: 0.05837683592523847, Validation accuracy: 0.9151785714285714\n",
            "Epoch: 70, LR: [0.08000000000000002]\n",
            "Train loss: 0.01233941333900605, Train accuracy: 0.9837053571428571\n",
            "Validation loss: 0.058807886338659694, Validation accuracy: 0.9084821428571429\n",
            "Target number of exemplars per class: 200\n",
            "Target total number of exemplars: 2000\n",
            "Extracting exemplars from class 0 of current split... Extracted 200 exemplars.\n",
            "Saved 10 exemplars for features analysis\n",
            "Extracting exemplars from class 1 of current split... Extracted 200 exemplars.\n",
            "Extracting exemplars from class 2 of current split... Extracted 200 exemplars.\n",
            "Extracting exemplars from class 3 of current split... Extracted 200 exemplars.\n",
            "Extracting exemplars from class 4 of current split... Extracted 200 exemplars.\n",
            "Extracting exemplars from class 5 of current split... Extracted 200 exemplars.\n",
            "Extracting exemplars from class 6 of current split... Extracted 200 exemplars.\n",
            "Extracting exemplars from class 7 of current split... Extracted 200 exemplars.\n",
            "Extracting exemplars from class 8 of current split... Extracted 200 exemplars.\n",
            "Extracting exemplars from class 9 of current split... Extracted 200 exemplars.\n",
            "Randomly extracting exemplars from class 0 of current split... Extracted 200 exemplars.\n",
            "Randomly extracting exemplars from class 1 of current split... Extracted 200 exemplars.\n",
            "Randomly extracting exemplars from class 2 of current split... Extracted 200 exemplars.\n",
            "Randomly extracting exemplars from class 3 of current split... Extracted 200 exemplars.\n",
            "Randomly extracting exemplars from class 4 of current split... Extracted 200 exemplars.\n",
            "Randomly extracting exemplars from class 5 of current split... Extracted 200 exemplars.\n",
            "Randomly extracting exemplars from class 6 of current split... Extracted 200 exemplars.\n",
            "Randomly extracting exemplars from class 7 of current split... Extracted 200 exemplars.\n",
            "Randomly extracting exemplars from class 8 of current split... Extracted 200 exemplars.\n",
            "Randomly extracting exemplars from class 9 of current split... Extracted 200 exemplars.\n",
            "Random:\n",
            "Computing mean of exemplars... done\n",
            "Test accuracy (iCaRL): 0.888 (exemplars and training data)\n",
            "## Split 1 of run 0 ##\n",
            "Length of exemplars set: 2000\n",
            "Epoch: 1, LR: [2]\n",
            "Train loss: 0.15700153755669546, Train accuracy: 0.3310643564356436\n",
            "Validation loss: 0.22817089089325496, Validation accuracy: 0.11383928571428571\n",
            "Epoch: 2, LR: [2]\n",
            "Train loss: 0.12453023145104399, Train accuracy: 0.4368811881188119\n",
            "Validation loss: 0.18830807081290654, Validation accuracy: 0.26339285714285715\n",
            "Epoch: 3, LR: [2]\n",
            "Train loss: 0.11439779954086436, Train accuracy: 0.510519801980198\n",
            "Validation loss: 0.1878391525575093, Validation accuracy: 0.2857142857142857\n",
            "Epoch: 4, LR: [2]\n",
            "Train loss: 0.10678474332141404, Train accuracy: 0.562809405940594\n",
            "Validation loss: 0.17731202287333353, Validation accuracy: 0.36160714285714285\n",
            "Epoch: 5, LR: [2]\n",
            "Train loss: 0.10279858554943953, Train accuracy: 0.5909653465346535\n",
            "Validation loss: 0.18302969208785466, Validation accuracy: 0.4017857142857143\n",
            "Epoch: 6, LR: [2]\n",
            "Train loss: 0.10014100896544975, Train accuracy: 0.6183477722772277\n",
            "Validation loss: 0.17518837111336844, Validation accuracy: 0.4263392857142857\n",
            "Epoch: 7, LR: [2]\n",
            "Train loss: 0.09639363492479419, Train accuracy: 0.6448019801980198\n",
            "Validation loss: 0.15770259925297328, Validation accuracy: 0.47544642857142855\n",
            "Epoch: 8, LR: [2]\n",
            "Train loss: 0.09243087182835777, Train accuracy: 0.6649133663366337\n",
            "Validation loss: 0.16234107315540314, Validation accuracy: 0.5044642857142857\n",
            "Epoch: 9, LR: [2]\n",
            "Train loss: 0.09068399977565993, Train accuracy: 0.6811571782178217\n",
            "Validation loss: 0.16371831936495645, Validation accuracy: 0.5\n",
            "Epoch: 10, LR: [2]\n",
            "Train loss: 0.09138273890360747, Train accuracy: 0.6806930693069307\n",
            "Validation loss: 0.1676337080342429, Validation accuracy: 0.5223214285714286\n",
            "Epoch: 11, LR: [2]\n",
            "Train loss: 0.08583834302602428, Train accuracy: 0.7046720297029703\n",
            "Validation loss: 0.17501544952392578, Validation accuracy: 0.47544642857142855\n",
            "Epoch: 12, LR: [2]\n",
            "Train loss: 0.08594068062334957, Train accuracy: 0.708230198019802\n",
            "Validation loss: 0.16221262088843755, Validation accuracy: 0.5223214285714286\n",
            "Epoch: 13, LR: [2]\n",
            "Train loss: 0.08652621640427278, Train accuracy: 0.7161200495049505\n",
            "Validation loss: 0.17946480001722062, Validation accuracy: 0.4799107142857143\n",
            "Epoch: 14, LR: [2]\n",
            "Train loss: 0.0846152519530589, Train accuracy: 0.7249381188118812\n",
            "Validation loss: 0.16521317405360086, Validation accuracy: 0.5915178571428571\n",
            "Epoch: 15, LR: [2]\n",
            "Train loss: 0.08275072180693692, Train accuracy: 0.7315903465346535\n",
            "Validation loss: 0.15126768818923406, Validation accuracy: 0.5669642857142857\n",
            "Epoch: 16, LR: [2]\n",
            "Train loss: 0.08119134450017816, Train accuracy: 0.7425742574257426\n",
            "Validation loss: 0.1630502130304064, Validation accuracy: 0.5625\n",
            "Epoch: 17, LR: [2]\n",
            "Train loss: 0.08201523737447096, Train accuracy: 0.7467512376237624\n",
            "Validation loss: 0.15742541210991995, Validation accuracy: 0.5558035714285714\n",
            "Epoch: 18, LR: [2]\n",
            "Train loss: 0.08037671461553857, Train accuracy: 0.7523205445544554\n",
            "Validation loss: 0.16238523168223246, Validation accuracy: 0.546875\n",
            "Epoch: 19, LR: [2]\n",
            "Train loss: 0.07887052040141408, Train accuracy: 0.7585086633663366\n",
            "Validation loss: 0.1615117085831506, Validation accuracy: 0.5870535714285714\n",
            "Epoch: 20, LR: [2]\n",
            "Train loss: 0.07986532653322315, Train accuracy: 0.7602103960396039\n",
            "Validation loss: 0.1550618771995817, Validation accuracy: 0.578125\n",
            "Epoch: 21, LR: [2]\n",
            "Train loss: 0.07741495848882317, Train accuracy: 0.7634591584158416\n",
            "Validation loss: 0.17380192875862122, Validation accuracy: 0.5424107142857143\n",
            "Epoch: 22, LR: [2]\n",
            "Train loss: 0.07721429141146122, Train accuracy: 0.7721225247524752\n",
            "Validation loss: 0.14626815489360265, Validation accuracy: 0.6183035714285714\n",
            "Epoch: 23, LR: [2]\n",
            "Train loss: 0.07610784353006005, Train accuracy: 0.7797029702970297\n",
            "Validation loss: 0.1610531998532159, Validation accuracy: 0.5803571428571429\n",
            "Epoch: 24, LR: [2]\n",
            "Train loss: 0.07607365827454199, Train accuracy: 0.7800123762376238\n",
            "Validation loss: 0.1564639380999974, Validation accuracy: 0.5982142857142857\n",
            "Epoch: 25, LR: [2]\n",
            "Train loss: 0.07419293584062321, Train accuracy: 0.7928527227722773\n",
            "Validation loss: 0.17486385362488882, Validation accuracy: 0.5111607142857143\n",
            "Epoch: 26, LR: [2]\n",
            "Train loss: 0.07368013063574781, Train accuracy: 0.7962561881188119\n",
            "Validation loss: 0.16189623730523245, Validation accuracy: 0.6026785714285714\n",
            "Epoch: 27, LR: [2]\n",
            "Train loss: 0.07449565134426155, Train accuracy: 0.7930074257425742\n",
            "Validation loss: 0.16638818170343125, Validation accuracy: 0.578125\n",
            "Epoch: 28, LR: [2]\n",
            "Train loss: 0.07204594156972252, Train accuracy: 0.8044554455445545\n",
            "Validation loss: 0.15813427524907248, Validation accuracy: 0.5959821428571429\n",
            "Epoch: 29, LR: [2]\n",
            "Train loss: 0.07403248530065659, Train accuracy: 0.7937809405940595\n",
            "Validation loss: 0.13607555414949143, Validation accuracy: 0.6160714285714286\n",
            "Epoch: 30, LR: [2]\n",
            "Train loss: 0.07247363252214867, Train accuracy: 0.8030631188118812\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-3e0ef86b6d55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"## Split {split_i} of run {run_i} ##\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mtrain_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0micarl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mincremental_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_subsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrun_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_subsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrun_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mall_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_subsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrun_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-a6d269b7c03c>\u001b[0m in \u001b[0;36mincremental_train\u001b[0;34m(self, split, train_dataset, val_dataset)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;31m# Improve network parameters upon receiving new classes. Effectively\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;31m# train a new network starting from the current network parameters.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m         \u001b[0mtrain_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_representation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0;31m# Compute the number of exemplars per class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-a6d269b7c03c>\u001b[0m in \u001b[0;36mupdate_representation\u001b[0;34m(self, train_dataset, val_dataset)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Train the network on combined dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtrain_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset_with_exemplars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# @todo: include exemplars in validation set?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;31m# Keep a copy of the current network in order to compute its outputs for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-a6d269b7c03c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataset, val_dataset)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;31m# Validate after each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m             \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;31m# Validation criterion: best net is the one that minimizes the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-a6d269b7c03c>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0mbatch_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    828\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m                 \u001b[0;31m# no valid `self._rcvd_idx` is found (i.e., didn't break)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 830\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown_workers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    831\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_shutdown_workers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    939\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworker_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m                     \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m                     \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancel_join_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/process.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a child process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     48\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;31m# This shouldn't block if wait() returned successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWNOHANG\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                     \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                     \u001b[0;31m# Child process not yet created. See #1731717\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuDM6Ydokv05",
        "colab_type": "text"
      },
      "source": [
        "### Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3LN94fQfozr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "debc1c88-50a2-4dc9-9c40-ea20f5973d3d"
      },
      "source": [
        "logs_analisys"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{1: [tensor([[1.0000e+00, 1.5512e-07, 2.7733e-09, 9.1395e-06, 5.4964e-08, 4.7753e-09,\n",
              "            5.9064e-09, 4.2234e-09, 4.2606e-07, 3.8278e-06],\n",
              "           [1.0000e+00, 4.7220e-09, 1.7920e-10, 7.7666e-08, 1.7943e-09, 5.6214e-12,\n",
              "            6.7881e-10, 2.7197e-12, 4.2738e-08, 3.3349e-08],\n",
              "           [1.0000e+00, 1.9654e-11, 3.7885e-14, 2.2945e-07, 5.6073e-10, 5.4636e-13,\n",
              "            4.6445e-11, 4.8380e-11, 2.7386e-08, 5.7785e-09],\n",
              "           [1.0000e+00, 1.5525e-08, 1.0396e-08, 1.9264e-07, 2.1828e-09, 1.2135e-09,\n",
              "            3.1585e-08, 5.8995e-10, 9.9534e-09, 3.5256e-08],\n",
              "           [1.0000e+00, 1.2908e-08, 3.4542e-07, 6.1864e-07, 1.2921e-08, 3.1958e-09,\n",
              "            9.4153e-08, 3.6375e-09, 3.7195e-08, 9.2690e-09],\n",
              "           [1.0000e+00, 2.9726e-09, 7.0455e-11, 1.8400e-07, 2.3927e-09, 3.2849e-11,\n",
              "            2.6100e-10, 7.3590e-12, 4.3375e-09, 6.4679e-08],\n",
              "           [1.0000e+00, 4.0591e-10, 6.5797e-08, 4.2255e-09, 1.5108e-09, 1.3463e-12,\n",
              "            2.2160e-10, 1.0328e-14, 2.1021e-10, 2.1925e-08],\n",
              "           [1.0000e+00, 1.2241e-08, 8.1332e-12, 8.7271e-08, 1.8324e-09, 4.0020e-12,\n",
              "            2.0444e-09, 1.9574e-11, 2.4395e-08, 6.1851e-08],\n",
              "           [9.9966e-01, 1.5357e-06, 2.1753e-07, 2.3316e-04, 2.5847e-04, 2.5666e-07,\n",
              "            2.7809e-07, 2.5095e-08, 1.7301e-05, 1.5338e-04],\n",
              "           [1.0000e+00, 4.6669e-08, 5.4749e-09, 1.4178e-06, 4.1075e-08, 8.7116e-11,\n",
              "            1.5250e-09, 1.8640e-12, 2.8481e-07, 1.2294e-07]], device='cuda:0',\n",
              "          grad_fn=<SigmoidBackward>),\n",
              "   tensor([[1.0000e+00, 1.5512e-07, 2.7733e-09, 9.1395e-06, 5.4964e-08, 4.7753e-09,\n",
              "            5.9064e-09, 4.2234e-09, 4.2606e-07, 3.8278e-06],\n",
              "           [1.0000e+00, 4.7220e-09, 1.7920e-10, 7.7666e-08, 1.7943e-09, 5.6214e-12,\n",
              "            6.7881e-10, 2.7197e-12, 4.2738e-08, 3.3349e-08],\n",
              "           [1.0000e+00, 1.9654e-11, 3.7885e-14, 2.2945e-07, 5.6073e-10, 5.4636e-13,\n",
              "            4.6445e-11, 4.8380e-11, 2.7386e-08, 5.7785e-09],\n",
              "           [1.0000e+00, 1.5525e-08, 1.0396e-08, 1.9264e-07, 2.1828e-09, 1.2135e-09,\n",
              "            3.1585e-08, 5.8995e-10, 9.9534e-09, 3.5256e-08],\n",
              "           [1.0000e+00, 1.2908e-08, 3.4542e-07, 6.1864e-07, 1.2921e-08, 3.1958e-09,\n",
              "            9.4153e-08, 3.6375e-09, 3.7195e-08, 9.2690e-09],\n",
              "           [1.0000e+00, 2.9726e-09, 7.0455e-11, 1.8400e-07, 2.3927e-09, 3.2849e-11,\n",
              "            2.6100e-10, 7.3590e-12, 4.3375e-09, 6.4679e-08],\n",
              "           [1.0000e+00, 4.0591e-10, 6.5797e-08, 4.2255e-09, 1.5108e-09, 1.3463e-12,\n",
              "            2.2160e-10, 1.0328e-14, 2.1021e-10, 2.1925e-08],\n",
              "           [1.0000e+00, 1.2241e-08, 8.1332e-12, 8.7271e-08, 1.8324e-09, 4.0020e-12,\n",
              "            2.0444e-09, 1.9574e-11, 2.4395e-08, 6.1851e-08],\n",
              "           [9.9966e-01, 1.5357e-06, 2.1753e-07, 2.3316e-04, 2.5847e-04, 2.5666e-07,\n",
              "            2.7809e-07, 2.5095e-08, 1.7301e-05, 1.5338e-04],\n",
              "           [1.0000e+00, 4.6669e-08, 5.4749e-09, 1.4178e-06, 4.1075e-08, 8.7116e-11,\n",
              "            1.5250e-09, 1.8640e-12, 2.8481e-07, 1.2294e-07]], device='cuda:0',\n",
              "          grad_fn=<SigmoidBackward>)],\n",
              "  2: [tensor([[9.9904e-01, 6.1108e-06, 7.6811e-07, 2.6569e-05, 1.1443e-06, 2.8027e-07,\n",
              "            4.8393e-06, 1.3142e-05, 1.1733e-04, 8.9212e-03, 3.6623e-06, 7.4250e-08,\n",
              "            1.1871e-07, 1.9095e-04, 1.2327e-08, 1.9918e-08, 4.5079e-09, 4.7653e-10,\n",
              "            1.1713e-07, 1.6491e-05],\n",
              "           [9.9999e-01, 1.8378e-07, 7.4163e-07, 1.6811e-06, 1.6994e-07, 4.5483e-09,\n",
              "            3.4043e-07, 1.5851e-07, 1.9727e-05, 9.2757e-06, 6.6584e-07, 2.2817e-08,\n",
              "            2.6848e-09, 1.3572e-07, 1.5413e-09, 6.3152e-09, 2.3346e-09, 7.8178e-13,\n",
              "            2.7959e-08, 7.2424e-08],\n",
              "           [9.9898e-01, 4.3246e-06, 1.3550e-06, 1.1471e-04, 8.7652e-05, 1.4895e-07,\n",
              "            5.0754e-05, 1.2141e-05, 8.1777e-05, 7.4493e-04, 1.1550e-06, 9.8130e-08,\n",
              "            2.3800e-05, 5.2410e-05, 9.3319e-07, 1.1695e-06, 1.6644e-08, 2.6441e-09,\n",
              "            2.6572e-07, 8.8477e-07],\n",
              "           [9.9961e-01, 1.0428e-05, 8.3710e-05, 3.3551e-05, 3.0381e-05, 1.2643e-06,\n",
              "            9.1982e-05, 9.8438e-05, 4.0849e-04, 3.7268e-04, 5.6644e-04, 1.6377e-06,\n",
              "            5.8960e-07, 1.1287e-03, 9.4880e-07, 1.4330e-07, 3.2545e-07, 8.1160e-09,\n",
              "            4.1411e-04, 3.4461e-04],\n",
              "           [9.9996e-01, 2.2000e-06, 1.7469e-04, 2.3958e-06, 2.0135e-06, 1.6926e-07,\n",
              "            5.6029e-06, 1.3688e-05, 3.3362e-05, 2.5196e-05, 6.1075e-06, 2.9075e-08,\n",
              "            4.8573e-08, 1.7029e-09, 1.2466e-08, 3.0845e-08, 9.7068e-07, 4.9751e-08,\n",
              "            8.6962e-05, 3.1717e-06],\n",
              "           [9.9990e-01, 2.8315e-06, 8.2047e-06, 2.3720e-05, 8.9772e-06, 7.9908e-07,\n",
              "            3.9742e-06, 1.0073e-05, 1.5856e-05, 7.9337e-05, 3.4752e-06, 1.2206e-07,\n",
              "            1.1070e-07, 8.8884e-06, 3.8883e-07, 9.4539e-07, 4.7949e-07, 6.8461e-08,\n",
              "            2.9232e-07, 3.8337e-05],\n",
              "           [9.9971e-01, 1.1861e-05, 7.3742e-05, 2.3601e-04, 6.9816e-05, 2.4166e-06,\n",
              "            4.2156e-05, 2.7891e-06, 1.2529e-04, 1.3164e-04, 2.6155e-04, 5.5860e-06,\n",
              "            8.3533e-08, 1.0086e-05, 8.8398e-08, 3.6213e-08, 9.8903e-07, 1.4704e-07,\n",
              "            1.2090e-05, 2.8844e-06],\n",
              "           [9.9902e-01, 1.7233e-05, 5.6348e-05, 5.5970e-05, 2.8565e-04, 2.8437e-06,\n",
              "            1.5302e-05, 4.2305e-06, 2.2740e-04, 1.1709e-03, 1.3844e-05, 2.6668e-07,\n",
              "            7.4909e-06, 8.8376e-05, 2.5774e-05, 4.3247e-08, 1.6700e-08, 2.9542e-07,\n",
              "            3.0934e-06, 4.1988e-08],\n",
              "           [9.9983e-01, 8.1740e-06, 1.3645e-04, 2.3626e-05, 1.1034e-04, 4.2919e-07,\n",
              "            2.1350e-05, 2.0771e-06, 3.5675e-05, 1.4272e-04, 8.2387e-05, 5.9825e-06,\n",
              "            1.1562e-07, 6.9221e-06, 3.8257e-08, 5.4804e-07, 5.5636e-07, 1.4444e-10,\n",
              "            1.4953e-05, 1.2633e-06],\n",
              "           [9.9985e-01, 9.5231e-07, 1.1093e-06, 4.7206e-05, 1.4982e-05, 5.3036e-09,\n",
              "            1.4137e-05, 3.0088e-08, 2.5937e-06, 1.4501e-04, 1.0794e-08, 4.3337e-07,\n",
              "            7.9758e-10, 2.4959e-06, 6.6511e-11, 5.9032e-11, 4.0701e-09, 3.4270e-11,\n",
              "            8.0493e-07, 1.0403e-05]], device='cuda:0', grad_fn=<SigmoidBackward>),\n",
              "   tensor([[1.0000e+00, 4.0539e-07, 5.3036e-09, 2.3897e-06, 5.6445e-08, 5.8158e-09,\n",
              "            1.3008e-08, 7.9494e-09, 5.2112e-07, 8.4610e-06],\n",
              "           [1.0000e+00, 1.8461e-10, 2.1985e-12, 2.0374e-09, 7.6756e-11, 3.1285e-14,\n",
              "            1.8355e-11, 2.2137e-14, 1.4756e-09, 3.7414e-09],\n",
              "           [1.0000e+00, 3.1312e-09, 2.0415e-11, 2.1626e-06, 3.8640e-08, 1.1514e-10,\n",
              "            4.6784e-09, 2.8972e-09, 4.2748e-07, 2.7371e-07],\n",
              "           [1.0000e+00, 1.0963e-09, 7.6110e-10, 1.4282e-07, 4.7674e-10, 4.6220e-11,\n",
              "            2.1577e-09, 4.2405e-11, 1.1324e-07, 1.1012e-08],\n",
              "           [1.0000e+00, 5.6656e-10, 1.0182e-08, 2.3817e-08, 1.1296e-09, 6.0204e-11,\n",
              "            5.0308e-09, 1.1462e-10, 1.1088e-08, 4.8738e-09],\n",
              "           [1.0000e+00, 1.5873e-08, 2.0167e-09, 3.2493e-07, 2.1377e-09, 9.5178e-10,\n",
              "            2.7259e-09, 5.7873e-10, 9.1451e-09, 1.4482e-07],\n",
              "           [9.9995e-01, 9.2030e-07, 7.6245e-06, 1.2260e-06, 3.4697e-06, 1.0736e-08,\n",
              "            1.4169e-05, 2.7383e-09, 1.3860e-06, 6.8341e-06],\n",
              "           [1.0000e+00, 2.2978e-08, 1.5485e-10, 2.2725e-07, 7.4805e-10, 1.0605e-09,\n",
              "            2.3003e-09, 6.3426e-10, 5.8909e-07, 5.3563e-06],\n",
              "           [9.9998e-01, 1.5130e-06, 1.5883e-05, 8.6189e-07, 1.3249e-05, 1.8953e-08,\n",
              "            1.0330e-06, 9.7505e-10, 4.9172e-07, 3.2706e-06],\n",
              "           [1.0000e+00, 1.6511e-08, 9.0421e-10, 2.2618e-06, 4.1464e-08, 9.3147e-11,\n",
              "            4.8591e-10, 1.7294e-12, 3.3435e-08, 1.3159e-06]], device='cuda:0',\n",
              "          grad_fn=<SigmoidBackward>)],\n",
              "  3: [tensor([[9.9497e-01, 1.3670e-04, 6.2672e-05, 7.8652e-04, 8.8190e-05, 8.6947e-05,\n",
              "            1.3595e-04, 5.7186e-04, 3.1095e-03, 8.1867e-03, 1.2887e-02, 6.8811e-07,\n",
              "            1.8423e-04, 4.8562e-03, 2.5540e-05, 1.8609e-05, 3.3238e-05, 4.3052e-05,\n",
              "            1.1514e-05, 3.1777e-04, 2.4182e-06, 5.1525e-05, 3.5149e-07, 1.5444e-04,\n",
              "            1.8624e-03, 4.0914e-06, 1.2528e-04, 5.8105e-07, 8.3717e-07, 3.5384e-06],\n",
              "           [9.9926e-01, 1.9702e-05, 2.5127e-05, 9.2505e-05, 1.2716e-05, 2.4741e-06,\n",
              "            9.4557e-05, 2.4500e-05, 8.4409e-04, 6.4998e-04, 2.4969e-04, 2.4986e-06,\n",
              "            2.8274e-05, 9.7097e-05, 9.1761e-06, 2.8689e-04, 5.0013e-06, 1.6412e-07,\n",
              "            4.7498e-06, 1.4030e-04, 8.0608e-06, 2.1785e-05, 3.1336e-07, 1.0161e-06,\n",
              "            4.9465e-05, 1.9331e-07, 2.8468e-07, 1.1440e-07, 6.5992e-07, 6.3921e-07],\n",
              "           [9.9732e-01, 3.8367e-05, 1.5710e-05, 5.2855e-04, 2.7407e-04, 1.4189e-05,\n",
              "            3.4510e-04, 7.1055e-05, 6.2532e-04, 1.4013e-03, 9.6550e-05, 1.9125e-06,\n",
              "            9.0568e-05, 2.5789e-04, 2.8191e-04, 2.2703e-04, 1.1072e-05, 1.2632e-06,\n",
              "            4.7813e-05, 1.2004e-04, 5.0406e-05, 2.6994e-04, 2.1034e-07, 3.4974e-07,\n",
              "            6.2481e-06, 1.1822e-06, 8.0045e-07, 1.5527e-06, 8.4397e-07, 7.8099e-04],\n",
              "           [9.9991e-01, 9.4056e-06, 1.0654e-04, 1.6004e-05, 2.0681e-05, 3.1005e-06,\n",
              "            1.1372e-04, 2.9922e-05, 7.4122e-05, 1.3311e-04, 3.9588e-04, 1.8885e-07,\n",
              "            4.5795e-06, 5.9266e-05, 5.3764e-06, 3.8286e-06, 1.4571e-07, 8.0020e-07,\n",
              "            9.0456e-04, 3.4095e-04, 1.2139e-08, 4.8333e-05, 9.6611e-09, 7.9337e-06,\n",
              "            6.4256e-07, 1.8233e-07, 1.9338e-07, 2.3928e-08, 8.1668e-08, 1.6064e-10],\n",
              "           [9.9692e-01, 1.5815e-04, 2.5399e-03, 3.3636e-04, 6.9519e-05, 1.3867e-04,\n",
              "            1.0205e-03, 5.2695e-04, 9.6117e-04, 2.5466e-03, 7.4275e-04, 7.1466e-06,\n",
              "            6.9022e-05, 2.3228e-04, 2.5895e-05, 9.9411e-05, 1.9898e-04, 3.5482e-04,\n",
              "            4.5961e-04, 5.6532e-03, 4.4535e-05, 1.5114e-05, 4.2548e-06, 7.1443e-05,\n",
              "            6.5261e-05, 7.4741e-07, 2.5288e-05, 7.0361e-05, 5.9697e-07, 1.1101e-06],\n",
              "           [9.9972e-01, 2.3293e-05, 2.6264e-04, 5.0283e-05, 1.7808e-04, 4.4024e-05,\n",
              "            1.2901e-05, 7.1257e-05, 3.9415e-04, 7.6657e-04, 4.5464e-05, 1.5366e-06,\n",
              "            1.7035e-05, 3.8906e-05, 7.0340e-04, 1.0755e-03, 2.8262e-06, 1.3301e-05,\n",
              "            1.3366e-05, 3.8523e-04, 2.3048e-07, 2.6555e-03, 5.6095e-09, 1.3740e-08,\n",
              "            9.4972e-04, 1.4793e-06, 1.1411e-05, 6.2993e-07, 3.4391e-05, 6.9141e-09],\n",
              "           [9.9955e-01, 3.7735e-05, 6.2206e-04, 2.2252e-04, 4.2827e-05, 1.8215e-05,\n",
              "            1.9561e-04, 7.5382e-06, 1.2090e-04, 5.8907e-04, 1.6830e-04, 1.5263e-05,\n",
              "            2.7702e-05, 9.6200e-05, 1.3708e-06, 2.8780e-05, 5.4921e-06, 6.8853e-07,\n",
              "            5.8054e-05, 1.9539e-04, 1.8952e-08, 1.0535e-06, 6.7485e-07, 7.9980e-08,\n",
              "            1.2567e-06, 1.6740e-06, 5.9675e-07, 1.7051e-07, 3.8934e-05, 3.8763e-08],\n",
              "           [9.9865e-01, 2.2290e-04, 2.5009e-04, 3.2739e-04, 1.3660e-03, 7.6049e-05,\n",
              "            6.2460e-04, 6.8481e-05, 9.4228e-04, 4.6150e-03, 8.9465e-03, 3.4566e-06,\n",
              "            5.1222e-04, 1.4141e-04, 1.2064e-04, 1.5942e-04, 1.3034e-05, 9.7301e-04,\n",
              "            8.0239e-04, 2.7224e-06, 6.2506e-05, 3.8117e-05, 8.9434e-08, 1.2114e-06,\n",
              "            3.4772e-06, 2.2164e-05, 5.2218e-05, 1.0493e-04, 1.6241e-07, 1.3735e-06],\n",
              "           [9.9903e-01, 1.5231e-04, 1.6216e-04, 1.1899e-04, 5.9836e-04, 3.4135e-05,\n",
              "            8.2819e-05, 4.9766e-06, 9.4933e-05, 1.0512e-03, 1.1538e-04, 1.3711e-06,\n",
              "            8.0326e-06, 1.4810e-05, 8.9577e-06, 5.3398e-05, 6.6580e-05, 1.7708e-06,\n",
              "            1.8322e-04, 1.7642e-05, 6.8387e-07, 9.8164e-06, 1.3419e-08, 1.8031e-09,\n",
              "            3.8905e-06, 6.0016e-07, 3.9403e-07, 6.3632e-07, 1.1190e-08, 6.4758e-04],\n",
              "           [9.9679e-01, 7.2829e-05, 4.8762e-05, 2.7307e-04, 5.5423e-05, 2.6464e-05,\n",
              "            6.9354e-05, 8.6936e-06, 4.7876e-05, 3.4233e-03, 2.3324e-05, 6.4399e-06,\n",
              "            1.7130e-05, 6.6205e-05, 3.2829e-06, 4.7439e-06, 3.9406e-06, 1.2660e-07,\n",
              "            2.0765e-05, 1.7318e-03, 6.1373e-08, 3.4050e-05, 2.2953e-08, 4.4887e-07,\n",
              "            1.6524e-05, 2.4105e-07, 4.5070e-08, 2.5709e-08, 1.6703e-05, 8.0363e-05]],\n",
              "          device='cuda:0', grad_fn=<SigmoidBackward>),\n",
              "   tensor([[9.9987e-01, 2.4680e-05, 1.8700e-07, 1.2716e-04, 2.4063e-05, 3.0993e-07,\n",
              "            1.0672e-06, 8.0062e-07, 1.0360e-04, 7.8824e-05, 4.4446e-04, 2.9240e-07,\n",
              "            2.8301e-06, 1.7289e-03, 2.7222e-07, 3.2630e-07, 5.7026e-07, 3.3757e-07,\n",
              "            6.0039e-06, 4.7954e-05],\n",
              "           [1.0000e+00, 1.7523e-09, 4.3527e-11, 2.9970e-08, 2.8811e-10, 7.4064e-13,\n",
              "            1.4748e-10, 2.9498e-13, 2.6416e-08, 3.9409e-09, 4.7417e-07, 6.3283e-08,\n",
              "            1.9351e-08, 1.3180e-06, 3.0784e-09, 2.3058e-08, 1.4804e-09, 4.8282e-12,\n",
              "            5.5130e-08, 3.8734e-07],\n",
              "           [1.0000e+00, 4.6700e-10, 5.9283e-12, 3.3245e-06, 1.5430e-08, 4.7375e-11,\n",
              "            2.3706e-09, 6.9842e-10, 2.1725e-07, 3.0642e-08, 1.3325e-07, 1.5980e-08,\n",
              "            2.4591e-06, 5.2045e-06, 1.4639e-06, 2.6079e-07, 4.3705e-09, 1.5232e-10,\n",
              "            1.6661e-07, 3.7063e-08],\n",
              "           [1.0000e+00, 1.2636e-09, 2.1382e-10, 1.2505e-07, 8.5986e-10, 5.0049e-11,\n",
              "            6.4731e-10, 6.6049e-12, 1.6817e-09, 9.6507e-10, 1.3608e-04, 3.0652e-07,\n",
              "            9.7352e-08, 1.0914e-05, 1.6591e-06, 1.2558e-08, 2.0924e-08, 1.0739e-08,\n",
              "            7.5602e-04, 2.9525e-06],\n",
              "           [1.0000e+00, 1.6401e-09, 3.8214e-08, 2.3238e-08, 3.3990e-10, 4.3282e-11,\n",
              "            7.6048e-09, 1.6215e-10, 6.4609e-08, 1.0747e-08, 6.9916e-05, 1.7930e-06,\n",
              "            9.6979e-07, 5.5376e-07, 1.4907e-06, 1.6927e-06, 2.1360e-06, 2.4554e-06,\n",
              "            2.4849e-04, 4.3064e-03],\n",
              "           [1.0000e+00, 4.5650e-10, 8.5759e-11, 1.1311e-07, 4.0049e-09, 1.6196e-11,\n",
              "            2.2601e-10, 2.5111e-12, 2.3588e-09, 4.9547e-09, 3.4757e-08, 1.0179e-08,\n",
              "            5.0768e-09, 2.7156e-08, 7.0065e-06, 4.9165e-09, 1.1584e-09, 2.0520e-09,\n",
              "            4.0622e-09, 4.1126e-07],\n",
              "           [9.9998e-01, 1.0615e-07, 1.0389e-06, 1.5352e-06, 2.7051e-07, 4.7834e-09,\n",
              "            3.9737e-07, 3.8776e-10, 1.1340e-07, 6.7827e-06, 4.7191e-06, 2.4034e-06,\n",
              "            1.2632e-08, 1.0240e-05, 2.3031e-09, 4.6428e-09, 1.1530e-07, 5.4102e-10,\n",
              "            2.8358e-06, 1.3331e-06],\n",
              "           [1.0000e+00, 8.1287e-09, 1.2897e-11, 5.9185e-08, 1.4771e-09, 3.4110e-12,\n",
              "            1.5214e-09, 5.8082e-12, 1.7846e-08, 1.2081e-08, 2.8583e-05, 1.6558e-08,\n",
              "            7.2524e-06, 6.1947e-06, 3.2974e-08, 1.9900e-08, 7.3111e-09, 1.3744e-06,\n",
              "            1.7257e-06, 1.2238e-08],\n",
              "           [9.9987e-01, 9.4912e-08, 5.3217e-09, 5.2093e-06, 2.0340e-05, 5.8806e-09,\n",
              "            2.2925e-08, 1.2471e-09, 8.2344e-07, 1.3634e-04, 1.6633e-07, 8.2097e-09,\n",
              "            5.1092e-10, 9.2388e-07, 4.1078e-09, 1.3430e-08, 6.1960e-08, 2.9340e-11,\n",
              "            2.2553e-06, 5.4524e-07],\n",
              "           [9.9994e-01, 4.2031e-07, 2.5006e-08, 4.2994e-06, 7.2355e-07, 1.2443e-09,\n",
              "            1.1733e-07, 3.6851e-10, 9.0084e-07, 4.4407e-05, 1.6455e-07, 1.8854e-06,\n",
              "            1.6645e-08, 1.6419e-05, 2.2738e-09, 3.7601e-09, 2.1062e-08, 2.7692e-10,\n",
              "            3.3552e-06, 1.0201e-05]], device='cuda:0', grad_fn=<CatBackward>)],\n",
              "  4: [tensor([[9.7691e-01, 1.4708e-04, 4.7844e-04, 2.8038e-03, 4.5718e-04, 1.9647e-03,\n",
              "            1.0082e-03, 1.4207e-03, 2.2999e-03, 2.1587e-02, 2.0280e-02, 1.1083e-05,\n",
              "            6.1546e-03, 2.6712e-03, 3.0335e-05, 3.2448e-04, 6.3143e-04, 3.2993e-05,\n",
              "            3.7900e-05, 5.8161e-04, 3.2715e-05, 2.9348e-04, 1.1942e-05, 9.6408e-04,\n",
              "            2.6015e-03, 1.2103e-05, 1.4322e-04, 1.5728e-05, 5.7640e-06, 2.1039e-04,\n",
              "            8.2887e-08, 1.3949e-03, 1.7249e-09, 2.6718e-09, 3.8979e-06, 1.2251e-08,\n",
              "            2.3329e-07, 5.6653e-07, 1.0003e-02, 2.8273e-08],\n",
              "           [9.9941e-01, 3.2515e-05, 1.0898e-03, 4.0120e-04, 1.5220e-04, 7.8571e-05,\n",
              "            4.6232e-04, 8.2248e-05, 2.4346e-03, 9.3341e-04, 2.9846e-04, 1.1499e-04,\n",
              "            1.6542e-04, 2.5813e-04, 1.3948e-04, 8.5149e-04, 2.0161e-05, 2.0307e-05,\n",
              "            1.8085e-04, 3.8683e-04, 1.8636e-05, 2.4377e-05, 9.8580e-05, 2.7593e-05,\n",
              "            2.2343e-03, 5.0732e-05, 6.9431e-06, 3.4352e-06, 3.2180e-05, 1.9513e-06,\n",
              "            1.4551e-08, 1.8068e-05, 1.2592e-10, 8.9021e-10, 6.1303e-08, 8.3844e-09,\n",
              "            4.3853e-07, 1.0865e-05, 2.4779e-05, 3.2192e-06],\n",
              "           [9.9336e-01, 1.6664e-04, 1.1315e-03, 4.1938e-04, 1.5843e-03, 2.4920e-04,\n",
              "            1.9865e-03, 1.9230e-03, 4.2043e-03, 5.8243e-03, 1.2787e-03, 1.0164e-04,\n",
              "            7.2291e-03, 3.4117e-04, 4.4599e-04, 1.4795e-02, 2.5073e-04, 4.5961e-05,\n",
              "            1.2937e-04, 1.2266e-03, 1.6173e-03, 6.6866e-04, 1.7317e-04, 6.2953e-05,\n",
              "            2.1501e-03, 1.7499e-04, 6.1385e-05, 4.5397e-04, 1.6133e-04, 7.0917e-05,\n",
              "            1.7552e-05, 1.4930e-03, 2.4483e-09, 5.3960e-09, 4.6697e-06, 2.7052e-07,\n",
              "            4.8098e-06, 1.4384e-03, 8.4151e-03, 9.5712e-07],\n",
              "           [9.9894e-01, 6.9062e-05, 1.9329e-03, 5.2304e-04, 1.3921e-04, 1.7751e-04,\n",
              "            2.5363e-03, 4.6113e-04, 7.1088e-04, 2.1927e-03, 2.8335e-03, 6.7619e-05,\n",
              "            3.3661e-04, 1.5671e-03, 6.8507e-05, 1.1497e-04, 2.8356e-06, 1.3089e-04,\n",
              "            7.4816e-03, 2.3854e-03, 2.0346e-05, 1.0145e-03, 2.4882e-05, 3.3182e-03,\n",
              "            2.1772e-04, 4.5713e-06, 2.1817e-05, 1.1833e-05, 9.7620e-06, 1.0292e-06,\n",
              "            6.0327e-09, 5.1043e-07, 1.8336e-10, 1.8131e-09, 4.0356e-06, 5.2559e-08,\n",
              "            1.9099e-06, 8.7277e-07, 1.7378e-03, 1.2166e-06],\n",
              "           [9.9361e-01, 3.3689e-04, 2.8253e-03, 7.6572e-04, 3.0162e-04, 4.2129e-04,\n",
              "            1.7565e-03, 2.4402e-03, 8.3579e-03, 4.8822e-03, 9.3997e-03, 8.0528e-05,\n",
              "            4.2455e-04, 2.4641e-04, 6.4972e-05, 1.2291e-03, 2.5784e-04, 9.2451e-04,\n",
              "            1.1746e-03, 5.3570e-03, 6.6608e-04, 5.1273e-05, 3.6691e-04, 1.3497e-03,\n",
              "            5.8225e-04, 1.0353e-05, 8.0235e-04, 5.5745e-04, 2.3993e-06, 4.0560e-06,\n",
              "            7.1123e-05, 2.4614e-06, 6.3053e-09, 6.4534e-10, 4.8015e-06, 8.0572e-08,\n",
              "            3.5163e-07, 1.7527e-06, 1.0345e-03, 7.1951e-05],\n",
              "           [9.9708e-01, 5.3553e-04, 4.6028e-03, 4.0834e-04, 3.0074e-03, 1.0745e-03,\n",
              "            4.9136e-04, 1.5309e-03, 2.9569e-03, 5.9007e-03, 9.4669e-04, 1.7102e-04,\n",
              "            2.4217e-03, 6.9735e-04, 2.0822e-03, 1.8290e-03, 6.6120e-05, 6.9437e-04,\n",
              "            1.1984e-03, 1.9620e-03, 2.9104e-04, 3.9732e-03, 6.6100e-05, 1.3089e-04,\n",
              "            6.4165e-03, 4.2787e-05, 8.2833e-04, 1.1061e-04, 4.6951e-05, 6.5818e-05,\n",
              "            5.1693e-06, 4.5311e-05, 3.9764e-09, 5.0618e-09, 3.1990e-03, 2.0915e-08,\n",
              "            4.6575e-07, 9.0827e-06, 6.1502e-04, 3.2784e-07],\n",
              "           [9.9863e-01, 9.4833e-05, 2.0799e-03, 2.0133e-03, 4.1358e-04, 1.3242e-04,\n",
              "            2.6939e-03, 5.9353e-05, 1.3154e-03, 1.8865e-03, 3.7327e-04, 3.9800e-04,\n",
              "            7.0560e-04, 2.1839e-03, 1.4001e-05, 1.0479e-04, 2.4410e-05, 2.2700e-05,\n",
              "            7.5576e-04, 9.3660e-04, 6.7073e-06, 1.6954e-04, 4.0545e-05, 2.8844e-05,\n",
              "            3.0445e-04, 1.9457e-05, 1.4366e-05, 2.7028e-05, 8.9899e-05, 3.9096e-05,\n",
              "            9.7293e-10, 1.5828e-05, 1.2253e-10, 1.7786e-09, 7.0902e-06, 1.9011e-06,\n",
              "            2.9243e-05, 1.5332e-08, 1.2452e-04, 5.1426e-07],\n",
              "           [9.9807e-01, 3.3541e-04, 6.5154e-04, 7.8196e-04, 2.1611e-03, 2.4309e-04,\n",
              "            9.6032e-04, 4.4961e-04, 1.7884e-03, 2.8664e-03, 1.7875e-02, 1.0500e-05,\n",
              "            1.0430e-03, 6.7101e-04, 3.7754e-05, 5.4442e-04, 4.1418e-05, 1.0791e-03,\n",
              "            6.9423e-04, 9.1352e-05, 5.1099e-05, 1.0865e-04, 1.3864e-05, 1.7260e-04,\n",
              "            2.3099e-04, 7.9722e-05, 4.6435e-04, 1.5711e-03, 3.4303e-06, 1.0876e-05,\n",
              "            3.2234e-07, 1.4337e-06, 7.4365e-09, 3.7361e-10, 2.2813e-05, 1.6622e-10,\n",
              "            3.2374e-07, 9.1015e-07, 8.7211e-01, 6.1890e-07],\n",
              "           [9.9250e-01, 2.8877e-04, 3.8188e-03, 1.2403e-03, 6.5572e-03, 3.6633e-03,\n",
              "            5.2551e-04, 1.5810e-04, 1.4610e-03, 4.8822e-03, 1.6009e-03, 5.0023e-04,\n",
              "            5.5941e-04, 8.7524e-04, 5.3133e-04, 6.9835e-04, 3.9461e-04, 1.7114e-04,\n",
              "            7.7599e-04, 9.2931e-05, 1.6476e-04, 3.3837e-03, 7.9322e-05, 6.1120e-06,\n",
              "            1.1150e-03, 7.9710e-05, 5.3115e-05, 1.0544e-04, 1.2782e-05, 1.0660e-02,\n",
              "            6.8643e-08, 6.9406e-06, 8.4672e-09, 6.6181e-08, 1.0911e-04, 7.1068e-07,\n",
              "            1.7796e-05, 1.4838e-05, 3.5799e-03, 6.1294e-07],\n",
              "           [9.9849e-01, 2.6325e-05, 9.2676e-04, 1.7828e-03, 2.1110e-04, 3.2023e-04,\n",
              "            3.2471e-04, 9.6808e-06, 7.4102e-04, 9.2448e-04, 2.2285e-05, 9.7824e-05,\n",
              "            1.5740e-04, 8.0065e-04, 3.6693e-06, 1.8092e-04, 2.7119e-05, 4.3486e-06,\n",
              "            1.1122e-04, 7.3391e-04, 8.4874e-07, 4.1992e-05, 1.2266e-05, 7.5185e-06,\n",
              "            1.3150e-04, 2.3698e-05, 1.9802e-06, 2.8446e-06, 5.8505e-06, 1.3382e-04,\n",
              "            1.2479e-10, 1.1718e-05, 8.4009e-12, 4.2854e-10, 1.2017e-06, 2.1740e-09,\n",
              "            7.3533e-07, 2.1082e-08, 4.3835e-07, 8.5802e-07]], device='cuda:0',\n",
              "          grad_fn=<SigmoidBackward>),\n",
              "   tensor([[9.9987e-01, 6.7159e-06, 1.5844e-07, 2.3563e-04, 7.1418e-05, 7.5361e-08,\n",
              "            7.0188e-07, 6.6285e-08, 5.6897e-05, 3.5947e-05, 4.7790e-03, 1.0675e-06,\n",
              "            1.0006e-06, 4.3781e-03, 1.5212e-06, 4.1284e-06, 1.8449e-06, 6.1799e-07,\n",
              "            3.5275e-05, 9.9769e-05, 2.4968e-06, 7.5498e-05, 8.9476e-07, 1.9447e-03,\n",
              "            1.0859e-03, 1.5178e-06, 9.7048e-05, 3.0003e-07, 7.1291e-07, 7.2794e-07],\n",
              "           [1.0000e+00, 1.1807e-07, 2.9886e-07, 2.7769e-08, 1.0997e-07, 2.4552e-10,\n",
              "            2.1881e-07, 6.1704e-11, 2.7008e-07, 1.7047e-07, 2.3885e-06, 4.5382e-06,\n",
              "            1.0490e-07, 1.6664e-06, 1.5743e-07, 8.1369e-07, 8.0432e-07, 9.6372e-10,\n",
              "            9.6244e-06, 3.3131e-05, 7.2828e-06, 2.8669e-06, 1.4604e-07, 7.7093e-09,\n",
              "            7.0538e-05, 5.3454e-07, 2.1764e-07, 1.1455e-07, 1.5141e-06, 2.6136e-07],\n",
              "           [1.0000e+00, 5.0164e-10, 2.0191e-11, 6.0766e-07, 5.2080e-09, 3.8754e-11,\n",
              "            8.2597e-10, 9.0102e-11, 6.9640e-09, 4.1604e-08, 7.0534e-07, 5.9183e-08,\n",
              "            1.1033e-05, 2.2550e-08, 2.4415e-06, 8.2153e-06, 3.1781e-09, 2.8391e-10,\n",
              "            8.2264e-10, 6.8072e-10, 3.2225e-03, 1.1683e-03, 3.2649e-05, 1.0207e-06,\n",
              "            1.7260e-04, 4.4697e-05, 3.4249e-06, 3.7568e-05, 1.8890e-05, 4.7580e-06],\n",
              "           [1.0000e+00, 3.6516e-08, 2.0179e-08, 1.8168e-07, 4.1485e-08, 5.6788e-10,\n",
              "            5.2025e-08, 1.4914e-10, 2.5363e-08, 1.0129e-08, 3.5849e-03, 1.4716e-06,\n",
              "            3.1772e-06, 1.7145e-04, 1.2911e-05, 7.1784e-07, 6.0757e-07, 5.5441e-07,\n",
              "            2.4329e-03, 9.6962e-05, 2.3205e-07, 3.8542e-04, 5.3733e-08, 9.8563e-05,\n",
              "            1.1279e-05, 2.0679e-06, 7.9739e-08, 5.9056e-07, 1.3294e-06, 2.0209e-08],\n",
              "           [9.9999e-01, 2.2385e-07, 1.3772e-05, 3.6688e-06, 8.7289e-07, 2.3523e-08,\n",
              "            3.4613e-06, 2.5454e-07, 6.2658e-06, 2.9207e-07, 5.7150e-04, 3.1207e-07,\n",
              "            1.0811e-06, 1.9178e-07, 1.3907e-06, 1.0981e-06, 1.0239e-05, 6.6514e-05,\n",
              "            5.2404e-03, 6.5375e-04, 1.6572e-02, 1.1477e-06, 1.6525e-06, 1.2310e-04,\n",
              "            6.0133e-05, 3.1376e-07, 4.4168e-05, 4.6179e-05, 3.6010e-07, 3.7847e-08],\n",
              "           [1.0000e+00, 4.9273e-09, 7.0017e-10, 7.1248e-07, 6.5853e-09, 6.2969e-10,\n",
              "            1.1883e-09, 1.9957e-10, 1.4328e-08, 6.8209e-08, 1.6170e-07, 7.1714e-08,\n",
              "            1.7291e-08, 2.6293e-07, 1.3290e-06, 3.1879e-08, 9.8781e-09, 5.6548e-09,\n",
              "            1.8234e-08, 3.7201e-06, 7.1477e-07, 2.3142e-03, 2.2940e-08, 2.1182e-07,\n",
              "            3.0488e-04, 5.2921e-06, 3.5915e-05, 2.4225e-06, 4.2975e-05, 2.3039e-07],\n",
              "           [1.0000e+00, 3.2858e-10, 4.6788e-10, 9.9061e-08, 2.1664e-10, 1.0558e-12,\n",
              "            4.5664e-09, 1.5862e-14, 2.6154e-10, 8.1627e-09, 1.8155e-07, 5.3357e-06,\n",
              "            1.9354e-08, 1.7374e-06, 9.5368e-10, 5.6616e-11, 1.0426e-08, 1.0029e-10,\n",
              "            3.1686e-06, 9.5612e-06, 1.4570e-08, 3.7090e-06, 2.4661e-05, 4.4784e-07,\n",
              "            1.5292e-05, 5.5943e-07, 3.5794e-08, 2.4288e-08, 2.7045e-06, 1.5066e-08],\n",
              "           [1.0000e+00, 1.3563e-09, 3.7369e-12, 2.8677e-08, 1.0548e-09, 1.8642e-13,\n",
              "            6.7658e-10, 2.0810e-13, 6.5628e-09, 5.4553e-10, 7.1902e-05, 1.1116e-08,\n",
              "            5.8666e-07, 5.2920e-07, 1.0673e-09, 2.0710e-09, 7.1731e-09, 3.7589e-06,\n",
              "            1.3931e-06, 6.7785e-09, 3.0142e-06, 8.8025e-06, 7.6731e-08, 2.8095e-07,\n",
              "            1.0521e-06, 1.4587e-05, 4.8487e-07, 1.4011e-04, 1.0220e-07, 2.3506e-07],\n",
              "           [9.9993e-01, 3.7276e-07, 5.8291e-08, 1.5813e-05, 4.4158e-05, 2.8018e-08,\n",
              "            2.0783e-07, 6.3076e-09, 2.4923e-06, 5.2088e-05, 5.9594e-06, 4.6699e-07,\n",
              "            2.1365e-08, 1.9074e-05, 8.8786e-07, 6.5738e-08, 1.2630e-07, 6.3257e-08,\n",
              "            1.2444e-04, 7.0189e-06, 8.2656e-06, 7.7038e-05, 1.6444e-07, 5.9382e-08,\n",
              "            9.5577e-06, 5.2083e-06, 2.2234e-06, 2.2665e-06, 2.1714e-07, 1.1337e-02],\n",
              "           [9.9997e-01, 1.4419e-07, 4.8525e-08, 1.5151e-05, 5.0104e-07, 3.0108e-09,\n",
              "            3.8155e-09, 1.9726e-11, 1.4384e-07, 2.2587e-06, 1.1912e-07, 3.9706e-06,\n",
              "            3.3555e-09, 7.1716e-06, 2.2191e-09, 1.8646e-09, 3.7483e-08, 4.8747e-10,\n",
              "            6.3055e-07, 2.5798e-05, 1.0014e-08, 2.1708e-06, 7.5820e-08, 1.1204e-07,\n",
              "            4.5720e-06, 2.5173e-06, 9.4937e-09, 2.0395e-08, 8.0086e-07, 1.7020e-05]],\n",
              "          device='cuda:0', grad_fn=<CatBackward>)],\n",
              "  5: [tensor([[9.1109e-01, 1.1706e-03, 3.1035e-03, 7.6748e-03, 3.2692e-03, 3.6345e-03,\n",
              "            5.7706e-03, 3.0696e-03, 5.7163e-03, 4.6223e-02, 1.5713e-02, 4.6612e-04,\n",
              "            6.4481e-03, 2.3743e-02, 6.9806e-04, 6.1178e-03, 4.2951e-04, 4.3952e-04,\n",
              "            4.1621e-03, 6.9975e-03, 2.1408e-03, 2.9255e-03, 8.1034e-04, 8.0679e-03,\n",
              "            4.6842e-03, 1.3496e-04, 9.4564e-04, 5.8643e-04, 6.0001e-04, 2.7310e-03,\n",
              "            3.8864e-05, 1.3062e-02, 2.1040e-04, 7.5377e-06, 2.3408e-04, 8.0858e-05,\n",
              "            6.4179e-05, 3.8047e-03, 3.2392e-02, 1.4735e-04, 6.6889e-08, 2.5277e-06,\n",
              "            2.3315e-05, 5.9174e-03, 5.0249e-05, 1.3230e-05, 9.4544e-06, 6.1643e-07,\n",
              "            9.9686e-06, 5.4625e-05],\n",
              "           [9.9770e-01, 1.1408e-04, 2.8428e-03, 2.0750e-03, 7.7548e-04, 5.5324e-04,\n",
              "            5.2772e-04, 3.1546e-04, 2.5263e-03, 5.7583e-03, 2.2811e-03, 3.4412e-04,\n",
              "            4.5658e-04, 1.9311e-03, 6.4028e-04, 2.1599e-03, 4.5385e-05, 1.6675e-04,\n",
              "            1.5840e-03, 3.5883e-04, 1.3477e-03, 4.6349e-05, 4.4962e-04, 7.6390e-04,\n",
              "            6.7278e-04, 6.1616e-06, 1.9031e-04, 2.3723e-04, 2.7236e-04, 1.2866e-04,\n",
              "            6.1811e-06, 7.8669e-04, 8.1425e-06, 4.8721e-07, 1.4054e-05, 2.1505e-05,\n",
              "            2.6832e-05, 3.9863e-04, 3.5050e-03, 1.1251e-05, 1.6952e-08, 1.2359e-07,\n",
              "            1.4670e-06, 1.1051e-03, 2.5651e-07, 4.5663e-08, 8.3925e-07, 8.7665e-08,\n",
              "            1.5492e-08, 3.6169e-07],\n",
              "           [9.9711e-01, 1.1831e-05, 5.9661e-04, 3.3436e-04, 7.3352e-04, 1.0505e-04,\n",
              "            6.1798e-04, 5.3418e-04, 1.4043e-03, 5.0456e-03, 1.1951e-03, 6.8789e-05,\n",
              "            2.1934e-03, 3.3871e-04, 1.3341e-04, 5.7418e-03, 2.6844e-05, 2.1504e-05,\n",
              "            4.2955e-05, 7.1165e-05, 5.8294e-04, 3.1983e-05, 2.4205e-05, 1.2242e-04,\n",
              "            1.9217e-03, 2.3301e-06, 6.5802e-06, 3.4843e-05, 9.4101e-05, 1.6275e-05,\n",
              "            2.6861e-06, 1.8147e-04, 4.6204e-08, 2.0671e-07, 6.5120e-06, 7.7981e-07,\n",
              "            7.5335e-07, 3.5363e-04, 8.2875e-03, 2.6722e-06, 4.7083e-10, 4.0198e-09,\n",
              "            5.6578e-05, 4.4230e-07, 1.0198e-08, 1.5229e-08, 7.1202e-08, 1.0081e-08,\n",
              "            1.3206e-10, 1.9393e-07],\n",
              "           [9.9866e-01, 8.5314e-05, 3.5297e-03, 5.8935e-04, 3.1888e-04, 9.5796e-04,\n",
              "            1.4368e-03, 6.9577e-04, 5.7425e-04, 2.7255e-03, 1.0918e-03, 1.9210e-04,\n",
              "            4.9212e-04, 1.1067e-03, 9.8474e-05, 1.8471e-03, 1.1546e-05, 4.0858e-04,\n",
              "            5.2084e-03, 1.3688e-03, 3.5741e-05, 2.4305e-04, 1.2435e-04, 1.3180e-03,\n",
              "            2.4241e-04, 1.5620e-06, 1.1403e-04, 2.5675e-04, 1.6463e-04, 4.3505e-06,\n",
              "            9.4639e-07, 5.2333e-05, 1.4691e-07, 2.8712e-07, 7.7227e-05, 1.5143e-06,\n",
              "            1.3766e-05, 5.2088e-05, 7.3718e-04, 8.4571e-06, 2.5062e-12, 7.4790e-09,\n",
              "            3.4730e-07, 9.4406e-08, 2.7800e-07, 3.0731e-09, 1.9130e-07, 3.9629e-07,\n",
              "            6.2497e-10, 6.5868e-09],\n",
              "           [9.9336e-01, 1.6342e-04, 1.2179e-02, 3.7915e-03, 5.2278e-04, 1.9378e-03,\n",
              "            8.8090e-04, 3.0151e-03, 4.4122e-03, 5.6653e-03, 3.1570e-03, 8.6794e-04,\n",
              "            9.3131e-04, 5.5301e-04, 3.0783e-04, 6.3102e-03, 1.7370e-04, 2.2948e-03,\n",
              "            5.9791e-04, 4.5837e-03, 4.9790e-04, 1.6652e-04, 7.4848e-04, 1.0093e-03,\n",
              "            5.2491e-04, 2.1114e-06, 3.5963e-03, 3.7236e-03, 1.4728e-04, 1.5014e-05,\n",
              "            2.1376e-04, 1.9723e-03, 4.1734e-07, 2.0390e-06, 4.0853e-04, 1.2726e-05,\n",
              "            3.5479e-05, 4.5196e-06, 4.4749e-04, 4.5998e-05, 1.1919e-08, 4.9841e-07,\n",
              "            2.8638e-06, 1.7145e-06, 1.8970e-06, 3.7374e-06, 1.9680e-08, 9.1521e-08,\n",
              "            7.7655e-09, 2.6093e-05],\n",
              "           [9.9818e-01, 9.4042e-05, 6.4968e-04, 7.5201e-04, 1.5588e-03, 8.6139e-04,\n",
              "            2.3566e-04, 1.6262e-03, 1.4133e-03, 4.8433e-03, 1.5086e-04, 6.7744e-05,\n",
              "            5.0263e-04, 1.3391e-03, 8.6690e-04, 1.5842e-03, 1.3636e-05, 4.4261e-04,\n",
              "            2.0985e-04, 2.4919e-03, 9.8081e-05, 3.9636e-03, 1.0696e-04, 8.3307e-05,\n",
              "            1.2098e-03, 1.2940e-06, 4.2210e-04, 9.3828e-05, 2.0774e-04, 8.3882e-05,\n",
              "            5.2184e-05, 4.1829e-04, 1.7527e-07, 1.0171e-07, 7.1358e-04, 1.4425e-06,\n",
              "            7.6149e-06, 1.6018e-05, 1.1912e-03, 2.4176e-07, 2.1230e-12, 2.0678e-06,\n",
              "            2.5681e-06, 1.4611e-05, 3.1994e-07, 4.2690e-10, 7.2574e-09, 2.7926e-08,\n",
              "            1.6961e-10, 3.7349e-06],\n",
              "           [9.8906e-01, 2.5780e-04, 2.9833e-02, 3.3814e-03, 1.6007e-03, 2.0973e-03,\n",
              "            4.4741e-03, 5.2821e-04, 9.1631e-04, 3.9548e-03, 3.3629e-03, 4.6067e-03,\n",
              "            1.5561e-03, 7.4788e-04, 1.5795e-04, 5.1808e-03, 1.1527e-04, 6.0824e-04,\n",
              "            1.1353e-02, 1.4096e-03, 1.9919e-04, 2.7724e-04, 3.4652e-03, 5.4958e-04,\n",
              "            3.9645e-04, 2.0137e-05, 3.4977e-04, 7.6293e-04, 7.7959e-04, 1.0378e-04,\n",
              "            4.8227e-06, 7.1350e-04, 1.9608e-06, 7.3075e-06, 2.8143e-04, 3.8274e-04,\n",
              "            2.4311e-04, 3.7361e-05, 1.0880e-03, 2.2798e-04, 8.4487e-10, 4.9479e-07,\n",
              "            8.9190e-07, 4.3196e-05, 1.6293e-05, 7.2021e-07, 1.0655e-05, 8.3578e-06,\n",
              "            1.7462e-08, 1.5005e-07],\n",
              "           [9.9676e-01, 1.7346e-04, 6.5098e-04, 1.7136e-03, 2.5357e-03, 4.7441e-04,\n",
              "            1.1422e-03, 7.7404e-04, 1.8754e-03, 6.0482e-03, 1.4291e-02, 3.8306e-05,\n",
              "            3.4797e-03, 1.0426e-03, 1.5021e-04, 8.6603e-04, 1.7262e-05, 3.4517e-03,\n",
              "            1.0560e-03, 4.9413e-05, 4.7529e-05, 6.5781e-05, 3.6834e-05, 1.4333e-03,\n",
              "            2.6053e-04, 2.7667e-05, 1.9886e-03, 3.2055e-04, 1.6771e-05, 4.0044e-05,\n",
              "            5.4538e-05, 5.8570e-05, 1.4917e-06, 3.3420e-07, 3.1084e-04, 5.0991e-08,\n",
              "            1.1438e-06, 2.9020e-05, 1.0466e-01, 7.6396e-06, 1.9687e-11, 2.0161e-09,\n",
              "            1.3330e-05, 1.0516e-05, 5.8214e-08, 8.0324e-06, 2.0573e-06, 7.3155e-07,\n",
              "            3.7752e-10, 6.1115e-07],\n",
              "           [9.9061e-01, 1.1963e-04, 3.3359e-03, 1.4511e-03, 1.6289e-03, 6.5654e-03,\n",
              "            9.8716e-04, 3.6388e-04, 4.1336e-04, 8.3278e-03, 3.8778e-03, 3.4136e-04,\n",
              "            1.0041e-03, 2.3836e-04, 1.0838e-04, 2.0663e-03, 3.4011e-04, 2.1448e-04,\n",
              "            1.4956e-03, 5.7133e-04, 2.4325e-04, 3.2837e-04, 1.0350e-03, 6.7181e-05,\n",
              "            2.3354e-04, 5.9587e-06, 2.1957e-04, 3.5476e-04, 2.5686e-05, 7.3265e-04,\n",
              "            2.3963e-06, 1.0722e-03, 9.1289e-07, 1.3102e-06, 1.3576e-04, 2.0704e-05,\n",
              "            5.1079e-05, 8.2226e-05, 8.7657e-04, 1.7450e-06, 1.1659e-09, 1.1604e-08,\n",
              "            1.2126e-06, 2.3205e-04, 1.5953e-06, 1.4046e-07, 1.1191e-09, 1.3002e-08,\n",
              "            2.7600e-08, 3.9515e-06],\n",
              "           [9.8997e-01, 1.0882e-04, 3.0366e-03, 1.1568e-03, 7.6263e-04, 4.6278e-03,\n",
              "            5.1943e-04, 8.6943e-05, 4.7494e-05, 3.5008e-03, 2.8495e-04, 2.6404e-04,\n",
              "            3.3786e-04, 3.5620e-04, 1.5173e-05, 3.1582e-04, 2.1960e-05, 3.7292e-05,\n",
              "            3.6060e-03, 4.4290e-04, 2.6473e-05, 3.4788e-05, 4.8751e-05, 6.7035e-05,\n",
              "            7.4560e-05, 8.0812e-07, 1.2806e-05, 6.8790e-05, 6.7662e-05, 1.1484e-04,\n",
              "            3.0401e-08, 1.0625e-04, 2.0196e-07, 9.2441e-07, 2.6467e-05, 8.8225e-06,\n",
              "            2.7305e-05, 3.7853e-06, 1.3133e-04, 1.5254e-07, 9.2978e-13, 2.6040e-09,\n",
              "            9.6712e-11, 4.6403e-06, 3.4450e-07, 9.5785e-10, 2.1591e-10, 9.8636e-09,\n",
              "            2.2300e-10, 1.0893e-08]], device='cuda:0', grad_fn=<SigmoidBackward>),\n",
              "   tensor([[9.9948e-01, 2.1611e-05, 6.6664e-07, 1.9065e-04, 5.1596e-06, 8.8803e-07,\n",
              "            2.5331e-06, 1.5160e-06, 2.7261e-05, 4.3884e-04, 2.2886e-04, 2.5145e-06,\n",
              "            3.0209e-06, 1.0647e-02, 1.4485e-05, 2.3764e-06, 8.9595e-07, 5.6571e-07,\n",
              "            1.6875e-05, 1.1432e-03, 1.5548e-05, 4.9307e-03, 7.4413e-05, 2.0912e-04,\n",
              "            1.1818e-02, 3.1406e-05, 4.9858e-05, 1.5456e-05, 6.6409e-05, 3.7935e-05,\n",
              "            2.0905e-07, 4.7484e-03, 1.6120e-07, 2.5867e-08, 2.3967e-05, 5.7685e-07,\n",
              "            3.2598e-06, 1.0993e-04, 4.4240e-04, 3.0864e-06],\n",
              "           [1.0000e+00, 1.0545e-09, 3.1139e-11, 3.4034e-09, 2.6900e-10, 1.1532e-13,\n",
              "            1.1725e-10, 2.8712e-14, 9.2055e-10, 1.0312e-09, 6.5216e-07, 9.2392e-09,\n",
              "            2.9984e-09, 4.5219e-08, 2.5594e-09, 8.5159e-09, 2.6790e-10, 8.2623e-14,\n",
              "            3.6353e-09, 2.1939e-08, 8.3651e-06, 1.7327e-06, 1.3345e-07, 5.9547e-06,\n",
              "            6.8423e-05, 2.1526e-08, 1.5055e-08, 7.8625e-08, 8.4952e-08, 3.8430e-08,\n",
              "            1.1671e-09, 5.0764e-06, 6.1035e-10, 3.3154e-10, 5.5747e-07, 9.1468e-10,\n",
              "            2.3003e-08, 5.9079e-06, 5.6538e-05, 6.6267e-08],\n",
              "           [1.0000e+00, 4.7700e-11, 1.4589e-12, 2.2735e-07, 2.7753e-09, 1.6718e-12,\n",
              "            2.8915e-10, 5.4675e-12, 2.2424e-09, 1.5231e-09, 7.0566e-08, 2.0385e-08,\n",
              "            5.5006e-07, 1.4243e-09, 2.2307e-06, 2.8538e-05, 5.6227e-10, 9.9238e-12,\n",
              "            7.2155e-10, 3.4875e-10, 3.7064e-05, 1.3357e-03, 4.8674e-07, 2.2116e-07,\n",
              "            1.3135e-04, 2.3160e-06, 1.1461e-06, 3.5536e-06, 4.9310e-07, 8.2796e-07,\n",
              "            3.5874e-07, 7.5423e-05, 7.0929e-11, 6.7563e-10, 4.9812e-07, 2.3541e-08,\n",
              "            8.2188e-08, 8.7535e-04, 1.1483e-03, 7.9793e-07],\n",
              "           [1.0000e+00, 4.5102e-09, 9.2171e-09, 1.5386e-08, 1.3560e-09, 8.7343e-11,\n",
              "            1.3473e-08, 2.6632e-11, 9.5508e-09, 8.1420e-09, 8.0417e-06, 2.7104e-06,\n",
              "            2.5582e-06, 1.7289e-06, 6.6412e-07, 2.7477e-08, 4.8623e-08, 1.4436e-09,\n",
              "            1.3932e-04, 1.9639e-06, 8.3630e-08, 1.1879e-04, 4.6372e-07, 4.7580e-06,\n",
              "            5.9315e-05, 5.0971e-06, 7.7718e-08, 3.1003e-07, 7.1468e-06, 2.0892e-07,\n",
              "            1.8279e-08, 1.6572e-06, 8.7861e-10, 1.7657e-09, 2.0499e-05, 1.7783e-08,\n",
              "            9.0077e-07, 3.5742e-06, 4.1779e-04, 3.2397e-06],\n",
              "           [1.0000e+00, 4.2889e-08, 1.8820e-07, 1.1470e-06, 1.2124e-08, 5.4738e-09,\n",
              "            5.6681e-08, 1.5625e-08, 1.3269e-06, 5.7840e-07, 7.9370e-04, 4.1719e-06,\n",
              "            2.1857e-06, 1.3179e-06, 6.8647e-06, 5.8087e-06, 5.0853e-06, 3.5645e-06,\n",
              "            1.5565e-03, 4.5606e-03, 2.4521e-04, 2.6597e-04, 1.6534e-05, 1.1269e-03,\n",
              "            6.5432e-04, 4.9374e-06, 9.4299e-05, 6.5518e-05, 6.9635e-07, 6.6520e-06,\n",
              "            2.3285e-06, 6.1214e-06, 7.4687e-09, 6.8773e-09, 8.7651e-05, 3.2725e-07,\n",
              "            1.0001e-06, 1.3447e-07, 2.1267e-03, 8.8947e-06],\n",
              "           [1.0000e+00, 6.7422e-10, 1.1289e-10, 6.4406e-07, 5.8586e-10, 8.5270e-11,\n",
              "            5.0566e-11, 5.0937e-12, 1.7348e-08, 1.3837e-08, 1.0549e-07, 1.4012e-08,\n",
              "            3.5850e-09, 1.2802e-08, 2.9198e-06, 1.9689e-08, 1.3685e-08, 2.3599e-07,\n",
              "            1.0611e-08, 1.1821e-05, 3.3744e-07, 2.8592e-04, 5.0024e-09, 2.3187e-08,\n",
              "            2.2863e-04, 5.1288e-07, 3.1099e-05, 4.9227e-07, 5.4073e-05, 1.9974e-08,\n",
              "            6.0726e-07, 5.5955e-06, 3.3323e-10, 1.2071e-10, 6.1116e-04, 8.0324e-10,\n",
              "            1.2380e-08, 3.3898e-06, 4.3688e-03, 5.9761e-09],\n",
              "           [1.0000e+00, 4.4812e-09, 1.5821e-07, 2.9381e-08, 1.3313e-08, 2.7872e-11,\n",
              "            2.7671e-09, 3.1399e-13, 4.9416e-09, 4.1317e-08, 1.0864e-06, 9.1715e-07,\n",
              "            5.6857e-09, 1.3548e-07, 6.0657e-10, 3.1229e-10, 2.2574e-08, 9.4643e-12,\n",
              "            3.9283e-07, 8.3117e-08, 5.0317e-08, 6.1939e-07, 2.8982e-07, 9.9798e-09,\n",
              "            3.3780e-06, 5.6461e-06, 1.5571e-08, 1.1007e-07, 3.9543e-06, 3.4719e-08,\n",
              "            1.4150e-09, 2.0596e-06, 4.8676e-11, 2.5428e-09, 1.1763e-06, 1.3419e-08,\n",
              "            1.1857e-06, 1.2653e-07, 5.6949e-05, 2.3271e-06],\n",
              "           [1.0000e+00, 3.3548e-08, 5.1610e-12, 6.9990e-07, 1.1073e-09, 1.3539e-11,\n",
              "            9.1148e-10, 3.9717e-11, 1.6513e-07, 1.3312e-07, 9.2876e-04, 9.5120e-09,\n",
              "            1.0697e-06, 7.8164e-05, 7.8076e-09, 2.4249e-08, 1.6308e-09, 9.7036e-08,\n",
              "            4.0583e-07, 5.7388e-09, 1.7569e-06, 7.4800e-06, 6.9111e-08, 2.3307e-08,\n",
              "            1.8923e-06, 8.0656e-07, 1.8600e-04, 4.7166e-06, 2.9984e-08, 1.6386e-08,\n",
              "            1.1533e-06, 9.5359e-05, 6.0237e-09, 1.0336e-09, 4.6788e-05, 3.5446e-09,\n",
              "            5.2606e-07, 2.2921e-07, 1.5549e-01, 3.9765e-08],\n",
              "           [9.9985e-01, 1.7422e-07, 2.7862e-08, 1.1637e-05, 4.5956e-05, 1.5953e-08,\n",
              "            5.6475e-08, 2.0992e-09, 1.5115e-06, 2.1113e-04, 5.7729e-06, 1.5027e-07,\n",
              "            1.2189e-08, 1.9204e-05, 4.5803e-08, 8.2064e-08, 2.5866e-07, 1.6170e-08,\n",
              "            3.1012e-05, 2.2001e-05, 2.0932e-05, 1.0307e-04, 2.4625e-07, 3.2256e-08,\n",
              "            1.5707e-05, 4.1425e-06, 6.5683e-06, 4.5559e-06, 1.7549e-07, 2.3880e-03,\n",
              "            6.9581e-07, 1.4475e-05, 2.7318e-08, 3.9685e-08, 1.3837e-04, 1.0521e-06,\n",
              "            1.5322e-05, 1.0245e-04, 4.6690e-02, 2.2940e-06],\n",
              "           [1.0000e+00, 6.7895e-10, 5.8545e-11, 5.2954e-09, 4.6222e-11, 1.3670e-12,\n",
              "            3.0486e-11, 1.0365e-14, 9.6298e-11, 2.7916e-08, 1.2138e-09, 2.0379e-07,\n",
              "            3.1403e-10, 1.9182e-08, 6.5372e-11, 3.1074e-11, 1.1852e-09, 4.8830e-13,\n",
              "            4.1339e-08, 5.2703e-08, 1.1039e-09, 1.7342e-07, 5.1006e-09, 4.5145e-08,\n",
              "            1.5468e-06, 3.1462e-07, 9.7341e-10, 5.7212e-09, 4.2525e-07, 4.3093e-06,\n",
              "            3.3175e-11, 1.2992e-06, 1.6784e-11, 9.7534e-10, 5.3692e-07, 5.1677e-09,\n",
              "            2.9907e-07, 1.4928e-08, 5.5152e-06, 5.7938e-08]], device='cuda:0',\n",
              "          grad_fn=<CatBackward>)],\n",
              "  6: [tensor([[8.8289e-01, 1.0784e-03, 3.3760e-03, 8.3431e-03, 4.3805e-03, 5.3576e-03,\n",
              "            4.1142e-03, 2.9339e-03, 1.3245e-02, 9.3742e-02, 7.4423e-02, 5.7284e-04,\n",
              "            9.1368e-03, 1.7792e-02, 7.8364e-04, 5.1170e-03, 6.1124e-04, 7.5646e-04,\n",
              "            1.5315e-03, 7.5653e-03, 4.3931e-03, 5.5333e-03, 8.1136e-04, 8.9894e-03,\n",
              "            3.0225e-03, 2.3723e-04, 4.0780e-03, 4.6627e-04, 8.8912e-04, 1.9971e-03,\n",
              "            1.4415e-03, 1.3451e-02, 4.8969e-04, 1.2928e-05, 1.2454e-04, 3.7168e-04,\n",
              "            2.0911e-04, 4.4293e-03, 4.3227e-02, 6.9765e-05, 3.9644e-05, 6.7464e-05,\n",
              "            7.3460e-03, 1.3950e-02, 1.4673e-04, 6.8295e-04, 2.3229e-05, 7.0519e-06,\n",
              "            3.4949e-04, 1.0879e-03, 1.5523e-05, 6.9798e-04, 2.3816e-07, 3.0045e-08,\n",
              "            1.0719e-06, 1.7400e-04, 9.2563e-09, 1.8052e-05, 4.1100e-04, 3.3733e-04],\n",
              "           [9.9125e-01, 2.5103e-04, 2.0088e-02, 2.5707e-03, 9.0987e-04, 4.9717e-04,\n",
              "            1.7698e-03, 9.0353e-04, 2.6562e-03, 8.3991e-03, 3.0456e-03, 3.1881e-04,\n",
              "            3.3957e-03, 5.6789e-04, 3.2283e-04, 2.7875e-03, 9.7053e-04, 1.8748e-03,\n",
              "            1.8799e-03, 4.6848e-04, 3.1384e-03, 1.6861e-04, 2.6369e-03, 3.2458e-05,\n",
              "            2.6211e-04, 1.7803e-05, 7.0493e-04, 8.8793e-05, 5.3855e-04, 1.0271e-03,\n",
              "            4.7968e-05, 9.0308e-05, 4.5804e-05, 3.6758e-06, 3.9195e-05, 2.7767e-04,\n",
              "            4.4023e-04, 4.4425e-05, 5.7228e-03, 1.3461e-04, 6.4695e-05, 2.0470e-07,\n",
              "            8.1001e-06, 9.0938e-04, 1.9937e-06, 7.7715e-06, 1.0639e-05, 1.1964e-04,\n",
              "            6.7812e-07, 2.1234e-05, 5.1733e-08, 3.5191e-06, 3.7552e-05, 9.0523e-08,\n",
              "            1.3501e-06, 8.3187e-08, 2.0857e-09, 1.8461e-07, 3.6611e-06, 6.6288e-10],\n",
              "           [9.9343e-01, 1.6077e-04, 8.6359e-03, 1.9510e-03, 1.4529e-03, 5.3493e-04,\n",
              "            5.0283e-03, 5.8959e-03, 7.3181e-03, 1.6714e-02, 4.3852e-03, 6.3551e-04,\n",
              "            9.6524e-03, 9.1922e-04, 2.1174e-03, 5.6796e-02, 2.2387e-03, 4.3551e-04,\n",
              "            5.7121e-04, 1.1242e-03, 1.4260e-02, 5.9938e-04, 5.5111e-04, 2.3057e-04,\n",
              "            1.4655e-02, 2.4468e-05, 5.6672e-04, 3.0265e-04, 1.4231e-03, 1.9461e-04,\n",
              "            1.1049e-03, 9.1958e-04, 3.3082e-05, 2.6936e-06, 1.3587e-04, 3.7294e-04,\n",
              "            1.1949e-04, 1.5175e-03, 2.2380e-02, 3.3911e-04, 3.1860e-04, 2.1182e-06,\n",
              "            1.4769e-02, 8.6937e-04, 2.8704e-06, 3.7815e-05, 4.6772e-05, 2.6584e-04,\n",
              "            9.9061e-07, 1.3387e-04, 4.7124e-08, 1.1495e-04, 3.0679e-06, 1.8652e-06,\n",
              "            1.2073e-06, 2.2318e-05, 1.3370e-06, 2.1946e-04, 8.4984e-08, 1.9615e-07],\n",
              "           [9.8493e-01, 6.9873e-04, 9.2812e-03, 4.5382e-03, 1.8526e-03, 1.5435e-03,\n",
              "            1.0719e-02, 2.8651e-03, 1.1366e-03, 5.2260e-03, 7.0698e-03, 3.3735e-04,\n",
              "            2.4179e-03, 3.5577e-03, 3.3671e-04, 2.5640e-03, 3.0404e-04, 8.8171e-03,\n",
              "            1.3028e-02, 2.2954e-03, 5.3686e-04, 2.4446e-03, 2.2696e-03, 1.2150e-03,\n",
              "            7.9538e-04, 6.9947e-05, 8.9248e-04, 4.2807e-04, 4.2346e-04, 4.2525e-04,\n",
              "            7.9007e-05, 2.7408e-04, 1.6120e-05, 1.8253e-05, 3.9859e-04, 4.3091e-04,\n",
              "            6.0337e-04, 4.5424e-04, 1.1817e-02, 2.7291e-04, 1.1936e-06, 4.6508e-06,\n",
              "            3.1077e-05, 3.6628e-05, 1.4383e-04, 1.1055e-04, 7.0772e-05, 2.0279e-04,\n",
              "            2.9295e-06, 1.1758e-05, 3.2664e-08, 7.0387e-06, 1.9522e-08, 3.5064e-05,\n",
              "            1.3115e-06, 1.9746e-06, 1.0576e-08, 6.8245e-05, 2.2750e-05, 1.8442e-08],\n",
              "           [9.9189e-01, 6.5473e-05, 1.2142e-02, 1.3053e-03, 6.8569e-04, 4.6183e-03,\n",
              "            9.2158e-04, 1.4556e-03, 1.6080e-03, 7.2949e-03, 3.5579e-02, 8.7769e-04,\n",
              "            1.4713e-03, 6.8955e-05, 2.0460e-04, 6.9113e-03, 7.0595e-04, 3.6675e-03,\n",
              "            6.1428e-04, 1.9493e-04, 1.2458e-03, 9.0334e-05, 9.1044e-04, 1.1380e-04,\n",
              "            4.1120e-04, 5.3091e-06, 1.4669e-03, 1.1539e-03, 5.2579e-05, 2.1256e-04,\n",
              "            1.0954e-04, 2.2445e-04, 4.2736e-06, 5.1060e-06, 7.2227e-05, 1.4453e-04,\n",
              "            4.4008e-05, 4.5647e-05, 9.7708e-04, 2.0089e-04, 7.2833e-06, 7.7640e-07,\n",
              "            3.9096e-05, 1.2142e-04, 1.7492e-05, 3.8021e-05, 7.5902e-07, 3.4112e-06,\n",
              "            2.1663e-06, 4.3855e-05, 3.2821e-09, 2.3539e-06, 3.4609e-07, 2.0105e-06,\n",
              "            1.3176e-09, 8.2791e-07, 6.6333e-10, 1.2577e-04, 6.0876e-08, 4.0770e-07],\n",
              "           [9.9196e-01, 1.2590e-03, 4.0610e-03, 4.8451e-03, 6.2819e-03, 1.3666e-03,\n",
              "            1.9397e-03, 5.6066e-03, 2.7882e-03, 1.1200e-02, 6.3328e-03, 1.1841e-04,\n",
              "            2.7590e-03, 7.3089e-03, 5.1373e-03, 1.6074e-03, 1.9765e-04, 2.5406e-03,\n",
              "            1.9502e-03, 3.9143e-03, 1.1995e-03, 1.3815e-02, 1.6126e-03, 3.0850e-04,\n",
              "            2.6296e-03, 5.6989e-05, 4.1774e-03, 2.6331e-04, 4.9691e-04, 1.2128e-03,\n",
              "            1.4830e-03, 2.1957e-03, 4.1373e-05, 3.8936e-06, 1.4128e-03, 1.4085e-04,\n",
              "            3.2229e-04, 6.9040e-04, 3.0999e-02, 4.9003e-06, 4.7749e-06, 1.2482e-04,\n",
              "            2.0132e-04, 9.6364e-04, 5.1904e-05, 1.9148e-05, 1.0278e-05, 2.7517e-05,\n",
              "            8.6121e-07, 1.4775e-04, 7.3692e-08, 5.6103e-05, 1.5297e-09, 6.3849e-06,\n",
              "            8.5590e-08, 1.2167e-07, 4.2749e-08, 8.2181e-05, 3.8431e-06, 6.6433e-06],\n",
              "           [9.7722e-01, 6.2141e-04, 3.2720e-02, 3.5114e-03, 2.3512e-03, 2.0753e-03,\n",
              "            1.0863e-02, 1.7136e-03, 9.4635e-04, 9.4922e-03, 4.1080e-03, 1.1251e-03,\n",
              "            6.4388e-03, 1.4290e-03, 2.9430e-04, 6.8969e-03, 1.6594e-03, 7.8472e-04,\n",
              "            6.6862e-03, 2.3221e-03, 1.0710e-03, 2.7421e-03, 3.4294e-03, 1.4642e-04,\n",
              "            6.2764e-04, 7.1096e-05, 4.9192e-04, 3.5021e-04, 1.3377e-03, 1.2211e-03,\n",
              "            1.2007e-04, 6.7715e-04, 2.1830e-05, 2.4138e-05, 1.6656e-04, 9.0206e-04,\n",
              "            2.2305e-03, 2.1682e-04, 4.4112e-03, 2.1303e-04, 4.7715e-05, 4.4008e-06,\n",
              "            5.5056e-05, 2.4293e-04, 1.2411e-04, 8.6477e-05, 1.2352e-05, 1.8739e-04,\n",
              "            1.8065e-06, 2.7141e-05, 1.6500e-08, 4.6155e-05, 1.6053e-06, 6.4080e-07,\n",
              "            5.2607e-06, 7.4452e-07, 4.1982e-08, 3.4238e-06, 6.5515e-06, 2.1083e-07],\n",
              "           [9.7779e-01, 1.1427e-03, 3.3370e-03, 3.2348e-03, 7.6386e-03, 1.2150e-03,\n",
              "            2.6283e-03, 2.1613e-03, 2.9393e-03, 2.0721e-02, 3.0906e-02, 3.4035e-04,\n",
              "            1.7410e-02, 4.4843e-03, 4.8541e-04, 9.0069e-04, 2.5868e-04, 5.0464e-03,\n",
              "            3.0321e-03, 1.1076e-04, 1.0456e-03, 4.2127e-04, 2.1447e-04, 1.3432e-03,\n",
              "            9.9618e-04, 6.3480e-05, 7.0492e-03, 1.5291e-03, 3.4097e-05, 6.6842e-04,\n",
              "            5.1951e-04, 2.3747e-03, 1.5420e-04, 4.3918e-06, 6.9483e-04, 3.2952e-05,\n",
              "            1.8904e-04, 5.3737e-04, 7.5863e-02, 1.3907e-05, 1.9926e-06, 7.2277e-06,\n",
              "            1.7667e-04, 4.7971e-03, 5.1918e-05, 6.3742e-04, 2.2820e-05, 9.1188e-05,\n",
              "            3.4833e-06, 1.4692e-04, 3.9964e-07, 1.3970e-02, 4.0455e-09, 7.9343e-09,\n",
              "            4.2283e-08, 8.7046e-05, 6.2129e-09, 3.3370e-03, 8.0077e-06, 2.9524e-07],\n",
              "           [9.6365e-01, 2.3566e-04, 9.6230e-03, 2.5117e-03, 3.6011e-03, 1.6720e-03,\n",
              "            2.1688e-03, 4.9224e-04, 9.2940e-05, 1.1755e-02, 3.2313e-03, 2.7649e-04,\n",
              "            2.8171e-03, 6.0109e-04, 1.6514e-04, 1.8710e-03, 5.3913e-04, 1.6433e-04,\n",
              "            1.7928e-03, 6.1599e-04, 6.1639e-04, 5.5918e-03, 1.4245e-03, 3.0079e-05,\n",
              "            5.2486e-04, 1.1164e-05, 3.6111e-04, 1.8255e-04, 1.2914e-04, 1.5244e-03,\n",
              "            1.0355e-04, 7.4020e-04, 1.1808e-05, 2.3322e-05, 1.9942e-04, 6.4005e-04,\n",
              "            7.2726e-04, 1.8203e-04, 2.4940e-02, 6.3671e-06, 4.3760e-06, 8.7526e-07,\n",
              "            1.0975e-04, 2.2616e-04, 3.1839e-05, 1.9118e-04, 9.0752e-07, 5.7023e-05,\n",
              "            1.9744e-06, 6.0913e-04, 5.1999e-09, 5.7918e-06, 1.0929e-07, 1.8913e-05,\n",
              "            1.2031e-07, 3.1165e-06, 7.3223e-08, 1.3715e-05, 1.8077e-07, 6.7896e-06],\n",
              "           [9.8452e-01, 1.2162e-04, 3.9667e-03, 3.6115e-03, 6.4047e-04, 3.1040e-03,\n",
              "            6.5689e-04, 6.7632e-05, 8.1545e-05, 4.7472e-03, 3.2963e-04, 9.6614e-05,\n",
              "            1.1126e-03, 1.3425e-04, 2.2130e-05, 2.7852e-04, 2.7861e-04, 1.5312e-04,\n",
              "            1.5685e-03, 1.2468e-04, 6.3945e-05, 1.4043e-04, 1.8007e-04, 9.1219e-06,\n",
              "            3.4866e-05, 1.4558e-06, 8.5300e-05, 5.6187e-06, 4.0004e-05, 1.5137e-03,\n",
              "            1.3927e-06, 8.8667e-05, 1.4485e-06, 4.0469e-06, 1.7134e-05, 3.2940e-05,\n",
              "            9.5230e-05, 1.3661e-06, 7.1144e-04, 1.9338e-06, 4.2463e-07, 9.6636e-09,\n",
              "            1.5013e-07, 4.8733e-05, 1.9894e-06, 8.2239e-07, 9.0065e-09, 8.0101e-06,\n",
              "            2.8424e-08, 1.3661e-06, 8.6930e-11, 5.1253e-07, 4.7679e-08, 5.1365e-09,\n",
              "            5.9453e-11, 5.6972e-09, 7.0064e-10, 2.3160e-07, 7.9023e-11, 5.9598e-10]],\n",
              "          device='cuda:0', grad_fn=<SigmoidBackward>),\n",
              "   tensor([[9.9691e-01, 1.4129e-04, 8.7632e-07, 1.4948e-03, 9.7212e-05, 6.6318e-06,\n",
              "            1.5184e-06, 2.9562e-06, 8.4292e-04, 5.6795e-04, 1.3256e-04, 8.1973e-08,\n",
              "            1.7976e-06, 2.5594e-02, 2.5607e-07, 2.6801e-07, 5.5726e-08, 5.6738e-07,\n",
              "            3.7876e-07, 6.4406e-06, 1.2899e-06, 6.9697e-04, 1.0919e-06, 7.9554e-04,\n",
              "            9.6891e-04, 1.9067e-05, 3.2315e-05, 9.7277e-07, 8.9470e-07, 3.0937e-06,\n",
              "            1.8967e-07, 2.4899e-03, 2.4699e-08, 4.6224e-09, 2.4250e-05, 2.6433e-08,\n",
              "            2.0853e-07, 1.1007e-04, 2.4591e-03, 6.6079e-08, 9.4112e-09, 1.5396e-06,\n",
              "            6.4836e-04, 5.7018e-04, 2.0221e-05, 3.7175e-06, 7.3041e-07, 2.7645e-08,\n",
              "            1.7590e-06, 5.6159e-05],\n",
              "           [1.0000e+00, 3.4104e-10, 6.5802e-11, 1.7143e-08, 1.2880e-10, 1.5455e-12,\n",
              "            1.2944e-10, 1.5664e-13, 1.3595e-09, 9.7594e-10, 1.5152e-07, 9.8074e-08,\n",
              "            1.8084e-08, 2.1177e-08, 3.7285e-08, 6.5756e-09, 1.9984e-09, 8.6011e-12,\n",
              "            1.1800e-07, 1.5027e-08, 6.4474e-06, 9.4635e-06, 6.4130e-07, 6.0994e-07,\n",
              "            2.8181e-05, 6.2896e-07, 1.6566e-08, 3.6371e-08, 8.0576e-08, 3.6942e-07,\n",
              "            1.4459e-09, 2.2643e-06, 1.5965e-10, 1.7000e-10, 3.4103e-07, 4.8663e-10,\n",
              "            7.3751e-08, 5.5147e-06, 7.0913e-06, 8.1133e-07, 8.9529e-10, 2.9783e-08,\n",
              "            6.2327e-07, 1.5283e-04, 9.7491e-08, 6.0946e-09, 4.0586e-07, 1.1399e-07,\n",
              "            3.0366e-09, 1.5612e-07],\n",
              "           [1.0000e+00, 1.2656e-09, 1.6256e-10, 4.2417e-06, 5.5116e-08, 3.7469e-10,\n",
              "            1.9573e-09, 1.9391e-10, 1.9899e-08, 3.7388e-08, 4.8529e-06, 3.0818e-07,\n",
              "            2.1055e-06, 1.3725e-07, 3.6050e-06, 5.0507e-06, 1.3885e-08, 1.3959e-09,\n",
              "            2.3015e-08, 6.4472e-09, 3.4947e-04, 6.3475e-04, 2.5003e-06, 4.3780e-07,\n",
              "            1.0187e-04, 1.1063e-05, 4.3197e-06, 1.1476e-05, 8.4391e-06, 8.1657e-07,\n",
              "            3.9218e-06, 1.9322e-04, 7.5702e-10, 1.8967e-09, 2.3429e-06, 2.9334e-08,\n",
              "            5.4342e-07, 8.5785e-04, 8.2697e-03, 3.0677e-06, 1.1930e-09, 5.1905e-08,\n",
              "            4.9679e-04, 2.4123e-06, 2.1300e-08, 9.6184e-08, 4.4036e-07, 5.5913e-08,\n",
              "            5.4639e-10, 1.2439e-06],\n",
              "           [1.0000e+00, 2.3602e-08, 2.1184e-08, 4.3339e-07, 2.8265e-08, 1.0893e-09,\n",
              "            1.0095e-07, 2.2091e-10, 2.9173e-08, 1.4672e-08, 9.6672e-06, 1.4434e-07,\n",
              "            1.8417e-07, 1.4203e-06, 5.8105e-07, 4.1531e-09, 5.7484e-08, 1.5883e-08,\n",
              "            3.7110e-03, 2.0505e-06, 7.6117e-07, 1.1536e-04, 1.3902e-06, 8.1849e-06,\n",
              "            1.1994e-05, 8.9669e-06, 1.9422e-07, 1.8955e-06, 2.1501e-06, 7.2865e-08,\n",
              "            7.1603e-09, 1.1574e-06, 3.8387e-10, 3.1546e-09, 2.5290e-05, 4.7145e-08,\n",
              "            1.1427e-06, 1.1308e-06, 1.2547e-03, 6.3432e-06, 5.5045e-11, 3.0753e-07,\n",
              "            2.3859e-06, 1.7387e-06, 2.0678e-05, 2.7796e-07, 4.5629e-05, 3.3699e-05,\n",
              "            1.0221e-07, 5.1846e-06],\n",
              "           [1.0000e+00, 2.8705e-09, 8.5043e-09, 1.1471e-08, 1.6648e-10, 3.5209e-11,\n",
              "            4.9881e-09, 1.2321e-10, 1.2016e-07, 1.0952e-08, 2.5595e-05, 8.8518e-07,\n",
              "            2.4845e-07, 2.1144e-08, 5.4367e-07, 7.5038e-07, 2.1098e-07, 3.5715e-07,\n",
              "            2.3628e-05, 9.3108e-04, 1.3445e-04, 3.3091e-06, 2.0621e-05, 7.8247e-05,\n",
              "            4.5922e-05, 9.5354e-08, 4.8234e-06, 1.2038e-05, 8.0630e-08, 1.6071e-08,\n",
              "            1.2389e-06, 3.1185e-06, 7.9797e-10, 2.6104e-10, 4.9073e-05, 2.0732e-07,\n",
              "            3.6972e-07, 5.0600e-08, 4.9351e-04, 3.5539e-06, 1.2046e-08, 4.1603e-08,\n",
              "            1.6475e-07, 2.4413e-05, 5.2927e-08, 2.1290e-07, 3.1255e-10, 7.8512e-09,\n",
              "            2.4762e-09, 8.9177e-07],\n",
              "           [1.0000e+00, 3.1176e-08, 5.8800e-09, 5.6653e-06, 2.1864e-08, 8.8540e-09,\n",
              "            8.5804e-10, 1.9542e-10, 2.6470e-08, 8.0813e-08, 5.9169e-08, 3.4047e-08,\n",
              "            6.4141e-09, 2.6899e-08, 7.4719e-07, 2.1466e-08, 5.0271e-08, 4.9740e-09,\n",
              "            1.2121e-08, 8.9858e-06, 3.4673e-06, 1.5369e-03, 9.5532e-08, 3.5796e-06,\n",
              "            1.8494e-04, 1.3023e-05, 2.1591e-04, 2.1864e-06, 2.3394e-05, 5.2245e-06,\n",
              "            1.0693e-06, 5.8324e-06, 3.6652e-10, 8.4999e-10, 1.3212e-03, 1.5021e-09,\n",
              "            3.1960e-08, 1.6924e-06, 1.5670e-04, 4.1285e-07, 4.2787e-12, 1.0162e-05,\n",
              "            1.4109e-06, 1.1233e-04, 7.3040e-07, 9.7569e-10, 1.2223e-07, 1.2928e-07,\n",
              "            2.4511e-09, 9.5957e-07],\n",
              "           [1.0000e+00, 5.2894e-09, 4.7019e-08, 1.2972e-08, 3.9302e-09, 2.5784e-11,\n",
              "            1.5916e-08, 3.7626e-13, 1.1588e-09, 8.1475e-09, 8.9667e-07, 3.2393e-05,\n",
              "            3.3658e-08, 4.2970e-08, 5.1351e-09, 3.2800e-10, 1.0392e-07, 3.1968e-10,\n",
              "            1.9560e-05, 1.5057e-06, 4.1436e-07, 9.0949e-06, 1.9256e-05, 1.8574e-07,\n",
              "            3.7993e-05, 5.9320e-06, 1.4295e-08, 1.9591e-07, 1.7793e-06, 1.5533e-06,\n",
              "            7.1547e-10, 8.1707e-06, 1.1714e-10, 1.2892e-08, 1.6073e-05, 2.7676e-07,\n",
              "            2.2095e-05, 3.7205e-07, 4.7250e-06, 8.8194e-07, 2.0192e-09, 4.7803e-07,\n",
              "            3.7204e-07, 1.0261e-04, 1.1068e-05, 8.1715e-07, 1.0798e-06, 6.8213e-06,\n",
              "            2.8565e-08, 6.8513e-07],\n",
              "           [1.0000e+00, 3.5256e-07, 5.7005e-10, 5.2089e-06, 3.7594e-07, 8.1015e-10,\n",
              "            4.8905e-08, 1.4668e-09, 6.7533e-07, 1.3644e-06, 4.2790e-05, 4.5824e-07,\n",
              "            7.2854e-05, 1.2162e-05, 3.8070e-07, 2.0436e-07, 2.2027e-07, 1.5002e-04,\n",
              "            1.0234e-05, 5.2358e-07, 4.6150e-05, 2.3364e-05, 1.6147e-06, 2.9246e-07,\n",
              "            1.8833e-06, 1.0197e-05, 1.3523e-03, 3.3143e-05, 3.2310e-07, 1.8251e-07,\n",
              "            1.4023e-05, 4.9683e-04, 2.9925e-07, 2.2326e-08, 4.8635e-05, 4.6629e-07,\n",
              "            2.0223e-06, 6.4472e-06, 7.4074e-02, 5.1168e-07, 3.1866e-11, 1.0891e-08,\n",
              "            8.7509e-07, 5.0348e-05, 1.1027e-07, 1.3484e-05, 3.0058e-06, 1.7844e-05,\n",
              "            2.5166e-09, 2.1638e-07],\n",
              "           [1.0000e+00, 1.4056e-09, 3.0522e-09, 2.1485e-08, 4.8683e-08, 2.6269e-12,\n",
              "            2.7285e-10, 2.7026e-14, 3.4810e-10, 3.8021e-09, 9.8293e-07, 1.0249e-06,\n",
              "            1.4698e-09, 1.0008e-06, 4.3928e-10, 1.9569e-09, 1.1695e-10, 4.1760e-13,\n",
              "            3.0049e-08, 8.0134e-09, 6.1933e-06, 4.1460e-05, 2.6346e-08, 1.6655e-08,\n",
              "            1.1041e-05, 2.8839e-08, 4.7489e-07, 2.5428e-06, 3.7030e-08, 2.0200e-03,\n",
              "            4.3389e-09, 2.5152e-06, 1.0794e-09, 1.3180e-09, 2.7027e-04, 2.3029e-09,\n",
              "            7.8901e-07, 8.6194e-08, 4.1837e-03, 5.4308e-08, 2.7193e-12, 3.5312e-09,\n",
              "            3.4686e-09, 6.8745e-05, 3.2359e-07, 1.4459e-07, 3.3484e-09, 3.9314e-09,\n",
              "            1.1291e-09, 4.4069e-05],\n",
              "           [9.9995e-01, 1.6036e-07, 2.6521e-09, 3.0359e-06, 6.0814e-07, 1.1189e-10,\n",
              "            1.2414e-08, 1.8314e-11, 1.9433e-07, 3.5336e-05, 2.1436e-07, 1.9489e-06,\n",
              "            1.4876e-08, 8.1911e-06, 1.4327e-09, 2.6813e-09, 6.5472e-08, 6.9205e-10,\n",
              "            1.9582e-05, 2.8429e-05, 4.3902e-08, 2.6484e-05, 2.7483e-08, 8.4729e-07,\n",
              "            2.4917e-05, 4.0470e-07, 3.9544e-08, 2.1863e-08, 2.2771e-05, 4.2784e-05,\n",
              "            6.7004e-11, 1.9020e-05, 1.1714e-11, 1.3845e-10, 2.0696e-06, 4.3964e-09,\n",
              "            5.2569e-07, 3.6211e-09, 3.0165e-07, 2.6087e-08, 2.9208e-12, 3.0816e-09,\n",
              "            4.1911e-10, 1.2977e-03, 1.5631e-06, 6.1408e-09, 3.0134e-10, 1.7059e-08,\n",
              "            1.4667e-08, 5.2817e-08]], device='cuda:0', grad_fn=<CatBackward>)],\n",
              "  7: [tensor([[8.5760e-01, 1.9248e-03, 1.7344e-03, 1.3639e-02, 5.0408e-03, 4.4330e-03,\n",
              "            5.3192e-03, 4.5892e-03, 1.1188e-02, 1.5671e-01, 4.2374e-02, 4.5401e-04,\n",
              "            1.2050e-02, 3.5256e-02, 1.2727e-03, 9.1030e-03, 4.0230e-04, 1.8815e-03,\n",
              "            3.6585e-03, 1.6254e-02, 3.7635e-03, 2.1353e-02, 1.0105e-03, 1.9524e-02,\n",
              "            5.1913e-03, 1.2795e-04, 9.0202e-03, 4.3555e-04, 8.7874e-04, 3.5810e-03,\n",
              "            3.2787e-03, 2.1100e-02, 5.1584e-04, 3.2044e-05, 4.6765e-04, 1.1751e-03,\n",
              "            1.7682e-04, 6.6708e-03, 1.0755e-01, 1.5381e-04, 8.3686e-05, 3.0753e-04,\n",
              "            1.1905e-02, 1.3844e-02, 8.8655e-04, 9.2013e-04, 1.8891e-04, 9.9015e-05,\n",
              "            2.0830e-03, 4.0536e-03, 1.2056e-04, 1.1473e-02, 2.7865e-05, 3.2020e-06,\n",
              "            4.7346e-05, 6.7149e-03, 1.7053e-05, 1.4681e-03, 1.1710e-03, 5.8252e-03,\n",
              "            1.2907e-05, 3.2088e-07, 3.0842e-05, 3.8017e-07, 4.1295e-04, 1.3378e-07,\n",
              "            2.4366e-05, 6.8855e-06, 4.9339e-03, 1.1752e-04],\n",
              "           [9.9196e-01, 7.5620e-04, 1.0928e-02, 2.5095e-03, 3.1531e-03, 1.1345e-03,\n",
              "            5.0975e-03, 6.0698e-04, 2.9537e-03, 9.2010e-03, 1.1917e-02, 5.0654e-04,\n",
              "            3.1778e-03, 1.2694e-03, 3.2910e-04, 3.3381e-03, 2.0979e-03, 2.3080e-03,\n",
              "            2.9680e-03, 6.0879e-04, 4.7353e-03, 2.4771e-04, 4.3335e-03, 1.8098e-04,\n",
              "            3.2428e-04, 1.2089e-05, 7.0763e-04, 7.8874e-04, 1.0622e-04, 2.4916e-04,\n",
              "            1.4875e-04, 2.1752e-04, 9.6084e-05, 2.1288e-05, 5.0321e-05, 1.9548e-04,\n",
              "            1.5176e-04, 2.7719e-04, 8.6102e-03, 2.8327e-04, 1.1106e-04, 3.3338e-06,\n",
              "            1.6502e-04, 8.0039e-04, 6.1670e-05, 8.9011e-05, 5.1853e-05, 2.7351e-05,\n",
              "            1.2829e-05, 6.5630e-05, 1.6897e-05, 3.1218e-05, 4.3217e-05, 1.9598e-06,\n",
              "            3.3680e-05, 2.8326e-05, 6.4276e-07, 2.3700e-05, 7.9437e-05, 3.2295e-06,\n",
              "            2.7235e-10, 1.3017e-12, 4.2544e-06, 2.8805e-07, 1.0254e-06, 1.1045e-07,\n",
              "            1.4271e-05, 4.6409e-09, 2.3543e-07, 9.5317e-06],\n",
              "           [9.7987e-01, 7.8994e-04, 6.6462e-03, 1.4080e-03, 5.5530e-03, 8.9248e-04,\n",
              "            1.6441e-02, 1.1104e-02, 6.5453e-03, 2.1828e-02, 1.2196e-02, 3.9546e-04,\n",
              "            2.7967e-02, 1.9972e-03, 2.7939e-03, 1.9343e-02, 4.4704e-03, 3.2636e-03,\n",
              "            1.5653e-03, 2.4107e-03, 1.3616e-02, 2.5608e-03, 3.5256e-03, 2.4466e-04,\n",
              "            4.3659e-03, 1.8571e-04, 1.1748e-03, 1.1705e-03, 1.6976e-03, 3.7191e-04,\n",
              "            2.2363e-03, 6.8852e-04, 2.0554e-04, 9.4437e-06, 9.6111e-05, 1.1875e-03,\n",
              "            1.0833e-03, 3.7315e-03, 1.0577e-01, 3.9400e-04, 1.4948e-03, 1.7676e-05,\n",
              "            1.9132e-02, 1.2201e-03, 5.4047e-05, 6.4156e-04, 1.1380e-03, 6.5088e-04,\n",
              "            1.2250e-05, 6.9512e-05, 9.0150e-06, 3.3984e-04, 1.7454e-04, 2.3358e-05,\n",
              "            1.8349e-03, 2.3101e-05, 5.3181e-05, 3.2365e-04, 1.0494e-03, 1.0769e-04,\n",
              "            8.3343e-08, 1.9814e-09, 1.3861e-04, 1.0134e-06, 1.1889e-05, 1.5044e-06,\n",
              "            1.1040e-05, 2.2032e-07, 2.4341e-06, 2.7393e-04],\n",
              "           [9.9230e-01, 4.7193e-04, 1.9076e-03, 4.2292e-03, 8.5849e-04, 1.8196e-03,\n",
              "            4.9086e-03, 3.0133e-03, 8.9093e-04, 1.8487e-02, 1.0243e-02, 2.8531e-04,\n",
              "            2.0719e-03, 3.3124e-03, 7.7414e-04, 1.6918e-03, 1.0916e-04, 4.7244e-03,\n",
              "            5.3392e-03, 5.7113e-03, 3.0259e-04, 5.8216e-03, 3.7759e-03, 3.4619e-03,\n",
              "            1.0404e-03, 8.0286e-06, 1.0099e-03, 2.1403e-04, 3.6702e-04, 1.2176e-04,\n",
              "            2.3793e-04, 2.7118e-04, 9.8258e-06, 4.3389e-05, 9.8251e-05, 3.5039e-04,\n",
              "            8.9767e-05, 9.8752e-04, 3.9440e-02, 6.1598e-05, 1.4125e-06, 2.8926e-05,\n",
              "            6.3514e-04, 2.9644e-05, 6.8913e-04, 2.5166e-04, 1.0258e-04, 5.5264e-05,\n",
              "            6.3620e-05, 4.6685e-05, 4.5784e-06, 2.9004e-04, 1.6681e-06, 5.5535e-05,\n",
              "            1.5027e-06, 2.7555e-04, 2.0109e-06, 9.5571e-05, 8.1740e-04, 2.5507e-05,\n",
              "            1.2645e-06, 3.2956e-10, 6.5477e-08, 3.4329e-05, 2.4663e-08, 1.2731e-07,\n",
              "            3.3983e-05, 6.4390e-10, 5.4519e-06, 4.4500e-05],\n",
              "           [9.0832e-01, 1.8994e-03, 1.0931e-02, 5.4762e-03, 4.2715e-03, 5.2758e-03,\n",
              "            2.7717e-02, 2.8136e-02, 1.4077e-02, 1.3756e-02, 3.5753e-02, 2.1862e-03,\n",
              "            6.3139e-03, 4.7063e-03, 2.3476e-03, 2.3206e-02, 2.0785e-03, 2.6589e-02,\n",
              "            9.0646e-03, 2.6196e-02, 8.1270e-03, 5.8861e-03, 5.8227e-03, 4.9764e-03,\n",
              "            6.4401e-03, 1.0649e-04, 3.0478e-02, 7.5844e-03, 9.8604e-04, 7.0881e-04,\n",
              "            7.3741e-03, 3.8665e-03, 3.8985e-04, 3.6041e-04, 8.1023e-04, 3.3049e-03,\n",
              "            7.9509e-04, 1.1444e-03, 4.3053e-02, 3.9433e-03, 2.2413e-04, 2.1553e-04,\n",
              "            1.5240e-03, 1.6055e-03, 1.9894e-03, 1.1781e-02, 1.4410e-03, 1.2348e-03,\n",
              "            1.5292e-03, 2.5591e-03, 4.8912e-04, 8.5357e-04, 3.4488e-04, 1.9332e-04,\n",
              "            2.2633e-04, 3.7053e-04, 1.0955e-04, 1.1939e-02, 3.0029e-03, 1.8780e-03,\n",
              "            1.3637e-04, 1.1832e-06, 3.8453e-05, 2.7663e-06, 5.3933e-05, 3.5091e-06,\n",
              "            5.0493e-04, 4.4092e-06, 5.1354e-05, 1.8272e-04],\n",
              "           [9.8885e-01, 1.3727e-03, 5.7090e-03, 3.1567e-03, 8.5499e-03, 8.2825e-04,\n",
              "            6.0071e-03, 3.9102e-03, 3.4022e-03, 7.8828e-03, 7.0500e-03, 1.1436e-04,\n",
              "            5.3575e-03, 5.7856e-03, 1.2795e-03, 3.8792e-03, 8.1005e-04, 4.5316e-03,\n",
              "            1.5914e-03, 4.9084e-03, 5.8578e-04, 7.9189e-03, 1.3265e-03, 2.2464e-04,\n",
              "            1.8746e-03, 3.4102e-05, 5.5989e-03, 4.1477e-04, 2.3085e-04, 3.5364e-04,\n",
              "            4.0737e-03, 5.2335e-04, 2.8245e-05, 9.5003e-06, 7.7207e-04, 1.3983e-04,\n",
              "            1.9178e-04, 3.0193e-04, 3.5936e-02, 8.0959e-05, 1.0354e-05, 3.6650e-05,\n",
              "            8.6268e-04, 6.4094e-04, 1.9247e-04, 9.8966e-05, 1.3706e-04, 6.4578e-05,\n",
              "            6.9230e-06, 8.1063e-05, 5.7618e-05, 5.5531e-04, 5.0996e-07, 2.6463e-06,\n",
              "            1.4112e-05, 3.4213e-06, 2.3674e-06, 1.3967e-04, 1.0805e-04, 2.3425e-05,\n",
              "            4.1485e-09, 9.7776e-11, 3.5177e-07, 3.8704e-07, 1.1017e-07, 4.2630e-08,\n",
              "            8.0340e-06, 2.1118e-08, 1.5624e-06, 6.3853e-06],\n",
              "           [9.8954e-01, 2.8939e-04, 1.0741e-02, 8.2862e-03, 1.1452e-03, 7.7632e-04,\n",
              "            1.8467e-02, 1.6264e-03, 1.3643e-03, 4.3277e-03, 1.4423e-02, 6.5372e-04,\n",
              "            2.3691e-03, 6.1440e-03, 2.0752e-04, 7.1565e-03, 8.4495e-04, 1.2026e-03,\n",
              "            3.7936e-03, 6.9908e-03, 3.9402e-04, 2.3372e-03, 2.0401e-03, 6.5189e-04,\n",
              "            4.2087e-04, 6.3318e-06, 9.5149e-04, 7.5711e-04, 1.3145e-03, 9.7235e-05,\n",
              "            1.4780e-04, 3.3642e-04, 1.9338e-05, 5.8517e-05, 9.2715e-05, 2.5904e-04,\n",
              "            5.1729e-04, 2.5753e-04, 1.9693e-02, 8.1326e-04, 1.0256e-05, 3.5912e-06,\n",
              "            2.3619e-04, 7.4012e-05, 1.1063e-03, 3.8132e-04, 3.0462e-04, 4.8362e-05,\n",
              "            1.1147e-05, 1.0587e-04, 8.9062e-07, 2.2201e-04, 1.7328e-05, 3.3133e-06,\n",
              "            1.5594e-05, 2.9086e-05, 3.2999e-06, 6.4217e-05, 7.4911e-04, 4.4373e-05,\n",
              "            5.2756e-09, 3.7834e-10, 4.7264e-07, 3.8912e-07, 1.7068e-07, 9.2233e-09,\n",
              "            2.9917e-03, 1.0651e-08, 5.8602e-07, 3.6079e-06],\n",
              "           [9.8424e-01, 9.0365e-04, 2.4445e-03, 1.8136e-03, 8.7461e-03, 1.0679e-03,\n",
              "            6.1520e-03, 2.3689e-03, 4.0395e-03, 2.2588e-02, 5.8938e-02, 4.3099e-04,\n",
              "            3.9421e-02, 5.0958e-03, 5.6382e-04, 1.9265e-03, 3.3991e-04, 2.3553e-03,\n",
              "            2.9025e-03, 2.7316e-04, 1.4999e-03, 6.6856e-04, 5.7405e-04, 2.5880e-03,\n",
              "            8.2976e-04, 5.3446e-05, 5.0178e-03, 5.0660e-04, 1.1517e-04, 9.6849e-04,\n",
              "            1.0235e-03, 9.2272e-04, 2.1818e-04, 2.4500e-05, 7.4945e-04, 9.9555e-05,\n",
              "            1.1687e-04, 1.3989e-03, 2.0628e-01, 3.2720e-05, 6.5805e-06, 3.4260e-05,\n",
              "            4.2007e-03, 4.7242e-03, 2.3898e-04, 1.3284e-03, 3.1585e-04, 1.2887e-04,\n",
              "            1.7730e-05, 3.7262e-04, 8.2502e-05, 3.7296e-03, 1.7709e-06, 1.7870e-06,\n",
              "            1.0872e-05, 3.7882e-04, 4.2823e-06, 8.2043e-04, 2.2338e-04, 7.7749e-04,\n",
              "            3.2136e-08, 2.5192e-09, 6.4936e-05, 8.7478e-07, 2.0086e-05, 5.7712e-07,\n",
              "            4.6454e-06, 2.9930e-08, 7.0172e-03, 1.5706e-05],\n",
              "           [9.8548e-01, 1.9650e-04, 3.6023e-03, 5.2566e-03, 1.5636e-03, 2.3546e-03,\n",
              "            2.1571e-03, 5.7070e-04, 4.1221e-04, 1.8941e-02, 1.0663e-02, 3.7399e-04,\n",
              "            2.3593e-03, 2.1519e-03, 1.4320e-04, 2.7124e-03, 7.0651e-04, 5.9558e-04,\n",
              "            8.0140e-04, 1.2325e-03, 3.5172e-04, 2.1321e-03, 1.5162e-03, 3.3066e-04,\n",
              "            5.2167e-04, 5.1263e-06, 8.0268e-04, 2.7849e-04, 7.5599e-05, 3.6317e-04,\n",
              "            1.5916e-04, 4.3022e-04, 1.1486e-05, 5.5644e-05, 9.2545e-05, 2.6607e-04,\n",
              "            9.4423e-05, 2.8327e-04, 1.7717e-02, 4.2204e-05, 3.7862e-06, 4.4863e-06,\n",
              "            3.4057e-04, 2.1663e-04, 2.4661e-04, 4.8961e-04, 8.3549e-06, 5.6354e-06,\n",
              "            1.6292e-05, 3.4031e-04, 1.1413e-06, 1.7213e-04, 3.0257e-06, 2.2644e-05,\n",
              "            6.4829e-06, 2.0097e-05, 4.8991e-07, 4.9899e-05, 5.1483e-05, 9.4590e-05,\n",
              "            3.5636e-10, 1.8385e-10, 1.7914e-07, 9.5554e-07, 8.5140e-08, 7.4000e-09,\n",
              "            1.4123e-04, 6.7958e-09, 8.0634e-06, 5.8017e-05],\n",
              "           [9.9192e-01, 5.6493e-04, 4.9520e-03, 1.4429e-03, 2.6767e-03, 1.4205e-03,\n",
              "            7.8564e-03, 5.4979e-04, 3.1560e-04, 9.1379e-03, 2.7823e-03, 3.8627e-04,\n",
              "            3.7398e-03, 1.5782e-03, 1.3546e-04, 1.5748e-03, 1.2137e-03, 6.5007e-04,\n",
              "            3.3074e-03, 9.6911e-04, 5.8533e-04, 1.1540e-03, 4.0835e-03, 9.9595e-05,\n",
              "            4.9455e-04, 4.7793e-06, 9.1118e-05, 1.1288e-04, 3.1804e-04, 3.3429e-04,\n",
              "            3.4498e-05, 8.3799e-05, 1.7857e-05, 5.6389e-05, 5.7649e-05, 5.1703e-04,\n",
              "            2.9302e-04, 8.6357e-05, 2.2601e-02, 6.2423e-05, 9.0900e-06, 1.2600e-06,\n",
              "            9.1165e-05, 7.0348e-05, 3.5854e-04, 2.5992e-05, 2.8807e-05, 5.9679e-05,\n",
              "            5.6441e-06, 3.0570e-05, 7.9625e-07, 1.0975e-04, 1.6818e-05, 2.5030e-06,\n",
              "            6.5377e-07, 3.9032e-06, 2.8541e-06, 2.3156e-05, 3.1662e-05, 6.4762e-06,\n",
              "            1.4215e-08, 1.1911e-11, 1.8001e-06, 4.6508e-08, 1.8522e-08, 1.2346e-09,\n",
              "            4.3514e-05, 1.0627e-08, 1.5725e-07, 1.8695e-06]], device='cuda:0',\n",
              "          grad_fn=<SigmoidBackward>),\n",
              "   tensor([[9.9968e-01, 1.7206e-05, 1.4568e-07, 8.4414e-05, 1.2062e-05, 3.6473e-07,\n",
              "            1.6839e-06, 3.1264e-07, 2.4113e-04, 1.3128e-04, 2.6141e-03, 2.4215e-07,\n",
              "            1.4479e-06, 9.8740e-02, 6.1901e-06, 1.2801e-06, 1.6783e-07, 5.4892e-06,\n",
              "            1.9132e-06, 1.2049e-04, 1.4893e-05, 4.3437e-03, 1.6282e-05, 4.9748e-03,\n",
              "            1.3588e-03, 1.9623e-05, 5.8514e-05, 4.5638e-06, 3.4070e-06, 2.5184e-05,\n",
              "            5.5928e-08, 5.2856e-03, 4.8725e-08, 5.2468e-09, 2.4018e-05, 1.0373e-08,\n",
              "            2.3106e-07, 2.3386e-04, 2.7388e-03, 4.0262e-07, 3.0641e-09, 1.3008e-06,\n",
              "            8.4487e-05, 3.8236e-04, 6.9968e-06, 1.8346e-06, 2.4850e-07, 2.3220e-07,\n",
              "            1.6114e-06, 1.9207e-04, 4.0428e-05, 2.4794e-03, 2.3022e-07, 3.2831e-08,\n",
              "            2.5402e-06, 2.1909e-03, 4.7453e-08, 3.1543e-05, 1.7843e-04, 6.0016e-04],\n",
              "           [1.0000e+00, 4.9232e-08, 1.8345e-08, 8.4629e-08, 5.1455e-08, 7.2885e-11,\n",
              "            1.8108e-08, 1.9561e-11, 7.5899e-07, 4.4762e-07, 2.1964e-04, 1.7669e-06,\n",
              "            6.5824e-07, 9.2186e-05, 2.7546e-07, 2.7400e-06, 3.2523e-07, 5.2348e-09,\n",
              "            1.6319e-05, 9.0610e-05, 6.7801e-05, 3.1289e-06, 2.6579e-07, 3.0629e-07,\n",
              "            3.3797e-04, 1.3052e-06, 3.7455e-07, 4.4167e-07, 3.8998e-07, 7.2200e-07,\n",
              "            6.2504e-08, 2.1888e-05, 1.1396e-08, 3.7373e-09, 1.1853e-06, 2.0932e-08,\n",
              "            7.0879e-07, 1.2781e-05, 6.0520e-04, 1.8080e-05, 6.8710e-10, 1.5846e-07,\n",
              "            5.2232e-08, 1.1324e-02, 2.8142e-08, 4.4746e-09, 1.1562e-08, 2.8121e-07,\n",
              "            7.8335e-10, 2.4104e-08, 3.1458e-07, 4.0459e-05, 8.3169e-06, 1.1347e-07,\n",
              "            2.6894e-06, 1.5514e-06, 1.0831e-09, 3.2044e-06, 2.1133e-07, 2.0980e-09],\n",
              "           [1.0000e+00, 1.4694e-08, 1.0133e-09, 1.2285e-05, 1.8761e-06, 1.5885e-09,\n",
              "            2.7029e-08, 5.5520e-09, 3.9986e-07, 1.0920e-06, 2.1007e-07, 1.6859e-08,\n",
              "            2.5917e-05, 1.7853e-08, 1.4163e-06, 9.4081e-05, 4.5084e-09, 2.9886e-10,\n",
              "            6.8294e-10, 2.2616e-10, 1.1561e-03, 7.0847e-04, 9.1924e-06, 4.5267e-07,\n",
              "            6.9889e-05, 2.5238e-05, 7.5730e-06, 9.2215e-05, 8.0055e-06, 2.1653e-06,\n",
              "            6.5114e-05, 9.5950e-04, 7.4653e-09, 1.4009e-08, 8.6728e-06, 4.5994e-07,\n",
              "            8.1604e-06, 3.5153e-03, 3.6552e-03, 4.5380e-06, 1.1563e-07, 1.2597e-07,\n",
              "            3.4687e-04, 1.5343e-05, 3.0789e-07, 8.7786e-06, 7.4151e-06, 1.0214e-05,\n",
              "            3.4308e-08, 8.5246e-06, 1.1075e-06, 1.2720e-04, 3.1545e-06, 2.3391e-06,\n",
              "            1.1398e-04, 1.0813e-04, 2.5281e-06, 8.3600e-05, 4.2243e-06, 2.2473e-07],\n",
              "           [1.0000e+00, 2.2976e-09, 9.5791e-10, 1.6321e-08, 2.7984e-10, 1.2582e-11,\n",
              "            3.5014e-09, 4.6045e-12, 3.4037e-08, 4.0854e-09, 1.5339e-04, 1.5164e-07,\n",
              "            3.6675e-07, 3.4443e-05, 1.7264e-07, 9.0294e-09, 1.0631e-08, 7.7198e-10,\n",
              "            1.6304e-04, 2.9996e-06, 1.6512e-09, 1.5236e-05, 3.3539e-08, 4.3087e-05,\n",
              "            6.3458e-06, 5.5138e-07, 5.6833e-08, 2.0346e-08, 4.8090e-07, 1.5130e-10,\n",
              "            2.9775e-08, 2.1385e-06, 3.0356e-10, 8.8338e-10, 2.9066e-06, 6.1674e-09,\n",
              "            9.7521e-07, 7.2482e-07, 3.1162e-03, 8.5989e-07, 3.9652e-12, 1.3471e-07,\n",
              "            6.8470e-07, 1.4679e-07, 2.3124e-06, 9.7684e-09, 2.0764e-07, 1.5219e-07,\n",
              "            1.7096e-09, 7.2666e-09, 1.4197e-09, 4.4462e-06, 3.4561e-10, 5.6571e-06,\n",
              "            5.2054e-08, 2.6149e-07, 8.4463e-10, 1.5666e-05, 8.4116e-05, 3.8859e-08],\n",
              "           [9.9995e-01, 7.0282e-07, 6.4608e-05, 1.7178e-05, 5.8516e-06, 1.1210e-07,\n",
              "            2.0330e-06, 1.6241e-07, 3.1625e-06, 1.1837e-06, 7.8761e-04, 4.8970e-07,\n",
              "            6.7472e-06, 9.6940e-07, 1.0227e-06, 2.2291e-06, 2.8287e-05, 5.6318e-05,\n",
              "            8.4620e-04, 3.2112e-04, 1.5857e-02, 1.8949e-06, 2.4766e-06, 1.1186e-03,\n",
              "            2.0443e-04, 6.0270e-07, 8.7567e-05, 7.7783e-05, 8.2623e-07, 6.1146e-08,\n",
              "            2.3263e-03, 2.9905e-06, 5.4144e-09, 3.2838e-09, 5.8866e-06, 1.1277e-07,\n",
              "            1.2968e-06, 1.2475e-05, 9.4444e-04, 3.7956e-05, 1.4509e-07, 2.4816e-07,\n",
              "            5.3636e-06, 3.6281e-05, 2.5063e-06, 5.6124e-03, 7.1182e-06, 4.5980e-06,\n",
              "            2.6416e-06, 4.2101e-04, 1.3581e-06, 8.8518e-06, 6.0118e-05, 9.7585e-06,\n",
              "            5.3817e-07, 5.7680e-06, 3.4097e-08, 1.6159e-03, 1.6987e-04, 7.6961e-05],\n",
              "           [1.0000e+00, 1.6764e-08, 2.0333e-09, 5.0270e-06, 6.3536e-09, 7.3294e-09,\n",
              "            5.6408e-10, 2.6849e-10, 2.1498e-08, 8.7252e-08, 3.4000e-07, 1.3743e-07,\n",
              "            1.8756e-08, 1.5674e-07, 4.3994e-06, 3.8385e-08, 1.1679e-07, 1.3176e-08,\n",
              "            4.7601e-08, 5.9795e-06, 8.2634e-07, 3.3670e-03, 1.1737e-07, 7.4426e-06,\n",
              "            1.0279e-03, 1.6013e-05, 7.4593e-05, 7.5997e-07, 2.9784e-05, 1.7308e-06,\n",
              "            1.6536e-06, 2.1980e-05, 2.5333e-09, 6.7790e-09, 9.6094e-04, 2.6920e-08,\n",
              "            1.0421e-07, 1.2366e-05, 3.5937e-04, 1.3101e-06, 5.9223e-12, 1.0582e-06,\n",
              "            5.0207e-07, 3.1304e-04, 7.4096e-07, 1.2826e-09, 3.7476e-07, 1.6902e-07,\n",
              "            7.6546e-09, 5.0803e-07, 8.8897e-08, 5.6808e-05, 1.0511e-09, 1.8759e-06,\n",
              "            1.1518e-07, 7.2294e-08, 1.3147e-08, 1.0474e-05, 4.3657e-06, 7.3055e-07],\n",
              "           [1.0000e+00, 7.1896e-10, 1.1613e-09, 1.3308e-08, 2.8522e-10, 8.8830e-13,\n",
              "            1.7202e-08, 3.8996e-14, 2.5088e-10, 4.6892e-09, 1.1360e-07, 1.6509e-06,\n",
              "            1.0352e-08, 3.4656e-07, 3.0760e-10, 1.4912e-11, 2.1520e-09, 6.1863e-12,\n",
              "            9.1983e-07, 6.0009e-07, 1.8064e-08, 6.6521e-07, 1.5204e-05, 4.6068e-08,\n",
              "            3.0187e-05, 4.2122e-07, 1.5096e-08, 3.0433e-08, 9.8407e-07, 1.2572e-08,\n",
              "            1.4075e-09, 2.5259e-05, 1.2667e-10, 3.3238e-09, 4.4602e-06, 3.2124e-06,\n",
              "            4.1917e-05, 4.9502e-08, 1.2138e-04, 6.2943e-07, 2.9188e-10, 4.0393e-07,\n",
              "            9.1621e-08, 4.0542e-05, 4.0177e-05, 9.7128e-07, 4.6288e-07, 2.4331e-06,\n",
              "            9.8961e-08, 7.0153e-07, 1.5918e-09, 1.0881e-05, 1.6008e-06, 7.7525e-07,\n",
              "            3.8078e-07, 1.2301e-07, 9.0307e-09, 2.7103e-06, 1.9539e-05, 7.9116e-08],\n",
              "           [1.0000e+00, 5.5563e-07, 1.3321e-09, 1.7945e-06, 1.0319e-07, 6.2541e-10,\n",
              "            9.0350e-08, 1.1229e-09, 3.7719e-07, 6.4339e-07, 9.0582e-05, 8.6594e-07,\n",
              "            6.6746e-04, 3.4156e-05, 2.0909e-07, 1.6511e-07, 4.1650e-08, 3.8062e-06,\n",
              "            1.7425e-05, 3.2503e-07, 3.3499e-06, 1.6568e-05, 1.0242e-06, 3.5275e-07,\n",
              "            3.1746e-06, 2.2717e-05, 3.0823e-03, 7.4670e-06, 1.1792e-06, 1.9805e-07,\n",
              "            2.7259e-06, 2.2173e-04, 2.0983e-08, 6.1300e-09, 1.9711e-05, 4.8493e-08,\n",
              "            1.4497e-06, 8.6237e-07, 3.8299e-02, 9.2404e-08, 1.4208e-10, 2.2442e-09,\n",
              "            7.2001e-05, 2.9413e-05, 1.4165e-06, 2.0306e-06, 2.0595e-05, 3.6205e-06,\n",
              "            3.0029e-09, 2.3811e-06, 3.1844e-07, 5.7643e-02, 1.0473e-08, 3.6804e-08,\n",
              "            3.0536e-08, 3.3364e-05, 3.9072e-08, 2.0740e-04, 7.0394e-05, 1.1587e-06],\n",
              "           [9.9999e-01, 2.2219e-08, 1.9896e-09, 2.8420e-06, 2.3417e-06, 1.0594e-09,\n",
              "            7.0712e-10, 2.5895e-11, 6.9810e-08, 1.4510e-05, 2.0317e-07, 2.3722e-08,\n",
              "            1.3871e-09, 1.2557e-06, 9.0635e-09, 1.8267e-08, 4.9185e-08, 1.3438e-10,\n",
              "            4.0021e-07, 7.5835e-06, 4.2334e-07, 9.2314e-06, 3.3440e-08, 8.6371e-10,\n",
              "            3.5014e-06, 1.2824e-07, 1.2819e-07, 4.2122e-07, 3.6333e-09, 8.9731e-05,\n",
              "            1.5174e-08, 5.3283e-07, 1.1248e-11, 3.1840e-10, 5.1602e-06, 3.3125e-09,\n",
              "            5.7798e-07, 9.8888e-07, 2.7515e-04, 1.5437e-08, 3.4590e-11, 1.4438e-09,\n",
              "            1.4081e-07, 4.6058e-05, 4.0230e-07, 1.0568e-08, 9.8126e-11, 3.8158e-10,\n",
              "            2.2561e-09, 7.5536e-07, 1.5315e-08, 1.5854e-04, 1.6941e-07, 4.7005e-07,\n",
              "            3.8005e-08, 4.1600e-06, 3.5966e-10, 6.2817e-07, 6.3055e-09, 4.8681e-07],\n",
              "           [1.0000e+00, 3.6234e-08, 8.3495e-08, 8.7862e-08, 2.9489e-08, 2.6652e-10,\n",
              "            4.8580e-09, 2.1569e-12, 5.9351e-09, 2.0739e-07, 3.1349e-08, 1.4274e-06,\n",
              "            4.2774e-09, 5.7307e-07, 3.0923e-09, 6.1393e-08, 8.1212e-08, 9.6838e-11,\n",
              "            1.4631e-06, 3.4028e-07, 2.7367e-08, 2.1152e-06, 5.8077e-09, 1.2873e-07,\n",
              "            4.9948e-06, 6.9965e-07, 1.1300e-09, 3.6716e-08, 1.8298e-06, 2.1394e-06,\n",
              "            1.0814e-10, 2.9016e-07, 2.4071e-11, 5.9327e-09, 1.2582e-06, 8.3965e-09,\n",
              "            3.8752e-07, 1.4718e-07, 7.4282e-06, 3.7510e-07, 3.3430e-11, 1.1491e-08,\n",
              "            2.2171e-09, 5.2087e-05, 2.1325e-06, 4.1989e-09, 7.8486e-09, 8.6940e-08,\n",
              "            1.1132e-09, 6.8157e-08, 8.8158e-10, 8.7358e-07, 5.1818e-08, 6.1939e-08,\n",
              "            2.7854e-09, 3.6010e-08, 7.9968e-09, 1.6058e-06, 4.2558e-08, 4.5688e-09]],\n",
              "          device='cuda:0', grad_fn=<CatBackward>)],\n",
              "  8: [tensor([[9.4308e-01, 1.6969e-03, 5.9912e-03, 7.7871e-03, 7.6981e-03, 4.0134e-03,\n",
              "            5.3719e-03, 9.4514e-03, 5.6826e-03, 8.1009e-02, 9.9040e-02, 1.0702e-03,\n",
              "            9.7548e-03, 1.4392e-02, 4.4638e-03, 7.5678e-03, 8.5898e-04, 2.4414e-03,\n",
              "            3.7499e-03, 7.4997e-03, 3.0166e-03, 1.1859e-02, 3.1481e-03, 5.3400e-03,\n",
              "            6.0824e-03, 3.1031e-04, 5.7328e-03, 4.7787e-04, 1.4566e-03, 1.9095e-03,\n",
              "            1.7848e-03, 3.4384e-03, 4.2011e-04, 2.9418e-04, 4.5399e-04, 1.2405e-03,\n",
              "            5.8337e-04, 7.6111e-03, 2.5756e-01, 1.3418e-04, 9.7953e-05, 3.5410e-04,\n",
              "            2.0313e-02, 3.7419e-03, 8.7271e-04, 2.8698e-03, 4.9797e-04, 1.5055e-04,\n",
              "            9.4158e-04, 1.0160e-03, 2.8769e-04, 2.3280e-03, 2.7061e-04, 3.2206e-04,\n",
              "            1.5732e-04, 2.1350e-03, 2.1308e-05, 5.3195e-04, 1.9381e-03, 8.0356e-03,\n",
              "            2.3347e-04, 1.1151e-05, 1.3145e-04, 2.7028e-05, 3.1019e-04, 3.1652e-05,\n",
              "            8.9817e-05, 1.0662e-04, 7.3734e-03, 4.7453e-04, 7.4809e-07, 1.3428e-07,\n",
              "            1.3304e-02, 2.6540e-07, 1.6141e-03, 3.6877e-09, 2.3556e-06, 1.8352e-05,\n",
              "            1.3258e-07, 1.4701e-04],\n",
              "           [9.8614e-01, 1.3109e-03, 2.3581e-02, 2.8633e-03, 3.4635e-03, 5.4196e-04,\n",
              "            1.1078e-02, 2.6177e-03, 8.0909e-03, 1.7301e-02, 2.3387e-02, 7.5468e-04,\n",
              "            1.3108e-02, 2.3864e-03, 1.0746e-03, 9.3913e-03, 2.5175e-03, 5.1850e-03,\n",
              "            3.3855e-03, 1.8511e-03, 7.6959e-03, 4.6336e-04, 2.0646e-02, 3.1522e-04,\n",
              "            7.1016e-04, 1.7143e-04, 4.0537e-03, 2.6275e-03, 4.9364e-04, 4.5354e-04,\n",
              "            1.7128e-03, 5.4326e-04, 6.8678e-04, 1.1202e-04, 2.1386e-04, 2.7407e-04,\n",
              "            1.2437e-03, 1.0241e-03, 3.0655e-02, 1.2360e-03, 2.2197e-03, 5.1814e-05,\n",
              "            4.6510e-04, 1.4973e-03, 1.1095e-04, 1.3456e-03, 1.5145e-03, 2.9357e-04,\n",
              "            2.3912e-05, 2.1774e-04, 4.7227e-04, 8.9019e-05, 3.2083e-04, 1.0866e-04,\n",
              "            3.2388e-03, 2.4704e-05, 2.4539e-05, 3.5199e-04, 1.0930e-03, 6.0589e-05,\n",
              "            5.1857e-07, 4.1612e-07, 1.8316e-04, 1.5397e-06, 1.0723e-04, 9.3734e-05,\n",
              "            4.7403e-04, 8.1533e-06, 1.2129e-05, 8.1942e-05, 2.6935e-06, 2.1854e-07,\n",
              "            1.1101e-05, 5.8804e-06, 8.2557e-09, 1.4009e-08, 5.9229e-07, 7.0805e-05,\n",
              "            1.2628e-09, 1.6259e-04],\n",
              "           [9.7506e-01, 3.4857e-04, 4.9763e-03, 6.8546e-04, 1.9751e-03, 6.6709e-04,\n",
              "            8.9399e-03, 1.9615e-02, 1.3287e-03, 5.2062e-02, 5.4385e-03, 2.8854e-04,\n",
              "            4.2968e-02, 5.8006e-04, 2.5112e-03, 8.0352e-03, 4.5674e-03, 1.6635e-03,\n",
              "            5.8377e-04, 1.9902e-03, 7.0493e-03, 3.8869e-03, 1.1303e-02, 7.0578e-05,\n",
              "            1.7068e-03, 1.4674e-04, 5.8585e-04, 1.9257e-04, 5.6884e-04, 5.6808e-04,\n",
              "            1.2225e-03, 3.4660e-04, 1.4171e-04, 1.3538e-05, 1.0156e-04, 1.0623e-03,\n",
              "            3.9055e-04, 6.8619e-03, 4.5121e-02, 1.0391e-04, 1.5231e-03, 8.3916e-05,\n",
              "            1.4735e-02, 6.1479e-04, 5.3245e-05, 1.1123e-04, 2.9211e-04, 3.1605e-04,\n",
              "            1.9758e-05, 1.2004e-04, 5.9385e-05, 2.7985e-04, 1.7485e-04, 1.1516e-04,\n",
              "            7.7251e-04, 9.1372e-05, 1.0154e-04, 2.5761e-05, 3.4242e-04, 1.2907e-04,\n",
              "            2.1913e-06, 2.6451e-07, 2.3497e-05, 3.4841e-06, 3.9611e-05, 1.9381e-04,\n",
              "            4.2797e-05, 8.6658e-05, 2.7293e-06, 4.9324e-04, 1.5405e-08, 9.5821e-08,\n",
              "            2.4224e-07, 8.7743e-07, 2.2753e-06, 5.3442e-10, 3.8053e-07, 1.9672e-06,\n",
              "            1.2582e-09, 2.7128e-05],\n",
              "           [9.9640e-01, 2.6567e-04, 1.8002e-03, 2.0001e-03, 8.4633e-04, 3.0770e-04,\n",
              "            2.8799e-03, 4.2715e-03, 1.8848e-04, 6.0365e-03, 1.5689e-02, 5.2775e-05,\n",
              "            8.0091e-04, 1.5645e-03, 2.7999e-04, 1.6630e-03, 7.1387e-05, 2.3579e-03,\n",
              "            1.9265e-03, 3.4511e-03, 6.9285e-05, 2.4253e-03, 2.7793e-03, 3.6616e-04,\n",
              "            2.9953e-04, 8.0784e-06, 1.1869e-03, 4.4884e-04, 1.2092e-04, 4.0874e-05,\n",
              "            2.5802e-04, 3.6141e-05, 1.8409e-05, 1.6313e-05, 5.3640e-05, 5.5259e-05,\n",
              "            1.5037e-04, 4.1542e-04, 3.5054e-02, 2.0558e-05, 2.4229e-06, 2.0095e-05,\n",
              "            9.3623e-05, 1.1257e-05, 1.4662e-04, 8.2610e-04, 1.0124e-04, 7.6018e-06,\n",
              "            9.7077e-06, 1.0598e-05, 8.3791e-06, 1.7474e-05, 1.9134e-06, 9.8064e-05,\n",
              "            2.1462e-05, 9.4141e-06, 3.7127e-07, 4.2563e-05, 4.1562e-04, 1.2305e-05,\n",
              "            4.8750e-07, 3.6269e-07, 9.8981e-07, 5.4176e-07, 6.5592e-08, 1.2070e-06,\n",
              "            8.4304e-05, 2.1658e-08, 9.5094e-06, 8.5164e-06, 1.9862e-08, 1.0607e-09,\n",
              "            2.0617e-05, 2.3985e-13, 3.6201e-10, 3.2427e-10, 6.0987e-10, 1.2066e-06,\n",
              "            2.9872e-10, 4.5776e-07],\n",
              "           [9.3289e-01, 1.0347e-03, 1.3682e-02, 4.8397e-03, 1.8752e-03, 7.3559e-03,\n",
              "            1.5574e-02, 2.3430e-02, 2.9477e-03, 2.4397e-02, 4.1962e-02, 7.7097e-03,\n",
              "            1.4922e-02, 3.1829e-03, 1.0936e-03, 5.8982e-03, 1.6160e-03, 1.8386e-02,\n",
              "            6.6610e-03, 7.0568e-03, 3.7405e-03, 2.3052e-03, 2.1268e-02, 5.1727e-03,\n",
              "            2.8095e-03, 1.0398e-04, 3.1916e-02, 3.9524e-03, 3.7544e-04, 4.5887e-04,\n",
              "            4.6738e-03, 1.1746e-03, 4.1528e-04, 1.1257e-03, 6.2506e-04, 7.8318e-03,\n",
              "            2.6489e-04, 9.6526e-04, 2.9644e-02, 3.1875e-03, 3.6397e-04, 4.0686e-04,\n",
              "            2.6843e-03, 7.0045e-04, 5.3003e-03, 2.9844e-03, 5.4218e-04, 1.2781e-03,\n",
              "            9.9652e-04, 9.4193e-04, 1.1848e-03, 1.7557e-03, 1.0044e-03, 6.5308e-04,\n",
              "            1.6863e-04, 9.5998e-04, 5.7496e-05, 1.0624e-03, 5.1361e-04, 2.8266e-03,\n",
              "            8.8471e-04, 2.5800e-05, 4.3461e-04, 2.0876e-05, 2.1553e-04, 1.1055e-05,\n",
              "            1.4866e-03, 2.5562e-04, 1.5243e-04, 1.1961e-04, 3.4258e-05, 1.8247e-06,\n",
              "            2.1950e-02, 1.4494e-06, 1.3393e-05, 4.5445e-08, 1.0348e-06, 7.5068e-04,\n",
              "            5.5829e-05, 1.8235e-04],\n",
              "           [9.9697e-01, 3.5543e-04, 2.1695e-03, 1.4785e-03, 3.5847e-03, 1.9473e-04,\n",
              "            1.2015e-03, 1.0719e-02, 6.9820e-04, 1.2981e-02, 3.4615e-03, 5.8750e-05,\n",
              "            2.8948e-03, 1.6494e-03, 4.6231e-03, 2.5263e-03, 1.4800e-04, 1.8093e-03,\n",
              "            3.4402e-04, 3.4637e-03, 1.1184e-04, 1.1756e-02, 1.2407e-03, 6.3130e-05,\n",
              "            2.7526e-03, 1.5619e-05, 9.1998e-03, 1.2146e-04, 2.1486e-04, 5.5411e-05,\n",
              "            9.8402e-03, 1.0103e-04, 1.4937e-05, 6.1835e-06, 3.4123e-04, 6.3220e-05,\n",
              "            4.0809e-05, 4.0106e-04, 8.6366e-02, 9.3403e-06, 4.7638e-06, 3.8060e-05,\n",
              "            1.8342e-03, 1.5472e-04, 7.0752e-05, 1.2220e-04, 7.5213e-05, 2.8026e-05,\n",
              "            6.0273e-06, 1.7682e-05, 8.4249e-05, 1.8579e-04, 8.7102e-07, 7.1981e-05,\n",
              "            1.8223e-05, 1.3055e-05, 2.1570e-06, 5.5885e-05, 6.2582e-05, 5.2499e-05,\n",
              "            6.2635e-07, 2.2007e-08, 6.0380e-07, 1.5160e-06, 6.5129e-07, 2.5839e-06,\n",
              "            2.7779e-05, 1.7704e-06, 4.6159e-06, 2.0202e-04, 3.1799e-09, 5.8062e-08,\n",
              "            4.3848e-07, 2.2538e-12, 5.3948e-07, 1.2322e-11, 1.1078e-09, 1.6958e-06,\n",
              "            6.1675e-12, 5.2219e-08],\n",
              "           [9.7552e-01, 5.5669e-04, 9.4657e-03, 1.3676e-02, 2.8971e-03, 7.0937e-04,\n",
              "            4.1131e-02, 2.8965e-03, 3.0524e-03, 1.3358e-02, 1.5802e-02, 6.5910e-04,\n",
              "            8.3502e-03, 7.4768e-03, 4.7061e-04, 2.4831e-02, 1.2145e-03, 2.1089e-03,\n",
              "            4.7546e-03, 8.6874e-03, 9.2459e-04, 2.2042e-03, 4.5602e-03, 1.3997e-03,\n",
              "            9.9126e-04, 4.3680e-05, 2.5652e-03, 1.0091e-03, 2.1285e-03, 3.6776e-04,\n",
              "            1.1618e-03, 1.2505e-03, 1.2874e-04, 8.4205e-05, 3.6129e-04, 2.1783e-04,\n",
              "            8.3247e-04, 1.2992e-03, 2.5521e-02, 1.1555e-03, 2.3192e-04, 4.8420e-05,\n",
              "            8.1090e-04, 2.7718e-04, 6.8667e-04, 7.7522e-04, 1.8561e-03, 1.7379e-04,\n",
              "            3.1222e-05, 5.2692e-04, 1.5029e-04, 1.9915e-04, 3.4502e-05, 1.7612e-05,\n",
              "            9.7630e-04, 1.7281e-04, 3.1181e-05, 3.7020e-05, 5.5331e-03, 8.6949e-05,\n",
              "            1.6553e-06, 2.0765e-06, 1.9343e-05, 1.0492e-06, 8.6678e-06, 5.3782e-05,\n",
              "            1.4433e-03, 1.7002e-05, 1.0023e-05, 7.5087e-05, 1.1457e-07, 4.0293e-09,\n",
              "            2.9606e-05, 3.2416e-08, 9.0236e-08, 1.4502e-09, 2.9475e-06, 1.3442e-06,\n",
              "            3.9773e-07, 2.6272e-04],\n",
              "           [9.8623e-01, 1.5408e-03, 4.0136e-03, 4.0613e-03, 1.1700e-02, 6.5664e-04,\n",
              "            1.0600e-02, 1.5150e-03, 2.6056e-03, 1.0542e-02, 9.7740e-02, 3.3390e-04,\n",
              "            1.8806e-02, 6.6977e-03, 4.8392e-04, 1.0928e-03, 4.8447e-04, 4.5067e-03,\n",
              "            7.9382e-03, 1.2399e-04, 1.7015e-03, 2.7596e-04, 5.9472e-04, 1.5292e-03,\n",
              "            4.5262e-04, 1.1377e-04, 6.3861e-03, 1.2976e-03, 8.1816e-05, 5.5422e-04,\n",
              "            7.1714e-04, 5.8742e-04, 5.6105e-04, 6.1204e-05, 5.9289e-04, 4.0549e-05,\n",
              "            5.4340e-04, 1.0452e-03, 2.1746e-01, 6.5626e-05, 3.4902e-05, 2.7803e-05,\n",
              "            9.1804e-04, 1.8542e-03, 2.2960e-04, 3.4032e-03, 4.0867e-04, 1.6612e-04,\n",
              "            1.1744e-05, 3.4709e-04, 3.9256e-04, 8.8260e-04, 2.3130e-05, 9.0323e-06,\n",
              "            8.4167e-05, 6.6294e-05, 4.0767e-06, 7.8251e-04, 4.0892e-04, 2.8875e-04,\n",
              "            3.1360e-06, 3.7472e-07, 3.4380e-04, 1.1417e-06, 5.2409e-05, 2.6125e-05,\n",
              "            1.4929e-05, 1.1255e-06, 8.7731e-03, 3.0006e-05, 1.0613e-07, 6.9378e-08,\n",
              "            5.2592e-03, 1.2557e-08, 7.8866e-06, 1.4724e-09, 3.1680e-09, 7.4911e-06,\n",
              "            8.9183e-09, 3.7546e-04],\n",
              "           [9.5387e-01, 3.3404e-04, 8.9344e-03, 2.6458e-03, 3.6143e-03, 4.5346e-03,\n",
              "            8.3959e-03, 2.1969e-03, 2.9310e-04, 2.7054e-02, 7.8259e-03, 8.0912e-04,\n",
              "            1.3685e-02, 1.5001e-03, 3.8254e-04, 2.8098e-03, 3.7324e-03, 9.2694e-04,\n",
              "            2.0364e-03, 1.4548e-03, 4.5294e-04, 3.1652e-03, 3.2496e-03, 2.2252e-04,\n",
              "            3.3608e-04, 4.6761e-05, 1.0825e-03, 3.5805e-04, 1.1403e-04, 4.8048e-04,\n",
              "            3.5857e-04, 1.5948e-04, 4.6703e-05, 4.6151e-04, 1.9173e-04, 3.3050e-04,\n",
              "            3.5905e-04, 2.1847e-03, 2.4816e-02, 1.1189e-04, 4.2059e-05, 1.7205e-05,\n",
              "            1.0523e-03, 2.7015e-04, 9.1240e-04, 4.5941e-04, 5.8846e-05, 1.1348e-04,\n",
              "            8.1502e-05, 4.1294e-04, 6.2991e-05, 4.4064e-04, 9.0456e-05, 8.1902e-05,\n",
              "            4.0000e-05, 4.2559e-04, 7.0318e-06, 2.7837e-05, 5.5091e-05, 3.3218e-04,\n",
              "            1.5775e-05, 3.3992e-07, 3.3222e-05, 3.1758e-06, 7.7171e-06, 3.6471e-05,\n",
              "            2.6756e-04, 3.0801e-05, 6.1091e-05, 9.0575e-05, 4.5713e-07, 1.9000e-09,\n",
              "            2.0763e-04, 2.2204e-08, 5.4442e-06, 2.2117e-10, 4.1531e-07, 1.0570e-05,\n",
              "            6.7734e-08, 7.0005e-05],\n",
              "           [9.8495e-01, 3.6151e-04, 1.4496e-03, 4.9361e-03, 1.3440e-03, 1.1974e-03,\n",
              "            5.4756e-03, 7.0155e-04, 4.3430e-04, 1.4952e-02, 2.2941e-03, 3.6386e-04,\n",
              "            5.1396e-03, 2.9121e-03, 8.5587e-05, 5.0929e-03, 2.6420e-04, 6.8767e-04,\n",
              "            1.4737e-03, 2.4386e-03, 9.8128e-05, 1.1433e-03, 9.1509e-04, 3.9278e-04,\n",
              "            3.2023e-04, 8.2986e-06, 6.6888e-04, 2.3251e-04, 3.3236e-04, 2.8164e-04,\n",
              "            2.1553e-04, 3.6256e-04, 2.6539e-05, 1.7148e-04, 8.2073e-05, 5.3300e-05,\n",
              "            1.0865e-04, 1.1269e-04, 2.5624e-02, 7.6121e-05, 1.7117e-05, 2.9619e-06,\n",
              "            8.5169e-05, 1.1078e-04, 3.1709e-04, 4.1681e-04, 4.7920e-05, 3.5512e-05,\n",
              "            1.5193e-05, 1.3317e-04, 1.1340e-05, 5.1034e-05, 1.3419e-05, 2.0641e-06,\n",
              "            1.1496e-05, 1.0110e-04, 5.6679e-06, 6.5519e-05, 3.9253e-05, 8.3295e-05,\n",
              "            1.5831e-06, 1.0931e-07, 3.2359e-06, 2.7279e-08, 4.9753e-06, 1.1016e-06,\n",
              "            1.3243e-04, 6.2487e-06, 1.8121e-06, 2.6639e-05, 4.5007e-08, 1.1243e-09,\n",
              "            4.3933e-05, 8.1461e-09, 2.4160e-08, 4.9452e-14, 1.3088e-07, 2.0312e-06,\n",
              "            2.3976e-09, 2.6576e-06]], device='cuda:0', grad_fn=<SigmoidBackward>),\n",
              "   tensor([[9.9995e-01, 3.8543e-06, 3.7210e-08, 2.7998e-04, 2.0512e-05, 6.6691e-08,\n",
              "            3.5782e-07, 8.4758e-08, 1.8237e-04, 1.7706e-05, 3.5138e-03, 1.1317e-06,\n",
              "            6.4768e-07, 6.8161e-03, 1.3220e-06, 2.9803e-06, 1.1470e-06, 5.4372e-07,\n",
              "            1.6254e-04, 1.8312e-04, 2.4752e-06, 4.6606e-05, 1.0194e-06, 5.2570e-03,\n",
              "            3.8288e-04, 2.5457e-06, 6.6563e-05, 2.6142e-07, 3.9403e-07, 7.3129e-07,\n",
              "            5.4256e-08, 1.3752e-03, 1.5161e-09, 2.3655e-09, 2.7402e-06, 2.7329e-08,\n",
              "            2.0449e-07, 2.7902e-07, 1.0307e-02, 3.8085e-08, 5.7589e-08, 3.7922e-06,\n",
              "            1.1800e-02, 1.9976e-03, 8.7775e-05, 4.2548e-06, 9.1367e-07, 1.3800e-07,\n",
              "            1.7369e-06, 2.7150e-05, 6.6856e-06, 2.0612e-03, 6.0428e-07, 2.0019e-07,\n",
              "            5.8310e-07, 1.4128e-04, 1.2140e-08, 6.9428e-05, 2.4681e-04, 1.0948e-03,\n",
              "            1.5926e-05, 7.1464e-09, 3.7409e-05, 2.0083e-05, 2.4351e-05, 6.5669e-08,\n",
              "            6.1810e-06, 3.6520e-06, 1.5456e-02, 2.2171e-04],\n",
              "           [1.0000e+00, 9.4053e-08, 8.7937e-09, 3.3226e-07, 8.8741e-08, 1.6719e-10,\n",
              "            1.2202e-08, 3.7142e-11, 1.1252e-06, 1.1779e-06, 3.8629e-05, 1.6952e-06,\n",
              "            3.9410e-07, 1.5253e-05, 1.8168e-07, 4.4161e-06, 1.1267e-06, 1.9442e-08,\n",
              "            1.9486e-05, 4.9739e-05, 1.5945e-04, 1.8670e-06, 2.4054e-06, 3.1782e-07,\n",
              "            1.8329e-04, 1.5559e-06, 1.4960e-05, 3.6864e-06, 2.8109e-06, 2.4413e-07,\n",
              "            2.6449e-07, 1.4501e-04, 9.3507e-09, 7.9092e-09, 1.2600e-06, 4.5784e-07,\n",
              "            9.3620e-06, 5.4682e-06, 2.5186e-04, 5.1157e-06, 6.8258e-09, 1.5502e-06,\n",
              "            4.6586e-07, 2.5774e-03, 5.1058e-07, 3.6559e-08, 1.9862e-07, 2.0569e-05,\n",
              "            2.3135e-08, 1.9949e-07, 1.4035e-06, 2.3318e-05, 1.3736e-04, 7.6934e-07,\n",
              "            1.5796e-05, 1.9655e-06, 2.1943e-08, 6.3629e-05, 1.9014e-05, 1.7694e-08,\n",
              "            3.2820e-09, 4.0654e-11, 1.8739e-05, 7.9312e-07, 1.5837e-06, 5.1070e-07,\n",
              "            4.4607e-05, 8.1075e-09, 4.2889e-07, 1.0146e-04],\n",
              "           [1.0000e+00, 4.1324e-09, 4.6021e-11, 6.4898e-06, 6.7102e-08, 1.6974e-10,\n",
              "            1.0111e-08, 1.1083e-09, 6.5034e-07, 2.0823e-07, 5.2708e-07, 2.4779e-07,\n",
              "            1.5499e-05, 1.5098e-05, 3.4266e-06, 1.9469e-06, 3.1823e-08, 1.4074e-09,\n",
              "            7.3219e-07, 3.4088e-07, 1.6819e-04, 3.7555e-04, 3.5587e-06, 1.4610e-06,\n",
              "            7.8943e-06, 2.4406e-05, 1.1695e-06, 4.0176e-06, 2.6596e-06, 1.5892e-03,\n",
              "            1.1230e-06, 1.8050e-04, 5.1300e-10, 2.4645e-09, 5.5102e-06, 1.3999e-08,\n",
              "            1.5458e-06, 3.7816e-05, 2.3327e-03, 3.9391e-07, 1.8454e-07, 8.1406e-07,\n",
              "            4.9291e-03, 1.6592e-05, 9.0325e-08, 3.9959e-07, 7.5091e-07, 4.1585e-06,\n",
              "            3.1299e-09, 1.0515e-05, 3.7392e-07, 1.1333e-03, 1.9652e-07, 8.5562e-08,\n",
              "            1.3862e-05, 2.3126e-05, 4.8181e-07, 7.1410e-05, 1.3861e-05, 2.7714e-07,\n",
              "            1.2093e-07, 8.5101e-09, 4.4683e-06, 9.0759e-06, 2.4726e-05, 7.6242e-06,\n",
              "            8.2390e-05, 4.5917e-06, 3.3653e-06, 1.4313e-04],\n",
              "           [1.0000e+00, 2.7745e-11, 9.8638e-12, 2.4537e-09, 3.8815e-12, 1.8392e-13,\n",
              "            3.4138e-11, 2.9719e-14, 2.9800e-10, 9.1221e-11, 7.7670e-07, 9.7454e-09,\n",
              "            1.2173e-08, 2.3472e-07, 1.3941e-08, 5.4388e-11, 5.2331e-10, 1.8892e-12,\n",
              "            2.0858e-05, 5.5174e-08, 2.7792e-10, 2.9494e-05, 1.7825e-08, 2.3028e-07,\n",
              "            8.4857e-07, 7.3048e-08, 2.8085e-09, 1.0003e-09, 1.8335e-07, 2.4063e-10,\n",
              "            1.0323e-09, 1.2631e-08, 2.5633e-12, 8.3800e-12, 1.6211e-07, 4.4563e-11,\n",
              "            1.9924e-08, 2.0965e-07, 3.6427e-04, 3.3363e-08, 1.6123e-14, 3.4795e-09,\n",
              "            2.0800e-09, 6.1225e-09, 2.2207e-08, 2.2135e-11, 1.7486e-09, 1.1053e-09,\n",
              "            2.2195e-12, 1.5090e-11, 7.9016e-13, 3.9505e-08, 9.3215e-12, 2.0233e-06,\n",
              "            3.1592e-09, 1.9993e-09, 6.1461e-12, 9.8232e-08, 4.3120e-07, 1.2162e-09,\n",
              "            1.3740e-08, 2.4971e-12, 2.8822e-09, 1.6846e-06, 8.4470e-10, 1.1118e-09,\n",
              "            2.2080e-06, 5.7458e-12, 6.4188e-08, 1.1100e-05],\n",
              "           [1.0000e+00, 2.4863e-09, 3.7890e-08, 8.0342e-08, 8.3442e-10, 9.8994e-11,\n",
              "            1.5079e-08, 1.2872e-10, 4.4617e-08, 5.8832e-09, 3.1726e-05, 3.1899e-06,\n",
              "            6.5969e-07, 1.3381e-06, 1.4833e-06, 1.0500e-06, 1.5252e-06, 3.3054e-07,\n",
              "            3.6328e-05, 1.3609e-02, 9.4915e-06, 4.1983e-04, 5.6737e-05, 1.0342e-04,\n",
              "            1.0421e-03, 1.6235e-06, 1.8496e-05, 1.4115e-05, 3.8417e-06, 1.9843e-07,\n",
              "            1.2454e-06, 8.9823e-07, 6.0152e-10, 5.1822e-10, 2.5458e-05, 1.3340e-08,\n",
              "            9.5067e-08, 1.5573e-07, 1.0621e-03, 3.1862e-05, 2.3527e-08, 3.6698e-07,\n",
              "            1.6169e-06, 1.8412e-05, 3.5400e-06, 1.2458e-05, 1.0373e-08, 1.0364e-07,\n",
              "            3.3977e-08, 1.0704e-05, 4.4034e-07, 3.3191e-05, 4.3635e-06, 4.8373e-05,\n",
              "            1.1449e-07, 3.6128e-05, 3.7043e-09, 2.8206e-03, 4.5422e-06, 3.2203e-06,\n",
              "            1.2668e-05, 1.7600e-07, 1.5664e-05, 1.2759e-05, 5.2632e-05, 1.4981e-06,\n",
              "            5.6935e-04, 6.6006e-07, 3.1444e-05, 1.2259e-04],\n",
              "           [1.0000e+00, 6.8802e-09, 7.1275e-10, 3.1137e-08, 7.5194e-10, 6.7332e-11,\n",
              "            1.5096e-09, 1.5674e-10, 3.3520e-09, 2.6925e-07, 5.5019e-06, 1.0293e-06,\n",
              "            5.1581e-07, 5.8058e-07, 9.1341e-06, 7.8345e-07, 1.7354e-07, 1.7715e-08,\n",
              "            7.7206e-07, 7.8664e-06, 1.3478e-07, 7.7339e-04, 2.2758e-08, 1.4848e-08,\n",
              "            1.3141e-04, 1.3243e-07, 5.6310e-07, 3.9980e-08, 2.9415e-05, 1.0517e-08,\n",
              "            1.9477e-07, 1.4443e-07, 1.2175e-11, 6.3647e-11, 3.3682e-06, 3.9417e-10,\n",
              "            7.7372e-08, 5.7733e-07, 2.4135e-04, 3.1303e-09, 4.3839e-12, 1.5552e-06,\n",
              "            1.6645e-05, 2.2935e-07, 7.6556e-08, 3.3937e-10, 6.0390e-08, 1.2848e-07,\n",
              "            1.8859e-10, 9.5263e-07, 2.0263e-08, 2.6432e-05, 1.2238e-11, 3.7486e-07,\n",
              "            1.9897e-09, 1.1568e-08, 2.1288e-10, 6.5519e-06, 5.1534e-08, 8.0389e-07,\n",
              "            1.2662e-08, 1.2089e-11, 2.3239e-09, 4.4050e-08, 1.5604e-08, 2.4015e-09,\n",
              "            1.5003e-06, 6.7564e-08, 3.0632e-07, 3.9776e-05],\n",
              "           [1.0000e+00, 6.0125e-10, 6.8573e-10, 8.1634e-08, 6.2866e-10, 1.9734e-12,\n",
              "            3.3121e-09, 7.4570e-14, 6.6286e-10, 1.7406e-08, 2.8339e-07, 2.4181e-06,\n",
              "            6.3475e-09, 2.0524e-08, 3.9015e-10, 3.2800e-11, 4.4937e-09, 8.4642e-12,\n",
              "            1.9651e-07, 8.0757e-07, 1.5446e-08, 2.3092e-06, 1.3749e-05, 6.6194e-08,\n",
              "            8.9313e-06, 9.7710e-07, 2.5053e-08, 3.0326e-08, 8.1466e-07, 8.4019e-08,\n",
              "            8.5187e-10, 5.3332e-06, 7.3629e-11, 2.8234e-09, 1.1210e-06, 1.5172e-07,\n",
              "            7.2702e-06, 2.8553e-07, 2.2074e-05, 4.0705e-06, 7.2810e-11, 1.1767e-07,\n",
              "            4.2065e-07, 8.1750e-05, 8.5374e-06, 4.0424e-07, 2.8395e-07, 4.4990e-06,\n",
              "            1.1985e-07, 4.1031e-07, 4.5236e-08, 1.7433e-05, 3.5602e-07, 1.3286e-06,\n",
              "            4.3971e-06, 3.1805e-06, 3.8787e-08, 1.3698e-06, 6.1680e-05, 7.6375e-07,\n",
              "            4.6592e-09, 2.2510e-10, 5.4034e-07, 1.7093e-06, 3.0087e-08, 1.2928e-08,\n",
              "            6.8055e-05, 5.0068e-10, 4.6618e-07, 8.3417e-06],\n",
              "           [1.0000e+00, 3.1227e-08, 4.9655e-11, 6.8075e-07, 1.1669e-08, 2.4256e-11,\n",
              "            3.2623e-09, 1.9238e-11, 6.2050e-08, 2.1280e-08, 2.6576e-05, 8.2531e-08,\n",
              "            2.2252e-05, 8.1314e-06, 4.7125e-08, 3.7391e-08, 2.9591e-08, 1.3458e-06,\n",
              "            4.8169e-06, 3.8172e-08, 2.7021e-05, 2.1078e-05, 1.0296e-07, 1.0411e-06,\n",
              "            1.0569e-06, 1.1004e-05, 8.3961e-05, 1.6329e-04, 3.1522e-07, 3.5020e-07,\n",
              "            1.0574e-06, 1.2782e-04, 4.2530e-08, 6.3662e-09, 5.6604e-05, 3.2895e-09,\n",
              "            1.3321e-06, 1.2995e-06, 3.4792e-02, 7.0495e-07, 9.8077e-12, 4.0289e-10,\n",
              "            8.5246e-06, 6.0714e-07, 5.5201e-08, 4.9221e-06, 3.2612e-06, 3.6876e-06,\n",
              "            6.2048e-11, 3.1803e-07, 2.1119e-08, 5.4231e-03, 1.4845e-09, 1.0536e-09,\n",
              "            1.0426e-09, 1.3409e-06, 3.9176e-09, 2.1262e-03, 5.7657e-07, 4.1086e-08,\n",
              "            1.0684e-08, 3.6794e-09, 4.2090e-05, 7.8979e-08, 2.7173e-05, 8.5113e-08,\n",
              "            1.1470e-05, 5.3237e-09, 3.8519e-03, 7.4863e-06],\n",
              "           [1.0000e+00, 6.9932e-08, 6.1757e-09, 2.5633e-07, 1.9209e-07, 1.7097e-10,\n",
              "            3.2071e-09, 7.3026e-12, 1.4059e-08, 3.7106e-07, 3.7448e-07, 2.4895e-07,\n",
              "            2.2723e-09, 3.8688e-07, 1.5765e-11, 5.4212e-08, 2.0857e-09, 1.2918e-13,\n",
              "            3.4852e-08, 2.2144e-08, 6.0391e-05, 3.0228e-06, 1.6541e-08, 1.1326e-07,\n",
              "            4.7086e-05, 8.8018e-09, 6.0401e-07, 3.8812e-06, 3.2836e-08, 1.2349e-04,\n",
              "            1.3158e-09, 2.5984e-07, 3.8397e-11, 5.7657e-11, 2.0069e-05, 5.9866e-11,\n",
              "            6.7844e-08, 2.8017e-09, 1.1067e-04, 5.3349e-08, 5.0622e-11, 1.3011e-09,\n",
              "            4.1192e-08, 1.2763e-04, 5.6285e-07, 2.8728e-07, 2.3875e-09, 7.0943e-09,\n",
              "            2.4701e-08, 7.4663e-05, 2.6212e-08, 5.2553e-05, 1.4163e-06, 2.0694e-05,\n",
              "            2.9007e-08, 3.7918e-06, 3.6722e-08, 2.6142e-05, 1.6043e-07, 1.7868e-05,\n",
              "            1.5131e-08, 8.7845e-10, 7.9473e-06, 1.3870e-06, 4.5001e-07, 6.2283e-09,\n",
              "            3.0737e-04, 4.1916e-07, 1.5818e-05, 5.6301e-06],\n",
              "           [9.9908e-01, 2.4686e-06, 1.0012e-07, 9.7268e-06, 1.5495e-05, 2.0025e-09,\n",
              "            3.1259e-07, 1.1191e-09, 2.3730e-06, 5.6846e-04, 9.4779e-07, 5.6614e-06,\n",
              "            2.6592e-08, 2.8935e-05, 8.4761e-09, 1.7907e-08, 1.9392e-07, 9.2735e-09,\n",
              "            6.9976e-05, 4.6603e-05, 3.0517e-08, 7.9450e-06, 3.1874e-09, 2.7599e-07,\n",
              "            6.9577e-06, 9.8038e-08, 2.4853e-08, 1.4453e-08, 4.6981e-06, 9.8826e-05,\n",
              "            7.3242e-11, 1.0158e-05, 2.0952e-11, 2.8253e-10, 3.0429e-06, 8.4373e-09,\n",
              "            3.8399e-07, 2.7019e-09, 8.8411e-07, 3.7349e-08, 1.5131e-12, 2.7576e-09,\n",
              "            1.4064e-10, 1.1535e-03, 1.7190e-06, 1.4252e-08, 2.0807e-10, 1.5373e-08,\n",
              "            3.2981e-08, 7.7455e-08, 1.3849e-10, 5.2133e-07, 1.6189e-07, 3.9482e-09,\n",
              "            1.0246e-10, 2.1076e-09, 1.3844e-09, 4.7442e-07, 2.4197e-10, 2.7533e-09,\n",
              "            7.9573e-10, 3.5811e-12, 2.2580e-07, 1.5613e-08, 3.0426e-08, 2.1594e-10,\n",
              "            2.7919e-05, 1.0155e-08, 7.9849e-08, 1.5416e-06]], device='cuda:0',\n",
              "          grad_fn=<CatBackward>)],\n",
              "  9: [tensor([[9.1711e-01, 1.0010e-03, 2.9850e-03, 4.3067e-03, 9.6675e-03, 4.2705e-03,\n",
              "            4.3700e-03, 4.4590e-03, 3.3410e-03, 9.2555e-02, 6.7271e-02, 1.4341e-03,\n",
              "            1.3616e-02, 2.2734e-02, 1.5304e-03, 5.3759e-03, 3.8469e-04, 3.8317e-03,\n",
              "            2.5059e-03, 3.5212e-03, 3.2598e-03, 3.4173e-03, 4.0834e-03, 7.0849e-03,\n",
              "            2.9551e-03, 3.2065e-04, 1.4053e-03, 7.5724e-04, 1.0811e-03, 5.7240e-03,\n",
              "            8.4250e-04, 5.2245e-03, 5.8078e-04, 2.7282e-04, 2.6425e-04, 1.3326e-03,\n",
              "            1.7501e-04, 1.9365e-02, 1.0328e-01, 3.6375e-04, 4.1844e-04, 2.8159e-04,\n",
              "            1.0474e-02, 4.8729e-03, 1.2269e-03, 1.2828e-03, 4.6640e-04, 9.8948e-05,\n",
              "            9.7559e-04, 7.7003e-04, 3.4308e-04, 4.1613e-03, 1.0883e-03, 1.8371e-04,\n",
              "            2.6144e-04, 1.2900e-03, 4.6879e-05, 3.4565e-04, 1.2521e-03, 1.1276e-02,\n",
              "            1.2117e-04, 2.1633e-05, 3.7097e-04, 4.4541e-05, 2.5575e-03, 1.0392e-04,\n",
              "            2.3488e-04, 8.1360e-04, 1.9419e-03, 4.1325e-04, 6.3988e-06, 6.0376e-05,\n",
              "            4.5467e-03, 2.1710e-05, 2.3453e-03, 4.5627e-06, 1.1446e-05, 2.6601e-04,\n",
              "            6.7132e-05, 2.1671e-03, 2.1455e-07, 4.7834e-05, 1.2080e-08, 6.7917e-04,\n",
              "            1.4877e-05, 4.3658e-07, 1.4592e-05, 4.6550e-04, 2.6897e-09, 2.0758e-04],\n",
              "           [9.8823e-01, 1.0003e-03, 1.5907e-02, 1.3114e-03, 7.7452e-03, 2.0122e-04,\n",
              "            1.3319e-02, 4.0391e-03, 7.6404e-03, 1.8415e-02, 2.7052e-02, 9.7337e-04,\n",
              "            2.2777e-02, 3.5109e-03, 1.6707e-03, 5.3010e-03, 8.1128e-04, 5.9936e-03,\n",
              "            3.9368e-03, 1.2546e-03, 2.7505e-02, 2.4494e-03, 4.9367e-03, 6.0558e-04,\n",
              "            1.5756e-03, 2.0179e-04, 2.5337e-03, 1.5572e-03, 7.1438e-04, 1.0764e-03,\n",
              "            4.4489e-03, 1.2303e-03, 1.6154e-03, 5.5858e-05, 1.3489e-04, 1.0720e-03,\n",
              "            8.1980e-04, 5.4979e-03, 2.2018e-01, 1.3588e-03, 7.7695e-03, 2.5131e-04,\n",
              "            4.4171e-03, 2.1587e-03, 1.3432e-04, 8.7588e-04, 1.4394e-03, 1.4181e-03,\n",
              "            6.4061e-05, 2.5139e-04, 1.5558e-03, 5.1485e-04, 1.5736e-03, 5.4944e-04,\n",
              "            1.7462e-03, 7.7466e-05, 2.6704e-04, 5.6325e-04, 7.0358e-04, 9.8463e-04,\n",
              "            2.6989e-05, 2.9362e-06, 9.6763e-04, 2.8930e-05, 1.9670e-03, 9.7301e-05,\n",
              "            4.6234e-04, 2.7209e-04, 1.9450e-04, 2.7940e-04, 1.9293e-05, 3.1882e-04,\n",
              "            3.0777e-04, 3.1422e-04, 7.6355e-06, 2.8728e-05, 5.3991e-06, 4.6953e-03,\n",
              "            5.8800e-06, 3.7991e-03, 3.5583e-04, 8.7017e-07, 1.7790e-06, 3.2651e-05,\n",
              "            3.6296e-06, 4.9355e-05, 7.8275e-06, 3.0410e-04, 2.1874e-07, 2.2250e-05],\n",
              "           [9.6161e-01, 4.5023e-04, 7.7009e-03, 1.2093e-03, 5.4437e-03, 3.4461e-04,\n",
              "            1.6401e-02, 2.3887e-02, 4.6167e-03, 2.2577e-02, 1.4909e-02, 6.3082e-04,\n",
              "            6.2737e-02, 1.7520e-03, 4.7185e-03, 1.0174e-02, 1.9194e-03, 2.9479e-03,\n",
              "            7.8251e-04, 1.0709e-03, 5.6524e-03, 3.4388e-03, 6.2081e-03, 2.6702e-04,\n",
              "            2.8832e-03, 1.0215e-03, 1.2481e-03, 7.1039e-04, 5.9581e-04, 8.4564e-04,\n",
              "            3.3089e-03, 9.9975e-04, 2.7830e-04, 2.3013e-05, 4.7074e-04, 1.0505e-03,\n",
              "            3.8093e-04, 1.6833e-02, 6.7556e-02, 5.7785e-04, 1.2843e-03, 2.7320e-04,\n",
              "            2.7280e-02, 1.6838e-03, 9.7255e-05, 4.9843e-04, 1.4503e-03, 9.9595e-04,\n",
              "            3.6133e-05, 1.0402e-04, 4.8291e-04, 1.0505e-03, 8.8653e-05, 6.8041e-04,\n",
              "            6.9025e-03, 1.5297e-04, 2.2175e-04, 2.2346e-04, 3.0184e-03, 4.7027e-04,\n",
              "            2.1300e-05, 1.2560e-05, 8.4706e-04, 2.8062e-05, 1.2594e-04, 6.3286e-04,\n",
              "            6.6629e-05, 5.0504e-05, 7.5053e-05, 5.9458e-04, 3.3466e-06, 3.4235e-05,\n",
              "            4.6686e-05, 6.3546e-06, 1.5481e-05, 5.2941e-05, 3.4310e-06, 3.0208e-04,\n",
              "            7.4664e-06, 1.8537e-04, 7.6302e-07, 1.6768e-07, 9.5593e-08, 1.1992e-04,\n",
              "            5.1803e-07, 4.9380e-06, 5.1964e-07, 1.2657e-06, 2.9567e-07, 1.4457e-05],\n",
              "           [9.6688e-01, 2.1980e-03, 1.3638e-02, 7.0172e-03, 4.9016e-03, 1.9688e-03,\n",
              "            3.1275e-02, 1.7625e-02, 1.2726e-03, 1.0381e-02, 1.8133e-02, 1.2214e-03,\n",
              "            1.0495e-02, 1.0325e-02, 2.0561e-03, 3.0607e-03, 7.1460e-04, 1.3293e-02,\n",
              "            2.4309e-02, 8.2316e-03, 1.1448e-03, 1.3915e-02, 1.1981e-02, 2.9346e-03,\n",
              "            1.7882e-03, 1.2340e-04, 7.5622e-03, 1.7124e-03, 8.3816e-04, 1.0656e-03,\n",
              "            2.5933e-03, 8.8672e-04, 2.5513e-04, 2.5811e-04, 2.3032e-03, 2.0878e-03,\n",
              "            1.1153e-03, 2.8094e-03, 8.1746e-02, 5.2358e-04, 1.4668e-04, 7.3809e-04,\n",
              "            2.3325e-03, 3.1953e-04, 2.3527e-03, 1.1273e-03, 1.0329e-03, 1.3155e-03,\n",
              "            1.7280e-04, 2.0725e-04, 5.2099e-04, 3.0421e-03, 1.0325e-04, 1.4445e-03,\n",
              "            1.5060e-04, 1.5897e-04, 1.3892e-04, 4.8615e-04, 2.2367e-03, 4.4547e-04,\n",
              "            2.1831e-04, 6.1462e-05, 1.0088e-04, 7.8136e-05, 3.6164e-05, 1.5768e-04,\n",
              "            3.3599e-03, 2.6820e-05, 6.6461e-04, 1.9939e-04, 2.2300e-05, 7.8091e-05,\n",
              "            8.0393e-04, 4.4948e-07, 9.7120e-05, 1.8674e-05, 4.3931e-06, 4.3405e-04,\n",
              "            2.0675e-05, 9.1487e-05, 2.3799e-06, 4.5463e-07, 1.0070e-06, 7.5293e-06,\n",
              "            6.6177e-07, 7.0287e-06, 1.8625e-06, 6.8329e-05, 3.4067e-06, 1.5572e-06],\n",
              "           [9.3015e-01, 2.1857e-03, 2.0865e-02, 7.8275e-03, 6.6724e-03, 5.3074e-03,\n",
              "            1.2594e-02, 5.7089e-02, 8.6756e-03, 1.5385e-02, 8.1017e-02, 6.3789e-03,\n",
              "            1.3207e-02, 6.9315e-03, 7.9827e-03, 1.0227e-02, 1.2117e-03, 4.6871e-02,\n",
              "            6.7880e-03, 6.2191e-03, 7.0073e-03, 6.2950e-03, 1.7086e-02, 9.4933e-03,\n",
              "            5.0171e-03, 5.8494e-04, 5.3913e-02, 1.1178e-02, 8.8974e-04, 1.2896e-03,\n",
              "            1.7022e-02, 3.0007e-03, 1.0717e-03, 8.2749e-04, 1.8435e-03, 1.1413e-02,\n",
              "            5.4737e-04, 5.4242e-03, 6.1530e-02, 3.3063e-03, 1.3618e-03, 1.6114e-03,\n",
              "            1.6030e-02, 1.9762e-03, 5.0185e-03, 9.1918e-03, 1.7148e-03, 1.9985e-03,\n",
              "            1.6088e-03, 1.1683e-03, 6.6904e-03, 3.2227e-03, 2.1280e-03, 7.5081e-03,\n",
              "            9.0095e-04, 2.4619e-03, 4.5818e-04, 4.5602e-03, 2.6267e-03, 3.0602e-03,\n",
              "            2.2776e-03, 8.5371e-05, 2.0115e-03, 4.5407e-04, 1.4996e-03, 4.8977e-04,\n",
              "            4.1680e-03, 6.0431e-04, 1.1565e-03, 6.2601e-04, 2.0180e-04, 8.3425e-04,\n",
              "            8.5401e-03, 6.7228e-05, 9.2041e-04, 6.8828e-04, 4.6154e-05, 1.2259e-03,\n",
              "            6.5790e-04, 5.7310e-03, 5.2390e-04, 4.0174e-06, 9.5671e-07, 5.2296e-04,\n",
              "            2.9926e-05, 2.9043e-04, 1.3694e-04, 1.6519e-04, 4.5518e-04, 7.7946e-04],\n",
              "           [9.9154e-01, 4.8844e-04, 5.1979e-03, 2.0213e-03, 8.0798e-03, 2.0518e-04,\n",
              "            3.1996e-03, 2.0363e-02, 1.7466e-03, 1.4460e-02, 1.1441e-02, 1.7134e-04,\n",
              "            1.2768e-02, 7.3745e-03, 3.5262e-03, 2.1754e-03, 2.7967e-04, 1.1812e-02,\n",
              "            9.8841e-04, 4.0629e-03, 1.0166e-03, 2.1418e-02, 1.4499e-03, 4.0895e-04,\n",
              "            6.2662e-03, 9.5776e-05, 1.5170e-02, 9.3584e-04, 3.0259e-04, 3.6403e-04,\n",
              "            1.9603e-02, 9.0770e-04, 1.7815e-04, 1.8056e-05, 7.8759e-04, 4.2453e-04,\n",
              "            9.9721e-05, 2.0361e-03, 2.4384e-01, 1.8885e-04, 1.8781e-04, 4.3375e-04,\n",
              "            5.4198e-03, 6.8650e-04, 3.9648e-04, 7.5535e-04, 3.9223e-04, 3.4189e-04,\n",
              "            3.5732e-05, 1.4437e-04, 8.6084e-04, 1.3369e-03, 4.3833e-05, 3.5373e-04,\n",
              "            1.1076e-04, 7.6251e-05, 7.1608e-05, 5.7108e-04, 2.4657e-04, 2.0879e-03,\n",
              "            1.8814e-05, 2.8161e-06, 3.6558e-05, 3.8405e-05, 1.5460e-04, 2.0478e-05,\n",
              "            7.4715e-04, 1.0026e-04, 1.7387e-04, 1.8291e-04, 6.9562e-06, 1.1339e-04,\n",
              "            6.3611e-04, 1.1480e-06, 3.5075e-04, 1.0432e-05, 3.1910e-07, 4.9007e-04,\n",
              "            1.4031e-06, 5.1939e-05, 7.4980e-04, 3.9148e-08, 1.3370e-08, 1.4394e-06,\n",
              "            1.5273e-06, 1.3286e-07, 1.5073e-06, 7.1971e-05, 8.9996e-07, 2.2124e-06],\n",
              "           [9.7489e-01, 5.0468e-04, 9.1569e-03, 9.2901e-03, 6.6405e-03, 4.0770e-04,\n",
              "            3.8753e-02, 4.2500e-03, 8.6792e-04, 5.4301e-03, 1.1541e-02, 1.0807e-03,\n",
              "            7.4427e-03, 8.4811e-03, 3.9979e-04, 4.1591e-03, 3.9630e-04, 1.0153e-02,\n",
              "            7.1530e-03, 2.5960e-03, 6.2576e-04, 2.0869e-03, 4.7744e-03, 1.0506e-03,\n",
              "            9.9518e-04, 3.6497e-05, 3.0112e-03, 1.1544e-03, 5.9165e-04, 1.1223e-03,\n",
              "            1.6535e-03, 1.7131e-03, 1.5425e-04, 1.1321e-04, 5.5596e-04, 3.7894e-04,\n",
              "            7.0241e-04, 1.1762e-03, 2.4723e-02, 9.1865e-04, 2.6063e-04, 6.6612e-05,\n",
              "            5.8708e-04, 3.4879e-04, 1.2017e-03, 3.9968e-04, 7.7914e-04, 4.4285e-04,\n",
              "            3.7430e-05, 2.3852e-04, 5.6067e-04, 1.5306e-03, 1.5035e-04, 7.0854e-05,\n",
              "            2.2522e-04, 2.5200e-05, 7.4763e-05, 4.8351e-05, 2.3296e-03, 9.8424e-05,\n",
              "            3.0215e-05, 4.5637e-06, 1.5523e-04, 1.2504e-05, 1.7878e-05, 8.4747e-05,\n",
              "            3.0142e-03, 1.1744e-04, 5.8863e-05, 3.2607e-05, 1.0191e-05, 3.5890e-06,\n",
              "            1.2741e-03, 9.6195e-07, 2.7706e-06, 6.3097e-06, 9.8562e-06, 4.4204e-05,\n",
              "            3.0057e-05, 2.4578e-04, 9.5493e-06, 7.3681e-07, 9.0218e-07, 2.9223e-04,\n",
              "            4.3100e-09, 1.1821e-07, 2.3263e-08, 4.7509e-05, 1.3145e-07, 1.4226e-07],\n",
              "           [9.6882e-01, 9.8827e-04, 4.6446e-03, 5.0450e-03, 8.0317e-03, 1.0137e-03,\n",
              "            1.3395e-02, 3.8505e-03, 2.3825e-03, 2.7827e-02, 1.3194e-01, 6.5746e-04,\n",
              "            4.3756e-02, 1.4028e-02, 1.0366e-03, 1.4748e-03, 3.2026e-04, 2.7197e-03,\n",
              "            8.8438e-03, 5.4699e-04, 1.4652e-03, 1.0447e-03, 1.5880e-03, 4.3574e-03,\n",
              "            5.1273e-04, 3.6991e-04, 5.7032e-03, 1.1487e-03, 2.9706e-04, 1.1603e-03,\n",
              "            1.7154e-03, 1.3446e-03, 3.6110e-04, 2.1099e-04, 1.1211e-03, 1.8495e-04,\n",
              "            1.5722e-04, 6.4819e-03, 2.5838e-01, 2.2066e-04, 1.5489e-04, 3.7068e-04,\n",
              "            5.2041e-03, 2.7529e-03, 4.7270e-04, 2.0425e-03, 6.9287e-04, 3.7818e-04,\n",
              "            5.5204e-05, 1.1074e-03, 7.2996e-04, 7.0162e-04, 5.6425e-05, 3.4223e-04,\n",
              "            1.1373e-04, 3.7295e-04, 3.3031e-05, 9.1048e-04, 1.4205e-03, 6.4006e-03,\n",
              "            2.3067e-05, 1.2772e-05, 4.4753e-04, 8.0976e-05, 6.2572e-04, 7.3427e-05,\n",
              "            8.7490e-05, 4.4185e-05, 2.1092e-02, 9.9245e-05, 7.8117e-06, 4.0309e-05,\n",
              "            9.5159e-03, 1.6777e-05, 2.0896e-04, 8.4745e-06, 3.5957e-06, 5.9918e-03,\n",
              "            4.8502e-06, 8.8648e-04, 2.0483e-05, 7.1405e-07, 2.6265e-07, 4.0342e-07,\n",
              "            2.0433e-02, 8.7856e-06, 1.8866e-03, 2.5797e-04, 6.2815e-08, 3.9771e-06],\n",
              "           [9.0755e-01, 9.0974e-04, 4.1858e-02, 1.0816e-02, 9.1266e-03, 9.1146e-03,\n",
              "            1.2061e-02, 3.5740e-02, 3.5240e-03, 4.0801e-02, 3.7978e-02, 1.5316e-02,\n",
              "            1.0678e-02, 1.3756e-02, 7.7507e-03, 9.1767e-03, 2.5517e-03, 2.0397e-02,\n",
              "            5.5274e-03, 1.4609e-02, 5.3045e-03, 2.4224e-02, 1.4905e-02, 6.3370e-03,\n",
              "            7.7243e-03, 4.7850e-04, 2.5453e-02, 1.7608e-03, 2.6367e-03, 3.7058e-03,\n",
              "            5.2457e-03, 2.4568e-03, 5.4998e-04, 5.9156e-03, 1.2417e-03, 1.5712e-02,\n",
              "            9.6542e-04, 6.3795e-03, 1.4326e-01, 4.5866e-03, 8.1429e-04, 9.4325e-04,\n",
              "            1.1113e-02, 2.0783e-03, 1.8990e-02, 3.9697e-03, 1.0535e-03, 2.0466e-03,\n",
              "            5.1831e-03, 3.2465e-03, 4.4922e-03, 6.2555e-03, 4.8855e-03, 9.9823e-03,\n",
              "            5.0969e-04, 4.5807e-03, 4.8476e-04, 4.8764e-04, 1.4968e-03, 1.0912e-02,\n",
              "            2.1983e-03, 1.0154e-04, 5.3146e-04, 7.2580e-04, 3.1422e-03, 7.9724e-04,\n",
              "            2.4083e-02, 4.3651e-03, 2.8891e-03, 2.5372e-03, 2.3270e-04, 5.6523e-04,\n",
              "            5.0415e-02, 1.1188e-04, 5.0022e-03, 4.7912e-04, 1.0221e-03, 1.7698e-03,\n",
              "            6.0669e-04, 2.3459e-03, 2.1274e-03, 1.7852e-06, 8.3191e-05, 1.2768e-03,\n",
              "            5.5910e-03, 4.2627e-05, 1.3283e-04, 1.8549e-03, 1.2477e-04, 8.2422e-04],\n",
              "           [9.9659e-01, 9.9988e-05, 2.7562e-03, 1.6506e-03, 1.1031e-03, 6.6678e-05,\n",
              "            3.7632e-03, 4.8857e-04, 1.3065e-04, 2.9146e-03, 1.4494e-03, 1.2309e-04,\n",
              "            2.0133e-03, 3.0173e-03, 3.7704e-05, 7.1642e-04, 6.2242e-05, 2.3234e-03,\n",
              "            6.8653e-04, 5.8913e-04, 1.7560e-04, 9.0725e-04, 8.5801e-04, 1.1064e-04,\n",
              "            2.2841e-04, 2.2579e-06, 2.4474e-04, 8.4441e-05, 1.2125e-04, 2.6566e-04,\n",
              "            1.3444e-04, 2.7682e-04, 1.3624e-05, 8.3291e-06, 3.7412e-05, 7.3785e-05,\n",
              "            7.6289e-05, 1.2956e-04, 5.9243e-02, 9.3485e-05, 4.0475e-05, 2.7217e-06,\n",
              "            1.9663e-04, 4.0591e-05, 1.3290e-04, 4.5788e-05, 6.7731e-05, 3.9036e-05,\n",
              "            1.3160e-06, 1.3462e-05, 1.9565e-05, 2.6119e-04, 1.6297e-05, 4.5729e-06,\n",
              "            1.9220e-05, 2.2146e-06, 8.3672e-06, 5.7262e-06, 9.9817e-05, 2.4808e-05,\n",
              "            1.5341e-06, 6.3370e-08, 1.1457e-05, 1.7743e-07, 2.2563e-06, 1.9828e-06,\n",
              "            4.5867e-04, 6.6181e-06, 5.0997e-06, 4.0477e-06, 4.1308e-07, 1.1524e-06,\n",
              "            4.7731e-05, 2.0896e-08, 6.3924e-07, 3.8762e-08, 7.5432e-08, 1.5409e-05,\n",
              "            1.6040e-07, 7.4333e-06, 8.2627e-07, 2.0538e-10, 1.6219e-09, 3.8425e-06,\n",
              "            3.2495e-10, 1.6146e-08, 5.5142e-11, 1.1678e-06, 7.4937e-11, 1.2263e-05]],\n",
              "          device='cuda:0', grad_fn=<SigmoidBackward>),\n",
              "   tensor([[1.0000e+00, 1.7307e-07, 3.0456e-09, 1.7270e-05, 6.4998e-08, 6.8176e-09,\n",
              "            5.9874e-09, 2.5287e-09, 6.5237e-07, 3.3236e-06, 1.2421e-05, 1.7091e-07,\n",
              "            3.2444e-07, 2.6255e-04, 3.1532e-08, 7.4034e-08, 5.6564e-09, 3.1431e-09,\n",
              "            3.1382e-07, 1.0633e-05, 7.6830e-08, 9.3520e-05, 2.8754e-07, 2.3557e-05,\n",
              "            2.4110e-03, 2.6864e-07, 1.0244e-06, 1.0995e-07, 5.5776e-06, 1.2585e-06,\n",
              "            1.7406e-08, 3.3394e-04, 1.0670e-09, 6.8570e-10, 1.1969e-06, 8.4320e-08,\n",
              "            1.2980e-07, 2.7753e-06, 2.6379e-04, 8.0851e-09, 2.2960e-09, 8.8976e-08,\n",
              "            3.5998e-05, 1.0492e-03, 7.6911e-06, 6.3475e-07, 7.2589e-08, 1.3666e-09,\n",
              "            1.1965e-07, 1.1938e-06, 5.8216e-06, 3.0701e-04, 1.1415e-07, 3.9282e-08,\n",
              "            1.5075e-06, 4.5404e-04, 1.6990e-09, 8.5154e-06, 1.6629e-05, 1.8363e-04,\n",
              "            1.0162e-07, 1.7673e-09, 2.0774e-05, 1.1290e-06, 1.5822e-05, 3.2373e-09,\n",
              "            3.4438e-06, 6.7343e-07, 6.8490e-04, 2.7392e-04, 1.5062e-07, 3.7817e-08,\n",
              "            1.1136e-03, 3.3599e-08, 7.5391e-04, 1.1709e-10, 1.8294e-07, 4.4786e-06,\n",
              "            9.7231e-07, 9.3916e-05],\n",
              "           [1.0000e+00, 5.6687e-08, 2.3314e-07, 1.5637e-07, 2.3377e-07, 6.9954e-10,\n",
              "            4.6306e-08, 1.1150e-10, 8.5839e-08, 8.5228e-07, 1.4683e-06, 3.7546e-06,\n",
              "            2.4960e-08, 1.2130e-06, 1.4796e-07, 3.5193e-07, 2.3644e-07, 7.1231e-10,\n",
              "            2.8312e-06, 6.6866e-06, 1.0420e-06, 8.8771e-07, 5.5844e-08, 8.4978e-09,\n",
              "            4.4987e-05, 1.7308e-07, 7.2787e-08, 2.7608e-08, 1.5770e-06, 1.8874e-07,\n",
              "            5.6410e-08, 8.1004e-05, 4.0612e-10, 7.8802e-10, 7.7220e-08, 7.2264e-09,\n",
              "            6.0349e-07, 3.5373e-06, 2.8170e-04, 3.4480e-06, 3.2356e-09, 2.8729e-07,\n",
              "            1.1758e-06, 2.8772e-03, 9.5136e-07, 1.0006e-07, 6.9579e-07, 5.2979e-06,\n",
              "            2.7203e-08, 1.4938e-07, 1.0109e-06, 3.2599e-05, 1.8210e-05, 1.0756e-07,\n",
              "            1.2285e-04, 2.1479e-06, 1.7775e-08, 4.5502e-06, 6.2349e-06, 6.4277e-08,\n",
              "            1.2531e-09, 1.8897e-11, 3.1836e-06, 3.7870e-07, 2.9255e-06, 1.8184e-08,\n",
              "            1.2046e-05, 1.1944e-08, 2.7154e-07, 3.0862e-05, 5.2705e-07, 2.3448e-07,\n",
              "            9.0712e-06, 6.2016e-06, 1.2243e-08, 1.6188e-10, 2.5973e-07, 3.3591e-05,\n",
              "            1.4162e-10, 2.6119e-04],\n",
              "           [1.0000e+00, 6.4335e-10, 2.7529e-11, 4.3847e-06, 4.7453e-08, 1.4095e-10,\n",
              "            4.2653e-10, 1.2966e-10, 2.3893e-08, 3.6964e-08, 4.4640e-07, 5.7526e-08,\n",
              "            1.6388e-06, 1.0420e-08, 2.6548e-07, 3.0569e-06, 3.3613e-09, 1.6369e-10,\n",
              "            9.2545e-10, 3.5170e-10, 3.1025e-04, 2.8433e-04, 1.6784e-06, 1.6670e-07,\n",
              "            3.7840e-05, 4.4432e-06, 1.6802e-06, 1.1756e-05, 1.1824e-05, 4.7410e-07,\n",
              "            7.3567e-06, 7.0479e-04, 5.1607e-10, 5.2940e-10, 1.3141e-06, 8.8372e-09,\n",
              "            3.0710e-07, 9.4764e-05, 1.8930e-02, 7.3451e-07, 4.0842e-09, 8.9730e-08,\n",
              "            3.9214e-04, 1.8301e-05, 1.0239e-07, 8.0049e-07, 8.3292e-07, 3.0837e-07,\n",
              "            8.3475e-10, 2.0211e-06, 3.4765e-07, 2.3004e-05, 2.0317e-06, 2.3916e-06,\n",
              "            1.0807e-05, 2.4795e-05, 8.6539e-07, 3.6952e-04, 2.4683e-07, 2.3177e-07,\n",
              "            1.4795e-08, 3.6690e-09, 1.9022e-05, 2.0668e-06, 8.8783e-06, 7.0601e-07,\n",
              "            4.2024e-06, 7.5339e-07, 1.5651e-06, 8.2154e-05, 3.7737e-09, 1.7097e-09,\n",
              "            2.7161e-08, 1.4632e-08, 3.4014e-09, 4.3994e-09, 2.7264e-08, 1.1827e-04,\n",
              "            7.5123e-10, 1.9875e-04],\n",
              "           [1.0000e+00, 3.9725e-08, 4.9600e-08, 2.6120e-07, 6.6990e-08, 1.0657e-09,\n",
              "            8.6575e-08, 2.9005e-10, 2.7567e-08, 1.9628e-08, 1.7095e-04, 1.3893e-06,\n",
              "            1.0397e-06, 1.6851e-04, 1.7863e-06, 6.2991e-08, 2.1574e-07, 2.2576e-08,\n",
              "            1.7012e-03, 1.0927e-05, 1.6072e-07, 9.5923e-04, 8.1717e-08, 9.3692e-05,\n",
              "            9.4765e-06, 3.0300e-06, 2.0920e-07, 5.0306e-07, 7.5311e-07, 8.5763e-09,\n",
              "            4.8808e-09, 2.6626e-06, 9.2247e-10, 1.2025e-08, 1.6568e-05, 9.2505e-08,\n",
              "            3.0814e-06, 7.5476e-07, 5.8927e-04, 3.8798e-06, 5.5796e-11, 1.0214e-06,\n",
              "            4.7684e-06, 4.2325e-07, 6.8270e-05, 1.4968e-07, 9.3778e-06, 3.0007e-06,\n",
              "            2.2971e-08, 6.8301e-07, 1.4727e-08, 5.8688e-05, 4.2510e-08, 1.4188e-05,\n",
              "            5.6649e-07, 1.3345e-06, 7.9929e-09, 3.2916e-04, 1.0531e-04, 6.0229e-07,\n",
              "            1.2984e-05, 2.6460e-09, 3.9050e-07, 3.6180e-05, 3.5561e-08, 1.0975e-06,\n",
              "            4.1348e-04, 1.3616e-09, 9.7608e-06, 3.9015e-05, 2.4561e-06, 1.3719e-07,\n",
              "            1.1077e-04, 8.3714e-10, 4.2956e-06, 1.7147e-08, 6.9571e-07, 1.8011e-05,\n",
              "            9.3387e-07, 2.5527e-06],\n",
              "           [1.0000e+00, 1.4767e-08, 6.7556e-07, 4.4814e-07, 7.5479e-09, 3.6617e-09,\n",
              "            7.3103e-08, 7.7175e-09, 3.5223e-08, 2.8515e-08, 1.9228e-04, 1.5999e-07,\n",
              "            2.5528e-07, 8.4291e-08, 1.1806e-08, 5.4516e-08, 3.8836e-06, 1.8132e-08,\n",
              "            3.7518e-05, 5.5312e-06, 1.6626e-04, 3.4101e-07, 2.0920e-07, 2.8025e-04,\n",
              "            5.8000e-05, 3.6045e-08, 7.8781e-07, 6.7230e-05, 1.6985e-07, 5.5669e-09,\n",
              "            4.7942e-05, 6.9447e-07, 8.3861e-10, 2.7245e-10, 1.7964e-06, 1.8531e-09,\n",
              "            8.4360e-08, 1.6672e-06, 2.0970e-04, 1.9887e-05, 1.6205e-09, 4.6460e-08,\n",
              "            6.8882e-07, 9.4000e-07, 1.1670e-07, 3.1426e-04, 3.0751e-08, 2.6966e-08,\n",
              "            1.7633e-08, 3.7940e-06, 8.6738e-08, 9.0060e-05, 2.3147e-06, 7.5384e-07,\n",
              "            1.7377e-08, 1.1620e-06, 1.5013e-08, 4.9261e-03, 1.9880e-06, 8.3627e-05,\n",
              "            5.9090e-05, 1.3653e-07, 7.0305e-06, 1.2458e-06, 1.6171e-05, 7.1519e-08,\n",
              "            9.4323e-05, 4.1079e-07, 2.4327e-05, 2.7158e-05, 1.4356e-05, 1.8153e-05,\n",
              "            4.7081e-02, 3.1397e-07, 2.7707e-05, 2.9734e-06, 5.9111e-07, 1.0352e-04,\n",
              "            1.3676e-05, 8.5559e-04],\n",
              "           [1.0000e+00, 9.0956e-09, 9.7896e-10, 6.6439e-08, 1.5122e-09, 1.7823e-10,\n",
              "            1.7454e-09, 1.8147e-10, 5.5038e-09, 1.2356e-07, 1.6634e-05, 5.7499e-08,\n",
              "            4.1851e-08, 5.2381e-08, 2.4565e-06, 1.3896e-07, 1.1365e-07, 2.8163e-09,\n",
              "            1.1337e-07, 1.0946e-06, 3.1336e-07, 5.4544e-04, 2.5713e-08, 3.5534e-08,\n",
              "            1.0678e-04, 8.3572e-07, 4.5677e-07, 1.5959e-07, 9.4330e-05, 3.5386e-08,\n",
              "            6.7805e-08, 3.6187e-07, 9.8466e-12, 1.1427e-10, 4.9841e-06, 2.4054e-09,\n",
              "            1.5039e-07, 3.8527e-07, 2.6960e-04, 1.1514e-08, 1.9833e-11, 8.4971e-06,\n",
              "            1.7111e-05, 1.3014e-06, 1.8390e-07, 8.3416e-10, 2.2187e-07, 3.6878e-07,\n",
              "            3.1466e-10, 8.8528e-07, 1.4549e-08, 3.4590e-05, 2.9277e-11, 6.3737e-07,\n",
              "            7.7764e-09, 2.9943e-08, 3.0751e-10, 2.4657e-06, 2.3067e-07, 2.3045e-06,\n",
              "            1.2675e-08, 7.5351e-12, 5.8213e-09, 2.7340e-08, 2.0862e-08, 3.2558e-09,\n",
              "            1.7092e-06, 1.0314e-07, 2.9484e-07, 9.5541e-06, 7.1577e-09, 1.0756e-07,\n",
              "            1.8580e-06, 8.4028e-12, 4.3610e-07, 8.8655e-11, 2.6282e-09, 2.8209e-06,\n",
              "            1.0743e-10, 1.9785e-07],\n",
              "           [1.0000e+00, 2.7283e-10, 2.1313e-09, 6.7566e-09, 2.0766e-10, 1.2308e-12,\n",
              "            5.8248e-10, 8.8433e-15, 3.8932e-11, 1.1601e-09, 2.7192e-07, 1.8540e-06,\n",
              "            7.8588e-09, 6.6913e-09, 5.8648e-10, 1.7773e-11, 4.6060e-09, 1.0733e-11,\n",
              "            1.1018e-06, 4.0837e-07, 7.7928e-08, 4.9772e-06, 3.2773e-06, 4.8775e-08,\n",
              "            1.9293e-05, 1.8773e-06, 5.7542e-09, 6.9951e-08, 1.6006e-06, 2.6771e-07,\n",
              "            3.4254e-10, 2.8117e-06, 1.9554e-11, 4.8368e-09, 2.3087e-06, 1.2121e-07,\n",
              "            9.2126e-06, 1.9328e-07, 6.5704e-06, 4.5515e-07, 1.2453e-10, 2.0510e-07,\n",
              "            2.8454e-07, 5.8800e-05, 1.1326e-05, 3.2217e-07, 8.7400e-07, 5.6583e-06,\n",
              "            5.0955e-08, 3.1779e-07, 2.5654e-09, 7.3172e-06, 2.1878e-07, 3.2130e-07,\n",
              "            1.5988e-06, 1.3720e-07, 8.5341e-09, 1.9395e-06, 3.9823e-06, 8.0884e-08,\n",
              "            8.4239e-10, 7.7942e-10, 4.7964e-07, 1.4320e-07, 4.0046e-08, 4.0946e-09,\n",
              "            7.9764e-05, 1.3059e-09, 1.0849e-07, 3.1876e-06, 1.1187e-07, 2.6021e-09,\n",
              "            1.1719e-05, 2.4522e-08, 9.8504e-09, 2.4103e-09, 5.9507e-06, 2.6456e-06,\n",
              "            3.2082e-07, 5.0343e-04],\n",
              "           [1.0000e+00, 1.7962e-07, 8.8030e-11, 1.1026e-06, 2.5077e-08, 1.0602e-10,\n",
              "            1.0758e-08, 2.8609e-10, 1.8399e-07, 1.2039e-06, 3.1150e-04, 1.0810e-07,\n",
              "            4.4190e-05, 6.8193e-05, 1.9839e-07, 2.1294e-07, 1.7606e-08, 1.3437e-06,\n",
              "            2.6668e-06, 9.9541e-08, 1.1876e-05, 5.7434e-05, 8.7175e-07, 2.0406e-06,\n",
              "            9.7133e-06, 1.2217e-04, 4.5253e-04, 8.2315e-06, 8.4298e-07, 3.3284e-06,\n",
              "            1.0142e-05, 2.9931e-04, 5.6493e-08, 1.3644e-08, 2.2370e-04, 5.5547e-08,\n",
              "            1.0751e-06, 3.7103e-05, 1.2171e-02, 6.1725e-08, 1.0488e-10, 1.0067e-09,\n",
              "            6.9537e-05, 1.2847e-04, 9.5372e-07, 3.0062e-06, 5.2161e-06, 1.9735e-06,\n",
              "            5.1099e-09, 3.6177e-06, 1.5957e-06, 5.6662e-02, 1.2434e-08, 5.8738e-08,\n",
              "            6.1450e-08, 6.1140e-05, 3.2020e-08, 1.0629e-04, 1.0831e-04, 4.4367e-06,\n",
              "            1.1762e-07, 1.0309e-08, 9.0983e-05, 1.3766e-06, 9.8791e-05, 2.5262e-06,\n",
              "            2.6297e-06, 1.3671e-07, 4.1500e-02, 7.4607e-06, 3.3381e-07, 1.0551e-07,\n",
              "            3.8679e-02, 1.0229e-07, 1.4107e-04, 1.9483e-08, 2.2838e-08, 4.1105e-05,\n",
              "            2.7559e-08, 2.6325e-04],\n",
              "           [9.9996e-01, 4.2634e-06, 7.2434e-07, 1.3512e-04, 1.4998e-05, 8.8217e-07,\n",
              "            5.9380e-07, 8.6147e-08, 4.9744e-05, 5.4125e-05, 6.2127e-05, 3.0378e-06,\n",
              "            1.3535e-06, 4.2090e-05, 2.8623e-06, 2.4983e-06, 3.2392e-07, 9.2404e-08,\n",
              "            2.1696e-05, 1.1615e-04, 1.9161e-05, 9.4272e-05, 2.0137e-06, 5.4964e-06,\n",
              "            1.6900e-04, 6.9894e-06, 1.0904e-04, 8.0016e-06, 1.3445e-06, 8.4311e-04,\n",
              "            3.2648e-07, 1.4232e-05, 7.6939e-08, 4.4996e-08, 1.0528e-04, 1.6220e-06,\n",
              "            1.2671e-05, 1.5220e-05, 2.1231e-03, 1.1919e-05, 5.3373e-08, 1.0245e-06,\n",
              "            1.9980e-06, 2.7413e-03, 6.0731e-06, 6.1659e-08, 6.1440e-09, 2.3521e-07,\n",
              "            2.2897e-07, 2.0849e-05, 8.9530e-07, 6.6472e-05, 6.8041e-06, 3.0007e-05,\n",
              "            4.1650e-06, 4.0209e-04, 3.2761e-09, 1.9308e-06, 3.7434e-07, 1.0432e-05,\n",
              "            1.5129e-07, 9.1802e-09, 4.8426e-06, 5.1530e-05, 4.3672e-06, 2.8591e-06,\n",
              "            2.3537e-03, 1.4590e-07, 9.8066e-05, 1.0384e-03, 3.5929e-05, 1.3567e-06,\n",
              "            5.7470e-03, 1.2769e-06, 9.9665e-04, 2.8710e-07, 5.3789e-04, 2.9985e-04,\n",
              "            4.2118e-06, 5.5037e-03],\n",
              "           [1.0000e+00, 3.3967e-09, 2.4267e-10, 2.6190e-07, 4.2031e-09, 5.8121e-12,\n",
              "            1.1151e-10, 9.0963e-14, 6.7375e-09, 1.9273e-07, 7.9171e-09, 1.4996e-07,\n",
              "            6.2101e-10, 2.3231e-06, 7.8317e-11, 7.8098e-11, 4.4621e-09, 2.2019e-11,\n",
              "            3.4116e-07, 3.1688e-05, 1.7586e-09, 1.5653e-06, 2.6506e-09, 1.9544e-08,\n",
              "            3.4458e-06, 3.9300e-08, 8.3244e-09, 4.6746e-09, 3.5842e-06, 8.6202e-07,\n",
              "            3.4535e-11, 1.8573e-05, 1.1374e-12, 8.8303e-11, 3.6727e-07, 1.5608e-09,\n",
              "            2.1732e-07, 3.1533e-10, 2.4016e-06, 1.3866e-08, 8.3776e-13, 3.2381e-10,\n",
              "            1.9440e-09, 2.0879e-04, 7.6539e-07, 3.4337e-09, 7.0637e-10, 1.2778e-08,\n",
              "            1.5219e-09, 2.0740e-08, 1.6004e-12, 1.7432e-07, 7.4693e-08, 1.0938e-09,\n",
              "            9.4434e-12, 3.4348e-10, 7.3909e-11, 1.5652e-07, 1.1365e-10, 3.0410e-10,\n",
              "            1.3168e-10, 1.8963e-12, 1.7055e-07, 6.9168e-09, 3.4384e-08, 1.9791e-10,\n",
              "            1.8407e-05, 7.2473e-09, 3.5226e-08, 5.4828e-07, 2.3177e-08, 3.8219e-10,\n",
              "            1.6682e-05, 3.5542e-09, 5.9894e-09, 5.2165e-14, 1.2231e-08, 4.2818e-07,\n",
              "            1.0237e-09, 3.1627e-05]], device='cuda:0', grad_fn=<CatBackward>)]},\n",
              " {1: [tensor([[9.9675e-01, 1.9405e-03, 2.9267e-03, 2.2958e-05, 7.6831e-04, 3.9533e-04,\n",
              "            3.6149e-04, 7.9860e-03, 5.9478e-04, 1.0889e-04],\n",
              "           [1.0000e+00, 3.9136e-08, 7.2778e-09, 3.1283e-10, 1.8783e-05, 2.5041e-09,\n",
              "            2.1833e-05, 5.4088e-07, 1.0370e-09, 1.8149e-08],\n",
              "           [1.0000e+00, 3.7585e-05, 1.1283e-06, 3.6188e-08, 2.0992e-05, 2.4672e-07,\n",
              "            1.3998e-06, 6.5545e-06, 5.2690e-07, 7.9246e-07],\n",
              "           [1.0000e+00, 1.1913e-06, 1.8508e-06, 9.6649e-09, 5.0319e-06, 1.8961e-07,\n",
              "            3.8241e-07, 1.1612e-06, 2.2529e-07, 2.0893e-06],\n",
              "           [1.0000e+00, 5.5362e-08, 5.3834e-07, 2.4824e-09, 3.5232e-06, 1.3453e-07,\n",
              "            5.7396e-07, 1.5680e-06, 4.6706e-08, 3.5064e-08],\n",
              "           [1.0000e+00, 3.3735e-06, 3.2294e-06, 3.3591e-08, 2.5237e-06, 6.6707e-07,\n",
              "            2.7052e-06, 1.7723e-05, 1.7670e-06, 8.0426e-07],\n",
              "           [1.0000e+00, 3.9221e-05, 6.3970e-08, 9.5927e-09, 8.8523e-06, 1.5219e-08,\n",
              "            1.8456e-05, 1.2740e-07, 3.9835e-08, 2.9568e-06],\n",
              "           [1.0000e+00, 3.1334e-08, 1.8194e-07, 5.3577e-10, 3.4858e-06, 8.8925e-09,\n",
              "            4.8822e-09, 8.5618e-08, 3.2582e-08, 1.2637e-06],\n",
              "           [9.9999e-01, 1.3771e-06, 4.0884e-05, 2.3278e-08, 1.8647e-06, 1.1383e-06,\n",
              "            1.5389e-06, 2.8489e-06, 1.0478e-06, 2.5620e-06],\n",
              "           [9.9997e-01, 9.6893e-06, 1.7038e-05, 2.3080e-07, 1.3176e-03, 7.5329e-06,\n",
              "            1.0037e-05, 5.8992e-05, 6.3828e-06, 2.7492e-05]], device='cuda:0',\n",
              "          grad_fn=<SigmoidBackward>),\n",
              "   tensor([[9.9675e-01, 1.9405e-03, 2.9267e-03, 2.2958e-05, 7.6831e-04, 3.9533e-04,\n",
              "            3.6149e-04, 7.9860e-03, 5.9478e-04, 1.0889e-04],\n",
              "           [1.0000e+00, 3.9136e-08, 7.2778e-09, 3.1283e-10, 1.8783e-05, 2.5041e-09,\n",
              "            2.1833e-05, 5.4088e-07, 1.0370e-09, 1.8149e-08],\n",
              "           [1.0000e+00, 3.7585e-05, 1.1283e-06, 3.6188e-08, 2.0992e-05, 2.4672e-07,\n",
              "            1.3998e-06, 6.5545e-06, 5.2690e-07, 7.9246e-07],\n",
              "           [1.0000e+00, 1.1913e-06, 1.8508e-06, 9.6649e-09, 5.0319e-06, 1.8961e-07,\n",
              "            3.8241e-07, 1.1612e-06, 2.2529e-07, 2.0893e-06],\n",
              "           [1.0000e+00, 5.5362e-08, 5.3834e-07, 2.4824e-09, 3.5232e-06, 1.3453e-07,\n",
              "            5.7396e-07, 1.5680e-06, 4.6706e-08, 3.5064e-08],\n",
              "           [1.0000e+00, 3.3735e-06, 3.2294e-06, 3.3591e-08, 2.5237e-06, 6.6707e-07,\n",
              "            2.7052e-06, 1.7723e-05, 1.7670e-06, 8.0426e-07],\n",
              "           [1.0000e+00, 3.9221e-05, 6.3970e-08, 9.5927e-09, 8.8523e-06, 1.5219e-08,\n",
              "            1.8456e-05, 1.2740e-07, 3.9835e-08, 2.9568e-06],\n",
              "           [1.0000e+00, 3.1334e-08, 1.8194e-07, 5.3577e-10, 3.4858e-06, 8.8925e-09,\n",
              "            4.8822e-09, 8.5618e-08, 3.2582e-08, 1.2637e-06],\n",
              "           [9.9999e-01, 1.3771e-06, 4.0884e-05, 2.3278e-08, 1.8647e-06, 1.1383e-06,\n",
              "            1.5389e-06, 2.8489e-06, 1.0478e-06, 2.5620e-06],\n",
              "           [9.9997e-01, 9.6893e-06, 1.7038e-05, 2.3080e-07, 1.3176e-03, 7.5329e-06,\n",
              "            1.0037e-05, 5.8992e-05, 6.3828e-06, 2.7492e-05]], device='cuda:0',\n",
              "          grad_fn=<SigmoidBackward>)],\n",
              "  2: [tensor([[9.9576e-01, 5.6356e-03, 5.1784e-03, 2.7833e-05, 1.3690e-03, 4.1772e-04,\n",
              "            2.6829e-03, 6.6040e-03, 7.3081e-04, 3.3454e-04, 3.9820e-05, 1.2683e-02,\n",
              "            1.4226e-05, 2.2656e-04, 1.7503e-04, 5.3236e-07, 2.2348e-05, 9.4289e-04,\n",
              "            8.2729e-05, 1.4333e-03],\n",
              "           [9.9984e-01, 8.8776e-06, 8.9419e-06, 5.4175e-07, 2.5605e-03, 3.5509e-06,\n",
              "            1.0875e-04, 6.2581e-05, 5.2045e-07, 4.1386e-06, 4.0294e-08, 7.7502e-07,\n",
              "            1.1723e-09, 3.8523e-08, 2.7014e-08, 1.6345e-11, 2.1542e-07, 3.7851e-06,\n",
              "            7.5020e-07, 1.1481e-06],\n",
              "           [9.9984e-01, 1.4393e-04, 1.2851e-05, 2.1621e-06, 1.8695e-03, 1.3385e-05,\n",
              "            1.5781e-04, 4.0013e-05, 4.3783e-06, 4.4051e-06, 4.5503e-08, 7.3673e-07,\n",
              "            3.2650e-07, 3.4725e-05, 3.7635e-09, 1.7517e-10, 9.7944e-08, 1.9125e-04,\n",
              "            3.4698e-09, 3.7376e-06],\n",
              "           [9.9992e-01, 3.2906e-05, 3.2963e-05, 1.5644e-06, 4.2078e-04, 3.5267e-06,\n",
              "            6.8188e-05, 1.0116e-05, 1.6289e-06, 3.3045e-05, 8.8960e-07, 5.8938e-07,\n",
              "            5.5091e-09, 2.8425e-04, 2.9692e-10, 2.3806e-09, 2.9855e-07, 1.7486e-08,\n",
              "            2.5218e-10, 1.9756e-07],\n",
              "           [9.9986e-01, 1.6137e-05, 2.7790e-05, 6.4894e-07, 2.9610e-04, 3.4952e-06,\n",
              "            8.6011e-05, 2.9024e-05, 2.6463e-06, 1.6302e-06, 1.0745e-07, 1.1834e-09,\n",
              "            1.1576e-09, 1.4385e-07, 1.2554e-09, 6.3223e-12, 8.5600e-10, 3.3882e-06,\n",
              "            1.2006e-09, 2.2862e-05],\n",
              "           [9.9999e-01, 8.5245e-06, 1.3647e-05, 6.1132e-07, 1.0319e-04, 1.4375e-06,\n",
              "            1.4362e-05, 1.0928e-05, 5.1880e-07, 1.6788e-06, 3.6971e-06, 2.7502e-08,\n",
              "            1.1650e-08, 1.3757e-07, 7.4059e-11, 5.9853e-12, 1.0773e-07, 5.3514e-08,\n",
              "            6.8858e-11, 7.9017e-07],\n",
              "           [9.9988e-01, 1.5405e-04, 3.8556e-05, 7.4754e-06, 1.9045e-03, 2.0296e-05,\n",
              "            2.4065e-04, 9.3337e-05, 5.2035e-06, 3.1621e-06, 2.6194e-07, 1.2176e-07,\n",
              "            4.0942e-07, 2.5713e-04, 4.7038e-09, 4.7090e-10, 1.0648e-07, 7.0159e-04,\n",
              "            7.4982e-09, 1.0849e-05],\n",
              "           [9.9994e-01, 5.3046e-06, 1.6588e-05, 6.5041e-07, 3.1737e-04, 1.0656e-06,\n",
              "            1.4958e-05, 3.4092e-06, 4.5773e-07, 9.9720e-06, 3.3355e-08, 1.1425e-07,\n",
              "            2.3886e-09, 6.5693e-07, 3.9801e-10, 5.3662e-11, 1.5949e-09, 4.0150e-09,\n",
              "            1.4452e-11, 8.2960e-07],\n",
              "           [9.9997e-01, 3.2125e-05, 5.7967e-05, 3.6462e-07, 2.9532e-05, 8.1232e-06,\n",
              "            6.3658e-06, 2.3678e-05, 8.4487e-06, 3.1693e-06, 4.0102e-07, 1.2584e-06,\n",
              "            3.7116e-10, 5.4485e-09, 2.8310e-09, 5.8144e-11, 7.2360e-09, 7.7373e-08,\n",
              "            3.9706e-08, 1.0055e-05],\n",
              "           [9.9865e-01, 7.1700e-04, 1.7421e-04, 1.0446e-05, 1.1263e-03, 3.9279e-05,\n",
              "            8.6711e-04, 1.1585e-04, 2.1755e-05, 6.3026e-05, 1.2658e-04, 1.0026e-05,\n",
              "            1.4193e-07, 1.0592e-04, 1.8455e-08, 1.7444e-07, 7.8008e-06, 1.3432e-06,\n",
              "            3.1778e-08, 5.8806e-06]], device='cuda:0', grad_fn=<SigmoidBackward>),\n",
              "   tensor([[9.9827e-01, 2.9183e-03, 1.8905e-03, 2.5136e-05, 6.7528e-04, 2.3172e-04,\n",
              "            2.9385e-04, 4.2130e-03, 4.8867e-04, 6.6612e-05],\n",
              "           [9.9999e-01, 5.4751e-07, 1.1815e-08, 2.3711e-09, 4.1564e-04, 1.2911e-08,\n",
              "            6.2294e-07, 2.4553e-05, 1.6831e-08, 5.0345e-08],\n",
              "           [9.9999e-01, 1.1651e-04, 4.1824e-06, 1.8877e-07, 2.1016e-03, 1.6216e-06,\n",
              "            9.8692e-05, 1.1898e-05, 1.1013e-06, 9.3140e-06],\n",
              "           [1.0000e+00, 5.8748e-06, 6.8655e-06, 7.3922e-08, 1.4613e-04, 1.9687e-06,\n",
              "            1.2051e-05, 2.7613e-06, 7.9749e-07, 1.3474e-05],\n",
              "           [1.0000e+00, 2.3167e-07, 8.5377e-06, 2.4754e-08, 1.3561e-05, 9.1074e-07,\n",
              "            2.3662e-05, 3.1505e-05, 6.2991e-07, 9.7880e-08],\n",
              "           [1.0000e+00, 3.1046e-05, 1.2751e-07, 3.7446e-09, 3.0354e-07, 4.1198e-09,\n",
              "            7.4486e-07, 1.0333e-07, 1.1081e-08, 5.9495e-08],\n",
              "           [1.0000e+00, 2.6165e-06, 1.6633e-06, 3.6293e-08, 1.9558e-04, 3.3095e-07,\n",
              "            3.1514e-06, 3.4841e-06, 1.6232e-07, 5.1189e-07],\n",
              "           [1.0000e+00, 1.7186e-08, 3.1150e-07, 1.8521e-09, 3.1228e-05, 7.0362e-08,\n",
              "            9.7707e-08, 1.1864e-07, 5.9518e-08, 5.8582e-06],\n",
              "           [1.0000e+00, 1.3397e-06, 4.0085e-06, 7.8311e-09, 7.8508e-06, 2.7688e-07,\n",
              "            4.2477e-07, 3.3033e-06, 3.6790e-07, 3.9823e-07],\n",
              "           [9.9998e-01, 7.1278e-05, 1.8846e-05, 1.6921e-06, 2.0342e-04, 1.6118e-05,\n",
              "            1.2092e-04, 2.2558e-04, 2.8075e-05, 1.5930e-05]], device='cuda:0',\n",
              "          grad_fn=<SigmoidBackward>)],\n",
              "  3: [tensor([[9.9503e-01, 8.4993e-03, 2.8418e-03, 1.3949e-05, 2.0869e-03, 4.8083e-04,\n",
              "            7.2865e-03, 2.0297e-03, 5.1354e-04, 3.7172e-04, 5.2104e-04, 2.1280e-02,\n",
              "            3.1946e-05, 1.6704e-04, 1.4777e-04, 2.2933e-05, 9.3523e-04, 3.8875e-04,\n",
              "            8.2627e-05, 4.3269e-03, 3.1947e-04, 1.2741e-06, 3.6073e-07, 5.1585e-04,\n",
              "            2.6785e-08, 1.2847e-07, 1.9966e-08, 1.3543e-07, 1.0941e-04, 6.6827e-07],\n",
              "           [9.9931e-01, 2.8303e-04, 1.1631e-04, 1.0430e-05, 7.0295e-04, 6.9354e-05,\n",
              "            1.1650e-03, 1.8328e-03, 6.8371e-05, 1.4154e-05, 5.7736e-06, 2.2837e-05,\n",
              "            9.1936e-08, 6.0962e-05, 3.3669e-07, 1.2953e-07, 3.1803e-05, 3.9351e-04,\n",
              "            2.6157e-05, 5.2331e-05, 2.1512e-08, 1.6242e-11, 1.2055e-09, 9.3072e-07,\n",
              "            9.0996e-10, 9.3384e-10, 1.2027e-11, 5.9412e-07, 7.0583e-06, 4.6345e-10],\n",
              "           [9.9228e-01, 6.7129e-03, 1.1457e-03, 3.7621e-05, 5.9777e-03, 1.1287e-03,\n",
              "            9.1497e-03, 1.9463e-03, 1.0652e-03, 1.1428e-04, 2.8567e-04, 1.5897e-03,\n",
              "            1.3597e-05, 2.7525e-03, 1.3696e-04, 1.4273e-06, 2.6253e-04, 7.2817e-04,\n",
              "            4.0369e-05, 2.2704e-03, 1.6133e-06, 1.9558e-08, 5.0992e-05, 1.4185e-03,\n",
              "            4.7836e-08, 2.1410e-06, 2.6764e-06, 1.3003e-04, 1.3130e-05, 2.7437e-08],\n",
              "           [9.9953e-01, 1.0698e-03, 7.2732e-04, 5.8218e-06, 6.0847e-04, 1.7425e-04,\n",
              "            2.3769e-04, 8.1146e-05, 2.9773e-04, 6.6919e-05, 2.5941e-04, 1.0977e-04,\n",
              "            1.0553e-07, 1.9915e-04, 3.2977e-06, 5.9093e-08, 2.9342e-05, 2.7776e-05,\n",
              "            9.2280e-06, 2.5439e-03, 2.3394e-08, 2.8444e-10, 3.4991e-07, 2.3408e-04,\n",
              "            6.5249e-09, 3.2697e-08, 2.7506e-10, 6.8546e-08, 9.9629e-07, 5.2957e-09],\n",
              "           [9.9833e-01, 3.2175e-04, 9.7046e-04, 3.2129e-05, 9.6789e-04, 2.7227e-04,\n",
              "            5.1882e-04, 1.6085e-03, 1.6680e-04, 3.9645e-05, 2.0164e-04, 1.4210e-05,\n",
              "            2.0438e-07, 1.3859e-04, 1.2309e-06, 7.5924e-08, 8.8493e-06, 1.2451e-03,\n",
              "            1.1119e-04, 8.8993e-05, 2.9417e-08, 1.8468e-10, 9.6302e-08, 2.4429e-07,\n",
              "            1.4767e-09, 2.1477e-08, 9.7230e-10, 4.7270e-06, 5.6098e-05, 4.4138e-10],\n",
              "           [9.9995e-01, 9.7342e-05, 2.8991e-05, 1.1838e-06, 2.2432e-04, 2.8845e-05,\n",
              "            1.6373e-05, 1.4316e-04, 1.1820e-05, 5.4785e-07, 9.3627e-07, 7.7587e-07,\n",
              "            1.1408e-09, 5.7174e-05, 5.0176e-09, 7.0010e-11, 9.8490e-08, 4.9134e-06,\n",
              "            5.1615e-08, 6.0093e-06, 1.5534e-13, 1.3353e-15, 1.4721e-12, 9.7821e-09,\n",
              "            2.4624e-14, 4.0016e-14, 1.0587e-12, 2.6132e-09, 4.7635e-10, 2.0690e-14],\n",
              "           [9.9850e-01, 1.0332e-03, 2.1986e-03, 1.3698e-05, 4.6563e-03, 6.4156e-04,\n",
              "            8.2740e-04, 1.8798e-03, 2.4848e-04, 2.7543e-05, 4.4739e-04, 1.3259e-05,\n",
              "            4.3685e-07, 3.1989e-03, 1.0785e-06, 7.4960e-08, 9.7972e-05, 2.8470e-03,\n",
              "            1.7670e-05, 1.8176e-03, 2.9934e-07, 4.7599e-10, 1.2395e-06, 9.6842e-05,\n",
              "            3.4658e-08, 4.6134e-07, 1.3975e-08, 1.1047e-05, 7.9402e-06, 1.6338e-10],\n",
              "           [9.9813e-01, 2.4486e-04, 3.0849e-04, 1.0803e-05, 1.4498e-03, 9.2054e-05,\n",
              "            5.3037e-04, 2.4014e-04, 1.6976e-04, 3.3828e-05, 1.2613e-05, 9.3269e-05,\n",
              "            1.2375e-06, 4.4656e-05, 1.2270e-06, 4.7148e-08, 4.9571e-06, 1.1231e-05,\n",
              "            4.1914e-07, 5.8704e-04, 7.2166e-10, 7.0118e-12, 1.1869e-07, 1.3125e-04,\n",
              "            1.0555e-09, 4.3480e-09, 2.8742e-10, 2.9181e-08, 7.5798e-08, 1.7984e-09],\n",
              "           [9.9901e-01, 8.0005e-04, 6.7738e-04, 6.9876e-06, 1.0963e-03, 2.2719e-04,\n",
              "            6.2372e-05, 4.1850e-04, 2.1361e-04, 4.1456e-05, 1.0130e-06, 5.0184e-04,\n",
              "            1.2799e-07, 1.2192e-05, 2.5164e-07, 1.9537e-07, 3.4819e-06, 7.5815e-05,\n",
              "            1.8209e-04, 5.2066e-05, 6.5873e-10, 7.0504e-11, 1.8832e-08, 4.6080e-05,\n",
              "            1.5310e-11, 3.5106e-10, 7.9916e-12, 1.7896e-08, 3.3186e-06, 2.1786e-10],\n",
              "           [9.9983e-01, 1.7374e-04, 3.2194e-04, 5.4866e-06, 8.1546e-04, 1.0699e-04,\n",
              "            7.4595e-05, 2.5189e-04, 7.2103e-05, 6.9897e-06, 3.3545e-05, 1.3324e-06,\n",
              "            2.5127e-08, 6.5214e-05, 1.1111e-07, 1.0391e-08, 2.2142e-06, 9.5226e-06,\n",
              "            1.4172e-05, 6.3561e-05, 1.1197e-11, 1.5489e-10, 8.0193e-10, 1.0038e-06,\n",
              "            1.3602e-11, 4.3504e-11, 2.6325e-12, 2.3741e-09, 1.2195e-06, 2.8637e-12]],\n",
              "          device='cuda:0', grad_fn=<SigmoidBackward>),\n",
              "   tensor([[9.9975e-01, 5.1315e-04, 1.7071e-04, 1.2916e-06, 1.7883e-04, 1.0117e-05,\n",
              "            2.2378e-05, 1.9019e-04, 2.4197e-05, 1.9729e-05, 7.7432e-07, 2.0611e-03,\n",
              "            9.9372e-08, 5.9699e-05, 3.0192e-06, 3.8196e-09, 1.3525e-06, 7.0448e-05,\n",
              "            1.9804e-07, 2.1485e-04],\n",
              "           [1.0000e+00, 5.1324e-07, 3.0047e-07, 1.9429e-08, 1.0331e-04, 3.6185e-07,\n",
              "            1.2612e-05, 2.8056e-05, 2.7405e-07, 5.4235e-07, 3.5129e-07, 9.7815e-07,\n",
              "            1.1971e-07, 3.3625e-07, 3.1900e-08, 3.8222e-10, 4.0482e-07, 4.4078e-06,\n",
              "            4.2083e-07, 7.9146e-06],\n",
              "           [9.9999e-01, 4.6443e-05, 2.0310e-05, 1.5277e-06, 2.6935e-04, 1.9346e-05,\n",
              "            9.9036e-05, 7.5857e-05, 2.0895e-05, 2.1258e-05, 4.5642e-05, 1.7690e-04,\n",
              "            1.9497e-06, 1.2515e-03, 1.3614e-05, 1.0484e-07, 1.7067e-05, 2.2162e-04,\n",
              "            1.9527e-06, 6.1075e-04],\n",
              "           [1.0000e+00, 4.8159e-06, 8.1106e-06, 5.5551e-08, 4.0566e-05, 1.6605e-06,\n",
              "            4.1070e-06, 1.1172e-05, 1.5542e-06, 7.8217e-06, 8.6537e-06, 4.1749e-04,\n",
              "            4.3665e-08, 6.3561e-05, 7.3827e-07, 6.5287e-09, 1.8306e-06, 9.6678e-07,\n",
              "            2.9811e-07, 1.6225e-05],\n",
              "           [9.9997e-01, 5.2654e-06, 1.2425e-04, 1.4041e-06, 1.3760e-04, 7.8537e-05,\n",
              "            3.2814e-05, 9.6733e-04, 6.8258e-05, 4.8839e-05, 7.4629e-06, 8.1491e-07,\n",
              "            5.9801e-07, 2.0407e-05, 6.6087e-07, 1.1304e-08, 2.6843e-06, 1.0994e-02,\n",
              "            2.4617e-07, 1.6353e-04],\n",
              "           [1.0000e+00, 4.5976e-06, 2.8846e-08, 1.6925e-09, 1.6193e-06, 4.5994e-09,\n",
              "            7.3610e-07, 7.3348e-08, 4.4083e-09, 5.0489e-08, 2.4480e-08, 1.7592e-08,\n",
              "            4.9662e-10, 4.9390e-07, 8.3069e-11, 1.2682e-12, 1.7818e-08, 3.6706e-07,\n",
              "            8.2752e-11, 2.0072e-07],\n",
              "           [1.0000e+00, 4.0728e-06, 2.8490e-06, 8.8488e-08, 6.8586e-05, 6.9147e-07,\n",
              "            4.8332e-05, 3.3041e-06, 5.9325e-07, 3.5570e-06, 3.4698e-06, 2.7940e-08,\n",
              "            9.3258e-08, 1.1164e-04, 1.3682e-09, 6.0882e-10, 5.4214e-07, 3.3565e-05,\n",
              "            2.1526e-09, 1.2690e-05],\n",
              "           [9.9991e-01, 1.0231e-06, 2.3174e-06, 1.2266e-07, 2.8928e-04, 9.2582e-07,\n",
              "            1.0064e-06, 5.2345e-06, 1.1800e-06, 3.8728e-04, 1.4835e-07, 7.7331e-06,\n",
              "            6.4413e-08, 2.1638e-06, 1.5097e-08, 4.0719e-10, 3.6983e-08, 8.6296e-08,\n",
              "            4.8588e-09, 3.1188e-05],\n",
              "           [1.0000e+00, 6.3628e-06, 1.7057e-05, 1.0489e-08, 3.6562e-06, 2.5651e-07,\n",
              "            3.7365e-07, 1.0441e-06, 3.1573e-07, 5.8169e-07, 6.5544e-07, 4.0966e-06,\n",
              "            5.2929e-10, 3.6034e-08, 1.0295e-08, 1.3253e-10, 6.0610e-09, 9.3168e-08,\n",
              "            1.2113e-07, 1.5345e-05],\n",
              "           [1.0000e+00, 2.1522e-06, 7.1459e-07, 1.6334e-08, 2.8384e-06, 7.0501e-08,\n",
              "            5.6469e-07, 1.5554e-06, 1.5645e-07, 1.7409e-07, 9.0906e-06, 3.0557e-08,\n",
              "            3.2501e-10, 1.4586e-07, 1.8648e-09, 1.1328e-10, 8.9617e-08, 4.0888e-08,\n",
              "            9.6390e-09, 1.0606e-06]], device='cuda:0', grad_fn=<CatBackward>)],\n",
              "  4: [tensor([[9.7729e-01, 4.1358e-02, 5.9934e-03, 3.8451e-05, 7.4464e-03, 1.5540e-03,\n",
              "            9.4944e-03, 4.3170e-03, 6.6100e-04, 2.5680e-03, 1.0830e-02, 2.4720e-02,\n",
              "            7.9576e-05, 5.6113e-04, 6.7674e-04, 3.6942e-05, 8.3344e-04, 1.4701e-03,\n",
              "            6.9450e-04, 1.8492e-02, 1.0188e-02, 2.7228e-05, 3.0767e-04, 5.7422e-03,\n",
              "            4.5415e-06, 7.8245e-06, 5.4848e-06, 8.3199e-05, 9.7906e-04, 5.8553e-05,\n",
              "            4.1034e-08, 3.4510e-06, 1.0485e-07, 4.3902e-07, 7.3744e-08, 3.6245e-10,\n",
              "            1.5575e-03, 1.3520e-06, 1.0893e-03, 1.5539e-06],\n",
              "           [9.9731e-01, 2.1486e-04, 4.9209e-04, 7.8332e-06, 1.1318e-03, 1.4855e-04,\n",
              "            7.2813e-03, 8.2162e-04, 1.8599e-05, 2.8585e-05, 3.8336e-05, 7.3996e-05,\n",
              "            6.1298e-08, 8.8483e-05, 5.4609e-06, 2.2726e-06, 1.0963e-04, 5.1165e-03,\n",
              "            3.8746e-05, 1.0748e-04, 7.7850e-06, 3.1281e-08, 5.5739e-05, 5.4466e-05,\n",
              "            5.5671e-08, 2.3372e-08, 5.2119e-08, 5.3451e-06, 7.8698e-05, 1.0754e-08,\n",
              "            2.8913e-13, 5.9628e-09, 1.5150e-11, 6.8567e-07, 2.2849e-11, 2.7943e-11,\n",
              "            5.3393e-10, 1.3971e-08, 4.5320e-09, 1.0189e-06],\n",
              "           [9.9552e-01, 2.2545e-03, 1.3943e-03, 1.2455e-05, 2.8243e-03, 7.3786e-04,\n",
              "            1.2005e-03, 5.9869e-04, 3.4605e-04, 1.6008e-04, 3.1328e-04, 1.1262e-03,\n",
              "            3.7898e-06, 1.7685e-04, 6.4193e-06, 1.1745e-05, 1.4792e-04, 3.0122e-03,\n",
              "            1.7863e-04, 6.7229e-04, 4.9537e-06, 9.8107e-07, 3.8180e-04, 2.1441e-03,\n",
              "            4.6421e-07, 1.2716e-06, 8.0712e-07, 2.3278e-04, 4.5080e-05, 1.9245e-07,\n",
              "            5.1284e-08, 1.3827e-08, 1.2276e-09, 1.3859e-07, 1.7933e-11, 1.3518e-08,\n",
              "            4.7049e-09, 2.7541e-05, 2.4249e-07, 1.4917e-05],\n",
              "           [9.9945e-01, 3.0222e-03, 4.1069e-04, 4.7861e-06, 1.3710e-03, 8.8137e-04,\n",
              "            2.0135e-04, 1.6422e-04, 6.5591e-05, 5.9231e-05, 4.6333e-04, 1.3976e-04,\n",
              "            6.3152e-07, 1.1122e-03, 1.7859e-06, 2.3419e-06, 1.1740e-05, 3.1908e-04,\n",
              "            2.7295e-05, 5.6427e-04, 2.9370e-07, 7.8366e-07, 6.0658e-05, 5.1399e-04,\n",
              "            6.0887e-08, 9.0224e-08, 3.4104e-07, 1.6791e-06, 8.7124e-06, 2.4569e-08,\n",
              "            3.7769e-08, 4.6322e-08, 8.5970e-11, 4.2865e-10, 1.5993e-12, 3.8961e-12,\n",
              "            5.8745e-07, 4.9287e-07, 1.2467e-09, 1.6952e-06],\n",
              "           [9.9933e-01, 4.1686e-04, 6.2118e-04, 8.4446e-06, 1.6214e-03, 6.0224e-04,\n",
              "            3.3388e-04, 5.8383e-04, 5.8334e-05, 5.0665e-05, 6.5414e-04, 1.3695e-05,\n",
              "            1.8696e-07, 1.6291e-03, 6.7536e-07, 5.7294e-07, 1.2802e-05, 1.1154e-03,\n",
              "            2.0363e-04, 2.2570e-04, 3.9765e-07, 1.7507e-07, 4.7663e-06, 1.0337e-04,\n",
              "            3.0739e-08, 2.2652e-08, 7.8004e-07, 4.5640e-06, 9.8494e-06, 1.0841e-08,\n",
              "            1.4216e-10, 2.4124e-10, 1.7866e-11, 1.4899e-09, 1.2508e-12, 3.4960e-10,\n",
              "            4.7851e-10, 3.4244e-07, 8.2674e-11, 8.5580e-07],\n",
              "           [9.9975e-01, 3.0494e-04, 1.8278e-04, 5.6341e-06, 5.8597e-04, 1.5693e-04,\n",
              "            2.4201e-04, 8.5013e-04, 2.6623e-05, 7.2694e-06, 4.8095e-05, 4.5725e-05,\n",
              "            1.3718e-07, 9.9958e-05, 1.9611e-07, 2.4462e-07, 1.3049e-05, 3.0867e-04,\n",
              "            3.1735e-05, 1.0075e-04, 1.2234e-07, 9.6179e-09, 5.7289e-07, 3.9184e-04,\n",
              "            1.2436e-08, 9.7028e-09, 4.6270e-07, 1.5944e-06, 1.8816e-06, 4.1686e-09,\n",
              "            6.6637e-11, 1.6493e-10, 2.2817e-11, 2.3550e-12, 4.0281e-14, 4.4441e-11,\n",
              "            6.0455e-11, 4.9354e-07, 6.0115e-07, 3.6466e-08],\n",
              "           [9.9649e-01, 3.4186e-03, 1.6506e-03, 1.2641e-05, 1.5234e-03, 6.2932e-04,\n",
              "            2.7040e-03, 7.3766e-04, 1.8486e-04, 1.4118e-04, 1.6752e-03, 1.6372e-04,\n",
              "            2.5193e-06, 3.7316e-04, 5.7218e-06, 5.3567e-06, 8.3636e-05, 1.3376e-02,\n",
              "            1.4150e-04, 1.2198e-03, 3.2688e-06, 7.4681e-06, 3.0616e-04, 7.5841e-04,\n",
              "            1.3584e-06, 9.4178e-07, 1.2049e-06, 8.4190e-05, 5.5579e-05, 2.4413e-07,\n",
              "            8.6154e-07, 5.2764e-09, 1.5527e-08, 2.7888e-07, 6.6174e-10, 2.2611e-07,\n",
              "            5.2546e-08, 1.4465e-07, 7.4548e-09, 8.6475e-05],\n",
              "           [9.9822e-01, 9.3057e-04, 1.6653e-03, 1.2460e-06, 5.9194e-04, 3.0653e-04,\n",
              "            1.3156e-04, 1.7165e-04, 5.5576e-05, 1.1301e-04, 1.0928e-04, 1.7681e-04,\n",
              "            1.3696e-07, 2.0484e-05, 8.8538e-07, 9.2863e-07, 2.8136e-06, 7.1707e-05,\n",
              "            3.3375e-06, 5.5485e-03, 3.3924e-07, 6.4187e-09, 1.0896e-04, 7.5755e-05,\n",
              "            1.0820e-08, 3.3856e-08, 3.6739e-08, 2.0693e-06, 9.9172e-07, 4.4499e-09,\n",
              "            1.7230e-08, 6.7578e-08, 3.1859e-11, 2.3359e-10, 3.5502e-13, 5.0145e-13,\n",
              "            3.4985e-09, 2.4281e-09, 1.1983e-07, 2.4369e-10],\n",
              "           [9.9319e-01, 7.4407e-03, 1.6501e-03, 2.6199e-05, 2.7478e-03, 1.1248e-03,\n",
              "            2.0257e-03, 6.5484e-04, 4.5499e-04, 5.0490e-04, 7.6048e-04, 2.3016e-03,\n",
              "            5.3688e-06, 3.6434e-04, 2.8416e-05, 2.7125e-05, 8.5093e-05, 2.1589e-03,\n",
              "            1.5274e-03, 5.3793e-04, 2.9985e-06, 1.1829e-06, 4.5475e-04, 5.4606e-03,\n",
              "            1.5027e-07, 3.5950e-07, 1.6755e-05, 2.4509e-04, 7.5605e-05, 9.7103e-07,\n",
              "            2.1528e-09, 1.4581e-09, 6.0916e-10, 6.8084e-08, 2.9966e-11, 2.0679e-08,\n",
              "            2.4650e-08, 1.0027e-04, 2.8678e-06, 4.0156e-06],\n",
              "           [9.9816e-01, 2.8903e-03, 1.1572e-03, 1.7467e-05, 2.7955e-03, 8.9984e-04,\n",
              "            5.6126e-04, 1.7253e-03, 1.7576e-04, 1.1295e-04, 9.4125e-04, 5.7194e-05,\n",
              "            1.8767e-06, 1.7087e-03, 7.4741e-06, 9.8153e-06, 4.3283e-05, 6.5028e-04,\n",
              "            1.5772e-04, 8.7344e-04, 8.0007e-07, 7.2594e-07, 4.5188e-05, 3.0800e-04,\n",
              "            1.9294e-07, 2.4977e-07, 3.3951e-06, 7.5919e-06, 1.7997e-05, 1.1903e-07,\n",
              "            3.1491e-09, 6.6047e-07, 5.3946e-11, 1.7905e-08, 3.9008e-12, 9.9466e-10,\n",
              "            1.3732e-07, 6.4043e-07, 5.6584e-09, 2.6020e-07]], device='cuda:0',\n",
              "          grad_fn=<SigmoidBackward>),\n",
              "   tensor([[9.9675e-01, 1.9405e-03, 2.9267e-03, 2.2958e-05, 7.6831e-04, 3.9533e-04,\n",
              "            3.6149e-04, 7.9860e-03, 5.9478e-04, 1.0889e-04, 4.7229e-04, 1.9576e-03,\n",
              "            1.0670e-04, 1.1273e-03, 1.1077e-05, 8.1197e-07, 1.0775e-04, 6.5548e-04,\n",
              "            1.8181e-05, 2.4716e-03, 3.0095e-04, 3.0275e-06, 1.1399e-07, 5.6137e-04,\n",
              "            4.2913e-07, 3.8367e-07, 3.5724e-08, 1.2737e-06, 1.8378e-05, 4.8027e-06],\n",
              "           [1.0000e+00, 3.7998e-07, 4.3262e-08, 9.9352e-10, 2.8273e-06, 7.3927e-09,\n",
              "            1.5353e-06, 6.1452e-07, 6.5618e-09, 2.2082e-08, 1.2664e-08, 4.8213e-06,\n",
              "            5.0238e-10, 9.9615e-08, 3.1846e-07, 2.1113e-11, 8.7905e-09, 1.2943e-06,\n",
              "            4.4205e-09, 1.2963e-06, 7.5218e-09, 2.2162e-12, 3.8212e-09, 5.6382e-07,\n",
              "            4.4898e-10, 9.3348e-10, 8.3981e-13, 1.7742e-07, 1.6781e-05, 2.4430e-10],\n",
              "           [1.0000e+00, 1.0841e-06, 4.3666e-06, 2.3677e-08, 5.3873e-05, 8.3908e-07,\n",
              "            3.0427e-06, 5.6047e-06, 6.1908e-07, 8.7366e-07, 1.6861e-07, 3.2178e-06,\n",
              "            1.8905e-08, 3.9509e-05, 1.3450e-08, 7.3527e-11, 1.9878e-08, 3.0896e-05,\n",
              "            4.8660e-09, 1.2600e-05, 1.5844e-09, 3.2405e-11, 5.4293e-06, 4.7892e-06,\n",
              "            1.9524e-10, 2.1426e-08, 4.6254e-09, 1.2256e-05, 1.7968e-06, 2.5308e-10],\n",
              "           [1.0000e+00, 7.7094e-08, 1.4917e-06, 3.5804e-09, 1.2766e-04, 2.9342e-07,\n",
              "            1.9051e-07, 1.1386e-06, 1.7690e-07, 2.3016e-06, 6.2241e-09, 3.4120e-06,\n",
              "            7.1443e-10, 4.5323e-07, 2.9176e-09, 1.2879e-11, 1.7194e-09, 3.1457e-08,\n",
              "            2.0008e-10, 5.4015e-07, 3.8158e-10, 6.8013e-12, 1.9826e-07, 4.5536e-06,\n",
              "            1.1184e-10, 1.8851e-09, 1.4891e-11, 1.5446e-08, 1.3878e-06, 1.1798e-10],\n",
              "           [1.0000e+00, 3.6720e-07, 1.0637e-05, 3.0444e-08, 1.8279e-05, 1.0387e-06,\n",
              "            1.5158e-06, 6.5379e-06, 3.6878e-07, 1.2611e-07, 6.4186e-08, 2.9194e-09,\n",
              "            3.7437e-09, 5.1739e-07, 3.9134e-11, 6.4861e-12, 9.3017e-09, 7.6671e-06,\n",
              "            4.7543e-10, 5.3478e-06, 8.8714e-11, 1.5113e-13, 6.7334e-10, 7.1619e-08,\n",
              "            6.9523e-12, 6.9923e-10, 7.7202e-11, 3.9892e-07, 1.5392e-07, 1.1532e-12],\n",
              "           [1.0000e+00, 7.1625e-07, 6.5400e-07, 1.6662e-09, 6.7108e-07, 2.0835e-08,\n",
              "            3.3150e-07, 3.2268e-07, 7.5809e-08, 1.0026e-07, 4.9565e-10, 3.2335e-09,\n",
              "            3.4885e-10, 5.1344e-08, 2.8151e-10, 1.0361e-12, 2.2043e-10, 6.0717e-07,\n",
              "            2.6509e-10, 1.2502e-06, 2.0971e-12, 2.3520e-14, 8.9682e-12, 2.9962e-07,\n",
              "            8.7709e-13, 1.2289e-11, 2.0295e-11, 4.0653e-09, 1.7805e-09, 3.8931e-12],\n",
              "           [1.0000e+00, 2.5234e-04, 1.0141e-06, 1.3677e-07, 2.0420e-05, 2.2664e-07,\n",
              "            1.0308e-04, 3.4210e-06, 5.3894e-07, 5.4590e-06, 2.4490e-06, 5.7135e-07,\n",
              "            3.5165e-08, 2.8242e-06, 2.0807e-09, 1.3512e-10, 4.1164e-07, 4.4318e-05,\n",
              "            9.4875e-09, 2.0377e-06, 7.8802e-10, 1.2806e-10, 1.2628e-06, 2.6845e-06,\n",
              "            1.0472e-09, 1.5630e-08, 7.2660e-09, 5.3122e-06, 2.2561e-06, 7.2112e-11],\n",
              "           [1.0000e+00, 3.2420e-08, 6.4797e-07, 9.5303e-10, 1.4385e-05, 2.6152e-08,\n",
              "            6.0016e-08, 2.2277e-07, 3.9362e-08, 5.6378e-07, 2.7354e-08, 3.8381e-07,\n",
              "            3.5030e-08, 8.1118e-07, 2.9356e-09, 7.0476e-11, 2.3461e-09, 1.3150e-06,\n",
              "            2.4049e-10, 4.8116e-06, 3.3782e-10, 1.7720e-11, 2.9966e-08, 3.2430e-05,\n",
              "            1.4607e-10, 8.0186e-10, 6.2635e-11, 1.3992e-08, 1.3471e-07, 1.0069e-10],\n",
              "           [9.9995e-01, 5.4302e-06, 4.7076e-05, 5.5716e-08, 2.4280e-05, 1.8178e-06,\n",
              "            2.8050e-06, 6.2149e-06, 2.5192e-06, 1.5529e-06, 8.8824e-07, 1.3995e-05,\n",
              "            3.2853e-09, 2.1982e-07, 3.5518e-08, 2.7318e-09, 1.8335e-08, 7.1371e-08,\n",
              "            2.5822e-06, 1.2769e-05, 5.9641e-09, 8.7913e-09, 4.3610e-07, 1.6578e-04,\n",
              "            2.4007e-10, 9.2807e-09, 1.5053e-09, 1.8628e-07, 4.4919e-06, 2.4081e-09],\n",
              "           [1.0000e+00, 1.5304e-05, 1.9115e-06, 9.1234e-08, 9.7628e-06, 5.1401e-07,\n",
              "            4.5374e-06, 5.6598e-06, 1.2179e-06, 5.6253e-06, 9.2211e-06, 5.6363e-08,\n",
              "            2.9524e-09, 2.4728e-07, 1.8444e-09, 3.1184e-10, 1.0226e-07, 6.6529e-07,\n",
              "            3.3009e-09, 3.0251e-06, 5.9326e-10, 2.9708e-09, 3.0257e-08, 3.1521e-05,\n",
              "            8.8196e-10, 1.8862e-09, 2.4048e-10, 3.1238e-08, 5.4142e-06, 6.9621e-11]],\n",
              "          device='cuda:0', grad_fn=<CatBackward>)],\n",
              "  5: [tensor([[9.7427e-01, 3.0776e-02, 7.0236e-03, 3.5646e-05, 5.3765e-03, 7.2342e-04,\n",
              "            8.0844e-03, 8.6134e-03, 1.0386e-03, 1.0995e-03, 8.0710e-03, 9.8909e-03,\n",
              "            2.1445e-04, 5.3387e-04, 2.6659e-04, 3.9863e-05, 9.7419e-04, 3.9525e-03,\n",
              "            1.8314e-03, 4.4058e-02, 9.6799e-03, 5.3028e-05, 1.8372e-03, 4.4518e-02,\n",
              "            4.7671e-05, 3.5197e-05, 4.2662e-05, 2.7761e-04, 6.1002e-04, 7.7841e-05,\n",
              "            1.5200e-05, 1.8990e-04, 3.8564e-06, 3.2046e-05, 1.2048e-05, 1.0820e-06,\n",
              "            1.5212e-02, 8.2539e-05, 2.3523e-03, 7.8170e-04, 9.1295e-06, 8.5012e-07,\n",
              "            4.4814e-07, 7.1689e-05, 1.9464e-04, 2.9712e-04, 1.6519e-02, 2.2220e-09,\n",
              "            1.3704e-06, 7.6322e-07],\n",
              "           [9.8047e-01, 1.0116e-03, 1.3827e-03, 1.0962e-05, 3.1044e-03, 3.2904e-04,\n",
              "            7.4766e-02, 6.6022e-03, 2.3236e-04, 2.5314e-04, 5.7985e-04, 3.8391e-04,\n",
              "            2.4582e-06, 1.0661e-03, 8.0700e-05, 2.2731e-05, 1.5098e-03, 9.5198e-03,\n",
              "            3.5104e-04, 2.4521e-03, 7.0741e-05, 6.5015e-06, 1.2863e-03, 6.2154e-04,\n",
              "            4.7540e-06, 1.0765e-05, 7.8909e-05, 4.0390e-04, 2.7516e-04, 8.4343e-07,\n",
              "            8.0025e-08, 1.1486e-04, 7.5119e-06, 3.4075e-04, 7.3357e-06, 5.8929e-06,\n",
              "            1.5015e-05, 2.4813e-05, 1.1964e-05, 6.6534e-05, 4.2757e-04, 4.0046e-07,\n",
              "            3.3056e-09, 7.4960e-09, 2.9999e-08, 9.1933e-04, 4.8156e-06, 4.6560e-08,\n",
              "            1.6903e-06, 6.6629e-07],\n",
              "           [9.8667e-01, 4.4180e-03, 1.6255e-03, 3.5491e-05, 2.9416e-02, 1.1417e-03,\n",
              "            4.7438e-03, 3.3079e-03, 9.5721e-05, 5.5254e-04, 1.2983e-03, 5.0247e-04,\n",
              "            6.9176e-06, 3.5990e-02, 1.7484e-05, 2.2020e-05, 1.2195e-03, 1.2592e-02,\n",
              "            4.7516e-04, 6.8679e-03, 2.7559e-05, 1.7406e-05, 4.5730e-04, 5.9616e-03,\n",
              "            2.2940e-05, 4.0800e-06, 6.1670e-05, 3.9694e-04, 2.3974e-04, 2.0545e-06,\n",
              "            8.8773e-07, 8.7051e-05, 1.1536e-05, 6.0760e-07, 7.6686e-06, 1.6588e-06,\n",
              "            2.1659e-05, 9.4796e-05, 1.2733e-06, 1.1948e-03, 3.4780e-07, 9.0219e-08,\n",
              "            2.5965e-08, 4.3246e-07, 3.3075e-08, 2.8555e-04, 8.5335e-07, 9.6700e-08,\n",
              "            6.5534e-06, 1.5472e-06],\n",
              "           [9.9887e-01, 1.9625e-03, 1.0324e-03, 2.4073e-06, 2.7510e-03, 3.8416e-04,\n",
              "            4.8301e-04, 1.5673e-03, 2.9597e-05, 1.7613e-04, 1.3592e-03, 2.1381e-04,\n",
              "            1.3918e-06, 5.8288e-03, 2.4209e-06, 4.5551e-06, 8.4799e-05, 1.5202e-03,\n",
              "            3.4539e-04, 1.0263e-02, 6.4754e-06, 2.4590e-06, 3.5882e-05, 2.7042e-03,\n",
              "            6.8641e-06, 3.8417e-07, 4.0343e-05, 1.2712e-05, 1.1471e-04, 2.0038e-06,\n",
              "            1.3623e-07, 4.7015e-05, 4.9722e-07, 1.5112e-07, 6.1201e-08, 4.7672e-08,\n",
              "            4.1246e-04, 4.4998e-05, 3.9027e-07, 6.6273e-05, 2.7022e-08, 1.6004e-08,\n",
              "            1.6777e-08, 5.4611e-06, 1.0109e-09, 3.6221e-07, 9.5163e-07, 1.6948e-09,\n",
              "            8.4265e-07, 4.0055e-09],\n",
              "           [9.9805e-01, 2.5899e-04, 2.6496e-03, 6.3194e-06, 3.3980e-03, 3.0473e-04,\n",
              "            4.8717e-04, 2.4405e-03, 4.4710e-05, 1.4312e-04, 2.7609e-04, 1.5120e-05,\n",
              "            4.3333e-07, 7.1339e-03, 2.6615e-06, 1.1106e-06, 2.0470e-04, 1.1462e-02,\n",
              "            6.4113e-04, 3.2908e-03, 6.8279e-06, 8.2659e-07, 2.1873e-05, 1.7782e-04,\n",
              "            2.8333e-06, 2.9107e-07, 1.1464e-04, 1.9974e-05, 2.4312e-05, 9.1035e-08,\n",
              "            2.2369e-09, 5.4859e-05, 3.7039e-07, 1.6628e-07, 8.1310e-08, 7.0495e-07,\n",
              "            2.0328e-06, 3.5834e-06, 2.6188e-08, 6.4921e-05, 3.8875e-08, 1.2010e-08,\n",
              "            4.9505e-11, 1.8100e-08, 1.6469e-10, 4.1260e-07, 1.8124e-10, 2.5807e-11,\n",
              "            7.2122e-08, 1.7154e-08],\n",
              "           [9.9866e-01, 7.7404e-04, 7.5264e-04, 3.2347e-06, 3.1223e-03, 1.8531e-04,\n",
              "            2.4961e-03, 4.5260e-03, 5.2135e-05, 6.7846e-05, 7.7655e-05, 4.9980e-04,\n",
              "            5.0404e-07, 1.6001e-03, 6.4850e-06, 1.9174e-06, 1.0493e-03, 1.2063e-02,\n",
              "            1.3144e-04, 1.9986e-03, 2.1640e-05, 7.4791e-07, 2.7173e-05, 4.3530e-03,\n",
              "            2.5983e-06, 1.1837e-06, 6.3898e-05, 8.2497e-05, 5.0616e-05, 5.5897e-07,\n",
              "            2.8251e-08, 3.8659e-05, 5.8369e-07, 2.4815e-06, 4.7415e-07, 5.2436e-07,\n",
              "            6.5067e-06, 7.5160e-05, 1.5049e-06, 3.4978e-04, 1.8759e-07, 1.2487e-06,\n",
              "            1.2612e-09, 4.2602e-07, 2.9396e-08, 2.5525e-06, 1.5468e-06, 6.0744e-09,\n",
              "            4.4164e-07, 6.2397e-07],\n",
              "           [9.8067e-01, 3.9320e-03, 5.5441e-03, 3.7928e-05, 1.1694e-02, 4.1678e-04,\n",
              "            2.9617e-03, 2.4609e-03, 1.3529e-04, 1.3763e-03, 5.4846e-03, 2.8077e-04,\n",
              "            7.5701e-06, 1.1130e-02, 8.3052e-06, 2.9967e-05, 5.8038e-04, 5.2058e-03,\n",
              "            4.5779e-04, 1.4474e-02, 5.5267e-05, 1.2408e-05, 1.8452e-03, 2.2126e-03,\n",
              "            1.5503e-05, 1.4423e-05, 2.7933e-05, 1.4353e-04, 1.1819e-04, 3.0155e-06,\n",
              "            3.2229e-06, 1.7110e-04, 4.5228e-06, 3.7270e-06, 3.2476e-06, 2.3062e-06,\n",
              "            5.2864e-05, 1.0270e-05, 2.9832e-06, 9.1799e-04, 5.5253e-06, 6.6766e-08,\n",
              "            3.8085e-08, 1.1452e-06, 5.1491e-09, 3.5954e-05, 2.7291e-06, 1.0334e-08,\n",
              "            1.2333e-05, 1.7548e-06],\n",
              "           [9.9539e-01, 1.3962e-03, 2.6764e-03, 2.4272e-06, 1.0290e-03, 2.0007e-04,\n",
              "            3.6801e-04, 8.0751e-04, 7.2013e-05, 3.3203e-04, 3.2059e-04, 5.2902e-04,\n",
              "            6.7683e-07, 2.2409e-04, 1.7272e-06, 3.8193e-06, 4.3456e-05, 7.2463e-04,\n",
              "            6.2658e-05, 5.1689e-03, 5.0929e-06, 5.2542e-07, 6.1036e-04, 1.9572e-04,\n",
              "            4.6719e-07, 1.0208e-06, 7.7140e-06, 4.7055e-05, 1.6017e-05, 1.1382e-07,\n",
              "            9.0405e-08, 3.2302e-05, 3.5748e-07, 1.3952e-06, 1.3039e-08, 4.3979e-08,\n",
              "            2.2613e-06, 7.2308e-06, 6.0926e-07, 1.0921e-04, 2.0608e-05, 2.0277e-08,\n",
              "            1.0195e-10, 5.6932e-09, 7.1085e-09, 2.7190e-08, 8.9348e-06, 2.5550e-10,\n",
              "            4.9443e-08, 2.2113e-08],\n",
              "           [9.9543e-01, 4.1715e-03, 3.9521e-03, 8.4711e-05, 2.6786e-03, 7.6149e-04,\n",
              "            3.7331e-03, 1.0469e-02, 1.0267e-03, 1.0760e-03, 3.6054e-03, 3.2299e-03,\n",
              "            2.4792e-05, 1.0517e-03, 4.6656e-05, 5.3500e-05, 3.3977e-04, 1.0090e-02,\n",
              "            5.6219e-03, 8.0685e-03, 3.3813e-04, 1.3588e-05, 1.6540e-03, 1.2335e-02,\n",
              "            1.3387e-05, 1.5806e-05, 2.8738e-04, 5.5375e-04, 1.6890e-04, 2.5373e-05,\n",
              "            1.5204e-06, 1.2933e-04, 8.2829e-06, 1.3759e-05, 2.2608e-06, 1.1317e-05,\n",
              "            1.8129e-04, 4.1412e-04, 6.6509e-04, 2.4634e-03, 3.7217e-05, 2.5528e-05,\n",
              "            3.1567e-07, 1.7912e-05, 8.6489e-07, 9.6095e-07, 2.1971e-03, 1.3147e-07,\n",
              "            6.0852e-06, 1.1183e-05],\n",
              "           [9.9523e-01, 6.3780e-03, 1.9487e-03, 3.6397e-05, 4.1828e-03, 1.1065e-03,\n",
              "            3.7233e-03, 5.0076e-03, 2.5382e-04, 3.4411e-04, 2.6525e-03, 3.9908e-04,\n",
              "            7.4534e-06, 1.1256e-02, 2.5580e-05, 4.1376e-05, 1.1283e-03, 2.1366e-02,\n",
              "            1.8465e-03, 3.1439e-03, 5.7436e-05, 4.6339e-05, 3.7718e-04, 3.4121e-03,\n",
              "            2.7003e-05, 6.3926e-06, 3.2500e-04, 2.5395e-04, 5.4979e-04, 5.8004e-06,\n",
              "            7.1882e-07, 1.4939e-04, 2.0523e-05, 1.1867e-05, 2.1670e-06, 1.5705e-05,\n",
              "            2.5601e-04, 2.5186e-04, 1.9378e-06, 1.9341e-03, 8.0535e-06, 1.8048e-06,\n",
              "            2.5225e-07, 1.8194e-05, 3.0471e-07, 5.5378e-06, 2.1559e-06, 3.7847e-07,\n",
              "            8.7585e-06, 1.3705e-06]], device='cuda:0', grad_fn=<SigmoidBackward>),\n",
              "   tensor([[9.9930e-01, 3.4964e-03, 1.3492e-03, 1.9468e-05, 3.3885e-04, 1.7016e-04,\n",
              "            2.5638e-04, 2.0690e-03, 4.1084e-04, 5.1789e-05, 4.1604e-05, 1.6871e-03,\n",
              "            2.1531e-06, 4.7367e-04, 8.2909e-06, 8.6476e-08, 3.1004e-06, 1.5432e-04,\n",
              "            1.3575e-05, 3.9793e-04, 1.2780e-04, 1.4848e-07, 1.0319e-07, 4.0423e-03,\n",
              "            1.7793e-08, 4.1139e-08, 3.8377e-09, 6.3258e-08, 4.1069e-05, 3.9185e-07,\n",
              "            1.5468e-07, 8.0581e-06, 1.3119e-08, 1.8022e-06, 3.8311e-09, 7.7896e-10,\n",
              "            3.6196e-03, 1.5581e-07, 3.4528e-05, 9.7702e-07],\n",
              "           [9.9999e-01, 4.3620e-07, 4.6028e-06, 2.8427e-08, 4.3693e-05, 1.1600e-06,\n",
              "            6.9035e-05, 1.5974e-05, 2.0386e-07, 1.5677e-07, 1.5428e-06, 2.6904e-05,\n",
              "            5.0124e-08, 1.0439e-05, 1.5219e-07, 1.1908e-09, 2.2039e-07, 4.3269e-06,\n",
              "            4.8003e-08, 2.1537e-06, 3.6123e-08, 7.4214e-10, 1.8802e-07, 3.1387e-06,\n",
              "            6.2190e-09, 1.9719e-08, 3.3745e-11, 5.5549e-07, 5.5277e-05, 2.7344e-09,\n",
              "            1.7280e-11, 3.1551e-08, 3.0665e-10, 1.5709e-05, 2.5999e-10, 8.0038e-10,\n",
              "            7.2878e-09, 7.1448e-08, 8.2714e-09, 2.9798e-05],\n",
              "           [9.9995e-01, 1.5602e-04, 8.6879e-06, 4.1921e-07, 5.8993e-03, 4.2933e-06,\n",
              "            1.7177e-04, 3.3202e-05, 2.9379e-06, 1.9037e-05, 9.8925e-08, 3.0141e-06,\n",
              "            4.9315e-07, 7.2444e-05, 1.2685e-08, 3.6499e-10, 2.3192e-07, 3.3128e-04,\n",
              "            1.4199e-08, 6.1670e-06, 1.4746e-07, 3.2350e-09, 7.7852e-06, 1.5856e-04,\n",
              "            1.4888e-08, 4.9276e-07, 4.6972e-08, 7.4957e-05, 7.5583e-06, 1.0418e-09,\n",
              "            4.8482e-07, 2.0623e-07, 3.1761e-09, 1.7007e-08, 4.7234e-09, 9.7949e-09,\n",
              "            5.3210e-09, 1.4460e-05, 2.3754e-08, 2.0618e-04],\n",
              "           [1.0000e+00, 3.3795e-07, 7.8053e-07, 7.3021e-09, 2.0321e-04, 4.1474e-07,\n",
              "            5.3281e-07, 8.6795e-07, 2.0570e-07, 7.4097e-06, 6.4485e-08, 6.1867e-06,\n",
              "            1.2504e-08, 9.6209e-05, 2.3024e-09, 2.7541e-10, 1.6890e-07, 3.4789e-08,\n",
              "            3.1825e-10, 1.9851e-06, 1.0361e-10, 7.9037e-11, 1.2290e-07, 2.4795e-06,\n",
              "            8.9808e-11, 1.4452e-09, 7.8110e-12, 2.5217e-08, 5.0534e-07, 1.7223e-11,\n",
              "            2.7415e-08, 1.0082e-07, 9.4611e-10, 1.0336e-08, 4.4469e-11, 1.7595e-11,\n",
              "            1.3172e-06, 1.3895e-05, 2.2550e-08, 1.4882e-05],\n",
              "           [1.0000e+00, 2.1921e-08, 1.3687e-06, 1.6492e-09, 1.3798e-06, 6.1836e-08,\n",
              "            2.0309e-07, 7.0326e-07, 3.4976e-08, 1.5905e-08, 6.5481e-09, 5.4095e-11,\n",
              "            2.5282e-11, 1.1455e-07, 4.4991e-12, 1.0406e-13, 4.9013e-11, 4.6626e-06,\n",
              "            3.0637e-11, 2.3787e-07, 7.1367e-11, 2.5262e-14, 3.0519e-11, 8.8912e-09,\n",
              "            2.4552e-12, 9.0621e-12, 9.1216e-13, 2.0793e-08, 1.4650e-06, 3.3957e-14,\n",
              "            2.0978e-12, 6.4689e-11, 3.8498e-11, 1.0870e-10, 6.7457e-10, 5.0096e-10,\n",
              "            3.5900e-09, 1.0174e-06, 3.7562e-11, 2.3541e-08],\n",
              "           [1.0000e+00, 4.5348e-05, 2.5893e-07, 8.4339e-09, 1.0580e-05, 2.7988e-08,\n",
              "            3.3975e-06, 3.6015e-07, 2.7474e-08, 2.5606e-07, 8.1708e-06, 7.8409e-07,\n",
              "            3.0773e-09, 8.4091e-05, 2.3090e-09, 2.3010e-10, 1.0470e-06, 8.7956e-06,\n",
              "            1.9499e-09, 1.2790e-06, 3.6366e-12, 7.4241e-13, 1.3919e-10, 2.3338e-07,\n",
              "            1.5636e-12, 1.9618e-12, 7.0751e-11, 1.3343e-08, 1.5987e-08, 1.3159e-12,\n",
              "            1.8397e-10, 2.1634e-08, 2.4879e-12, 4.9086e-10, 3.0545e-12, 3.8362e-10,\n",
              "            3.9457e-09, 2.9960e-07, 4.9722e-09, 6.9648e-08],\n",
              "           [1.0000e+00, 4.4549e-06, 1.6793e-06, 4.8367e-08, 5.9806e-05, 2.9915e-07,\n",
              "            4.7451e-05, 2.8241e-06, 1.6745e-07, 7.4010e-07, 1.4792e-06, 1.6820e-07,\n",
              "            1.8842e-07, 2.7761e-05, 3.8662e-09, 7.4129e-10, 7.7214e-07, 9.8708e-06,\n",
              "            6.8132e-09, 1.2586e-05, 7.2130e-08, 8.7902e-11, 8.9592e-08, 1.9448e-04,\n",
              "            6.4793e-09, 7.4679e-08, 2.1727e-08, 8.8417e-07, 4.8827e-07, 9.3565e-11,\n",
              "            6.6563e-07, 1.4157e-06, 1.1786e-09, 1.2155e-06, 2.0898e-08, 1.1963e-07,\n",
              "            1.3366e-08, 1.0636e-06, 4.5474e-08, 5.5819e-04],\n",
              "           [1.0000e+00, 1.1522e-07, 6.6042e-07, 3.1719e-09, 2.4061e-05, 7.5488e-08,\n",
              "            5.0119e-08, 2.4231e-07, 1.4487e-07, 1.0403e-05, 4.8204e-08, 5.1648e-06,\n",
              "            1.3413e-08, 2.2874e-06, 1.4565e-08, 2.3932e-10, 4.6539e-09, 1.2435e-08,\n",
              "            1.5930e-10, 4.1276e-06, 4.7770e-11, 5.2642e-12, 1.2320e-08, 1.6839e-06,\n",
              "            7.9093e-12, 1.0308e-10, 2.8893e-10, 1.0572e-08, 3.2462e-08, 2.2304e-11,\n",
              "            9.1616e-08, 2.7458e-07, 3.9305e-11, 9.5174e-09, 1.2614e-13, 2.3075e-11,\n",
              "            9.1532e-09, 1.2189e-08, 1.3360e-07, 2.6581e-09],\n",
              "           [1.0000e+00, 3.8530e-07, 3.2506e-06, 1.6358e-08, 2.6320e-05, 7.7503e-07,\n",
              "            7.3533e-07, 1.3253e-05, 1.1778e-06, 7.4081e-07, 4.6852e-07, 2.0589e-05,\n",
              "            1.8072e-09, 7.0578e-08, 2.8628e-08, 1.1880e-10, 4.3551e-08, 2.3032e-07,\n",
              "            8.1511e-08, 3.9765e-05, 3.1951e-09, 1.3875e-10, 4.2106e-07, 1.9214e-05,\n",
              "            1.3547e-10, 4.6571e-09, 1.0997e-10, 1.0589e-07, 1.9830e-06, 7.2109e-09,\n",
              "            2.8308e-09, 1.5366e-07, 2.6077e-09, 5.8049e-08, 2.1955e-10, 3.5720e-09,\n",
              "            5.7942e-07, 5.8262e-06, 1.9028e-04, 4.8196e-07],\n",
              "           [1.0000e+00, 1.7178e-05, 1.2843e-06, 1.1430e-07, 6.5136e-05, 6.7932e-07,\n",
              "            1.1452e-05, 7.2508e-06, 1.0122e-06, 4.2808e-06, 8.7652e-06, 7.3405e-07,\n",
              "            6.0894e-08, 2.1898e-05, 8.8198e-09, 2.2325e-09, 1.9128e-07, 8.1886e-07,\n",
              "            4.2345e-08, 3.2956e-06, 5.0887e-09, 2.5340e-08, 1.5552e-06, 2.4872e-04,\n",
              "            2.3543e-09, 2.1709e-08, 1.5488e-09, 1.8957e-07, 1.0603e-05, 4.0461e-10,\n",
              "            4.0522e-08, 3.2204e-07, 1.0033e-09, 9.5300e-08, 1.2791e-10, 7.0067e-09,\n",
              "            2.6234e-06, 9.4838e-06, 1.2595e-08, 1.1147e-06]], device='cuda:0',\n",
              "          grad_fn=<CatBackward>)],\n",
              "  6: [tensor([[9.6625e-01, 2.0775e-02, 5.3275e-03, 1.9789e-04, 1.6800e-02, 8.2670e-04,\n",
              "            6.9812e-02, 1.8075e-02, 1.1841e-03, 3.3188e-03, 1.3076e-02, 5.0121e-02,\n",
              "            2.3304e-04, 1.2598e-03, 1.3182e-03, 9.6500e-05, 6.8688e-03, 1.0209e-02,\n",
              "            3.6041e-03, 1.9661e-02, 1.0991e-02, 5.9641e-04, 1.0135e-03, 1.4027e-01,\n",
              "            9.4138e-05, 5.2635e-04, 6.2610e-04, 9.0894e-04, 6.8034e-04, 4.0973e-04,\n",
              "            1.0714e-04, 6.6983e-04, 1.3095e-04, 8.9184e-04, 2.1723e-04, 6.0595e-05,\n",
              "            1.0168e-01, 3.0869e-03, 1.9115e-02, 5.2460e-04, 2.6470e-03, 7.4283e-05,\n",
              "            5.5138e-04, 6.4523e-03, 7.9567e-04, 1.3789e-03, 5.8797e-02, 6.7361e-05,\n",
              "            4.1947e-05, 1.2245e-04, 7.9683e-04, 6.8793e-05, 4.4075e-03, 5.6924e-05,\n",
              "            2.6535e-04, 1.3077e-06, 2.3948e-06, 1.4012e-06, 1.4679e-05, 6.4401e-02],\n",
              "           [9.6298e-01, 1.8741e-03, 1.2137e-03, 5.4873e-05, 1.2967e-02, 3.1700e-04,\n",
              "            5.8401e-02, 7.9002e-03, 4.6629e-04, 1.9188e-03, 1.8103e-03, 1.4593e-03,\n",
              "            2.5851e-06, 3.3331e-03, 1.8843e-04, 1.8536e-04, 1.0823e-03, 1.4119e-02,\n",
              "            5.1937e-04, 2.5261e-03, 1.2942e-04, 8.1549e-06, 5.6557e-03, 6.3168e-03,\n",
              "            5.7812e-06, 2.8835e-05, 1.2557e-04, 3.5289e-04, 1.4762e-04, 3.2299e-06,\n",
              "            3.9482e-06, 3.2673e-04, 5.6148e-05, 1.2883e-04, 2.7505e-05, 5.6783e-06,\n",
              "            2.6581e-05, 2.7946e-04, 1.9952e-05, 5.7748e-04, 3.1884e-04, 2.7543e-06,\n",
              "            1.9507e-06, 4.9624e-06, 3.6924e-07, 3.5154e-04, 7.6907e-04, 1.2366e-05,\n",
              "            8.5343e-06, 1.4806e-05, 1.0774e-06, 3.1536e-09, 4.4162e-05, 2.8537e-08,\n",
              "            3.7939e-08, 1.2981e-07, 1.2211e-07, 1.4176e-09, 2.4146e-03, 1.7992e-04],\n",
              "           [9.6150e-01, 1.2608e-02, 4.0384e-03, 6.9556e-04, 1.5439e-02, 1.1947e-03,\n",
              "            4.0834e-02, 5.0562e-03, 1.1662e-03, 6.2005e-03, 8.3935e-03, 1.5060e-02,\n",
              "            7.4204e-05, 1.3235e-02, 2.6616e-04, 3.1836e-04, 9.6329e-04, 4.1558e-02,\n",
              "            2.4830e-03, 9.1242e-03, 3.0428e-04, 1.1207e-04, 5.4101e-03, 8.5781e-02,\n",
              "            2.1231e-04, 4.1865e-04, 1.8773e-03, 6.6026e-04, 2.5622e-04, 4.4230e-05,\n",
              "            2.6971e-04, 3.9487e-04, 2.2936e-04, 1.0833e-04, 7.0471e-05, 1.9137e-04,\n",
              "            3.5253e-03, 2.3961e-03, 2.3677e-04, 2.0326e-03, 4.3591e-04, 1.8634e-05,\n",
              "            1.9339e-05, 8.0228e-03, 1.8811e-05, 1.7913e-04, 1.6588e-03, 1.4097e-04,\n",
              "            7.9835e-05, 2.2357e-04, 4.6760e-06, 5.1502e-08, 9.0037e-04, 1.7102e-05,\n",
              "            4.8179e-07, 6.9494e-06, 5.8413e-05, 9.7174e-07, 5.9664e-04, 5.4727e-03],\n",
              "           [9.9322e-01, 7.3035e-03, 4.5330e-03, 1.4029e-04, 7.8861e-03, 4.0220e-04,\n",
              "            2.6182e-03, 4.0484e-03, 1.2452e-04, 4.8710e-04, 4.0570e-03, 1.5277e-03,\n",
              "            3.2901e-06, 3.0170e-03, 3.7307e-05, 4.2105e-05, 2.1767e-04, 2.5407e-03,\n",
              "            4.0670e-04, 1.5992e-02, 4.7359e-05, 5.7288e-06, 1.4670e-03, 2.9161e-03,\n",
              "            2.4194e-05, 3.8925e-06, 2.3995e-04, 1.4778e-05, 5.8929e-05, 7.6021e-06,\n",
              "            1.1333e-06, 1.1850e-04, 1.4804e-05, 1.6790e-06, 2.9051e-06, 2.9562e-07,\n",
              "            2.0706e-03, 6.7126e-05, 9.2882e-06, 2.0202e-04, 4.7668e-05, 9.3179e-07,\n",
              "            8.9660e-06, 1.9104e-05, 6.2623e-07, 1.4444e-05, 1.1501e-04, 1.5904e-07,\n",
              "            1.0464e-06, 4.3757e-07, 5.7486e-06, 9.8677e-11, 2.6075e-07, 4.8342e-07,\n",
              "            2.5039e-09, 2.1072e-11, 1.6851e-07, 6.8819e-09, 1.6363e-05, 2.4883e-06],\n",
              "           [9.9642e-01, 2.3487e-04, 2.7474e-03, 8.7630e-05, 2.2165e-03, 5.2773e-05,\n",
              "            4.8777e-04, 2.9871e-03, 1.2336e-04, 2.3388e-04, 1.5260e-04, 3.9283e-05,\n",
              "            8.2979e-08, 2.2421e-03, 1.8502e-06, 9.1344e-06, 8.3281e-05, 2.1330e-02,\n",
              "            4.2565e-04, 2.1043e-03, 1.0978e-05, 4.0099e-08, 4.0695e-05, 1.1124e-04,\n",
              "            4.5415e-06, 6.9619e-07, 2.5004e-04, 4.5484e-06, 4.3600e-06, 2.9041e-08,\n",
              "            1.2104e-08, 2.8077e-04, 5.5769e-07, 5.1161e-07, 3.8921e-08, 1.1463e-06,\n",
              "            6.3901e-07, 1.5093e-05, 1.0890e-07, 3.5126e-05, 3.8857e-07, 1.8089e-08,\n",
              "            2.2252e-09, 9.3749e-07, 3.0724e-08, 5.5582e-08, 8.7278e-08, 1.5567e-09,\n",
              "            7.4877e-08, 2.7417e-06, 5.7347e-12, 1.6669e-13, 3.1959e-09, 1.3979e-10,\n",
              "            1.3096e-10, 1.1758e-09, 1.9429e-13, 9.6697e-13, 8.2892e-07, 2.5372e-07],\n",
              "           [9.9421e-01, 2.0304e-03, 7.7034e-04, 1.0829e-04, 3.8973e-03, 9.9023e-05,\n",
              "            6.4473e-03, 6.2263e-03, 2.8466e-04, 5.2116e-04, 4.5086e-04, 1.2543e-03,\n",
              "            1.0991e-06, 1.3278e-03, 1.6740e-05, 4.9061e-05, 9.5803e-04, 3.3165e-02,\n",
              "            3.7219e-04, 1.7506e-03, 1.0294e-04, 2.6763e-06, 2.9184e-04, 9.3230e-03,\n",
              "            1.1559e-05, 1.4955e-05, 2.9554e-04, 5.2819e-05, 3.4575e-05, 7.6626e-07,\n",
              "            7.4034e-07, 2.3901e-04, 1.3835e-05, 1.6163e-05, 2.6288e-06, 2.1044e-05,\n",
              "            3.6155e-05, 2.4669e-04, 1.9964e-05, 1.3417e-03, 5.3273e-05, 8.3472e-06,\n",
              "            5.8155e-07, 3.5475e-05, 1.0817e-06, 2.7542e-05, 4.7553e-05, 8.7210e-07,\n",
              "            3.9048e-06, 1.9667e-05, 9.9815e-08, 1.5222e-09, 5.8771e-06, 3.3312e-07,\n",
              "            1.5390e-09, 4.8114e-07, 1.5687e-09, 3.0318e-09, 6.0314e-03, 3.8206e-05],\n",
              "           [9.8483e-01, 2.7494e-03, 7.9441e-03, 2.1807e-04, 7.8013e-03, 2.5638e-04,\n",
              "            8.7375e-03, 2.2215e-03, 3.3087e-04, 2.2806e-03, 3.6793e-03, 1.7346e-03,\n",
              "            5.4887e-06, 2.7878e-03, 2.3769e-05, 7.2475e-05, 3.0167e-04, 5.3036e-02,\n",
              "            6.6804e-04, 5.8231e-03, 1.0611e-04, 1.8615e-05, 3.8125e-03, 3.4588e-03,\n",
              "            3.0797e-05, 3.0019e-05, 1.7822e-04, 6.8900e-05, 6.1815e-05, 2.6259e-06,\n",
              "            4.4798e-06, 8.0441e-05, 3.8872e-05, 2.4489e-05, 1.1458e-05, 1.4263e-05,\n",
              "            9.5881e-05, 4.3999e-05, 4.5415e-05, 4.3623e-04, 6.1643e-05, 2.6713e-06,\n",
              "            7.2182e-07, 1.5917e-05, 1.3567e-06, 1.2609e-04, 6.4622e-05, 2.8418e-06,\n",
              "            6.1941e-06, 1.2270e-05, 3.6608e-07, 6.0311e-10, 2.9133e-06, 1.5315e-08,\n",
              "            9.5163e-10, 3.6805e-09, 2.2210e-07, 1.4165e-07, 9.3266e-05, 1.2332e-05],\n",
              "           [9.9304e-01, 4.7494e-04, 3.4960e-03, 3.0287e-05, 1.4881e-03, 5.8918e-05,\n",
              "            9.0730e-04, 1.5930e-03, 1.5759e-04, 1.2929e-03, 9.9918e-04, 4.2795e-04,\n",
              "            4.0693e-07, 1.8131e-04, 3.6603e-06, 7.7974e-06, 4.2304e-05, 1.7192e-03,\n",
              "            2.7080e-04, 9.8790e-03, 2.2877e-05, 2.1297e-07, 5.1070e-04, 6.9354e-04,\n",
              "            1.0366e-06, 2.9027e-06, 1.7000e-05, 1.0349e-05, 5.2052e-06, 4.2915e-07,\n",
              "            5.2195e-07, 2.9761e-05, 3.7380e-06, 4.3802e-06, 4.8972e-08, 4.6803e-07,\n",
              "            9.9734e-06, 8.3759e-06, 2.5090e-05, 2.5751e-05, 1.0067e-04, 3.5222e-08,\n",
              "            5.5617e-08, 1.0296e-06, 4.2528e-08, 3.6971e-08, 9.0960e-05, 5.8581e-08,\n",
              "            4.1348e-07, 1.9999e-06, 1.1372e-09, 5.6993e-12, 1.6046e-07, 4.5739e-07,\n",
              "            3.5184e-10, 8.8343e-12, 1.8374e-10, 4.0020e-14, 3.9617e-06, 3.4470e-05],\n",
              "           [9.8497e-01, 8.5363e-03, 5.1783e-03, 2.1356e-04, 5.8493e-03, 6.3799e-04,\n",
              "            1.1815e-02, 1.7349e-02, 1.7490e-03, 2.6033e-03, 1.0798e-02, 8.3146e-03,\n",
              "            3.5999e-05, 1.4963e-03, 2.2232e-04, 2.4122e-04, 1.4187e-03, 1.9877e-02,\n",
              "            2.5954e-03, 1.2077e-02, 1.4288e-03, 1.9764e-05, 4.2384e-03, 2.2270e-02,\n",
              "            6.2980e-05, 1.9504e-04, 6.4221e-04, 6.1871e-04, 3.3199e-04, 6.4309e-05,\n",
              "            2.4594e-05, 1.3561e-03, 5.9229e-05, 2.5389e-04, 5.6881e-05, 6.7459e-05,\n",
              "            8.1814e-04, 3.1866e-03, 7.2940e-04, 1.1255e-03, 5.0113e-04, 6.7082e-05,\n",
              "            5.0726e-05, 6.3248e-04, 2.9486e-06, 1.0603e-04, 3.8714e-03, 7.5288e-05,\n",
              "            1.4838e-04, 4.6203e-05, 4.3122e-06, 1.0585e-07, 1.0120e-03, 8.6222e-05,\n",
              "            5.0389e-07, 1.6962e-07, 4.8317e-06, 6.3460e-08, 3.1749e-04, 6.5976e-03],\n",
              "           [9.9081e-01, 3.6028e-03, 3.6458e-03, 3.7525e-04, 9.8203e-03, 5.8957e-04,\n",
              "            6.7820e-03, 1.4282e-02, 1.0498e-03, 1.0209e-03, 5.8081e-03, 7.6709e-04,\n",
              "            1.1199e-05, 1.1496e-02, 6.0918e-05, 1.3755e-04, 1.2248e-03, 3.8463e-02,\n",
              "            2.2468e-03, 6.8618e-03, 4.2708e-04, 3.0592e-05, 1.1631e-03, 8.5915e-03,\n",
              "            3.3837e-05, 4.0464e-05, 1.8803e-03, 1.5436e-04, 1.8130e-04, 7.1308e-06,\n",
              "            5.8713e-06, 8.6676e-04, 6.4513e-05, 6.0188e-05, 2.6017e-05, 1.2153e-04,\n",
              "            3.5927e-04, 5.5165e-04, 2.0969e-05, 1.2696e-03, 1.3183e-04, 1.6172e-05,\n",
              "            4.6421e-06, 1.0909e-04, 1.5207e-05, 6.9595e-05, 5.1274e-05, 8.0311e-06,\n",
              "            2.0533e-05, 9.3688e-05, 6.9494e-07, 1.2494e-08, 9.2789e-06, 1.2598e-06,\n",
              "            1.2486e-06, 1.2904e-07, 1.2058e-07, 4.0549e-07, 2.1010e-04, 9.2947e-05]],\n",
              "          device='cuda:0', grad_fn=<SigmoidBackward>),\n",
              "   tensor([[9.9952e-01, 3.8379e-04, 4.9068e-04, 4.1837e-06, 2.0100e-04, 8.2541e-05,\n",
              "            1.1129e-04, 2.0430e-03, 2.4704e-04, 2.6966e-04, 2.9582e-04, 5.1474e-03,\n",
              "            2.4370e-05, 1.0196e-04, 2.6103e-06, 2.6148e-08, 1.6155e-05, 9.2343e-04,\n",
              "            1.1529e-05, 1.7585e-03, 4.8872e-04, 1.7593e-05, 1.0673e-06, 1.6827e-03,\n",
              "            4.4533e-07, 1.2285e-06, 1.8523e-07, 3.2338e-06, 3.0983e-05, 4.7807e-05,\n",
              "            3.5817e-07, 2.8352e-06, 1.6202e-07, 1.2518e-06, 4.4427e-08, 2.6378e-09,\n",
              "            1.2230e-02, 7.4272e-07, 1.8298e-03, 3.3777e-07, 2.2758e-05, 1.0237e-06,\n",
              "            1.0931e-04, 2.5701e-04, 1.9300e-05, 2.0782e-03, 4.0177e-02, 1.0862e-07,\n",
              "            4.3463e-07, 2.3999e-06],\n",
              "           [1.0000e+00, 5.5440e-07, 1.7854e-06, 1.2413e-08, 2.0628e-05, 3.8874e-07,\n",
              "            1.0352e-05, 4.8212e-06, 8.6769e-08, 6.3413e-08, 1.2988e-07, 2.8470e-05,\n",
              "            9.4089e-10, 7.5026e-07, 9.2082e-07, 1.4362e-10, 4.6063e-08, 3.9451e-06,\n",
              "            3.9425e-08, 1.6008e-06, 4.1239e-08, 5.5319e-11, 6.9609e-08, 6.0140e-07,\n",
              "            2.3894e-09, 1.1438e-08, 3.6823e-11, 7.0807e-07, 4.9564e-05, 9.1147e-10,\n",
              "            3.2170e-12, 2.9948e-08, 5.9315e-11, 2.8718e-06, 1.2815e-10, 3.4184e-10,\n",
              "            1.3231e-09, 1.0908e-07, 5.0081e-08, 9.8665e-06, 6.1158e-05, 3.3555e-07,\n",
              "            2.1264e-09, 3.7039e-09, 1.6695e-08, 3.2358e-03, 6.1952e-06, 4.0028e-08,\n",
              "            7.2554e-07, 4.4508e-07],\n",
              "           [9.9999e-01, 4.0428e-05, 2.9621e-05, 1.0985e-06, 3.7832e-04, 1.9881e-05,\n",
              "            8.8371e-05, 1.0079e-04, 1.9430e-05, 1.5589e-05, 5.1752e-05, 2.9459e-04,\n",
              "            4.6144e-06, 2.0224e-03, 2.1265e-05, 1.3020e-07, 3.8347e-05, 3.1758e-04,\n",
              "            3.3176e-06, 1.4347e-03, 8.4443e-07, 7.8736e-09, 6.6547e-05, 1.6354e-03,\n",
              "            3.5564e-08, 1.2310e-06, 1.5254e-06, 7.4639e-05, 7.1971e-06, 2.1031e-08,\n",
              "            3.6481e-05, 1.2919e-06, 6.4757e-08, 4.5643e-06, 2.5232e-08, 6.9255e-06,\n",
              "            1.7416e-06, 3.1580e-04, 1.2545e-06, 6.4945e-04, 2.1865e-04, 3.8538e-06,\n",
              "            3.1291e-06, 3.4071e-04, 2.0037e-06, 7.6282e-05, 2.2304e-04, 1.3907e-06,\n",
              "            4.3008e-04, 3.5910e-05],\n",
              "           [1.0000e+00, 9.5768e-07, 1.4170e-05, 2.2414e-08, 2.4437e-04, 2.7864e-06,\n",
              "            1.4355e-06, 5.1029e-06, 7.9092e-07, 8.5866e-06, 3.1734e-07, 4.7212e-06,\n",
              "            6.8808e-09, 1.0647e-04, 1.3301e-09, 4.3633e-10, 3.4840e-07, 1.0670e-08,\n",
              "            8.5234e-11, 7.7653e-07, 3.6506e-10, 7.0840e-11, 6.8726e-08, 2.2492e-07,\n",
              "            1.2103e-10, 1.1841e-09, 3.6439e-12, 1.7548e-08, 8.4871e-07, 4.7587e-11,\n",
              "            4.3908e-09, 1.2491e-07, 4.8760e-10, 1.0874e-08, 3.0048e-11, 1.5980e-11,\n",
              "            5.8613e-06, 4.8613e-06, 4.9100e-08, 1.0567e-05, 6.0393e-08, 2.2328e-09,\n",
              "            4.3719e-09, 4.1088e-07, 1.7065e-09, 1.8240e-06, 8.5372e-07, 1.7087e-10,\n",
              "            1.3910e-07, 3.9557e-10],\n",
              "           [1.0000e+00, 2.7254e-08, 4.5132e-07, 1.3151e-09, 2.5432e-06, 7.6345e-08,\n",
              "            3.4961e-07, 7.0405e-07, 2.3267e-08, 1.7591e-08, 6.8408e-10, 2.8742e-10,\n",
              "            1.7014e-10, 8.5509e-06, 7.4140e-12, 1.1872e-13, 4.0537e-11, 1.4030e-06,\n",
              "            1.5792e-11, 1.9506e-07, 5.8831e-12, 1.1636e-15, 1.8577e-11, 8.3228e-09,\n",
              "            5.2817e-13, 7.6163e-12, 8.8378e-13, 3.7880e-08, 5.0820e-09, 6.5924e-14,\n",
              "            2.3553e-13, 9.6396e-12, 2.6218e-12, 2.3322e-11, 1.0560e-13, 4.3313e-11,\n",
              "            2.8338e-11, 2.3310e-07, 3.7045e-12, 9.5814e-08, 9.7403e-09, 1.3800e-09,\n",
              "            5.1967e-12, 6.3960e-10, 2.3389e-11, 1.4249e-08, 5.4877e-11, 1.4541e-12,\n",
              "            9.3970e-09, 5.0772e-09],\n",
              "           [1.0000e+00, 1.4385e-05, 1.9928e-06, 1.0192e-07, 7.4869e-06, 5.9494e-07,\n",
              "            6.1088e-06, 1.6799e-05, 7.6193e-07, 7.3363e-07, 1.4575e-05, 3.0081e-07,\n",
              "            6.3097e-07, 4.3300e-06, 4.7598e-08, 1.1345e-09, 4.7483e-05, 4.4832e-05,\n",
              "            1.9985e-08, 5.0649e-06, 8.9523e-10, 1.0545e-11, 7.2189e-09, 8.0529e-06,\n",
              "            1.9622e-10, 3.0827e-10, 4.2762e-10, 1.1814e-06, 1.0876e-07, 2.7690e-10,\n",
              "            2.9446e-09, 2.1546e-07, 1.3331e-10, 7.3244e-10, 9.5984e-11, 5.1191e-08,\n",
              "            4.2319e-08, 4.5917e-05, 6.4756e-08, 2.8315e-06, 9.1961e-07, 1.6563e-06,\n",
              "            2.0412e-09, 4.9912e-07, 5.1309e-08, 5.7753e-06, 8.0029e-08, 9.5472e-09,\n",
              "            1.0590e-07, 9.2459e-08],\n",
              "           [1.0000e+00, 2.0436e-05, 1.1888e-06, 1.0836e-07, 8.7785e-06, 2.9152e-07,\n",
              "            3.5452e-05, 2.9310e-06, 7.8503e-07, 2.7943e-06, 8.5756e-07, 6.2397e-07,\n",
              "            4.0522e-08, 3.1617e-05, 4.3260e-09, 1.6207e-10, 1.6288e-07, 1.2459e-04,\n",
              "            2.0422e-08, 1.8717e-06, 2.8711e-09, 8.2174e-11, 5.2639e-06, 4.9298e-06,\n",
              "            2.7388e-09, 9.1333e-08, 1.2400e-08, 5.4151e-06, 3.7794e-06, 1.4277e-09,\n",
              "            1.2465e-07, 6.8673e-09, 8.7136e-09, 4.4000e-06, 1.4242e-10, 1.2751e-07,\n",
              "            1.0456e-08, 1.4044e-07, 4.7109e-08, 1.8316e-04, 8.4835e-06, 4.1445e-08,\n",
              "            2.4261e-08, 2.8669e-08, 1.7157e-08, 1.2315e-04, 1.3966e-06, 1.4509e-08,\n",
              "            2.4306e-06, 1.1572e-07],\n",
              "           [1.0000e+00, 5.3200e-08, 3.0020e-07, 2.1703e-09, 1.1181e-05, 3.1172e-08,\n",
              "            2.6702e-08, 1.2566e-07, 6.6592e-08, 3.6039e-06, 1.3716e-08, 8.7712e-08,\n",
              "            6.6032e-10, 4.4768e-07, 3.3748e-10, 8.2430e-12, 2.6901e-10, 6.7826e-10,\n",
              "            4.9494e-12, 4.0461e-07, 1.3133e-11, 2.1575e-12, 4.1637e-09, 5.5627e-07,\n",
              "            5.1064e-12, 5.2304e-11, 3.1740e-10, 5.7974e-09, 1.1446e-08, 7.1297e-12,\n",
              "            2.5745e-09, 3.7485e-08, 6.7526e-12, 4.0804e-09, 1.0346e-15, 2.7337e-12,\n",
              "            1.4547e-09, 3.4924e-09, 1.1324e-07, 3.2316e-10, 1.3823e-05, 4.0842e-09,\n",
              "            1.3744e-11, 1.0102e-09, 5.1775e-10, 4.8041e-09, 3.2120e-06, 1.2489e-11,\n",
              "            5.7364e-09, 2.1949e-09],\n",
              "           [1.0000e+00, 1.3200e-07, 8.4691e-06, 1.4428e-08, 2.6564e-06, 1.1860e-06,\n",
              "            7.1725e-07, 3.7994e-05, 1.0483e-06, 2.0940e-06, 4.5225e-07, 4.3981e-05,\n",
              "            1.3565e-08, 3.1343e-08, 7.6152e-08, 2.4247e-10, 5.2894e-08, 1.2118e-06,\n",
              "            8.1348e-08, 3.2324e-05, 7.8595e-09, 6.3630e-11, 2.0036e-06, 4.8471e-05,\n",
              "            2.9303e-09, 3.1534e-08, 3.1763e-10, 1.1838e-07, 3.3908e-06, 1.1483e-07,\n",
              "            5.5143e-08, 1.2050e-07, 1.6613e-08, 3.0658e-07, 1.0489e-09, 8.5696e-09,\n",
              "            4.2322e-08, 3.9969e-05, 5.7404e-06, 5.2512e-06, 5.5439e-05, 2.0501e-04,\n",
              "            4.8283e-07, 5.8207e-05, 5.0129e-08, 2.4042e-05, 1.8372e-03, 2.5727e-06,\n",
              "            2.9215e-05, 5.5780e-07],\n",
              "           [1.0000e+00, 9.2703e-06, 2.4333e-06, 5.8691e-08, 3.1374e-04, 1.0841e-06,\n",
              "            2.0841e-05, 7.4839e-06, 7.3218e-07, 4.6094e-06, 1.0454e-04, 1.2844e-06,\n",
              "            9.7351e-09, 5.0707e-05, 1.0702e-08, 8.3378e-09, 1.9667e-06, 5.4913e-07,\n",
              "            1.1242e-07, 2.5546e-06, 4.1393e-10, 2.2214e-09, 1.3380e-07, 1.2005e-04,\n",
              "            6.0941e-10, 2.6558e-09, 3.9145e-10, 5.2710e-08, 2.8451e-06, 2.3006e-10,\n",
              "            4.5127e-10, 4.0500e-08, 1.1807e-10, 3.5473e-09, 1.9427e-12, 2.9869e-09,\n",
              "            3.7667e-07, 2.3765e-05, 4.7875e-10, 5.0180e-08, 7.7936e-07, 3.5060e-07,\n",
              "            1.5464e-08, 2.0762e-06, 5.4587e-08, 2.2451e-07, 3.1058e-07, 3.1519e-07,\n",
              "            1.4051e-06, 5.2134e-08]], device='cuda:0', grad_fn=<CatBackward>)],\n",
              "  7: [tensor([[9.6890e-01, 2.7504e-02, 7.3392e-03, 1.6639e-04, 1.7602e-02, 9.2176e-04,\n",
              "            3.1049e-02, 1.1750e-02, 1.2160e-03, 2.9780e-03, 1.1196e-02, 5.1184e-02,\n",
              "            2.5170e-04, 1.0196e-03, 5.0897e-04, 5.7380e-05, 5.3814e-03, 1.3460e-02,\n",
              "            2.1771e-03, 3.3553e-02, 1.4872e-02, 7.7254e-04, 1.0087e-03, 1.2713e-01,\n",
              "            2.6434e-04, 2.9501e-04, 3.3916e-04, 3.2965e-04, 4.7571e-04, 2.9128e-04,\n",
              "            8.2374e-05, 3.9244e-04, 7.8331e-05, 3.1398e-04, 2.0043e-04, 6.3160e-05,\n",
              "            1.2306e-01, 1.5489e-03, 1.2342e-02, 1.1666e-03, 7.3488e-04, 6.8453e-05,\n",
              "            2.3313e-04, 8.7195e-03, 9.5063e-04, 8.4867e-03, 2.2051e-02, 1.7614e-05,\n",
              "            2.4989e-05, 9.5908e-05, 1.0205e-04, 1.6967e-04, 4.3908e-03, 2.0253e-04,\n",
              "            3.3922e-04, 6.5394e-06, 9.3987e-06, 4.3554e-05, 1.3034e-05, 3.7712e-03,\n",
              "            3.9286e-09, 3.8041e-06, 5.1098e-03, 2.4826e-05, 3.0955e-04, 1.5223e-05,\n",
              "            6.1184e-08, 2.1137e-06, 9.1405e-07, 2.3657e-02],\n",
              "           [9.7226e-01, 1.1449e-03, 1.5333e-03, 1.1770e-04, 6.7839e-03, 1.6818e-04,\n",
              "            3.1403e-02, 7.6381e-03, 3.2528e-04, 7.8978e-04, 5.8502e-04, 1.6101e-03,\n",
              "            1.1620e-06, 1.1891e-03, 8.5433e-05, 8.4880e-05, 9.9797e-04, 2.4716e-02,\n",
              "            9.8939e-04, 2.3063e-03, 4.9451e-04, 9.7193e-06, 7.3805e-04, 9.2207e-03,\n",
              "            2.3399e-05, 2.5692e-05, 7.2339e-05, 3.6547e-05, 8.2076e-05, 5.5808e-06,\n",
              "            4.5549e-06, 3.4567e-04, 4.0731e-05, 2.5440e-05, 5.2065e-05, 6.0322e-06,\n",
              "            1.6269e-04, 2.4195e-04, 1.0232e-04, 6.3976e-05, 1.1178e-04, 1.5223e-05,\n",
              "            3.1859e-06, 2.2751e-05, 1.1785e-06, 4.8230e-04, 1.4767e-03, 1.3890e-05,\n",
              "            2.5153e-06, 6.0142e-06, 1.0838e-06, 2.6549e-07, 1.4331e-04, 4.3262e-06,\n",
              "            1.3205e-06, 2.6211e-05, 4.1147e-06, 1.6961e-07, 3.8454e-04, 3.2353e-04,\n",
              "            8.0329e-08, 3.6930e-06, 5.3673e-04, 4.5622e-07, 5.6224e-06, 2.5101e-09,\n",
              "            4.4664e-09, 6.2443e-08, 6.7195e-06, 1.8233e-09],\n",
              "           [9.9225e-01, 3.6034e-03, 1.6549e-03, 2.7650e-05, 5.6457e-03, 3.9422e-04,\n",
              "            6.9643e-03, 5.5329e-03, 7.3684e-04, 8.9164e-04, 3.0528e-03, 1.3793e-03,\n",
              "            2.0257e-06, 5.5171e-03, 3.0176e-05, 2.3178e-05, 1.6379e-03, 1.8171e-02,\n",
              "            8.0553e-04, 1.4300e-02, 6.3283e-05, 1.1260e-05, 2.1664e-03, 5.2773e-03,\n",
              "            4.7477e-05, 5.9961e-05, 5.2906e-04, 3.3589e-04, 2.4293e-05, 1.9800e-06,\n",
              "            2.1469e-05, 7.9692e-04, 7.6568e-05, 2.6158e-05, 7.9562e-05, 6.2525e-05,\n",
              "            4.8070e-05, 3.7495e-04, 4.7565e-05, 8.2162e-04, 6.0791e-05, 1.4447e-06,\n",
              "            6.5501e-06, 3.6947e-04, 2.9505e-06, 2.1528e-04, 1.9578e-04, 7.4936e-05,\n",
              "            2.4968e-06, 1.3911e-04, 1.7061e-06, 1.2508e-08, 1.6827e-04, 1.6317e-04,\n",
              "            4.2256e-06, 8.7007e-06, 6.1258e-06, 3.2721e-07, 9.2180e-05, 3.1198e-03,\n",
              "            6.3403e-10, 5.1926e-05, 2.1596e-05, 5.6546e-06, 1.6546e-06, 4.2116e-07,\n",
              "            2.7522e-08, 2.7655e-08, 2.5018e-06, 2.0765e-06],\n",
              "           [9.8614e-01, 2.3275e-02, 9.2989e-03, 4.8744e-04, 1.3938e-02, 6.2693e-04,\n",
              "            4.6314e-03, 4.1991e-03, 5.5129e-04, 1.2492e-03, 3.5697e-03, 8.5660e-03,\n",
              "            3.0122e-05, 3.7733e-03, 1.3446e-04, 1.7427e-04, 1.1902e-03, 1.3519e-02,\n",
              "            8.8381e-04, 3.7773e-02, 3.4520e-04, 3.6328e-05, 2.0684e-03, 5.4440e-02,\n",
              "            6.0822e-04, 1.2959e-04, 7.0011e-04, 2.9171e-05, 8.2950e-05, 9.4336e-05,\n",
              "            1.0272e-04, 2.8550e-04, 1.2688e-04, 1.7722e-05, 7.4225e-05, 9.5188e-06,\n",
              "            2.2821e-02, 3.5761e-04, 3.5482e-04, 6.7863e-04, 1.5733e-04, 2.8905e-05,\n",
              "            1.1885e-04, 1.5449e-03, 1.5079e-05, 6.1605e-04, 1.1885e-03, 5.3964e-06,\n",
              "            9.6603e-06, 9.2124e-06, 5.8185e-05, 8.0959e-07, 6.4100e-04, 1.4758e-04,\n",
              "            2.1984e-06, 5.1387e-06, 5.4351e-05, 3.7123e-06, 1.7632e-04, 1.1324e-04,\n",
              "            1.3704e-09, 5.2993e-05, 9.8574e-05, 3.8937e-05, 2.3171e-03, 9.0543e-08,\n",
              "            2.6471e-09, 3.2383e-08, 5.5599e-06, 3.5732e-06],\n",
              "           [9.3834e-01, 5.7781e-03, 1.1019e-02, 1.3435e-03, 8.4325e-02, 1.4811e-03,\n",
              "            4.2479e-02, 2.9150e-02, 2.3882e-03, 2.3234e-03, 1.3623e-03, 1.2728e-03,\n",
              "            5.2731e-05, 1.1063e-01, 3.4457e-03, 7.0528e-04, 5.9151e-03, 1.2401e-01,\n",
              "            6.7814e-03, 2.1819e-02, 2.4741e-03, 2.9721e-04, 3.0372e-03, 1.7611e-02,\n",
              "            2.2775e-03, 1.4072e-03, 1.4206e-02, 4.4413e-04, 3.0312e-04, 1.0905e-04,\n",
              "            3.8106e-04, 6.5005e-03, 6.1825e-04, 2.1956e-04, 2.1152e-03, 1.0470e-03,\n",
              "            1.5848e-03, 3.4130e-03, 1.5207e-04, 1.4043e-03, 1.8804e-04, 4.0857e-04,\n",
              "            1.9150e-04, 1.8341e-03, 3.5432e-04, 2.1809e-03, 1.1978e-04, 1.0401e-03,\n",
              "            8.7301e-05, 4.2017e-04, 2.2508e-04, 5.2261e-06, 1.2285e-03, 2.5135e-04,\n",
              "            5.6229e-05, 1.0512e-02, 8.4570e-05, 1.2083e-04, 2.7217e-03, 7.7639e-04,\n",
              "            1.7534e-05, 3.0050e-03, 4.0949e-04, 1.0236e-04, 9.3887e-05, 2.6311e-04,\n",
              "            1.9649e-05, 1.0731e-06, 7.0074e-05, 2.0413e-06],\n",
              "           [9.9174e-01, 3.0766e-03, 2.2971e-03, 2.0347e-04, 9.9685e-03, 2.6115e-04,\n",
              "            1.0520e-02, 9.9004e-03, 1.1486e-03, 4.3231e-04, 1.6676e-03, 2.8145e-03,\n",
              "            4.2457e-06, 5.1522e-03, 4.0769e-05, 1.2102e-04, 7.7810e-04, 4.9823e-02,\n",
              "            1.0014e-03, 7.6579e-03, 1.3175e-04, 1.3351e-05, 9.4745e-04, 2.9949e-02,\n",
              "            1.0186e-04, 1.2996e-04, 6.2517e-04, 6.5393e-05, 4.1619e-05, 9.0002e-06,\n",
              "            3.2517e-05, 7.3501e-04, 5.9941e-05, 1.5092e-05, 1.9275e-04, 9.2489e-05,\n",
              "            2.7071e-04, 3.3380e-04, 1.2730e-04, 4.1720e-04, 1.8369e-04, 9.6430e-06,\n",
              "            3.4062e-05, 4.1804e-04, 4.3960e-06, 2.3681e-04, 4.1945e-04, 6.0115e-05,\n",
              "            5.7906e-06, 5.6662e-05, 8.9227e-06, 1.5508e-07, 5.3604e-05, 2.0429e-05,\n",
              "            5.0393e-06, 2.4121e-05, 2.2147e-05, 5.6690e-06, 1.0007e-03, 9.2509e-04,\n",
              "            2.7737e-08, 8.9668e-06, 3.0475e-03, 7.0239e-06, 1.3461e-04, 4.6415e-06,\n",
              "            2.5048e-08, 1.8784e-08, 1.2829e-06, 7.2905e-07],\n",
              "           [9.6980e-01, 7.3591e-03, 5.0714e-03, 3.5182e-04, 2.5899e-02, 1.0458e-03,\n",
              "            2.1220e-02, 1.2901e-02, 2.0793e-03, 4.1231e-03, 1.1373e-02, 1.4884e-03,\n",
              "            2.3591e-05, 3.0039e-02, 1.3453e-04, 2.7518e-04, 4.1487e-03, 5.7978e-02,\n",
              "            2.4409e-03, 2.1436e-02, 2.9784e-04, 1.4241e-04, 5.5248e-03, 1.0775e-02,\n",
              "            2.9266e-04, 3.1134e-04, 1.3512e-03, 6.4459e-04, 1.8035e-04, 2.0099e-05,\n",
              "            1.8487e-04, 1.3227e-03, 4.8509e-04, 2.3273e-04, 3.3165e-04, 7.1714e-04,\n",
              "            2.1657e-04, 5.0315e-04, 1.7999e-04, 2.1545e-03, 5.0953e-04, 9.3259e-06,\n",
              "            7.8470e-05, 7.3151e-04, 4.4021e-05, 6.1647e-04, 3.1765e-04, 3.3293e-04,\n",
              "            1.6925e-05, 8.0045e-04, 1.0980e-05, 2.5268e-07, 3.2539e-04, 2.6808e-04,\n",
              "            5.9394e-05, 6.0885e-05, 2.1550e-05, 8.6607e-06, 2.8157e-04, 3.4705e-03,\n",
              "            3.1719e-08, 2.8039e-04, 5.5534e-05, 4.6821e-05, 2.3391e-05, 5.5682e-06,\n",
              "            2.9568e-07, 1.6819e-07, 6.8081e-06, 4.0544e-06],\n",
              "           [9.9499e-01, 1.5129e-03, 4.6684e-03, 1.4390e-05, 1.2884e-03, 5.3725e-05,\n",
              "            2.0380e-03, 3.8395e-03, 5.1612e-04, 8.7084e-04, 1.1502e-03, 8.9566e-04,\n",
              "            1.1443e-06, 2.3613e-04, 1.5771e-05, 1.0871e-05, 6.7178e-05, 5.1621e-03,\n",
              "            4.7117e-04, 2.9145e-02, 5.0234e-05, 1.2467e-06, 7.4300e-04, 2.0988e-03,\n",
              "            1.1895e-05, 1.9118e-05, 4.2424e-04, 2.6053e-05, 7.6936e-06, 1.1222e-06,\n",
              "            8.6335e-06, 1.2803e-04, 6.3508e-06, 1.7316e-05, 7.1030e-05, 7.3117e-06,\n",
              "            4.5800e-05, 8.8576e-05, 1.0442e-04, 1.1842e-04, 6.7051e-05, 7.8562e-07,\n",
              "            3.1115e-06, 3.1200e-05, 5.9345e-07, 5.2778e-05, 1.5293e-03, 1.0668e-05,\n",
              "            5.3933e-07, 1.3354e-05, 1.5986e-07, 1.6591e-08, 1.0153e-04, 2.7074e-05,\n",
              "            7.0787e-06, 1.0297e-06, 1.6299e-06, 7.6899e-08, 6.8635e-05, 2.0981e-03,\n",
              "            5.8081e-11, 1.7181e-07, 6.0104e-04, 1.3674e-06, 5.5262e-04, 1.7498e-07,\n",
              "            3.4863e-10, 2.2506e-09, 2.3341e-07, 3.8051e-07],\n",
              "           [9.8632e-01, 9.9877e-03, 4.1460e-03, 5.6357e-05, 5.0164e-03, 4.3204e-04,\n",
              "            9.3376e-03, 6.5038e-03, 1.6400e-03, 1.7265e-03, 8.2472e-03, 7.9396e-03,\n",
              "            1.8304e-05, 1.1960e-03, 9.0098e-05, 7.9688e-05, 6.9181e-04, 7.9132e-03,\n",
              "            3.9032e-03, 1.6359e-02, 2.2126e-04, 1.3388e-05, 3.7248e-03, 3.7489e-02,\n",
              "            6.5569e-05, 2.4476e-04, 1.0023e-03, 5.0164e-04, 4.8405e-05, 2.5397e-05,\n",
              "            6.1495e-05, 7.4199e-04, 2.5418e-05, 7.6345e-05, 2.4379e-04, 7.7066e-05,\n",
              "            3.7839e-04, 2.0228e-03, 7.3631e-04, 9.2070e-04, 1.0747e-04, 2.4364e-05,\n",
              "            2.6882e-05, 4.0778e-03, 2.1038e-06, 2.3489e-04, 1.6017e-03, 2.2867e-04,\n",
              "            2.7779e-05, 7.2280e-05, 1.5629e-06, 2.4379e-07, 1.7985e-03, 3.0055e-04,\n",
              "            3.4616e-05, 1.7379e-05, 2.9430e-05, 1.7216e-06, 1.8087e-04, 4.6090e-03,\n",
              "            1.4709e-09, 1.3350e-03, 6.1283e-03, 2.8958e-06, 4.3257e-06, 1.4645e-06,\n",
              "            8.9827e-08, 4.4932e-08, 8.3506e-07, 2.8038e-04],\n",
              "           [9.7990e-01, 1.1943e-02, 7.1060e-03, 2.1772e-04, 1.4237e-02, 5.0206e-04,\n",
              "            1.3128e-02, 7.0263e-03, 8.8643e-04, 6.1769e-04, 9.1054e-03, 2.1445e-03,\n",
              "            1.2813e-05, 5.5218e-03, 5.5117e-05, 2.0241e-04, 2.9821e-03, 3.6195e-02,\n",
              "            4.0644e-03, 1.8242e-02, 5.8384e-04, 7.3333e-05, 1.5921e-03, 1.6511e-02,\n",
              "            1.2617e-04, 1.6551e-04, 4.9520e-04, 2.8007e-04, 1.3413e-04, 2.8187e-05,\n",
              "            2.7280e-05, 5.4671e-04, 9.0779e-05, 1.1187e-04, 6.7912e-04, 2.8428e-04,\n",
              "            7.8830e-04, 2.4338e-04, 1.4503e-04, 6.1962e-04, 3.3010e-04, 5.9935e-05,\n",
              "            4.2936e-05, 7.8523e-04, 1.1889e-05, 6.0120e-04, 5.6846e-04, 3.4712e-04,\n",
              "            1.6084e-05, 3.6422e-05, 8.4081e-06, 8.0071e-07, 1.6606e-04, 6.7864e-05,\n",
              "            1.0811e-05, 5.2208e-05, 1.6081e-04, 1.8014e-05, 1.6220e-04, 1.7396e-03,\n",
              "            2.4324e-08, 5.5608e-05, 1.0606e-03, 7.5582e-06, 8.3062e-05, 9.7102e-06,\n",
              "            1.5828e-06, 4.3053e-08, 6.9687e-06, 3.5221e-06]], device='cuda:0',\n",
              "          grad_fn=<SigmoidBackward>),\n",
              "   tensor([[9.9927e-01, 3.9342e-04, 5.1272e-04, 6.0621e-06, 1.9052e-04, 8.5856e-05,\n",
              "            7.7070e-05, 2.2836e-03, 2.4763e-04, 3.6148e-04, 4.7066e-04, 1.4098e-02,\n",
              "            1.6050e-05, 9.2360e-05, 6.4537e-06, 5.7107e-08, 3.9585e-05, 4.7655e-04,\n",
              "            2.3891e-05, 1.9992e-03, 3.8568e-04, 6.5616e-06, 2.8272e-07, 2.0973e-04,\n",
              "            6.1903e-08, 3.6320e-07, 3.0733e-08, 1.5800e-06, 3.7899e-05, 1.1037e-05,\n",
              "            1.5975e-07, 3.0903e-06, 3.8679e-08, 8.7625e-07, 3.4586e-08, 1.4697e-09,\n",
              "            1.6993e-02, 2.2452e-07, 5.5663e-04, 2.3183e-07, 9.7144e-06, 4.6621e-07,\n",
              "            1.9907e-05, 5.5930e-04, 1.2136e-05, 8.0715e-04, 2.0941e-02, 2.6373e-08,\n",
              "            3.2737e-07, 1.3468e-06, 4.1287e-04, 4.6418e-05, 3.9994e-03, 2.3659e-05,\n",
              "            1.3458e-04, 6.6790e-07, 1.8043e-06, 1.0251e-06, 5.3895e-06, 3.2548e-02],\n",
              "           [1.0000e+00, 2.4568e-07, 2.3508e-08, 5.0008e-10, 5.8313e-06, 2.3017e-09,\n",
              "            3.1309e-07, 6.2484e-07, 1.0166e-09, 1.4806e-09, 3.9021e-10, 1.0566e-07,\n",
              "            1.4479e-12, 6.0515e-09, 7.4929e-08, 6.0368e-13, 1.6323e-10, 4.1160e-08,\n",
              "            2.5670e-07, 1.4316e-06, 7.2576e-10, 2.4744e-14, 1.1605e-10, 2.7780e-07,\n",
              "            1.3869e-11, 5.6553e-11, 2.5437e-14, 2.8244e-08, 3.7202e-06, 3.4590e-11,\n",
              "            8.5202e-14, 8.7611e-09, 3.8926e-13, 1.5309e-07, 3.3844e-13, 4.5740e-13,\n",
              "            1.2850e-10, 1.2401e-08, 1.2963e-09, 3.4680e-07, 3.4880e-06, 7.5731e-08,\n",
              "            1.0785e-10, 2.4861e-09, 1.8972e-09, 5.8170e-04, 5.9601e-06, 2.0605e-09,\n",
              "            5.9333e-08, 9.6217e-08, 3.0728e-08, 2.6211e-10, 5.5850e-06, 3.7796e-10,\n",
              "            2.5080e-10, 3.5179e-08, 3.7819e-09, 3.9189e-11, 3.9195e-04, 5.9063e-05],\n",
              "           [1.0000e+00, 2.2188e-07, 5.1856e-08, 4.9071e-10, 4.5231e-06, 8.4993e-09,\n",
              "            1.0801e-07, 1.5561e-07, 1.4929e-08, 1.0177e-07, 1.4252e-08, 1.7477e-07,\n",
              "            2.9990e-10, 3.0984e-07, 1.2297e-10, 1.3584e-13, 9.0181e-11, 1.6455e-06,\n",
              "            3.6240e-11, 1.4877e-05, 1.9605e-11, 8.8002e-14, 1.1026e-06, 8.1037e-08,\n",
              "            8.7774e-13, 1.7127e-10, 1.9573e-11, 7.6499e-07, 1.2154e-07, 4.8776e-13,\n",
              "            1.6440e-08, 1.2556e-10, 9.5125e-11, 7.3250e-12, 4.9555e-13, 2.1954e-10,\n",
              "            1.8605e-11, 6.1106e-06, 1.1142e-09, 2.5430e-07, 1.1374e-07, 1.9780e-09,\n",
              "            1.0531e-09, 1.3625e-08, 2.3967e-10, 4.8607e-05, 1.0578e-07, 1.4626e-10,\n",
              "            3.2430e-07, 1.1138e-07, 3.9993e-08, 4.2846e-11, 7.5756e-07, 9.3886e-09,\n",
              "            4.1427e-10, 7.2794e-10, 2.8817e-09, 1.2560e-10, 2.6553e-06, 2.9935e-04],\n",
              "           [1.0000e+00, 9.4856e-07, 4.8593e-06, 2.4670e-08, 1.6362e-04, 1.9260e-06,\n",
              "            2.5038e-06, 3.5077e-06, 1.5535e-06, 3.1797e-05, 2.6290e-07, 1.2698e-05,\n",
              "            1.0108e-08, 1.1146e-05, 8.5684e-09, 2.7340e-10, 2.9390e-07, 3.4924e-07,\n",
              "            2.9434e-09, 1.4173e-06, 5.6813e-09, 1.3439e-09, 1.1319e-06, 1.0499e-05,\n",
              "            1.0749e-09, 1.6395e-08, 4.9640e-11, 3.8749e-08, 2.7732e-06, 3.8154e-10,\n",
              "            8.1940e-07, 1.7845e-07, 1.9053e-09, 3.0656e-09, 3.9889e-10, 1.1588e-10,\n",
              "            9.0931e-06, 2.1598e-05, 2.8672e-08, 1.2468e-05, 9.0050e-08, 9.2936e-09,\n",
              "            2.7001e-08, 3.5867e-06, 1.2417e-08, 4.2308e-07, 9.5963e-07, 7.7659e-10,\n",
              "            8.8221e-07, 4.9517e-09, 6.6145e-05, 1.2895e-09, 2.1270e-06, 2.7276e-06,\n",
              "            1.4949e-08, 2.4949e-09, 1.2377e-05, 8.1774e-08, 8.7188e-05, 1.2380e-05],\n",
              "           [9.9995e-01, 2.9795e-05, 4.3348e-05, 1.3063e-06, 2.3048e-04, 2.6753e-05,\n",
              "            2.3030e-03, 3.3170e-04, 1.8667e-05, 1.5334e-05, 8.9883e-07, 4.8731e-07,\n",
              "            5.2188e-08, 5.0687e-04, 2.2942e-06, 1.1812e-08, 1.3397e-07, 2.6309e-04,\n",
              "            3.9791e-06, 1.1946e-04, 1.5777e-06, 5.1350e-09, 1.5403e-06, 7.1578e-05,\n",
              "            1.2034e-07, 5.8340e-07, 1.6320e-07, 3.9796e-06, 4.9034e-05, 8.4519e-10,\n",
              "            2.1278e-06, 2.8150e-06, 1.8854e-07, 3.4464e-07, 3.1656e-05, 7.9739e-07,\n",
              "            1.6056e-05, 9.1662e-06, 4.9538e-08, 2.2761e-05, 5.1749e-06, 1.2024e-06,\n",
              "            3.7049e-07, 2.0874e-05, 1.2906e-07, 2.7000e-05, 1.1796e-07, 1.7741e-07,\n",
              "            1.2002e-05, 5.7216e-06, 9.1958e-06, 1.3046e-08, 7.5193e-05, 2.8850e-06,\n",
              "            1.2738e-06, 2.6354e-04, 4.2958e-08, 6.1338e-07, 6.3707e-03, 2.7306e-05],\n",
              "           [1.0000e+00, 5.5493e-06, 4.9551e-07, 5.9953e-09, 4.2849e-06, 4.3735e-08,\n",
              "            3.7643e-06, 1.9775e-06, 1.0067e-07, 5.2575e-08, 2.5466e-08, 4.7122e-07,\n",
              "            9.5430e-09, 1.8563e-05, 1.0443e-07, 7.6725e-10, 2.2273e-08, 7.0830e-06,\n",
              "            6.9178e-08, 7.6307e-06, 2.0708e-10, 1.6494e-12, 3.9421e-10, 8.8338e-05,\n",
              "            1.5904e-10, 4.6854e-10, 5.7947e-10, 4.5516e-08, 1.0254e-08, 6.9279e-10,\n",
              "            2.0116e-08, 1.0055e-07, 2.2855e-10, 3.2538e-10, 5.6779e-11, 2.4144e-09,\n",
              "            1.1517e-08, 1.6899e-06, 4.5128e-07, 6.0438e-06, 1.5827e-06, 4.7799e-06,\n",
              "            1.1485e-07, 1.0315e-06, 1.0415e-06, 2.0087e-04, 9.7981e-07, 3.2849e-08,\n",
              "            2.4656e-06, 1.7197e-05, 1.8398e-06, 4.2589e-09, 1.1612e-06, 1.3952e-07,\n",
              "            1.8763e-08, 1.8611e-07, 7.3270e-09, 6.4341e-10, 7.1877e-04, 9.4681e-05],\n",
              "           [9.9998e-01, 5.1588e-05, 6.8390e-06, 3.1175e-07, 2.5913e-04, 3.8555e-06,\n",
              "            2.2259e-04, 1.6019e-05, 3.4131e-06, 2.2234e-05, 1.1949e-04, 8.6391e-06,\n",
              "            4.0334e-07, 3.5593e-04, 2.7853e-08, 1.1682e-08, 1.9077e-05, 2.3124e-04,\n",
              "            1.2511e-07, 2.9340e-06, 3.4189e-08, 5.5165e-09, 5.6383e-06, 1.1972e-04,\n",
              "            6.8795e-08, 1.3088e-06, 6.3472e-08, 4.3563e-05, 7.6014e-06, 1.3298e-08,\n",
              "            3.5824e-07, 5.1395e-08, 4.0049e-08, 3.7162e-05, 3.8187e-10, 8.9925e-07,\n",
              "            5.7292e-08, 1.5643e-06, 4.3761e-07, 3.1078e-04, 5.1781e-05, 2.1836e-07,\n",
              "            9.5932e-08, 1.2068e-06, 1.3922e-07, 1.7287e-04, 4.1145e-06, 8.8073e-08,\n",
              "            8.1573e-06, 1.5472e-06, 5.7900e-07, 2.1413e-09, 9.5199e-06, 3.1488e-07,\n",
              "            6.1521e-08, 4.4516e-08, 1.7784e-07, 2.7168e-06, 1.9678e-04, 6.7951e-05],\n",
              "           [1.0000e+00, 3.9109e-07, 1.8599e-07, 6.0853e-09, 4.3095e-07, 9.8276e-09,\n",
              "            3.8196e-08, 1.1119e-07, 4.1832e-08, 2.7726e-06, 5.4474e-09, 4.1669e-07,\n",
              "            1.9527e-09, 1.2930e-07, 3.2435e-09, 1.0544e-11, 1.6556e-09, 1.0695e-08,\n",
              "            4.6442e-10, 5.0739e-07, 1.1793e-11, 1.7209e-13, 1.8773e-09, 3.4233e-06,\n",
              "            1.3031e-11, 5.8925e-11, 4.0480e-11, 8.2943e-10, 9.3676e-09, 3.5306e-11,\n",
              "            2.0301e-10, 3.0517e-10, 1.7622e-12, 2.0587e-10, 3.2865e-17, 7.6890e-13,\n",
              "            2.2530e-10, 4.4744e-09, 3.9067e-07, 7.2888e-11, 5.5270e-06, 1.7215e-09,\n",
              "            2.3077e-12, 1.5699e-09, 6.7193e-10, 1.0045e-09, 2.9880e-06, 9.3406e-12,\n",
              "            1.2668e-08, 7.4357e-09, 1.8692e-09, 4.9025e-11, 3.5685e-06, 5.0941e-07,\n",
              "            3.9314e-10, 2.9345e-11, 7.4447e-10, 8.9303e-13, 4.3171e-05, 2.1655e-05],\n",
              "           [1.0000e+00, 6.5613e-08, 9.5917e-06, 2.1568e-09, 2.3789e-07, 1.4092e-07,\n",
              "            1.2733e-08, 4.7697e-06, 1.9745e-07, 4.4170e-07, 2.4013e-09, 1.3069e-05,\n",
              "            3.0765e-11, 4.6565e-11, 6.1062e-11, 1.5396e-13, 3.3597e-10, 1.4312e-07,\n",
              "            7.2696e-10, 2.0488e-07, 5.5595e-11, 1.4662e-13, 8.8376e-09, 4.1971e-05,\n",
              "            4.8519e-11, 1.8745e-10, 4.8979e-12, 5.3752e-09, 3.4772e-07, 6.6039e-09,\n",
              "            2.6271e-10, 4.1502e-10, 4.8637e-10, 2.3074e-09, 2.1424e-13, 8.0791e-11,\n",
              "            1.9439e-10, 6.2058e-05, 1.5254e-06, 1.1175e-06, 1.4883e-07, 5.5778e-06,\n",
              "            6.5616e-09, 2.1496e-06, 6.1604e-10, 1.0197e-06, 4.0868e-04, 7.1638e-08,\n",
              "            5.3466e-07, 3.4897e-09, 2.6962e-08, 2.1234e-09, 1.7170e-04, 1.8253e-06,\n",
              "            5.3423e-08, 2.7172e-09, 6.0674e-08, 4.6317e-10, 1.7139e-05, 4.4370e-04],\n",
              "           [9.9998e-01, 3.7573e-05, 5.5461e-05, 6.2451e-07, 2.1278e-04, 1.1761e-05,\n",
              "            1.5162e-05, 5.2794e-05, 1.1974e-05, 1.7163e-05, 1.4967e-05, 3.0585e-06,\n",
              "            8.1064e-08, 1.0978e-06, 4.2806e-08, 3.7034e-09, 1.7299e-06, 5.3450e-06,\n",
              "            1.2228e-07, 8.0584e-06, 7.0016e-09, 1.4730e-08, 5.1300e-07, 6.1863e-06,\n",
              "            4.4303e-09, 1.4334e-08, 1.6538e-10, 4.1551e-07, 4.5467e-05, 3.0982e-09,\n",
              "            5.5373e-08, 1.8149e-07, 3.4292e-09, 9.9317e-08, 1.1302e-10, 7.1736e-09,\n",
              "            7.5328e-07, 3.1819e-06, 6.8555e-08, 4.8033e-05, 1.4120e-05, 7.5598e-06,\n",
              "            3.3956e-07, 1.6536e-06, 8.7146e-07, 2.3346e-05, 5.9618e-06, 1.1699e-06,\n",
              "            1.4795e-06, 1.7455e-07, 1.2758e-05, 6.7129e-08, 3.6943e-05, 4.0345e-06,\n",
              "            1.1317e-06, 1.0772e-07, 1.5819e-05, 6.9153e-05, 1.1729e-03, 1.3393e-03]],\n",
              "          device='cuda:0', grad_fn=<CatBackward>)],\n",
              "  8: [tensor([[9.2063e-01, 6.6914e-02, 1.3863e-02, 8.7412e-04, 4.1343e-02, 1.1921e-03,\n",
              "            2.1934e-02, 1.5954e-02, 2.4651e-03, 5.1817e-03, 1.6006e-02, 1.2067e-01,\n",
              "            9.0780e-04, 2.4302e-03, 1.1055e-03, 2.1675e-04, 6.6171e-03, 1.8995e-02,\n",
              "            4.9220e-03, 3.6336e-02, 2.9821e-02, 9.4875e-04, 1.4603e-03, 2.6018e-01,\n",
              "            9.5330e-04, 7.5970e-04, 9.8422e-04, 1.1379e-03, 1.4913e-03, 6.3715e-04,\n",
              "            4.2457e-04, 3.6239e-03, 1.0038e-04, 2.3801e-04, 1.3030e-03, 1.1486e-04,\n",
              "            1.0719e-01, 1.8132e-03, 1.5868e-02, 2.9531e-03, 5.1489e-04, 3.1863e-04,\n",
              "            7.4333e-04, 2.1798e-02, 1.7136e-03, 7.1539e-03, 1.7848e-02, 5.5337e-05,\n",
              "            5.8083e-04, 2.1022e-04, 2.3543e-04, 1.0350e-03, 2.0184e-03, 4.5565e-04,\n",
              "            3.3456e-04, 3.7038e-05, 8.3337e-05, 3.9906e-04, 6.9956e-05, 3.9833e-03,\n",
              "            2.0338e-06, 3.3216e-05, 1.4050e-02, 3.2832e-04, 4.2203e-04, 1.0888e-03,\n",
              "            1.0887e-04, 2.2997e-05, 1.9815e-05, 1.6800e-02, 1.1687e-03, 1.6160e-04,\n",
              "            1.0066e-03, 9.1672e-06, 1.0063e-07, 7.7191e-06, 2.4545e-03, 1.5228e-06,\n",
              "            3.6136e-06, 2.2102e-07],\n",
              "           [9.6329e-01, 3.8270e-03, 4.5934e-03, 2.8797e-04, 1.2063e-02, 5.3015e-04,\n",
              "            4.3568e-02, 1.2422e-02, 1.1313e-03, 1.1389e-03, 7.9302e-03, 3.9034e-03,\n",
              "            9.8179e-06, 4.4604e-03, 6.1805e-04, 2.1031e-04, 1.6021e-03, 4.7175e-02,\n",
              "            2.1865e-03, 7.8213e-03, 6.4078e-04, 8.9026e-05, 1.2845e-03, 6.8757e-02,\n",
              "            1.4996e-04, 8.0221e-05, 4.3983e-04, 8.1735e-04, 6.2555e-04, 1.5582e-05,\n",
              "            5.5415e-05, 1.4782e-03, 8.4285e-05, 3.2028e-05, 6.7485e-04, 1.4408e-04,\n",
              "            6.5292e-04, 1.0056e-03, 2.2978e-04, 4.4343e-04, 1.9253e-04, 2.2187e-05,\n",
              "            6.0487e-05, 3.8609e-04, 1.5899e-05, 1.9671e-03, 1.7751e-03, 4.4586e-04,\n",
              "            2.3216e-05, 5.3312e-05, 5.5049e-06, 5.7442e-06, 3.9632e-04, 6.2481e-06,\n",
              "            3.1558e-05, 8.4038e-05, 1.3830e-04, 1.2923e-05, 1.1992e-03, 1.8269e-03,\n",
              "            1.6994e-05, 3.0413e-05, 1.7716e-03, 9.4329e-05, 4.7123e-05, 1.0413e-06,\n",
              "            8.8005e-06, 5.4709e-05, 2.2612e-05, 2.6441e-06, 5.2693e-06, 1.9623e-05,\n",
              "            1.2140e-05, 1.4497e-08, 1.3555e-06, 8.8108e-06, 1.9414e-07, 4.7174e-08,\n",
              "            9.6145e-08, 1.0471e-07],\n",
              "           [9.2099e-01, 4.1681e-02, 1.4407e-02, 1.0010e-03, 1.5601e-02, 2.4403e-03,\n",
              "            2.0597e-02, 1.3967e-02, 4.3292e-03, 4.5819e-03, 2.3369e-02, 2.2624e-02,\n",
              "            1.8711e-04, 7.6285e-03, 4.9673e-04, 7.1181e-04, 4.8593e-03, 6.3473e-02,\n",
              "            2.8950e-03, 3.1309e-02, 1.0826e-03, 6.3325e-04, 1.7144e-02, 3.5411e-02,\n",
              "            8.5072e-04, 7.9685e-04, 3.6550e-03, 2.9520e-03, 5.4520e-04, 1.6195e-04,\n",
              "            9.0438e-04, 2.6267e-03, 1.5197e-03, 1.1112e-03, 1.6413e-03, 1.2518e-03,\n",
              "            3.3344e-03, 2.8996e-03, 1.3499e-03, 8.1753e-03, 1.2144e-03, 2.7935e-04,\n",
              "            3.4395e-04, 5.2921e-03, 1.4513e-04, 6.6158e-03, 7.3058e-03, 2.3318e-03,\n",
              "            9.0466e-05, 2.2240e-03, 7.2644e-05, 1.3976e-05, 4.1933e-03, 2.0075e-03,\n",
              "            1.1949e-04, 5.3233e-04, 2.0406e-03, 4.4126e-04, 2.3218e-03, 1.6908e-02,\n",
              "            6.4812e-05, 1.1428e-03, 9.9666e-04, 9.9751e-04, 4.1258e-04, 7.4046e-05,\n",
              "            3.3807e-04, 2.8034e-04, 2.1189e-03, 1.6830e-03, 2.4427e-03, 6.1013e-04,\n",
              "            1.7398e-03, 1.6891e-03, 1.2708e-03, 4.1027e-05, 1.0324e-06, 1.4537e-06,\n",
              "            4.1499e-06, 1.9074e-07],\n",
              "           [9.6509e-01, 4.0645e-02, 2.5464e-02, 2.6104e-03, 1.2808e-02, 7.5398e-04,\n",
              "            6.1345e-03, 8.5401e-03, 1.0746e-03, 2.6794e-03, 8.6877e-03, 1.9791e-02,\n",
              "            1.7017e-04, 2.1610e-03, 1.9002e-04, 1.2076e-03, 1.3551e-03, 2.7451e-02,\n",
              "            2.3069e-03, 5.7185e-02, 1.4211e-03, 1.9170e-04, 3.2118e-03, 8.9296e-02,\n",
              "            1.6765e-03, 3.1601e-04, 9.6274e-04, 7.7431e-05, 3.3409e-04, 4.7079e-04,\n",
              "            4.9368e-04, 8.4968e-04, 3.3153e-04, 1.2246e-04, 1.5877e-04, 7.1102e-05,\n",
              "            1.1929e-01, 7.2599e-04, 1.7758e-03, 1.2092e-03, 1.7196e-03, 2.8049e-04,\n",
              "            2.1019e-04, 6.7553e-03, 5.1882e-05, 1.2623e-03, 5.4192e-03, 4.6384e-05,\n",
              "            1.0086e-04, 7.7770e-05, 3.4403e-05, 2.8720e-05, 3.1348e-03, 4.3114e-04,\n",
              "            2.5822e-05, 3.2549e-05, 3.1005e-04, 1.0023e-04, 1.8245e-03, 8.8897e-04,\n",
              "            5.3142e-06, 9.9276e-05, 4.8073e-03, 1.2366e-03, 1.1555e-02, 4.3459e-06,\n",
              "            2.5541e-05, 7.0208e-05, 2.2786e-05, 2.6505e-04, 3.0350e-04, 3.8295e-03,\n",
              "            7.4347e-03, 3.7044e-07, 9.0032e-06, 1.4956e-04, 1.0029e-06, 2.7254e-06,\n",
              "            2.3684e-05, 9.7104e-08],\n",
              "           [9.6969e-01, 7.7151e-03, 8.5717e-03, 7.5097e-04, 1.1506e-02, 2.5955e-04,\n",
              "            4.9589e-03, 5.5190e-03, 1.0891e-03, 1.3182e-03, 5.4904e-03, 5.4249e-04,\n",
              "            7.3880e-06, 1.5190e-02, 1.3112e-04, 2.1265e-04, 7.6516e-04, 4.6429e-02,\n",
              "            1.2221e-03, 1.1697e-02, 1.0956e-04, 6.6758e-05, 9.1528e-04, 5.7308e-03,\n",
              "            2.9351e-04, 1.1527e-04, 1.6668e-03, 1.1454e-04, 6.6291e-05, 4.5812e-06,\n",
              "            6.1612e-05, 5.4628e-04, 7.3782e-05, 1.9099e-05, 1.8907e-04, 4.0871e-04,\n",
              "            2.0502e-04, 4.5521e-04, 3.8770e-05, 7.0290e-04, 1.3005e-04, 9.8609e-06,\n",
              "            3.1209e-05, 4.7910e-04, 1.5915e-05, 1.3793e-04, 5.1975e-05, 1.7387e-04,\n",
              "            1.0505e-05, 1.5160e-04, 1.9871e-06, 2.3778e-07, 8.1604e-05, 4.0499e-05,\n",
              "            2.8103e-06, 9.7754e-05, 4.5938e-05, 1.5280e-05, 1.5034e-03, 6.2883e-04,\n",
              "            5.5939e-07, 6.4395e-04, 2.7175e-05, 6.7048e-05, 1.1371e-04, 8.7293e-06,\n",
              "            4.0108e-06, 9.2643e-07, 1.5968e-05, 1.4281e-06, 6.5683e-06, 2.3076e-06,\n",
              "            1.5445e-03, 3.5124e-07, 8.8307e-07, 4.2285e-06, 3.5930e-09, 3.3237e-09,\n",
              "            1.5345e-08, 3.3146e-09],\n",
              "           [9.5772e-01, 1.7834e-02, 7.1169e-03, 6.0577e-04, 1.1505e-02, 2.3842e-04,\n",
              "            8.0136e-03, 1.0679e-02, 2.5029e-03, 1.7569e-03, 6.6888e-03, 1.1125e-02,\n",
              "            3.1619e-05, 2.4199e-03, 8.0387e-05, 5.2496e-04, 1.2725e-03, 2.6258e-02,\n",
              "            1.4192e-03, 1.0798e-02, 2.9975e-04, 7.9334e-05, 1.9289e-03, 3.6931e-02,\n",
              "            1.5264e-04, 1.7043e-04, 9.9404e-04, 4.5868e-04, 2.2776e-04, 1.4928e-05,\n",
              "            9.3446e-05, 1.9515e-03, 9.2181e-05, 5.7318e-05, 4.4950e-04, 1.9025e-04,\n",
              "            7.6192e-04, 9.2334e-04, 7.7726e-04, 1.6790e-03, 7.6485e-04, 4.9810e-05,\n",
              "            7.6202e-05, 6.6744e-04, 1.9241e-05, 7.2248e-04, 3.5282e-03, 2.0724e-04,\n",
              "            2.7537e-05, 2.2649e-04, 8.3542e-06, 3.3590e-06, 3.7007e-04, 9.8740e-05,\n",
              "            1.3071e-05, 1.9186e-05, 4.3383e-05, 7.5308e-05, 3.4601e-03, 5.0185e-03,\n",
              "            1.6219e-05, 2.1456e-04, 1.4693e-03, 2.1543e-04, 1.0791e-04, 1.2261e-05,\n",
              "            8.6749e-06, 9.0811e-06, 7.5983e-06, 1.8520e-04, 2.3112e-03, 3.8638e-05,\n",
              "            5.3390e-05, 4.2908e-06, 2.3316e-07, 9.5069e-06, 6.1364e-07, 1.9418e-07,\n",
              "            1.2257e-08, 1.5815e-08],\n",
              "           [9.4308e-01, 1.9832e-02, 1.9149e-02, 1.4244e-03, 6.1465e-03, 6.0581e-04,\n",
              "            7.7156e-03, 9.1903e-03, 2.4901e-03, 2.4226e-03, 3.9778e-02, 2.6948e-03,\n",
              "            3.8203e-05, 3.7184e-03, 9.8287e-05, 2.1216e-04, 3.1261e-03, 1.5846e-01,\n",
              "            1.9175e-03, 1.1860e-02, 6.1697e-04, 5.0096e-04, 2.7316e-03, 1.3259e-02,\n",
              "            5.2764e-04, 2.2371e-04, 7.5539e-04, 4.2475e-04, 3.0269e-04, 2.5201e-05,\n",
              "            2.4342e-04, 6.0737e-04, 4.8865e-04, 2.0190e-04, 1.7349e-04, 1.6725e-03,\n",
              "            1.0698e-03, 2.6384e-04, 2.6397e-04, 3.6400e-03, 6.1146e-04, 3.3149e-05,\n",
              "            1.2248e-04, 1.0806e-03, 6.7634e-05, 2.4370e-03, 3.9021e-04, 2.7822e-04,\n",
              "            3.2609e-05, 8.2780e-04, 3.7607e-06, 1.6773e-06, 4.7531e-04, 1.2048e-04,\n",
              "            2.8155e-05, 1.3139e-04, 1.6925e-04, 1.8591e-04, 5.6701e-04, 1.9760e-03,\n",
              "            2.1011e-06, 1.2613e-03, 1.7561e-05, 1.5728e-04, 1.5188e-04, 9.2287e-06,\n",
              "            6.2110e-05, 8.8021e-06, 1.6010e-04, 6.8782e-05, 7.4316e-06, 5.7953e-04,\n",
              "            3.8817e-04, 2.5325e-05, 4.1805e-06, 1.0961e-06, 1.7014e-08, 4.9080e-08,\n",
              "            1.7243e-06, 3.6783e-08],\n",
              "           [9.6587e-01, 1.8390e-02, 1.1914e-02, 4.6663e-04, 9.6868e-03, 2.1528e-04,\n",
              "            3.4945e-03, 2.8673e-03, 1.7318e-03, 4.4489e-03, 6.0764e-03, 1.1155e-02,\n",
              "            3.0715e-05, 1.2451e-03, 6.4504e-05, 2.5790e-04, 4.3608e-04, 8.9571e-03,\n",
              "            7.7766e-04, 3.6298e-02, 2.9282e-04, 1.7031e-05, 2.4064e-03, 2.3420e-02,\n",
              "            1.2093e-04, 2.1124e-04, 6.9809e-04, 2.0464e-04, 1.2246e-04, 1.3006e-05,\n",
              "            1.6948e-04, 1.1296e-03, 3.9002e-05, 7.7093e-05, 1.5450e-04, 3.0608e-05,\n",
              "            1.3558e-03, 3.4331e-04, 7.1782e-04, 4.8568e-04, 4.4092e-04, 1.0765e-05,\n",
              "            2.8090e-05, 1.4300e-03, 1.8405e-05, 1.0851e-04, 3.2032e-03, 2.3579e-05,\n",
              "            3.1656e-05, 1.0506e-04, 1.9996e-06, 9.9367e-07, 2.7419e-04, 5.3270e-04,\n",
              "            7.4737e-06, 5.6137e-06, 2.5337e-05, 9.6225e-06, 3.0217e-04, 2.2139e-03,\n",
              "            8.0378e-07, 1.8311e-05, 4.6780e-04, 3.1801e-04, 3.4993e-04, 5.6198e-06,\n",
              "            4.2266e-06, 2.0823e-06, 3.7718e-06, 1.5974e-04, 2.1903e-05, 9.3872e-04,\n",
              "            4.1798e-04, 5.1748e-06, 1.5119e-08, 1.7442e-06, 2.2628e-08, 3.4451e-08,\n",
              "            3.2656e-08, 9.1066e-09],\n",
              "           [9.3582e-01, 3.1345e-02, 1.0958e-02, 3.0498e-04, 1.5668e-02, 8.8958e-04,\n",
              "            1.4816e-02, 9.6043e-03, 4.0247e-03, 2.4529e-03, 1.4100e-02, 8.1668e-02,\n",
              "            9.0688e-05, 2.5139e-03, 7.2453e-04, 1.3672e-04, 3.2818e-03, 2.0042e-02,\n",
              "            6.1209e-03, 9.9961e-03, 1.3164e-03, 1.4660e-04, 3.6571e-03, 1.2221e-01,\n",
              "            4.8121e-04, 5.0463e-04, 1.8680e-03, 3.5567e-03, 4.4327e-04, 6.0867e-05,\n",
              "            6.0264e-05, 6.2720e-03, 6.9933e-05, 9.2245e-05, 2.2734e-03, 1.2949e-04,\n",
              "            1.4774e-03, 3.1238e-03, 2.2403e-03, 4.9887e-03, 6.0930e-05, 1.1964e-04,\n",
              "            3.1673e-04, 7.3283e-03, 5.8436e-05, 1.5426e-03, 4.8019e-03, 1.6272e-04,\n",
              "            6.0782e-05, 1.4502e-04, 1.1234e-05, 2.8366e-05, 3.3027e-04, 5.9646e-05,\n",
              "            2.0381e-05, 4.6256e-05, 1.2423e-04, 2.1569e-04, 2.7501e-04, 1.5799e-03,\n",
              "            1.0415e-05, 1.7172e-04, 3.6756e-03, 3.1185e-05, 6.2570e-06, 2.9883e-05,\n",
              "            2.9456e-05, 3.4598e-06, 7.6650e-06, 3.3972e-03, 6.3969e-04, 3.1252e-06,\n",
              "            1.5905e-06, 6.2417e-07, 6.8975e-08, 1.9241e-06, 1.3010e-06, 6.0971e-07,\n",
              "            2.6773e-08, 2.9471e-07],\n",
              "           [9.8279e-01, 1.0286e-02, 9.0206e-03, 3.3758e-04, 8.7593e-03, 1.3648e-04,\n",
              "            3.5829e-03, 4.8569e-03, 8.1524e-04, 7.5225e-04, 1.3287e-02, 1.4877e-03,\n",
              "            6.7430e-06, 2.8535e-03, 3.8151e-05, 1.3107e-04, 8.2469e-04, 3.5864e-02,\n",
              "            1.6213e-03, 1.0303e-02, 2.6975e-04, 7.1495e-05, 7.0783e-04, 2.1523e-02,\n",
              "            8.2666e-05, 3.4731e-05, 5.3993e-04, 9.7609e-05, 1.6383e-04, 5.8355e-06,\n",
              "            1.2095e-05, 5.8473e-04, 3.2381e-05, 1.7908e-05, 3.6043e-04, 1.1221e-04,\n",
              "            3.8921e-04, 2.2278e-04, 1.3052e-04, 5.7715e-04, 8.4249e-05, 1.3969e-05,\n",
              "            2.9363e-05, 2.9584e-04, 1.6329e-05, 1.8425e-04, 3.5593e-04, 9.3731e-05,\n",
              "            2.0375e-05, 3.9462e-05, 5.4168e-07, 1.0927e-06, 4.2513e-05, 1.3903e-05,\n",
              "            3.9905e-06, 7.2045e-06, 6.6540e-05, 4.2205e-05, 1.6694e-04, 4.2029e-04,\n",
              "            7.2708e-07, 6.2858e-05, 8.4267e-05, 3.5410e-05, 2.7549e-05, 3.5952e-06,\n",
              "            2.2637e-05, 3.9175e-07, 2.0440e-06, 6.9071e-06, 2.1417e-06, 1.5742e-06,\n",
              "            1.2016e-04, 3.3701e-07, 1.0578e-07, 1.5978e-07, 3.7139e-08, 2.2594e-08,\n",
              "            4.9661e-09, 2.0311e-09]], device='cuda:0', grad_fn=<SigmoidBackward>),\n",
              "   tensor([[9.9908e-01, 6.9200e-04, 8.0072e-04, 6.9625e-06, 7.4145e-04, 1.4711e-04,\n",
              "            2.4716e-04, 3.2379e-03, 1.9919e-04, 6.0684e-05, 8.7689e-04, 1.4795e-03,\n",
              "            4.0972e-05, 1.3472e-03, 4.8064e-06, 1.4410e-07, 4.2784e-05, 7.0886e-04,\n",
              "            5.9732e-06, 3.4133e-03, 4.3562e-04, 4.6387e-06, 2.1214e-07, 5.8658e-04,\n",
              "            6.9392e-07, 3.9865e-07, 7.9708e-08, 1.3555e-06, 3.4763e-05, 1.3704e-05,\n",
              "            1.9209e-08, 1.9403e-06, 4.3153e-08, 4.2020e-07, 3.7238e-08, 1.5826e-10,\n",
              "            1.7362e-03, 7.0725e-07, 2.4322e-04, 6.2077e-07, 3.0596e-05, 2.0491e-07,\n",
              "            1.2148e-04, 7.7927e-05, 5.6224e-05, 1.6285e-03, 5.4466e-02, 2.9517e-08,\n",
              "            2.0784e-07, 3.2835e-06, 3.8881e-04, 4.2056e-05, 4.0017e-03, 2.5409e-04,\n",
              "            2.4236e-05, 8.2359e-07, 2.4384e-06, 1.9035e-07, 2.3073e-05, 1.1428e-02,\n",
              "            8.1056e-09, 2.9243e-06, 7.6995e-03, 7.2274e-05, 1.2191e-04, 2.2691e-05,\n",
              "            5.2998e-08, 1.2170e-06, 2.0950e-07, 1.9599e-02],\n",
              "           [1.0000e+00, 4.8492e-07, 8.1150e-07, 1.0362e-08, 4.0270e-05, 2.7533e-07,\n",
              "            3.3184e-05, 8.4204e-06, 8.8716e-08, 2.0187e-07, 4.2573e-07, 4.3933e-05,\n",
              "            2.5652e-09, 6.8812e-07, 1.7923e-07, 2.0900e-10, 2.3889e-07, 5.1605e-05,\n",
              "            1.2743e-07, 2.0778e-06, 2.9044e-08, 5.9167e-12, 5.4330e-09, 6.8410e-07,\n",
              "            3.7926e-10, 3.3011e-09, 5.6423e-12, 3.0810e-07, 6.7190e-05, 3.7466e-10,\n",
              "            1.3435e-12, 5.1881e-09, 1.8564e-11, 4.3423e-07, 1.6364e-11, 2.9239e-11,\n",
              "            4.3400e-10, 1.1583e-07, 1.0789e-07, 7.9823e-07, 4.2861e-06, 3.0959e-07,\n",
              "            1.2852e-09, 3.6185e-09, 1.9886e-08, 1.7517e-03, 1.6409e-05, 1.8498e-07,\n",
              "            1.0856e-06, 4.6288e-07, 6.8154e-08, 1.3247e-09, 9.9926e-06, 5.5676e-09,\n",
              "            1.2263e-08, 3.2483e-08, 2.2112e-08, 2.9702e-10, 4.8004e-04, 1.7813e-04,\n",
              "            1.1269e-07, 2.1631e-05, 1.2634e-03, 8.1985e-07, 4.1963e-06, 5.5841e-09,\n",
              "            9.4943e-09, 2.2211e-08, 3.6684e-06, 1.1148e-08],\n",
              "           [1.0000e+00, 4.4235e-05, 3.9204e-06, 2.1221e-07, 5.3139e-05, 1.9269e-06,\n",
              "            1.1930e-05, 1.4104e-05, 3.2766e-06, 5.0207e-06, 1.3716e-05, 2.2490e-05,\n",
              "            6.1373e-07, 7.1266e-05, 4.3726e-07, 9.0238e-09, 4.7590e-06, 1.4343e-04,\n",
              "            3.3249e-07, 3.3315e-04, 4.2677e-08, 9.9578e-10, 3.0770e-05, 1.5500e-05,\n",
              "            2.0124e-09, 1.0573e-07, 1.9891e-07, 3.5305e-05, 6.4607e-06, 1.0431e-09,\n",
              "            8.2108e-06, 2.0103e-06, 2.0106e-08, 7.7414e-07, 1.0650e-09, 1.4474e-06,\n",
              "            1.5022e-07, 1.0330e-04, 2.8796e-07, 3.0610e-04, 3.1960e-05, 9.1784e-07,\n",
              "            5.7860e-07, 2.5497e-05, 4.1775e-07, 2.3450e-04, 5.2293e-05, 2.1351e-07,\n",
              "            2.0445e-05, 8.8480e-06, 1.7400e-06, 1.1241e-08, 1.0254e-04, 7.4010e-06,\n",
              "            2.7599e-07, 9.2165e-07, 1.1783e-06, 8.7492e-08, 1.2582e-04, 3.2487e-03,\n",
              "            3.3307e-07, 1.7513e-03, 7.8850e-03, 3.7759e-04, 3.4265e-05, 6.5769e-05,\n",
              "            1.6974e-05, 6.5886e-06, 3.3915e-05, 2.0580e-04],\n",
              "           [9.9999e-01, 2.2478e-05, 4.0819e-05, 5.1062e-07, 4.5774e-04, 1.8481e-05,\n",
              "            2.8058e-05, 6.8651e-05, 1.6414e-05, 4.3917e-05, 1.0857e-05, 3.7650e-04,\n",
              "            7.4395e-07, 1.7993e-04, 1.3578e-06, 2.3530e-08, 4.4231e-06, 1.4510e-05,\n",
              "            1.0204e-06, 6.8003e-05, 3.4125e-07, 1.0105e-08, 3.5128e-06, 1.8945e-03,\n",
              "            9.3111e-08, 7.9602e-07, 2.6428e-08, 9.9818e-07, 5.1420e-06, 3.5291e-08,\n",
              "            7.3058e-06, 4.6001e-07, 1.1120e-08, 4.4645e-08, 4.8225e-09, 8.4143e-09,\n",
              "            4.3047e-04, 5.3224e-05, 2.4786e-07, 8.6821e-05, 9.8074e-07, 6.8903e-08,\n",
              "            8.5169e-08, 6.0948e-05, 1.0632e-07, 1.0041e-06, 1.4642e-05, 2.9089e-09,\n",
              "            5.3177e-06, 3.3957e-08, 1.1648e-04, 7.6467e-09, 6.6409e-06, 2.8094e-05,\n",
              "            4.4627e-08, 2.8971e-08, 2.9342e-05, 4.5039e-08, 2.8066e-04, 1.1379e-05,\n",
              "            4.6465e-09, 6.3909e-05, 1.6577e-04, 7.5948e-05, 8.7874e-03, 4.4715e-07,\n",
              "            2.1162e-08, 1.5308e-07, 8.5811e-06, 5.0737e-05],\n",
              "           [1.0000e+00, 3.2892e-06, 2.3595e-05, 1.3481e-07, 2.0522e-04, 7.1492e-06,\n",
              "            7.5380e-06, 4.7893e-05, 1.5782e-06, 8.2644e-07, 4.9282e-08, 3.7144e-08,\n",
              "            7.4850e-08, 4.1440e-05, 9.9630e-10, 2.0470e-10, 9.0763e-08, 1.3555e-04,\n",
              "            4.4645e-09, 1.1499e-05, 6.9140e-10, 2.4573e-12, 3.0633e-09, 2.2534e-06,\n",
              "            1.7030e-10, 3.4079e-09, 7.4912e-10, 1.8549e-06, 1.0884e-07, 2.4170e-12,\n",
              "            3.9477e-09, 1.0089e-08, 1.2726e-10, 8.1568e-09, 4.9966e-11, 3.2332e-09,\n",
              "            2.9195e-09, 2.3752e-07, 2.1880e-10, 2.9423e-06, 1.2972e-07, 1.4374e-08,\n",
              "            6.9272e-09, 5.3385e-07, 4.8447e-09, 9.4277e-07, 7.9305e-09, 5.9686e-09,\n",
              "            2.7876e-08, 3.3089e-07, 6.0583e-08, 6.6004e-11, 2.9463e-06, 2.9613e-07,\n",
              "            9.8864e-08, 2.3464e-07, 1.6869e-09, 6.1995e-09, 1.2356e-04, 8.7223e-06,\n",
              "            3.8794e-10, 2.8762e-04, 1.1962e-06, 4.4601e-06, 3.6969e-06, 3.7261e-06,\n",
              "            3.9959e-09, 5.4237e-10, 1.2262e-06, 2.1665e-07],\n",
              "           [1.0000e+00, 2.8102e-05, 3.3007e-06, 1.8039e-07, 1.7867e-05, 4.5562e-07,\n",
              "            2.3666e-05, 3.0321e-06, 7.7598e-07, 3.5545e-07, 2.1866e-06, 5.6248e-07,\n",
              "            7.2865e-08, 1.5414e-05, 2.1945e-09, 6.3591e-10, 7.9638e-08, 3.3080e-07,\n",
              "            1.7027e-09, 7.5247e-06, 3.4821e-10, 7.1898e-11, 5.3652e-09, 3.9638e-06,\n",
              "            1.1701e-10, 2.2745e-10, 1.1439e-07, 1.5616e-07, 1.8453e-07, 1.1493e-10,\n",
              "            3.5014e-09, 2.8371e-07, 4.5338e-11, 1.8242e-08, 2.6334e-12, 2.4513e-08,\n",
              "            3.6720e-08, 3.3587e-06, 2.2110e-07, 3.2221e-08, 3.8417e-06, 1.2377e-05,\n",
              "            2.9879e-08, 2.6192e-07, 7.6754e-08, 1.0275e-06, 4.4659e-05, 2.6043e-07,\n",
              "            1.2410e-06, 8.3409e-07, 3.6930e-07, 5.8822e-09, 1.0074e-05, 1.4728e-06,\n",
              "            3.6508e-08, 7.2212e-08, 5.0332e-09, 9.2354e-10, 4.0093e-03, 4.2112e-04,\n",
              "            7.9061e-08, 1.7951e-05, 5.0802e-03, 1.1939e-05, 1.2618e-04, 9.1541e-07,\n",
              "            1.8525e-08, 4.8036e-08, 5.8320e-07, 2.3856e-06],\n",
              "           [1.0000e+00, 1.1520e-04, 2.7779e-06, 4.1368e-07, 1.2517e-05, 9.8886e-07,\n",
              "            1.6817e-04, 1.4803e-05, 3.6708e-06, 8.3260e-06, 1.5695e-06, 4.7092e-07,\n",
              "            1.7338e-07, 4.7419e-05, 1.0294e-08, 7.8285e-10, 6.5684e-07, 5.2428e-05,\n",
              "            2.2145e-08, 2.7994e-06, 4.5749e-09, 1.1231e-10, 2.6104e-06, 1.2351e-05,\n",
              "            1.2798e-09, 8.2072e-08, 2.0546e-08, 1.3941e-05, 1.6354e-06, 8.2434e-11,\n",
              "            5.6648e-07, 5.3840e-09, 2.8903e-08, 1.0028e-06, 3.3167e-10, 6.2886e-07,\n",
              "            1.8063e-08, 1.2763e-07, 3.0293e-09, 1.1358e-03, 1.5005e-06, 7.3845e-09,\n",
              "            1.0343e-09, 5.7215e-08, 8.3859e-10, 6.8186e-05, 1.3064e-07, 2.4548e-10,\n",
              "            1.7721e-06, 1.0804e-08, 1.7062e-07, 3.5804e-10, 4.5781e-07, 5.7791e-09,\n",
              "            3.0184e-10, 6.8824e-09, 2.6051e-07, 3.1972e-07, 7.2086e-05, 3.0404e-06,\n",
              "            9.5294e-09, 1.4193e-04, 7.3911e-06, 7.0133e-05, 5.4532e-05, 4.1165e-06,\n",
              "            6.6870e-07, 9.0109e-08, 2.2419e-05, 2.4760e-06],\n",
              "           [9.9999e-01, 2.6787e-08, 1.7338e-06, 9.4711e-09, 5.5578e-05, 4.0109e-07,\n",
              "            2.7156e-07, 1.0116e-06, 3.9826e-07, 7.6756e-06, 6.6933e-08, 3.0601e-06,\n",
              "            3.3783e-08, 4.9536e-06, 5.0261e-09, 1.5874e-10, 2.3674e-08, 4.2293e-09,\n",
              "            1.4111e-11, 2.6479e-06, 4.5071e-09, 2.2931e-10, 1.7908e-07, 1.4718e-05,\n",
              "            1.2824e-09, 1.0668e-08, 3.5781e-08, 2.4240e-07, 2.5301e-07, 2.0920e-09,\n",
              "            1.4184e-08, 1.0575e-07, 1.0346e-10, 6.2776e-09, 4.5551e-15, 9.4344e-12,\n",
              "            1.0496e-08, 1.0608e-07, 8.2065e-06, 2.1395e-09, 6.4866e-05, 9.4885e-08,\n",
              "            6.5590e-10, 2.7408e-08, 6.7827e-09, 9.1735e-09, 7.7947e-05, 8.3855e-10,\n",
              "            2.0550e-07, 2.7558e-08, 1.5966e-08, 1.9500e-10, 1.9377e-06, 2.6023e-05,\n",
              "            2.6528e-09, 4.4533e-10, 1.3984e-08, 1.2303e-11, 1.7141e-04, 5.7072e-05,\n",
              "            2.5996e-09, 2.1057e-06, 3.7349e-04, 3.6164e-05, 3.6989e-04, 3.4500e-07,\n",
              "            3.4941e-09, 8.3525e-09, 2.2675e-07, 1.3285e-05],\n",
              "           [1.0000e+00, 5.1635e-07, 1.0300e-04, 9.9058e-09, 3.2265e-07, 6.1867e-07,\n",
              "            1.9642e-07, 2.4536e-06, 7.4995e-07, 8.6155e-07, 5.4114e-09, 3.4940e-05,\n",
              "            1.1758e-10, 1.1173e-10, 4.3528e-10, 5.7353e-13, 5.4245e-10, 5.1669e-07,\n",
              "            3.7378e-09, 1.3266e-06, 5.0680e-10, 3.2484e-12, 9.3181e-08, 3.3493e-04,\n",
              "            4.4336e-10, 6.1385e-10, 3.8011e-11, 8.1712e-09, 1.3309e-06, 4.2855e-08,\n",
              "            7.5056e-10, 3.2844e-10, 1.9126e-10, 8.1122e-09, 9.3865e-12, 1.0376e-09,\n",
              "            3.0539e-10, 3.3390e-05, 9.1770e-08, 6.9320e-06, 1.7867e-07, 1.3434e-05,\n",
              "            1.9522e-09, 1.5855e-06, 1.0299e-09, 2.3800e-06, 2.4416e-04, 3.2834e-08,\n",
              "            1.8295e-06, 4.2985e-09, 3.1876e-08, 1.5773e-09, 6.8505e-05, 3.1715e-07,\n",
              "            1.6754e-08, 1.8301e-09, 8.9405e-08, 4.6261e-10, 2.2130e-05, 4.7266e-05,\n",
              "            1.6206e-08, 1.1123e-03, 4.8956e-03, 6.0807e-06, 1.0776e-06, 1.5779e-06,\n",
              "            1.0567e-06, 1.2508e-08, 5.9781e-07, 5.4273e-04],\n",
              "           [1.0000e+00, 1.2937e-05, 2.3677e-05, 5.6655e-07, 2.8152e-05, 6.6959e-06,\n",
              "            5.3308e-06, 1.2006e-04, 1.2946e-05, 4.2006e-06, 3.3186e-05, 2.5173e-06,\n",
              "            5.2835e-09, 5.9312e-06, 5.0463e-09, 3.3154e-09, 9.2776e-07, 4.3737e-07,\n",
              "            3.9427e-08, 1.4702e-06, 4.7996e-11, 5.3613e-09, 2.3804e-08, 2.5086e-06,\n",
              "            7.5243e-11, 5.7315e-10, 6.5152e-11, 3.4224e-08, 3.4850e-06, 2.7782e-11,\n",
              "            5.9758e-11, 1.2988e-08, 2.1525e-11, 9.5504e-10, 4.3375e-13, 3.7756e-10,\n",
              "            4.2299e-08, 1.5204e-06, 2.8593e-10, 3.1248e-08, 3.1075e-07, 1.0578e-07,\n",
              "            4.8334e-09, 1.8225e-07, 2.5807e-08, 9.7184e-08, 9.8732e-08, 1.7799e-07,\n",
              "            3.5595e-07, 1.0382e-08, 1.1590e-07, 2.3672e-09, 7.0763e-07, 4.9935e-08,\n",
              "            1.8740e-07, 8.3083e-09, 5.0570e-09, 1.4904e-07, 1.0815e-04, 9.0862e-06,\n",
              "            1.2391e-09, 3.4619e-05, 1.8271e-05, 1.3404e-06, 3.2980e-06, 3.2864e-07,\n",
              "            1.0092e-07, 7.3097e-10, 2.3534e-07, 2.2890e-07]], device='cuda:0',\n",
              "          grad_fn=<CatBackward>)],\n",
              "  9: [tensor([[9.3244e-01, 8.0438e-02, 1.7978e-02, 1.2825e-03, 4.3520e-02, 2.4212e-03,\n",
              "            1.8792e-02, 1.1131e-02, 3.6004e-03, 1.1801e-02, 7.2559e-03, 1.6994e-01,\n",
              "            2.3011e-03, 2.2866e-03, 1.5450e-03, 4.3313e-04, 6.6715e-03, 6.5911e-02,\n",
              "            4.1955e-03, 3.3933e-02, 2.4877e-02, 1.5966e-03, 1.8695e-03, 3.4885e-01,\n",
              "            1.1903e-03, 6.8600e-04, 1.5033e-03, 1.4729e-03, 1.7423e-03, 1.1343e-03,\n",
              "            8.4370e-04, 2.2544e-03, 6.0807e-04, 6.4059e-04, 6.5322e-04, 1.4383e-04,\n",
              "            2.9058e-01, 1.8315e-03, 1.5853e-02, 2.3603e-03, 1.2780e-03, 1.7674e-04,\n",
              "            2.9480e-04, 2.4561e-02, 2.4741e-03, 1.7691e-02, 4.3905e-02, 1.4085e-04,\n",
              "            6.2409e-04, 4.0183e-04, 1.3235e-04, 1.5573e-03, 6.0027e-03, 2.2047e-04,\n",
              "            4.2496e-04, 1.0476e-04, 2.4690e-04, 1.0505e-03, 2.0984e-04, 1.6865e-03,\n",
              "            2.1677e-05, 3.6117e-05, 1.8185e-02, 3.4202e-04, 2.0219e-03, 1.8683e-04,\n",
              "            5.4200e-04, 1.0018e-04, 8.4957e-05, 1.0948e-02, 1.4891e-02, 2.7753e-03,\n",
              "            3.7107e-04, 1.0015e-04, 1.2850e-05, 4.0294e-05, 4.4675e-04, 8.3974e-05,\n",
              "            4.9371e-04, 1.0154e-06, 1.0783e-04, 6.9569e-09, 7.7065e-07, 1.8454e-05,\n",
              "            2.8709e-06, 3.3601e-03, 2.8257e-07, 1.9695e-05, 3.6996e-08, 5.2568e-06],\n",
              "           [9.3032e-01, 6.8645e-03, 7.8931e-03, 2.8308e-03, 1.8050e-02, 6.7103e-04,\n",
              "            5.8748e-02, 4.9866e-02, 6.0494e-03, 2.3433e-03, 6.5195e-03, 1.3176e-02,\n",
              "            4.6959e-05, 4.3449e-03, 3.1924e-03, 7.5755e-04, 3.1492e-03, 2.0223e-01,\n",
              "            2.4959e-03, 4.4070e-03, 1.6903e-03, 4.6819e-04, 1.6984e-03, 1.7355e-01,\n",
              "            3.4665e-04, 3.0862e-04, 1.5996e-03, 1.0223e-03, 3.7029e-03, 6.9560e-05,\n",
              "            5.1459e-04, 2.1655e-03, 2.1886e-04, 4.5491e-05, 8.7513e-04, 9.4813e-04,\n",
              "            2.9917e-03, 2.6170e-03, 1.1033e-03, 7.8529e-04, 7.9580e-04, 1.3701e-04,\n",
              "            9.4507e-05, 1.1319e-03, 1.0907e-04, 7.4774e-03, 6.5261e-03, 2.0542e-03,\n",
              "            1.5665e-04, 7.0180e-04, 1.4124e-05, 6.8016e-05, 1.1795e-03, 1.4613e-05,\n",
              "            1.0876e-03, 7.8803e-04, 3.0772e-04, 2.3339e-04, 1.1220e-03, 3.6564e-03,\n",
              "            4.7869e-05, 2.9496e-04, 6.4041e-03, 2.7609e-04, 1.5659e-04, 5.7716e-05,\n",
              "            2.0884e-04, 3.3371e-04, 2.0394e-04, 1.3297e-04, 3.7272e-04, 7.6629e-05,\n",
              "            1.4389e-04, 1.0577e-05, 2.2718e-06, 2.7142e-05, 5.2922e-05, 1.5303e-04,\n",
              "            1.1584e-04, 1.1534e-05, 6.1533e-04, 1.3008e-08, 1.9410e-08, 6.1056e-07,\n",
              "            1.4512e-08, 6.9283e-05, 4.9542e-07, 1.3963e-04, 3.6785e-07, 3.2630e-04],\n",
              "           [9.6410e-01, 1.5849e-02, 8.3041e-03, 2.0580e-04, 8.3709e-03, 5.9966e-04,\n",
              "            2.9065e-03, 1.2492e-02, 2.2495e-03, 6.5672e-04, 5.9422e-03, 5.1555e-03,\n",
              "            1.4520e-05, 2.2602e-03, 5.5664e-05, 8.9451e-05, 3.1717e-03, 7.6289e-02,\n",
              "            5.9824e-04, 1.4355e-02, 1.4136e-04, 2.1879e-04, 1.7259e-03, 8.0472e-03,\n",
              "            5.6628e-05, 5.5896e-05, 8.2786e-04, 1.1054e-03, 6.5280e-05, 4.3453e-06,\n",
              "            1.2158e-04, 1.3416e-03, 4.2005e-04, 1.6514e-05, 6.6651e-04, 3.4024e-04,\n",
              "            1.7973e-04, 1.0136e-04, 1.0361e-04, 8.6531e-04, 1.7146e-04, 4.9734e-06,\n",
              "            1.9533e-05, 1.2052e-04, 4.4662e-05, 2.2265e-03, 6.8223e-04, 1.1549e-03,\n",
              "            5.3255e-06, 2.0944e-03, 3.8053e-06, 6.7900e-07, 1.5323e-04, 2.8974e-05,\n",
              "            1.2378e-05, 2.3303e-05, 2.1708e-04, 5.2434e-05, 1.4720e-04, 7.6373e-03,\n",
              "            2.3822e-06, 2.0339e-04, 7.3582e-06, 3.6168e-05, 2.3316e-05, 7.2700e-06,\n",
              "            4.0441e-05, 1.0171e-04, 6.9732e-04, 1.1021e-04, 8.2465e-05, 1.2709e-04,\n",
              "            3.4797e-05, 8.2473e-05, 6.9906e-06, 1.2266e-06, 1.7265e-06, 6.8976e-06,\n",
              "            1.8808e-07, 1.3948e-08, 9.6990e-07, 1.2239e-08, 7.7302e-11, 3.6880e-06,\n",
              "            1.1324e-09, 6.2820e-09, 1.3344e-08, 8.1074e-09, 2.3544e-09, 1.7203e-03],\n",
              "           [9.8423e-01, 1.9530e-02, 1.3152e-02, 1.2624e-03, 1.5393e-02, 4.1074e-04,\n",
              "            2.3607e-03, 1.1465e-02, 1.7338e-03, 7.1125e-04, 7.0556e-03, 4.0425e-03,\n",
              "            2.1563e-05, 5.4140e-03, 9.5516e-05, 3.4767e-04, 1.4649e-03, 1.9927e-02,\n",
              "            1.2931e-03, 5.7071e-02, 2.3024e-04, 1.6530e-04, 1.0594e-03, 4.7153e-02,\n",
              "            4.8321e-04, 1.5277e-04, 2.3460e-03, 1.9825e-04, 1.6919e-04, 2.4027e-05,\n",
              "            1.6913e-04, 2.0003e-03, 3.4573e-04, 2.7417e-05, 3.5226e-04, 1.4561e-04,\n",
              "            9.9872e-03, 4.4125e-04, 4.3167e-04, 3.8642e-04, 4.3470e-04, 2.6438e-05,\n",
              "            1.1190e-04, 1.2822e-03, 3.2346e-05, 9.0108e-04, 6.0608e-04, 1.3279e-04,\n",
              "            4.5029e-05, 6.0684e-04, 8.0180e-06, 2.7864e-06, 2.7088e-04, 1.6559e-04,\n",
              "            1.1650e-04, 9.6356e-06, 1.4058e-04, 1.0330e-04, 2.0023e-04, 3.3673e-03,\n",
              "            2.4178e-06, 1.7928e-04, 9.9446e-05, 4.7380e-04, 1.0047e-03, 1.9098e-05,\n",
              "            1.0675e-04, 1.7713e-05, 8.4957e-05, 1.5299e-04, 3.7166e-04, 6.5652e-04,\n",
              "            2.8207e-03, 1.8610e-04, 8.9772e-07, 1.6744e-05, 8.1253e-06, 7.6791e-06,\n",
              "            1.4735e-05, 1.2607e-07, 9.8291e-09, 2.1045e-08, 1.1378e-09, 1.8577e-04,\n",
              "            8.3176e-06, 1.1085e-04, 4.1068e-09, 1.5166e-07, 1.5045e-09, 4.9642e-05],\n",
              "           [9.6699e-01, 5.3879e-03, 2.0219e-02, 1.5281e-03, 3.3274e-02, 8.8114e-04,\n",
              "            7.8306e-03, 1.7274e-02, 3.0681e-03, 1.6059e-03, 2.1109e-03, 2.7159e-03,\n",
              "            3.6074e-05, 1.3162e-02, 5.9139e-04, 3.0474e-04, 3.1365e-03, 1.8260e-01,\n",
              "            1.9695e-03, 2.4823e-02, 6.1541e-04, 4.0010e-04, 5.9885e-04, 1.4600e-02,\n",
              "            3.2946e-04, 3.4928e-04, 3.0588e-03, 7.7209e-04, 2.1707e-04, 2.3282e-05,\n",
              "            2.2498e-04, 1.1159e-03, 5.4441e-04, 5.9624e-05, 4.4081e-04, 1.5892e-03,\n",
              "            8.2352e-04, 5.9437e-04, 1.8300e-04, 2.6643e-04, 3.7011e-04, 3.8374e-05,\n",
              "            1.7053e-05, 8.3276e-04, 2.1888e-04, 9.5403e-04, 3.5491e-04, 1.3456e-03,\n",
              "            2.7192e-05, 2.0051e-03, 5.9136e-06, 4.1776e-06, 3.3822e-04, 6.2479e-05,\n",
              "            3.0947e-05, 7.1259e-04, 2.1575e-04, 5.6121e-05, 3.8857e-04, 3.7013e-03,\n",
              "            4.1335e-06, 2.9276e-04, 4.6872e-05, 1.5099e-04, 1.9869e-04, 4.9768e-05,\n",
              "            1.0039e-04, 5.2907e-05, 8.4045e-04, 3.4089e-05, 2.1133e-04, 1.5783e-04,\n",
              "            1.8705e-03, 6.1776e-04, 1.8951e-06, 3.3222e-06, 6.0935e-06, 1.3011e-05,\n",
              "            1.1266e-05, 8.0061e-08, 1.1408e-06, 1.1136e-06, 1.0034e-09, 2.4786e-06,\n",
              "            3.0881e-08, 5.9695e-06, 6.8997e-10, 1.3387e-06, 2.3720e-08, 8.3725e-06],\n",
              "           [9.8598e-01, 3.6963e-03, 5.6586e-03, 6.2305e-04, 8.5198e-03, 1.4766e-04,\n",
              "            5.2206e-03, 1.4932e-02, 1.5462e-03, 7.0245e-04, 1.3289e-03, 4.4176e-03,\n",
              "            7.1583e-06, 1.9251e-03, 5.0921e-05, 9.2474e-05, 1.3261e-03, 8.7419e-02,\n",
              "            4.4766e-04, 6.0020e-03, 8.3478e-05, 7.3486e-05, 2.3948e-04, 2.5541e-02,\n",
              "            3.7875e-05, 3.4430e-05, 6.4716e-04, 1.6136e-04, 4.7222e-05, 3.7139e-06,\n",
              "            4.2425e-05, 5.2191e-04, 8.6869e-05, 3.2921e-06, 7.0012e-05, 1.9657e-04,\n",
              "            3.4602e-04, 1.6294e-04, 3.1998e-04, 1.9628e-04, 1.4407e-04, 4.5677e-06,\n",
              "            9.5733e-06, 2.0415e-04, 1.6876e-05, 4.3998e-04, 8.7973e-04, 1.4869e-04,\n",
              "            3.0086e-06, 6.9990e-04, 2.8807e-06, 9.3176e-07, 1.5284e-04, 9.5297e-06,\n",
              "            6.3378e-06, 4.0115e-05, 9.1526e-06, 9.2230e-06, 3.2742e-04, 3.2499e-03,\n",
              "            1.0487e-06, 5.8278e-05, 7.0871e-05, 4.5794e-05, 5.1379e-05, 1.2944e-05,\n",
              "            1.9968e-06, 2.0584e-05, 4.6729e-05, 8.7316e-05, 2.5812e-04, 3.7704e-05,\n",
              "            9.1997e-05, 4.1599e-06, 4.4364e-07, 1.7032e-06, 4.4097e-07, 4.5084e-06,\n",
              "            6.4815e-07, 7.3309e-09, 3.1487e-08, 1.9152e-09, 2.8069e-12, 8.7355e-08,\n",
              "            7.3058e-10, 6.3019e-06, 1.1123e-09, 3.8013e-07, 2.2221e-10, 2.9787e-05],\n",
              "           [9.4669e-01, 1.5969e-02, 1.3717e-02, 9.3854e-04, 2.9763e-02, 1.1259e-03,\n",
              "            7.8245e-03, 1.8702e-02, 2.9702e-03, 2.3816e-03, 1.5943e-02, 2.8683e-03,\n",
              "            5.4046e-05, 1.8809e-02, 2.0942e-04, 2.4768e-04, 1.0313e-02, 1.6350e-01,\n",
              "            2.2486e-03, 1.8140e-02, 3.6275e-04, 1.6921e-03, 1.6247e-03, 1.8667e-02,\n",
              "            4.4128e-04, 4.2982e-04, 1.5103e-03, 1.7267e-03, 2.9398e-04, 1.7368e-05,\n",
              "            3.8838e-04, 1.7687e-03, 1.3589e-03, 6.6166e-05, 1.4134e-03, 3.4823e-03,\n",
              "            6.6051e-04, 2.1436e-04, 2.1989e-04, 2.3734e-03, 4.1401e-04, 1.8782e-05,\n",
              "            1.8460e-04, 6.2177e-04, 1.8380e-04, 3.4200e-03, 3.2379e-04, 4.5642e-03,\n",
              "            4.4852e-05, 3.5136e-03, 9.7835e-06, 2.5080e-06, 1.2481e-04, 7.5477e-05,\n",
              "            1.3312e-04, 1.1040e-04, 4.9188e-04, 1.9554e-03, 2.4881e-04, 7.8624e-03,\n",
              "            1.0139e-05, 9.6893e-04, 1.9062e-05, 1.2787e-04, 1.5320e-04, 4.0729e-05,\n",
              "            4.0834e-04, 1.9660e-04, 9.7734e-04, 3.1829e-04, 8.8333e-05, 3.5786e-04,\n",
              "            7.8255e-05, 2.4137e-03, 2.3758e-06, 8.1525e-06, 3.4081e-06, 1.0403e-04,\n",
              "            1.0914e-05, 2.3831e-07, 2.5977e-07, 1.7075e-08, 1.2008e-09, 6.8195e-05,\n",
              "            1.7521e-05, 4.0347e-08, 1.8639e-08, 5.0557e-08, 6.5490e-09, 4.8979e-03],\n",
              "           [9.8566e-01, 5.2592e-03, 1.1663e-02, 4.2809e-04, 8.1834e-03, 2.1638e-04,\n",
              "            3.8347e-03, 6.6723e-03, 1.9150e-03, 1.9844e-03, 3.9992e-03, 1.4844e-02,\n",
              "            8.2308e-06, 1.5718e-03, 5.6638e-05, 7.4718e-05, 6.3743e-04, 3.2922e-02,\n",
              "            7.0767e-04, 3.3718e-02, 2.5485e-04, 7.2841e-05, 6.5401e-04, 2.4803e-02,\n",
              "            6.6798e-05, 9.4472e-05, 7.6679e-04, 2.0707e-04, 8.5915e-05, 6.6945e-06,\n",
              "            1.3393e-04, 1.1385e-03, 1.1214e-04, 1.6279e-05, 1.2970e-04, 8.3153e-05,\n",
              "            2.0590e-03, 2.1339e-04, 4.2193e-04, 1.3439e-04, 2.4448e-04, 4.6033e-06,\n",
              "            1.2043e-05, 8.1352e-04, 2.9067e-05, 4.3606e-04, 3.3115e-03, 9.8422e-05,\n",
              "            6.6416e-06, 3.2543e-04, 1.8336e-06, 6.1130e-07, 5.6328e-04, 1.0534e-04,\n",
              "            6.3215e-06, 6.8739e-06, 5.5629e-05, 1.2270e-05, 6.0565e-05, 3.0538e-03,\n",
              "            6.9864e-07, 1.6010e-05, 6.2150e-05, 1.6775e-04, 2.1542e-04, 7.2062e-06,\n",
              "            1.5974e-05, 7.7388e-06, 1.1528e-04, 1.5186e-04, 1.4417e-04, 1.0833e-03,\n",
              "            7.2898e-04, 3.5720e-05, 3.1026e-07, 7.3415e-07, 5.9272e-07, 2.4826e-06,\n",
              "            2.7875e-06, 3.0702e-08, 2.4409e-07, 2.0546e-08, 5.0713e-12, 4.0821e-07,\n",
              "            1.3123e-07, 3.1717e-05, 3.6242e-10, 2.8738e-08, 1.7544e-09, 1.7337e-05],\n",
              "           [9.0465e-01, 5.2198e-02, 1.9440e-02, 1.6560e-03, 2.9360e-02, 2.2583e-03,\n",
              "            1.7080e-02, 6.0776e-03, 6.9196e-03, 6.3609e-03, 1.4683e-02, 7.5297e-02,\n",
              "            3.8913e-04, 2.3419e-03, 4.0856e-04, 1.1596e-03, 3.9206e-03, 2.3891e-02,\n",
              "            6.6942e-03, 2.7823e-02, 1.0498e-03, 4.7654e-04, 7.1675e-03, 9.3247e-02,\n",
              "            3.4518e-04, 5.9186e-04, 1.5644e-03, 1.8036e-03, 4.3881e-04, 4.8648e-04,\n",
              "            5.1345e-04, 1.0881e-03, 5.9874e-04, 2.2604e-04, 9.1103e-04, 3.8574e-04,\n",
              "            8.1492e-03, 1.5983e-03, 8.7726e-03, 2.5081e-03, 9.7682e-04, 3.4232e-04,\n",
              "            3.3894e-04, 1.1799e-02, 1.6564e-04, 8.2879e-04, 1.7003e-02, 9.3757e-04,\n",
              "            3.2239e-04, 3.8824e-04, 4.7283e-05, 6.1959e-05, 1.2831e-03, 1.1273e-03,\n",
              "            7.1482e-05, 1.1784e-04, 6.2650e-04, 1.4614e-04, 8.2562e-04, 2.0783e-03,\n",
              "            4.7264e-05, 6.2839e-04, 1.6831e-03, 1.6432e-04, 6.2594e-04, 6.3637e-05,\n",
              "            3.7202e-05, 3.8471e-05, 6.6085e-04, 1.3628e-02, 1.2272e-03, 3.1521e-04,\n",
              "            7.1920e-03, 2.6911e-04, 1.1955e-05, 1.0721e-04, 1.2813e-05, 2.4951e-05,\n",
              "            1.5260e-05, 4.1339e-06, 1.9896e-04, 1.3062e-06, 8.8286e-10, 6.3489e-07,\n",
              "            6.5136e-08, 4.7242e-04, 2.3174e-08, 1.3460e-04, 7.7047e-07, 7.1415e-06],\n",
              "           [9.7157e-01, 1.4559e-02, 1.3301e-02, 1.6095e-03, 2.6458e-02, 7.0683e-04,\n",
              "            1.4899e-02, 3.1804e-02, 2.9666e-03, 1.2287e-03, 1.6909e-02, 8.0889e-03,\n",
              "            7.5353e-05, 8.6553e-03, 4.2494e-04, 3.0119e-04, 5.1992e-03, 1.0943e-01,\n",
              "            6.7168e-03, 1.2426e-02, 1.2368e-03, 1.3626e-03, 7.6887e-04, 1.2717e-01,\n",
              "            4.2596e-04, 3.5373e-04, 3.4445e-03, 7.4356e-04, 5.5620e-04, 6.6020e-05,\n",
              "            1.3829e-04, 2.2389e-03, 3.5262e-04, 6.6041e-05, 3.8085e-03, 1.8228e-03,\n",
              "            6.8779e-03, 8.6109e-04, 7.6106e-04, 1.6828e-03, 8.1977e-04, 1.2998e-04,\n",
              "            2.6488e-04, 2.5762e-03, 1.3669e-04, 2.6402e-03, 2.1932e-03, 1.4727e-03,\n",
              "            1.5087e-04, 8.9510e-04, 1.0426e-05, 2.4319e-05, 2.5650e-04, 2.6112e-05,\n",
              "            2.3736e-04, 1.1665e-04, 8.4462e-04, 1.5341e-03, 7.9611e-04, 3.3479e-03,\n",
              "            1.4132e-05, 2.8185e-04, 6.6610e-04, 1.9117e-04, 2.7230e-04, 1.5030e-04,\n",
              "            8.0376e-04, 3.7865e-05, 2.5404e-04, 2.7322e-04, 6.7235e-04, 3.7713e-05,\n",
              "            1.4713e-03, 2.8991e-04, 2.5387e-06, 2.9492e-05, 7.6138e-05, 7.7035e-05,\n",
              "            1.2879e-05, 1.0991e-06, 7.1672e-08, 1.3618e-07, 8.3295e-09, 2.4436e-05,\n",
              "            1.9391e-06, 8.1152e-05, 3.8273e-08, 3.8523e-05, 3.9162e-08, 8.1332e-05]],\n",
              "          device='cuda:0', grad_fn=<SigmoidBackward>),\n",
              "   tensor([[9.9588e-01, 2.3390e-03, 2.2199e-03, 3.7238e-05, 6.3291e-03, 9.8143e-04,\n",
              "            1.8453e-03, 5.1647e-03, 5.8960e-04, 2.4653e-04, 2.3658e-03, 1.0801e-02,\n",
              "            1.2801e-05, 5.6695e-03, 2.2348e-05, 1.1380e-06, 3.2061e-04, 1.6561e-04,\n",
              "            7.2345e-05, 3.7950e-03, 1.9761e-04, 1.0559e-06, 1.0919e-06, 3.4084e-03,\n",
              "            9.2692e-07, 2.5322e-06, 2.3525e-07, 8.0215e-06, 2.6101e-05, 1.8874e-05,\n",
              "            2.2272e-07, 1.7287e-06, 9.1725e-08, 8.9510e-08, 5.5087e-08, 1.9176e-09,\n",
              "            2.2664e-03, 6.3557e-07, 1.6434e-05, 5.1960e-07, 1.5684e-05, 1.3739e-07,\n",
              "            7.7095e-06, 1.2741e-04, 7.7055e-05, 4.2096e-04, 2.0622e-02, 2.2073e-08,\n",
              "            7.1547e-07, 3.2050e-06, 1.9807e-04, 1.1096e-04, 1.1728e-03, 9.6705e-05,\n",
              "            2.1716e-04, 1.1105e-06, 8.6633e-07, 4.3099e-08, 8.0480e-06, 1.4380e-02,\n",
              "            6.0298e-09, 2.7838e-06, 1.0482e-02, 1.2181e-04, 4.4168e-04, 5.0553e-05,\n",
              "            1.3737e-07, 1.0775e-06, 5.7808e-07, 2.8296e-02, 2.0488e-03, 2.0671e-04,\n",
              "            9.5544e-04, 8.2062e-06, 4.7637e-07, 1.6726e-05, 2.4198e-03, 4.9513e-07,\n",
              "            1.7526e-05, 4.1272e-07],\n",
              "           [1.0000e+00, 1.5790e-06, 1.0343e-06, 3.3592e-08, 1.1915e-04, 3.1194e-07,\n",
              "            6.1787e-05, 4.9264e-05, 6.8516e-08, 4.2586e-08, 1.8073e-07, 7.3177e-05,\n",
              "            2.3955e-09, 6.3154e-06, 7.2798e-07, 2.0381e-09, 2.8211e-07, 7.3340e-06,\n",
              "            4.0362e-06, 1.3023e-06, 2.1524e-07, 2.4518e-10, 2.6250e-07, 9.5452e-06,\n",
              "            3.4235e-09, 1.2552e-08, 1.3603e-10, 4.6024e-07, 9.9055e-05, 2.4018e-09,\n",
              "            1.1834e-10, 2.5395e-06, 5.3649e-10, 1.2280e-05, 7.8908e-09, 1.8357e-10,\n",
              "            2.6017e-08, 5.1994e-08, 3.2749e-09, 4.4411e-04, 2.9745e-05, 7.2476e-07,\n",
              "            6.5132e-10, 4.1345e-08, 1.4918e-08, 4.7502e-03, 2.9501e-05, 7.2420e-09,\n",
              "            2.0497e-06, 5.4684e-07, 1.8447e-06, 3.8423e-08, 8.2077e-05, 4.7367e-08,\n",
              "            1.2912e-07, 4.9301e-07, 4.9047e-08, 3.3877e-09, 8.1491e-04, 8.7336e-04,\n",
              "            2.4615e-05, 3.6916e-05, 2.2374e-02, 5.2254e-06, 3.2485e-05, 1.2703e-07,\n",
              "            2.5641e-07, 2.6493e-06, 3.0835e-05, 2.0359e-07, 1.0997e-05, 4.0785e-05,\n",
              "            3.0943e-05, 6.0856e-08, 3.0227e-05, 3.7559e-05, 1.6184e-06, 2.2626e-07,\n",
              "            1.7525e-06, 3.6540e-06],\n",
              "           [1.0000e+00, 4.2556e-07, 4.6050e-07, 5.1574e-09, 4.6189e-05, 1.7922e-07,\n",
              "            2.4283e-06, 1.3648e-06, 1.3391e-07, 3.1818e-07, 1.5268e-07, 7.1951e-07,\n",
              "            1.7179e-08, 1.2489e-05, 1.8463e-09, 7.3837e-12, 7.9665e-09, 1.0529e-05,\n",
              "            1.3605e-10, 2.6523e-05, 3.5432e-11, 1.1684e-13, 1.4428e-07, 5.5376e-07,\n",
              "            3.4624e-12, 3.3754e-10, 1.5038e-11, 3.8027e-07, 4.3051e-08, 1.4756e-12,\n",
              "            4.4288e-09, 6.2904e-10, 1.5751e-10, 1.2598e-09, 5.5469e-13, 1.0022e-09,\n",
              "            1.8858e-10, 2.0268e-06, 4.0189e-09, 1.9199e-07, 7.0115e-08, 4.8351e-10,\n",
              "            6.5989e-10, 8.2777e-10, 8.1299e-11, 1.2793e-04, 1.3538e-08, 4.8475e-11,\n",
              "            6.9962e-08, 1.4866e-08, 1.1261e-08, 5.4147e-12, 1.3615e-07, 1.0140e-09,\n",
              "            3.8502e-11, 1.9754e-11, 2.5644e-09, 1.1931e-10, 1.4152e-06, 1.4706e-05,\n",
              "            5.8410e-10, 2.6341e-04, 4.1391e-06, 6.0933e-06, 8.9961e-07, 5.2628e-07,\n",
              "            1.4639e-08, 4.6956e-08, 7.2416e-06, 8.3190e-07, 2.1020e-04, 1.1892e-04,\n",
              "            1.0342e-05, 9.9328e-06, 1.8637e-05, 3.9227e-06, 2.6172e-08, 5.3768e-09,\n",
              "            9.7627e-09, 2.3188e-09],\n",
              "           [1.0000e+00, 3.3746e-07, 4.2053e-06, 1.7141e-08, 1.4401e-04, 1.1512e-06,\n",
              "            8.1250e-07, 2.7447e-06, 7.0187e-07, 8.7920e-06, 2.9803e-08, 9.6664e-06,\n",
              "            1.2860e-09, 1.0632e-06, 9.9578e-09, 1.7387e-11, 8.1297e-09, 5.8390e-08,\n",
              "            5.5432e-10, 3.6173e-06, 7.9785e-10, 1.1908e-10, 1.1160e-06, 4.3782e-06,\n",
              "            1.7298e-10, 3.7847e-09, 2.5745e-11, 2.4709e-08, 3.3741e-06, 1.6492e-10,\n",
              "            2.9150e-07, 3.9220e-08, 6.9260e-10, 2.8664e-10, 2.5997e-11, 1.5436e-11,\n",
              "            3.7267e-06, 1.7174e-06, 4.1739e-09, 9.2223e-07, 3.0226e-08, 7.4661e-10,\n",
              "            6.3543e-10, 3.3990e-07, 3.2651e-09, 1.7232e-07, 2.0447e-07, 1.2310e-10,\n",
              "            1.5328e-07, 6.3746e-10, 1.0002e-05, 7.6673e-11, 3.5194e-07, 1.8699e-07,\n",
              "            5.2315e-10, 1.2339e-10, 2.8807e-06, 7.0202e-10, 1.3076e-05, 1.4312e-06,\n",
              "            2.1189e-10, 2.2365e-05, 2.2081e-05, 2.5274e-05, 1.7043e-03, 2.8199e-08,\n",
              "            6.9348e-10, 1.2698e-08, 2.1263e-06, 2.7413e-06, 1.3112e-04, 1.2110e-03,\n",
              "            9.6432e-04, 1.2563e-08, 8.0824e-07, 2.2054e-05, 8.8213e-08, 9.2619e-08,\n",
              "            5.7640e-07, 6.3655e-09],\n",
              "           [1.0000e+00, 1.1420e-06, 2.2119e-05, 1.0107e-07, 6.3365e-05, 4.2046e-06,\n",
              "            7.4724e-05, 1.0581e-04, 2.7766e-06, 6.4663e-07, 9.6705e-07, 1.6672e-08,\n",
              "            1.0297e-08, 1.6618e-06, 2.2108e-08, 2.4181e-10, 1.6769e-08, 1.1526e-05,\n",
              "            3.1006e-08, 5.6049e-05, 2.1548e-08, 6.5086e-11, 7.2454e-08, 1.6885e-06,\n",
              "            5.7630e-10, 3.6295e-09, 1.1662e-09, 4.6836e-07, 2.8146e-05, 1.5371e-11,\n",
              "            3.6148e-08, 3.9928e-07, 2.9793e-09, 2.9493e-08, 5.6337e-07, 4.7364e-08,\n",
              "            9.6681e-07, 4.5739e-07, 4.6346e-09, 1.1216e-06, 1.9842e-06, 4.4128e-07,\n",
              "            3.1141e-08, 2.3461e-06, 2.7500e-08, 8.9916e-06, 9.3410e-08, 1.5924e-08,\n",
              "            2.6245e-06, 1.6182e-06, 2.5298e-08, 3.0047e-10, 6.0900e-06, 5.2467e-07,\n",
              "            7.8472e-08, 1.7994e-05, 4.4129e-10, 3.1054e-09, 2.9578e-04, 4.0481e-06,\n",
              "            6.1538e-08, 8.0008e-05, 2.4193e-05, 1.2507e-05, 1.7919e-05, 4.5072e-05,\n",
              "            8.6750e-07, 4.4945e-08, 1.6894e-05, 6.5167e-07, 2.6490e-05, 2.5445e-05,\n",
              "            7.7331e-03, 2.4881e-04, 5.1734e-06, 1.4517e-06, 1.5910e-06, 1.6005e-07,\n",
              "            3.1835e-07, 1.5074e-08],\n",
              "           [1.0000e+00, 2.6018e-06, 1.4774e-06, 2.0996e-08, 9.7799e-07, 2.3837e-07,\n",
              "            6.7930e-07, 8.3132e-06, 8.9151e-07, 4.4883e-07, 9.1584e-09, 4.5765e-07,\n",
              "            7.7409e-08, 4.1808e-06, 4.2837e-08, 2.0405e-10, 6.5086e-08, 8.5110e-05,\n",
              "            1.0626e-08, 8.0593e-06, 1.8694e-10, 1.6572e-13, 3.2545e-10, 6.2562e-06,\n",
              "            5.6829e-11, 4.3702e-10, 6.3919e-10, 3.8822e-08, 8.2933e-09, 1.2296e-10,\n",
              "            1.1702e-08, 1.6157e-08, 2.3383e-10, 8.1281e-11, 5.2455e-13, 6.9098e-10,\n",
              "            1.8402e-09, 5.6387e-07, 2.8242e-05, 3.0506e-08, 1.6458e-06, 7.7414e-07,\n",
              "            1.6144e-09, 1.9215e-07, 6.3592e-08, 5.1262e-06, 1.9849e-06, 5.6545e-09,\n",
              "            4.6426e-08, 2.0279e-06, 1.0733e-07, 6.4934e-10, 7.6699e-06, 1.5700e-07,\n",
              "            7.3539e-10, 3.4185e-08, 1.1789e-10, 8.1187e-11, 7.5938e-04, 1.0696e-04,\n",
              "            6.0916e-10, 3.1725e-06, 8.5104e-05, 1.3628e-06, 3.0997e-05, 1.6310e-06,\n",
              "            3.2725e-10, 2.3277e-09, 2.3063e-07, 1.8812e-06, 9.1048e-04, 6.6911e-06,\n",
              "            4.1260e-05, 2.2835e-07, 1.0177e-08, 3.2675e-06, 8.4826e-09, 9.2159e-08,\n",
              "            4.8613e-09, 1.3939e-09],\n",
              "           [1.0000e+00, 5.9124e-05, 1.2201e-06, 4.6669e-08, 1.7909e-04, 3.0240e-07,\n",
              "            3.3339e-05, 1.5705e-06, 3.7828e-07, 1.2375e-05, 2.5564e-05, 3.6742e-06,\n",
              "            1.4585e-07, 1.8926e-05, 3.6501e-09, 9.0818e-10, 5.4474e-06, 1.8664e-05,\n",
              "            4.8867e-09, 2.4893e-06, 2.2676e-09, 2.0188e-10, 1.4179e-06, 2.7424e-05,\n",
              "            6.0779e-09, 1.0853e-07, 4.4220e-09, 1.1840e-05, 1.7391e-06, 7.7223e-10,\n",
              "            8.5637e-08, 3.5662e-09, 1.0632e-08, 2.9766e-06, 1.9224e-10, 8.8833e-08,\n",
              "            6.6804e-09, 1.8734e-07, 1.4250e-08, 1.7073e-04, 7.5390e-06, 1.2706e-08,\n",
              "            3.7459e-09, 1.0592e-07, 8.1055e-09, 5.2721e-05, 1.3812e-07, 1.5672e-09,\n",
              "            1.6761e-06, 5.5332e-07, 1.4876e-07, 2.2930e-10, 7.7118e-07, 2.3047e-08,\n",
              "            1.1675e-08, 2.8615e-08, 5.6049e-08, 8.1943e-07, 4.9237e-05, 1.5074e-05,\n",
              "            9.5022e-09, 2.6753e-04, 1.1968e-05, 2.7166e-05, 4.1639e-05, 2.5793e-06,\n",
              "            1.3116e-07, 1.3323e-07, 9.8397e-06, 1.7221e-06, 4.5397e-05, 5.9755e-04,\n",
              "            7.3872e-05, 1.3383e-04, 7.9239e-06, 4.1756e-06, 2.1117e-08, 4.6008e-08,\n",
              "            8.2303e-07, 1.1696e-08],\n",
              "           [1.0000e+00, 2.8388e-08, 2.1861e-07, 1.3620e-09, 3.4180e-05, 2.5489e-08,\n",
              "            8.7798e-09, 3.8969e-07, 9.3255e-08, 1.6967e-06, 3.8718e-08, 1.4816e-07,\n",
              "            8.2539e-10, 7.8882e-07, 3.2433e-10, 4.8749e-12, 5.2194e-10, 5.0821e-10,\n",
              "            9.4965e-12, 8.1547e-07, 1.8700e-11, 2.0879e-13, 6.5520e-09, 2.3216e-06,\n",
              "            1.2558e-12, 4.2806e-11, 1.1186e-11, 2.4991e-09, 9.5531e-09, 4.2284e-12,\n",
              "            1.8261e-08, 4.1892e-09, 1.4273e-11, 9.6973e-09, 3.1219e-14, 6.6913e-12,\n",
              "            8.4735e-10, 7.9987e-10, 6.0318e-08, 3.2332e-09, 8.2372e-05, 5.1866e-09,\n",
              "            2.3439e-11, 3.3587e-09, 3.5282e-09, 3.4389e-08, 3.9837e-06, 7.7442e-12,\n",
              "            2.3888e-08, 2.6841e-08, 3.1544e-09, 2.3036e-11, 2.3200e-06, 3.2891e-07,\n",
              "            2.1902e-10, 4.8172e-11, 5.8608e-09, 3.9186e-13, 3.4354e-05, 7.5397e-06,\n",
              "            7.2161e-11, 1.2118e-07, 7.5793e-05, 1.0185e-05, 3.7251e-04, 3.1170e-07,\n",
              "            2.3006e-09, 1.8277e-09, 1.7386e-07, 1.1026e-06, 4.6410e-06, 8.2880e-04,\n",
              "            7.9356e-04, 8.0709e-07, 8.4713e-09, 1.5928e-07, 2.4214e-09, 3.3737e-09,\n",
              "            7.5731e-09, 2.1023e-09],\n",
              "           [9.9996e-01, 2.8709e-06, 1.4179e-04, 4.4837e-07, 9.9528e-05, 1.6856e-05,\n",
              "            3.6115e-06, 6.2199e-05, 1.9178e-05, 2.0411e-06, 8.9425e-07, 7.2160e-05,\n",
              "            8.4731e-09, 1.1158e-06, 2.3761e-07, 2.1212e-09, 1.0621e-07, 1.1290e-07,\n",
              "            3.1852e-07, 5.8168e-05, 8.6807e-08, 4.4254e-09, 5.9383e-06, 1.2614e-04,\n",
              "            2.6027e-09, 1.1898e-07, 6.7629e-09, 9.8572e-07, 1.2356e-05, 4.5312e-08,\n",
              "            2.3920e-08, 7.3084e-08, 1.1626e-08, 1.8726e-06, 6.3578e-09, 3.6031e-07,\n",
              "            4.3588e-07, 3.3693e-04, 1.9769e-05, 1.2855e-04, 7.9590e-05, 3.2010e-05,\n",
              "            7.2860e-07, 7.1314e-06, 9.3757e-06, 9.7731e-06, 5.5818e-03, 2.0180e-06,\n",
              "            1.1682e-05, 9.7893e-06, 2.3887e-06, 8.7477e-08, 9.8487e-05, 1.2847e-05,\n",
              "            9.8425e-07, 5.0124e-07, 2.3308e-06, 1.9017e-08, 1.1507e-04, 5.7715e-04,\n",
              "            4.2202e-07, 8.4777e-04, 9.2448e-02, 6.5968e-05, 1.2528e-04, 6.3759e-06,\n",
              "            4.2197e-06, 1.9836e-07, 2.3886e-06, 1.4890e-03, 2.8430e-04, 6.9013e-05,\n",
              "            8.6944e-04, 2.9493e-05, 9.8954e-07, 9.7847e-05, 7.1304e-07, 2.3879e-07,\n",
              "            9.5480e-07, 2.7202e-07],\n",
              "           [1.0000e+00, 2.5933e-06, 2.4950e-06, 3.9233e-08, 1.2527e-04, 1.1281e-06,\n",
              "            3.1023e-06, 9.2178e-06, 1.6403e-06, 1.3988e-05, 2.2142e-05, 2.5020e-06,\n",
              "            2.3343e-08, 1.1300e-05, 1.7355e-08, 2.5440e-09, 1.4530e-06, 5.4018e-06,\n",
              "            6.2615e-07, 1.9303e-06, 5.7033e-09, 8.9038e-09, 1.3261e-06, 4.1390e-05,\n",
              "            3.1321e-09, 4.3912e-08, 1.3351e-10, 3.6484e-07, 1.7988e-05, 8.2675e-10,\n",
              "            9.3956e-10, 1.3733e-08, 5.0931e-09, 8.0614e-09, 2.1652e-09, 2.0816e-08,\n",
              "            1.1780e-06, 1.3840e-06, 1.4100e-08, 8.1499e-06, 1.1463e-05, 1.4225e-05,\n",
              "            4.6074e-07, 2.7818e-06, 6.8231e-07, 4.3677e-05, 1.9350e-06, 8.8037e-06,\n",
              "            7.3260e-06, 2.5244e-07, 1.8243e-06, 3.3143e-08, 1.8635e-05, 3.2163e-07,\n",
              "            1.4100e-07, 1.1287e-07, 1.5528e-05, 7.3741e-06, 8.5410e-04, 1.0908e-04,\n",
              "            2.9984e-09, 1.7318e-04, 5.7468e-05, 2.0781e-06, 6.5529e-04, 1.4003e-06,\n",
              "            2.7435e-07, 4.3167e-09, 2.0205e-06, 1.2966e-06, 2.9839e-04, 3.0314e-06,\n",
              "            3.0545e-03, 6.8545e-06, 1.3950e-06, 8.3435e-06, 1.4881e-06, 1.9786e-06,\n",
              "            2.6845e-07, 4.7670e-08]], device='cuda:0', grad_fn=<CatBackward>)]},\n",
              " []]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHhsZ71cghfy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3f88b7ce-74cf-4b00-a24a-b7627e59154d"
      },
      "source": [
        "logs_analisys_split"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{1: [tensor([[1.0000e+00, 1.5512e-07, 2.7733e-09, 9.1395e-06, 5.4964e-08, 4.7753e-09,\n",
              "            5.9064e-09, 4.2234e-09, 4.2606e-07, 3.8278e-06],\n",
              "           [1.0000e+00, 4.7220e-09, 1.7920e-10, 7.7666e-08, 1.7943e-09, 5.6214e-12,\n",
              "            6.7881e-10, 2.7197e-12, 4.2738e-08, 3.3349e-08],\n",
              "           [1.0000e+00, 1.9654e-11, 3.7885e-14, 2.2945e-07, 5.6073e-10, 5.4636e-13,\n",
              "            4.6445e-11, 4.8380e-11, 2.7386e-08, 5.7785e-09],\n",
              "           [1.0000e+00, 1.5525e-08, 1.0396e-08, 1.9264e-07, 2.1828e-09, 1.2135e-09,\n",
              "            3.1585e-08, 5.8995e-10, 9.9534e-09, 3.5256e-08],\n",
              "           [1.0000e+00, 1.2908e-08, 3.4542e-07, 6.1864e-07, 1.2921e-08, 3.1958e-09,\n",
              "            9.4153e-08, 3.6375e-09, 3.7195e-08, 9.2690e-09],\n",
              "           [1.0000e+00, 2.9726e-09, 7.0455e-11, 1.8400e-07, 2.3927e-09, 3.2849e-11,\n",
              "            2.6100e-10, 7.3590e-12, 4.3375e-09, 6.4679e-08],\n",
              "           [1.0000e+00, 4.0591e-10, 6.5797e-08, 4.2255e-09, 1.5108e-09, 1.3463e-12,\n",
              "            2.2160e-10, 1.0328e-14, 2.1021e-10, 2.1925e-08],\n",
              "           [1.0000e+00, 1.2241e-08, 8.1332e-12, 8.7271e-08, 1.8324e-09, 4.0020e-12,\n",
              "            2.0444e-09, 1.9574e-11, 2.4395e-08, 6.1851e-08],\n",
              "           [9.9966e-01, 1.5357e-06, 2.1753e-07, 2.3316e-04, 2.5847e-04, 2.5666e-07,\n",
              "            2.7809e-07, 2.5095e-08, 1.7301e-05, 1.5338e-04],\n",
              "           [1.0000e+00, 4.6669e-08, 5.4749e-09, 1.4178e-06, 4.1075e-08, 8.7116e-11,\n",
              "            1.5250e-09, 1.8640e-12, 2.8481e-07, 1.2294e-07]], device='cuda:0',\n",
              "          grad_fn=<SigmoidBackward>),\n",
              "   tensor([[1.0000e+00, 1.5512e-07, 2.7733e-09, 9.1395e-06, 5.4964e-08, 4.7753e-09,\n",
              "            5.9064e-09, 4.2234e-09, 4.2606e-07, 3.8278e-06],\n",
              "           [1.0000e+00, 4.7220e-09, 1.7920e-10, 7.7666e-08, 1.7943e-09, 5.6214e-12,\n",
              "            6.7881e-10, 2.7197e-12, 4.2738e-08, 3.3349e-08],\n",
              "           [1.0000e+00, 1.9654e-11, 3.7885e-14, 2.2945e-07, 5.6073e-10, 5.4636e-13,\n",
              "            4.6445e-11, 4.8380e-11, 2.7386e-08, 5.7785e-09],\n",
              "           [1.0000e+00, 1.5525e-08, 1.0396e-08, 1.9264e-07, 2.1828e-09, 1.2135e-09,\n",
              "            3.1585e-08, 5.8995e-10, 9.9534e-09, 3.5256e-08],\n",
              "           [1.0000e+00, 1.2908e-08, 3.4542e-07, 6.1864e-07, 1.2921e-08, 3.1958e-09,\n",
              "            9.4153e-08, 3.6375e-09, 3.7195e-08, 9.2690e-09],\n",
              "           [1.0000e+00, 2.9726e-09, 7.0455e-11, 1.8400e-07, 2.3927e-09, 3.2849e-11,\n",
              "            2.6100e-10, 7.3590e-12, 4.3375e-09, 6.4679e-08],\n",
              "           [1.0000e+00, 4.0591e-10, 6.5797e-08, 4.2255e-09, 1.5108e-09, 1.3463e-12,\n",
              "            2.2160e-10, 1.0328e-14, 2.1021e-10, 2.1925e-08],\n",
              "           [1.0000e+00, 1.2241e-08, 8.1332e-12, 8.7271e-08, 1.8324e-09, 4.0020e-12,\n",
              "            2.0444e-09, 1.9574e-11, 2.4395e-08, 6.1851e-08],\n",
              "           [9.9966e-01, 1.5357e-06, 2.1753e-07, 2.3316e-04, 2.5847e-04, 2.5666e-07,\n",
              "            2.7809e-07, 2.5095e-08, 1.7301e-05, 1.5338e-04],\n",
              "           [1.0000e+00, 4.6669e-08, 5.4749e-09, 1.4178e-06, 4.1075e-08, 8.7116e-11,\n",
              "            1.5250e-09, 1.8640e-12, 2.8481e-07, 1.2294e-07]], device='cuda:0',\n",
              "          grad_fn=<SigmoidBackward>)],\n",
              "  2: [tensor([[9.9904e-01, 6.1108e-06, 7.6811e-07, 2.6569e-05, 1.1443e-06, 2.8027e-07,\n",
              "            4.8393e-06, 1.3142e-05, 1.1733e-04, 8.9212e-03, 3.6623e-06, 7.4250e-08,\n",
              "            1.1871e-07, 1.9095e-04, 1.2327e-08, 1.9918e-08, 4.5079e-09, 4.7653e-10,\n",
              "            1.1713e-07, 1.6491e-05],\n",
              "           [9.9999e-01, 1.8378e-07, 7.4163e-07, 1.6811e-06, 1.6994e-07, 4.5483e-09,\n",
              "            3.4043e-07, 1.5851e-07, 1.9727e-05, 9.2757e-06, 6.6584e-07, 2.2817e-08,\n",
              "            2.6848e-09, 1.3572e-07, 1.5413e-09, 6.3152e-09, 2.3346e-09, 7.8178e-13,\n",
              "            2.7959e-08, 7.2424e-08],\n",
              "           [9.9898e-01, 4.3246e-06, 1.3550e-06, 1.1471e-04, 8.7652e-05, 1.4895e-07,\n",
              "            5.0754e-05, 1.2141e-05, 8.1777e-05, 7.4493e-04, 1.1550e-06, 9.8130e-08,\n",
              "            2.3800e-05, 5.2410e-05, 9.3319e-07, 1.1695e-06, 1.6644e-08, 2.6441e-09,\n",
              "            2.6572e-07, 8.8477e-07],\n",
              "           [9.9961e-01, 1.0428e-05, 8.3710e-05, 3.3551e-05, 3.0381e-05, 1.2643e-06,\n",
              "            9.1982e-05, 9.8438e-05, 4.0849e-04, 3.7268e-04, 5.6644e-04, 1.6377e-06,\n",
              "            5.8960e-07, 1.1287e-03, 9.4880e-07, 1.4330e-07, 3.2545e-07, 8.1160e-09,\n",
              "            4.1411e-04, 3.4461e-04],\n",
              "           [9.9996e-01, 2.2000e-06, 1.7469e-04, 2.3958e-06, 2.0135e-06, 1.6926e-07,\n",
              "            5.6029e-06, 1.3688e-05, 3.3362e-05, 2.5196e-05, 6.1075e-06, 2.9075e-08,\n",
              "            4.8573e-08, 1.7029e-09, 1.2466e-08, 3.0845e-08, 9.7068e-07, 4.9751e-08,\n",
              "            8.6962e-05, 3.1717e-06],\n",
              "           [9.9990e-01, 2.8315e-06, 8.2047e-06, 2.3720e-05, 8.9772e-06, 7.9908e-07,\n",
              "            3.9742e-06, 1.0073e-05, 1.5856e-05, 7.9337e-05, 3.4752e-06, 1.2206e-07,\n",
              "            1.1070e-07, 8.8884e-06, 3.8883e-07, 9.4539e-07, 4.7949e-07, 6.8461e-08,\n",
              "            2.9232e-07, 3.8337e-05],\n",
              "           [9.9971e-01, 1.1861e-05, 7.3742e-05, 2.3601e-04, 6.9816e-05, 2.4166e-06,\n",
              "            4.2156e-05, 2.7891e-06, 1.2529e-04, 1.3164e-04, 2.6155e-04, 5.5860e-06,\n",
              "            8.3533e-08, 1.0086e-05, 8.8398e-08, 3.6213e-08, 9.8903e-07, 1.4704e-07,\n",
              "            1.2090e-05, 2.8844e-06],\n",
              "           [9.9902e-01, 1.7233e-05, 5.6348e-05, 5.5970e-05, 2.8565e-04, 2.8437e-06,\n",
              "            1.5302e-05, 4.2305e-06, 2.2740e-04, 1.1709e-03, 1.3844e-05, 2.6668e-07,\n",
              "            7.4909e-06, 8.8376e-05, 2.5774e-05, 4.3247e-08, 1.6700e-08, 2.9542e-07,\n",
              "            3.0934e-06, 4.1988e-08],\n",
              "           [9.9983e-01, 8.1740e-06, 1.3645e-04, 2.3626e-05, 1.1034e-04, 4.2919e-07,\n",
              "            2.1350e-05, 2.0771e-06, 3.5675e-05, 1.4272e-04, 8.2387e-05, 5.9825e-06,\n",
              "            1.1562e-07, 6.9221e-06, 3.8257e-08, 5.4804e-07, 5.5636e-07, 1.4444e-10,\n",
              "            1.4953e-05, 1.2633e-06],\n",
              "           [9.9985e-01, 9.5231e-07, 1.1093e-06, 4.7206e-05, 1.4982e-05, 5.3036e-09,\n",
              "            1.4137e-05, 3.0088e-08, 2.5937e-06, 1.4501e-04, 1.0794e-08, 4.3337e-07,\n",
              "            7.9758e-10, 2.4959e-06, 6.6511e-11, 5.9032e-11, 4.0701e-09, 3.4270e-11,\n",
              "            8.0493e-07, 1.0403e-05]], device='cuda:0', grad_fn=<SigmoidBackward>),\n",
              "   tensor([[1.0000e+00, 4.0539e-07, 5.3036e-09, 2.3897e-06, 5.6445e-08, 5.8158e-09,\n",
              "            1.3008e-08, 7.9494e-09, 5.2112e-07, 8.4610e-06],\n",
              "           [1.0000e+00, 1.8461e-10, 2.1985e-12, 2.0374e-09, 7.6756e-11, 3.1285e-14,\n",
              "            1.8355e-11, 2.2137e-14, 1.4756e-09, 3.7414e-09],\n",
              "           [1.0000e+00, 3.1312e-09, 2.0415e-11, 2.1626e-06, 3.8640e-08, 1.1514e-10,\n",
              "            4.6784e-09, 2.8972e-09, 4.2748e-07, 2.7371e-07],\n",
              "           [1.0000e+00, 1.0963e-09, 7.6110e-10, 1.4282e-07, 4.7674e-10, 4.6220e-11,\n",
              "            2.1577e-09, 4.2405e-11, 1.1324e-07, 1.1012e-08],\n",
              "           [1.0000e+00, 5.6656e-10, 1.0182e-08, 2.3817e-08, 1.1296e-09, 6.0204e-11,\n",
              "            5.0308e-09, 1.1462e-10, 1.1088e-08, 4.8738e-09],\n",
              "           [1.0000e+00, 1.5873e-08, 2.0167e-09, 3.2493e-07, 2.1377e-09, 9.5178e-10,\n",
              "            2.7259e-09, 5.7873e-10, 9.1451e-09, 1.4482e-07],\n",
              "           [9.9995e-01, 9.2030e-07, 7.6245e-06, 1.2260e-06, 3.4697e-06, 1.0736e-08,\n",
              "            1.4169e-05, 2.7383e-09, 1.3860e-06, 6.8341e-06],\n",
              "           [1.0000e+00, 2.2978e-08, 1.5485e-10, 2.2725e-07, 7.4805e-10, 1.0605e-09,\n",
              "            2.3003e-09, 6.3426e-10, 5.8909e-07, 5.3563e-06],\n",
              "           [9.9998e-01, 1.5130e-06, 1.5883e-05, 8.6189e-07, 1.3249e-05, 1.8953e-08,\n",
              "            1.0330e-06, 9.7505e-10, 4.9172e-07, 3.2706e-06],\n",
              "           [1.0000e+00, 1.6511e-08, 9.0421e-10, 2.2618e-06, 4.1464e-08, 9.3147e-11,\n",
              "            4.8591e-10, 1.7294e-12, 3.3435e-08, 1.3159e-06]], device='cuda:0',\n",
              "          grad_fn=<SigmoidBackward>)],\n",
              "  3: [tensor([[9.9497e-01, 1.3670e-04, 6.2672e-05, 7.8652e-04, 8.8190e-05, 8.6947e-05,\n",
              "            1.3595e-04, 5.7186e-04, 3.1095e-03, 8.1867e-03, 1.2887e-02, 6.8811e-07,\n",
              "            1.8423e-04, 4.8562e-03, 2.5540e-05, 1.8609e-05, 3.3238e-05, 4.3052e-05,\n",
              "            1.1514e-05, 3.1777e-04, 2.4182e-06, 5.1525e-05, 3.5149e-07, 1.5444e-04,\n",
              "            1.8624e-03, 4.0914e-06, 1.2528e-04, 5.8105e-07, 8.3717e-07, 3.5384e-06],\n",
              "           [9.9926e-01, 1.9702e-05, 2.5127e-05, 9.2505e-05, 1.2716e-05, 2.4741e-06,\n",
              "            9.4557e-05, 2.4500e-05, 8.4409e-04, 6.4998e-04, 2.4969e-04, 2.4986e-06,\n",
              "            2.8274e-05, 9.7097e-05, 9.1761e-06, 2.8689e-04, 5.0013e-06, 1.6412e-07,\n",
              "            4.7498e-06, 1.4030e-04, 8.0608e-06, 2.1785e-05, 3.1336e-07, 1.0161e-06,\n",
              "            4.9465e-05, 1.9331e-07, 2.8468e-07, 1.1440e-07, 6.5992e-07, 6.3921e-07],\n",
              "           [9.9732e-01, 3.8367e-05, 1.5710e-05, 5.2855e-04, 2.7407e-04, 1.4189e-05,\n",
              "            3.4510e-04, 7.1055e-05, 6.2532e-04, 1.4013e-03, 9.6550e-05, 1.9125e-06,\n",
              "            9.0568e-05, 2.5789e-04, 2.8191e-04, 2.2703e-04, 1.1072e-05, 1.2632e-06,\n",
              "            4.7813e-05, 1.2004e-04, 5.0406e-05, 2.6994e-04, 2.1034e-07, 3.4974e-07,\n",
              "            6.2481e-06, 1.1822e-06, 8.0045e-07, 1.5527e-06, 8.4397e-07, 7.8099e-04],\n",
              "           [9.9991e-01, 9.4056e-06, 1.0654e-04, 1.6004e-05, 2.0681e-05, 3.1005e-06,\n",
              "            1.1372e-04, 2.9922e-05, 7.4122e-05, 1.3311e-04, 3.9588e-04, 1.8885e-07,\n",
              "            4.5795e-06, 5.9266e-05, 5.3764e-06, 3.8286e-06, 1.4571e-07, 8.0020e-07,\n",
              "            9.0456e-04, 3.4095e-04, 1.2139e-08, 4.8333e-05, 9.6611e-09, 7.9337e-06,\n",
              "            6.4256e-07, 1.8233e-07, 1.9338e-07, 2.3928e-08, 8.1668e-08, 1.6064e-10],\n",
              "           [9.9692e-01, 1.5815e-04, 2.5399e-03, 3.3636e-04, 6.9519e-05, 1.3867e-04,\n",
              "            1.0205e-03, 5.2695e-04, 9.6117e-04, 2.5466e-03, 7.4275e-04, 7.1466e-06,\n",
              "            6.9022e-05, 2.3228e-04, 2.5895e-05, 9.9411e-05, 1.9898e-04, 3.5482e-04,\n",
              "            4.5961e-04, 5.6532e-03, 4.4535e-05, 1.5114e-05, 4.2548e-06, 7.1443e-05,\n",
              "            6.5261e-05, 7.4741e-07, 2.5288e-05, 7.0361e-05, 5.9697e-07, 1.1101e-06],\n",
              "           [9.9972e-01, 2.3293e-05, 2.6264e-04, 5.0283e-05, 1.7808e-04, 4.4024e-05,\n",
              "            1.2901e-05, 7.1257e-05, 3.9415e-04, 7.6657e-04, 4.5464e-05, 1.5366e-06,\n",
              "            1.7035e-05, 3.8906e-05, 7.0340e-04, 1.0755e-03, 2.8262e-06, 1.3301e-05,\n",
              "            1.3366e-05, 3.8523e-04, 2.3048e-07, 2.6555e-03, 5.6095e-09, 1.3740e-08,\n",
              "            9.4972e-04, 1.4793e-06, 1.1411e-05, 6.2993e-07, 3.4391e-05, 6.9141e-09],\n",
              "           [9.9955e-01, 3.7735e-05, 6.2206e-04, 2.2252e-04, 4.2827e-05, 1.8215e-05,\n",
              "            1.9561e-04, 7.5382e-06, 1.2090e-04, 5.8907e-04, 1.6830e-04, 1.5263e-05,\n",
              "            2.7702e-05, 9.6200e-05, 1.3708e-06, 2.8780e-05, 5.4921e-06, 6.8853e-07,\n",
              "            5.8054e-05, 1.9539e-04, 1.8952e-08, 1.0535e-06, 6.7485e-07, 7.9980e-08,\n",
              "            1.2567e-06, 1.6740e-06, 5.9675e-07, 1.7051e-07, 3.8934e-05, 3.8763e-08],\n",
              "           [9.9865e-01, 2.2290e-04, 2.5009e-04, 3.2739e-04, 1.3660e-03, 7.6049e-05,\n",
              "            6.2460e-04, 6.8481e-05, 9.4228e-04, 4.6150e-03, 8.9465e-03, 3.4566e-06,\n",
              "            5.1222e-04, 1.4141e-04, 1.2064e-04, 1.5942e-04, 1.3034e-05, 9.7301e-04,\n",
              "            8.0239e-04, 2.7224e-06, 6.2506e-05, 3.8117e-05, 8.9434e-08, 1.2114e-06,\n",
              "            3.4772e-06, 2.2164e-05, 5.2218e-05, 1.0493e-04, 1.6241e-07, 1.3735e-06],\n",
              "           [9.9903e-01, 1.5231e-04, 1.6216e-04, 1.1899e-04, 5.9836e-04, 3.4135e-05,\n",
              "            8.2819e-05, 4.9766e-06, 9.4933e-05, 1.0512e-03, 1.1538e-04, 1.3711e-06,\n",
              "            8.0326e-06, 1.4810e-05, 8.9577e-06, 5.3398e-05, 6.6580e-05, 1.7708e-06,\n",
              "            1.8322e-04, 1.7642e-05, 6.8387e-07, 9.8164e-06, 1.3419e-08, 1.8031e-09,\n",
              "            3.8905e-06, 6.0016e-07, 3.9403e-07, 6.3632e-07, 1.1190e-08, 6.4758e-04],\n",
              "           [9.9679e-01, 7.2829e-05, 4.8762e-05, 2.7307e-04, 5.5423e-05, 2.6464e-05,\n",
              "            6.9354e-05, 8.6936e-06, 4.7876e-05, 3.4233e-03, 2.3324e-05, 6.4399e-06,\n",
              "            1.7130e-05, 6.6205e-05, 3.2829e-06, 4.7439e-06, 3.9406e-06, 1.2660e-07,\n",
              "            2.0765e-05, 1.7318e-03, 6.1373e-08, 3.4050e-05, 2.2953e-08, 4.4887e-07,\n",
              "            1.6524e-05, 2.4105e-07, 4.5070e-08, 2.5709e-08, 1.6703e-05, 8.0363e-05]],\n",
              "          device='cuda:0', grad_fn=<SigmoidBackward>),\n",
              "   tensor([[9.9987e-01, 2.4680e-05, 1.8700e-07, 1.2716e-04, 2.4063e-05, 3.0993e-07,\n",
              "            1.0672e-06, 8.0062e-07, 1.0360e-04, 7.8824e-05, 4.4446e-04, 2.9240e-07,\n",
              "            2.8301e-06, 1.7289e-03, 2.7222e-07, 3.2630e-07, 5.7026e-07, 3.3757e-07,\n",
              "            6.0039e-06, 4.7954e-05],\n",
              "           [1.0000e+00, 1.7523e-09, 4.3527e-11, 2.9970e-08, 2.8811e-10, 7.4064e-13,\n",
              "            1.4748e-10, 2.9498e-13, 2.6416e-08, 3.9409e-09, 4.7417e-07, 6.3283e-08,\n",
              "            1.9351e-08, 1.3180e-06, 3.0784e-09, 2.3058e-08, 1.4804e-09, 4.8282e-12,\n",
              "            5.5130e-08, 3.8734e-07],\n",
              "           [1.0000e+00, 4.6700e-10, 5.9283e-12, 3.3245e-06, 1.5430e-08, 4.7375e-11,\n",
              "            2.3706e-09, 6.9842e-10, 2.1725e-07, 3.0642e-08, 1.3325e-07, 1.5980e-08,\n",
              "            2.4591e-06, 5.2045e-06, 1.4639e-06, 2.6079e-07, 4.3705e-09, 1.5232e-10,\n",
              "            1.6661e-07, 3.7063e-08],\n",
              "           [1.0000e+00, 1.2636e-09, 2.1382e-10, 1.2505e-07, 8.5986e-10, 5.0049e-11,\n",
              "            6.4731e-10, 6.6049e-12, 1.6817e-09, 9.6507e-10, 1.3608e-04, 3.0652e-07,\n",
              "            9.7352e-08, 1.0914e-05, 1.6591e-06, 1.2558e-08, 2.0924e-08, 1.0739e-08,\n",
              "            7.5602e-04, 2.9525e-06],\n",
              "           [1.0000e+00, 1.6401e-09, 3.8214e-08, 2.3238e-08, 3.3990e-10, 4.3282e-11,\n",
              "            7.6048e-09, 1.6215e-10, 6.4609e-08, 1.0747e-08, 6.9916e-05, 1.7930e-06,\n",
              "            9.6979e-07, 5.5376e-07, 1.4907e-06, 1.6927e-06, 2.1360e-06, 2.4554e-06,\n",
              "            2.4849e-04, 4.3064e-03],\n",
              "           [1.0000e+00, 4.5650e-10, 8.5759e-11, 1.1311e-07, 4.0049e-09, 1.6196e-11,\n",
              "            2.2601e-10, 2.5111e-12, 2.3588e-09, 4.9547e-09, 3.4757e-08, 1.0179e-08,\n",
              "            5.0768e-09, 2.7156e-08, 7.0065e-06, 4.9165e-09, 1.1584e-09, 2.0520e-09,\n",
              "            4.0622e-09, 4.1126e-07],\n",
              "           [9.9998e-01, 1.0615e-07, 1.0389e-06, 1.5352e-06, 2.7051e-07, 4.7834e-09,\n",
              "            3.9737e-07, 3.8776e-10, 1.1340e-07, 6.7827e-06, 4.7191e-06, 2.4034e-06,\n",
              "            1.2632e-08, 1.0240e-05, 2.3031e-09, 4.6428e-09, 1.1530e-07, 5.4102e-10,\n",
              "            2.8358e-06, 1.3331e-06],\n",
              "           [1.0000e+00, 8.1287e-09, 1.2897e-11, 5.9185e-08, 1.4771e-09, 3.4110e-12,\n",
              "            1.5214e-09, 5.8082e-12, 1.7846e-08, 1.2081e-08, 2.8583e-05, 1.6558e-08,\n",
              "            7.2524e-06, 6.1947e-06, 3.2974e-08, 1.9900e-08, 7.3111e-09, 1.3744e-06,\n",
              "            1.7257e-06, 1.2238e-08],\n",
              "           [9.9987e-01, 9.4912e-08, 5.3217e-09, 5.2093e-06, 2.0340e-05, 5.8806e-09,\n",
              "            2.2925e-08, 1.2471e-09, 8.2344e-07, 1.3634e-04, 1.6633e-07, 8.2097e-09,\n",
              "            5.1092e-10, 9.2388e-07, 4.1078e-09, 1.3430e-08, 6.1960e-08, 2.9340e-11,\n",
              "            2.2553e-06, 5.4524e-07],\n",
              "           [9.9994e-01, 4.2031e-07, 2.5006e-08, 4.2994e-06, 7.2355e-07, 1.2443e-09,\n",
              "            1.1733e-07, 3.6851e-10, 9.0084e-07, 4.4407e-05, 1.6455e-07, 1.8854e-06,\n",
              "            1.6645e-08, 1.6419e-05, 2.2738e-09, 3.7601e-09, 2.1062e-08, 2.7692e-10,\n",
              "            3.3552e-06, 1.0201e-05]], device='cuda:0', grad_fn=<CatBackward>)],\n",
              "  4: [tensor([[9.7691e-01, 1.4708e-04, 4.7844e-04, 2.8038e-03, 4.5718e-04, 1.9647e-03,\n",
              "            1.0082e-03, 1.4207e-03, 2.2999e-03, 2.1587e-02, 2.0280e-02, 1.1083e-05,\n",
              "            6.1546e-03, 2.6712e-03, 3.0335e-05, 3.2448e-04, 6.3143e-04, 3.2993e-05,\n",
              "            3.7900e-05, 5.8161e-04, 3.2715e-05, 2.9348e-04, 1.1942e-05, 9.6408e-04,\n",
              "            2.6015e-03, 1.2103e-05, 1.4322e-04, 1.5728e-05, 5.7640e-06, 2.1039e-04,\n",
              "            8.2887e-08, 1.3949e-03, 1.7249e-09, 2.6718e-09, 3.8979e-06, 1.2251e-08,\n",
              "            2.3329e-07, 5.6653e-07, 1.0003e-02, 2.8273e-08],\n",
              "           [9.9941e-01, 3.2515e-05, 1.0898e-03, 4.0120e-04, 1.5220e-04, 7.8571e-05,\n",
              "            4.6232e-04, 8.2248e-05, 2.4346e-03, 9.3341e-04, 2.9846e-04, 1.1499e-04,\n",
              "            1.6542e-04, 2.5813e-04, 1.3948e-04, 8.5149e-04, 2.0161e-05, 2.0307e-05,\n",
              "            1.8085e-04, 3.8683e-04, 1.8636e-05, 2.4377e-05, 9.8580e-05, 2.7593e-05,\n",
              "            2.2343e-03, 5.0732e-05, 6.9431e-06, 3.4352e-06, 3.2180e-05, 1.9513e-06,\n",
              "            1.4551e-08, 1.8068e-05, 1.2592e-10, 8.9021e-10, 6.1303e-08, 8.3844e-09,\n",
              "            4.3853e-07, 1.0865e-05, 2.4779e-05, 3.2192e-06],\n",
              "           [9.9336e-01, 1.6664e-04, 1.1315e-03, 4.1938e-04, 1.5843e-03, 2.4920e-04,\n",
              "            1.9865e-03, 1.9230e-03, 4.2043e-03, 5.8243e-03, 1.2787e-03, 1.0164e-04,\n",
              "            7.2291e-03, 3.4117e-04, 4.4599e-04, 1.4795e-02, 2.5073e-04, 4.5961e-05,\n",
              "            1.2937e-04, 1.2266e-03, 1.6173e-03, 6.6866e-04, 1.7317e-04, 6.2953e-05,\n",
              "            2.1501e-03, 1.7499e-04, 6.1385e-05, 4.5397e-04, 1.6133e-04, 7.0917e-05,\n",
              "            1.7552e-05, 1.4930e-03, 2.4483e-09, 5.3960e-09, 4.6697e-06, 2.7052e-07,\n",
              "            4.8098e-06, 1.4384e-03, 8.4151e-03, 9.5712e-07],\n",
              "           [9.9894e-01, 6.9062e-05, 1.9329e-03, 5.2304e-04, 1.3921e-04, 1.7751e-04,\n",
              "            2.5363e-03, 4.6113e-04, 7.1088e-04, 2.1927e-03, 2.8335e-03, 6.7619e-05,\n",
              "            3.3661e-04, 1.5671e-03, 6.8507e-05, 1.1497e-04, 2.8356e-06, 1.3089e-04,\n",
              "            7.4816e-03, 2.3854e-03, 2.0346e-05, 1.0145e-03, 2.4882e-05, 3.3182e-03,\n",
              "            2.1772e-04, 4.5713e-06, 2.1817e-05, 1.1833e-05, 9.7620e-06, 1.0292e-06,\n",
              "            6.0327e-09, 5.1043e-07, 1.8336e-10, 1.8131e-09, 4.0356e-06, 5.2559e-08,\n",
              "            1.9099e-06, 8.7277e-07, 1.7378e-03, 1.2166e-06],\n",
              "           [9.9361e-01, 3.3689e-04, 2.8253e-03, 7.6572e-04, 3.0162e-04, 4.2129e-04,\n",
              "            1.7565e-03, 2.4402e-03, 8.3579e-03, 4.8822e-03, 9.3997e-03, 8.0528e-05,\n",
              "            4.2455e-04, 2.4641e-04, 6.4972e-05, 1.2291e-03, 2.5784e-04, 9.2451e-04,\n",
              "            1.1746e-03, 5.3570e-03, 6.6608e-04, 5.1273e-05, 3.6691e-04, 1.3497e-03,\n",
              "            5.8225e-04, 1.0353e-05, 8.0235e-04, 5.5745e-04, 2.3993e-06, 4.0560e-06,\n",
              "            7.1123e-05, 2.4614e-06, 6.3053e-09, 6.4534e-10, 4.8015e-06, 8.0572e-08,\n",
              "            3.5163e-07, 1.7527e-06, 1.0345e-03, 7.1951e-05],\n",
              "           [9.9708e-01, 5.3553e-04, 4.6028e-03, 4.0834e-04, 3.0074e-03, 1.0745e-03,\n",
              "            4.9136e-04, 1.5309e-03, 2.9569e-03, 5.9007e-03, 9.4669e-04, 1.7102e-04,\n",
              "            2.4217e-03, 6.9735e-04, 2.0822e-03, 1.8290e-03, 6.6120e-05, 6.9437e-04,\n",
              "            1.1984e-03, 1.9620e-03, 2.9104e-04, 3.9732e-03, 6.6100e-05, 1.3089e-04,\n",
              "            6.4165e-03, 4.2787e-05, 8.2833e-04, 1.1061e-04, 4.6951e-05, 6.5818e-05,\n",
              "            5.1693e-06, 4.5311e-05, 3.9764e-09, 5.0618e-09, 3.1990e-03, 2.0915e-08,\n",
              "            4.6575e-07, 9.0827e-06, 6.1502e-04, 3.2784e-07],\n",
              "           [9.9863e-01, 9.4833e-05, 2.0799e-03, 2.0133e-03, 4.1358e-04, 1.3242e-04,\n",
              "            2.6939e-03, 5.9353e-05, 1.3154e-03, 1.8865e-03, 3.7327e-04, 3.9800e-04,\n",
              "            7.0560e-04, 2.1839e-03, 1.4001e-05, 1.0479e-04, 2.4410e-05, 2.2700e-05,\n",
              "            7.5576e-04, 9.3660e-04, 6.7073e-06, 1.6954e-04, 4.0545e-05, 2.8844e-05,\n",
              "            3.0445e-04, 1.9457e-05, 1.4366e-05, 2.7028e-05, 8.9899e-05, 3.9096e-05,\n",
              "            9.7293e-10, 1.5828e-05, 1.2253e-10, 1.7786e-09, 7.0902e-06, 1.9011e-06,\n",
              "            2.9243e-05, 1.5332e-08, 1.2452e-04, 5.1426e-07],\n",
              "           [9.9807e-01, 3.3541e-04, 6.5154e-04, 7.8196e-04, 2.1611e-03, 2.4309e-04,\n",
              "            9.6032e-04, 4.4961e-04, 1.7884e-03, 2.8664e-03, 1.7875e-02, 1.0500e-05,\n",
              "            1.0430e-03, 6.7101e-04, 3.7754e-05, 5.4442e-04, 4.1418e-05, 1.0791e-03,\n",
              "            6.9423e-04, 9.1352e-05, 5.1099e-05, 1.0865e-04, 1.3864e-05, 1.7260e-04,\n",
              "            2.3099e-04, 7.9722e-05, 4.6435e-04, 1.5711e-03, 3.4303e-06, 1.0876e-05,\n",
              "            3.2234e-07, 1.4337e-06, 7.4365e-09, 3.7361e-10, 2.2813e-05, 1.6622e-10,\n",
              "            3.2374e-07, 9.1015e-07, 8.7211e-01, 6.1890e-07],\n",
              "           [9.9250e-01, 2.8877e-04, 3.8188e-03, 1.2403e-03, 6.5572e-03, 3.6633e-03,\n",
              "            5.2551e-04, 1.5810e-04, 1.4610e-03, 4.8822e-03, 1.6009e-03, 5.0023e-04,\n",
              "            5.5941e-04, 8.7524e-04, 5.3133e-04, 6.9835e-04, 3.9461e-04, 1.7114e-04,\n",
              "            7.7599e-04, 9.2931e-05, 1.6476e-04, 3.3837e-03, 7.9322e-05, 6.1120e-06,\n",
              "            1.1150e-03, 7.9710e-05, 5.3115e-05, 1.0544e-04, 1.2782e-05, 1.0660e-02,\n",
              "            6.8643e-08, 6.9406e-06, 8.4672e-09, 6.6181e-08, 1.0911e-04, 7.1068e-07,\n",
              "            1.7796e-05, 1.4838e-05, 3.5799e-03, 6.1294e-07],\n",
              "           [9.9849e-01, 2.6325e-05, 9.2676e-04, 1.7828e-03, 2.1110e-04, 3.2023e-04,\n",
              "            3.2471e-04, 9.6808e-06, 7.4102e-04, 9.2448e-04, 2.2285e-05, 9.7824e-05,\n",
              "            1.5740e-04, 8.0065e-04, 3.6693e-06, 1.8092e-04, 2.7119e-05, 4.3486e-06,\n",
              "            1.1122e-04, 7.3391e-04, 8.4874e-07, 4.1992e-05, 1.2266e-05, 7.5185e-06,\n",
              "            1.3150e-04, 2.3698e-05, 1.9802e-06, 2.8446e-06, 5.8505e-06, 1.3382e-04,\n",
              "            1.2479e-10, 1.1718e-05, 8.4009e-12, 4.2854e-10, 1.2017e-06, 2.1740e-09,\n",
              "            7.3533e-07, 2.1082e-08, 4.3835e-07, 8.5802e-07]], device='cuda:0',\n",
              "          grad_fn=<SigmoidBackward>),\n",
              "   tensor([[9.9987e-01, 6.7159e-06, 1.5844e-07, 2.3563e-04, 7.1418e-05, 7.5361e-08,\n",
              "            7.0188e-07, 6.6285e-08, 5.6897e-05, 3.5947e-05, 4.7790e-03, 1.0675e-06,\n",
              "            1.0006e-06, 4.3781e-03, 1.5212e-06, 4.1284e-06, 1.8449e-06, 6.1799e-07,\n",
              "            3.5275e-05, 9.9769e-05, 2.4968e-06, 7.5498e-05, 8.9476e-07, 1.9447e-03,\n",
              "            1.0859e-03, 1.5178e-06, 9.7048e-05, 3.0003e-07, 7.1291e-07, 7.2794e-07],\n",
              "           [1.0000e+00, 1.1807e-07, 2.9886e-07, 2.7769e-08, 1.0997e-07, 2.4552e-10,\n",
              "            2.1881e-07, 6.1704e-11, 2.7008e-07, 1.7047e-07, 2.3885e-06, 4.5382e-06,\n",
              "            1.0490e-07, 1.6664e-06, 1.5743e-07, 8.1369e-07, 8.0432e-07, 9.6372e-10,\n",
              "            9.6244e-06, 3.3131e-05, 7.2828e-06, 2.8669e-06, 1.4604e-07, 7.7093e-09,\n",
              "            7.0538e-05, 5.3454e-07, 2.1764e-07, 1.1455e-07, 1.5141e-06, 2.6136e-07],\n",
              "           [1.0000e+00, 5.0164e-10, 2.0191e-11, 6.0766e-07, 5.2080e-09, 3.8754e-11,\n",
              "            8.2597e-10, 9.0102e-11, 6.9640e-09, 4.1604e-08, 7.0534e-07, 5.9183e-08,\n",
              "            1.1033e-05, 2.2550e-08, 2.4415e-06, 8.2153e-06, 3.1781e-09, 2.8391e-10,\n",
              "            8.2264e-10, 6.8072e-10, 3.2225e-03, 1.1683e-03, 3.2649e-05, 1.0207e-06,\n",
              "            1.7260e-04, 4.4697e-05, 3.4249e-06, 3.7568e-05, 1.8890e-05, 4.7580e-06],\n",
              "           [1.0000e+00, 3.6516e-08, 2.0179e-08, 1.8168e-07, 4.1485e-08, 5.6788e-10,\n",
              "            5.2025e-08, 1.4914e-10, 2.5363e-08, 1.0129e-08, 3.5849e-03, 1.4716e-06,\n",
              "            3.1772e-06, 1.7145e-04, 1.2911e-05, 7.1784e-07, 6.0757e-07, 5.5441e-07,\n",
              "            2.4329e-03, 9.6962e-05, 2.3205e-07, 3.8542e-04, 5.3733e-08, 9.8563e-05,\n",
              "            1.1279e-05, 2.0679e-06, 7.9739e-08, 5.9056e-07, 1.3294e-06, 2.0209e-08],\n",
              "           [9.9999e-01, 2.2385e-07, 1.3772e-05, 3.6688e-06, 8.7289e-07, 2.3523e-08,\n",
              "            3.4613e-06, 2.5454e-07, 6.2658e-06, 2.9207e-07, 5.7150e-04, 3.1207e-07,\n",
              "            1.0811e-06, 1.9178e-07, 1.3907e-06, 1.0981e-06, 1.0239e-05, 6.6514e-05,\n",
              "            5.2404e-03, 6.5375e-04, 1.6572e-02, 1.1477e-06, 1.6525e-06, 1.2310e-04,\n",
              "            6.0133e-05, 3.1376e-07, 4.4168e-05, 4.6179e-05, 3.6010e-07, 3.7847e-08],\n",
              "           [1.0000e+00, 4.9273e-09, 7.0017e-10, 7.1248e-07, 6.5853e-09, 6.2969e-10,\n",
              "            1.1883e-09, 1.9957e-10, 1.4328e-08, 6.8209e-08, 1.6170e-07, 7.1714e-08,\n",
              "            1.7291e-08, 2.6293e-07, 1.3290e-06, 3.1879e-08, 9.8781e-09, 5.6548e-09,\n",
              "            1.8234e-08, 3.7201e-06, 7.1477e-07, 2.3142e-03, 2.2940e-08, 2.1182e-07,\n",
              "            3.0488e-04, 5.2921e-06, 3.5915e-05, 2.4225e-06, 4.2975e-05, 2.3039e-07],\n",
              "           [1.0000e+00, 3.2858e-10, 4.6788e-10, 9.9061e-08, 2.1664e-10, 1.0558e-12,\n",
              "            4.5664e-09, 1.5862e-14, 2.6154e-10, 8.1627e-09, 1.8155e-07, 5.3357e-06,\n",
              "            1.9354e-08, 1.7374e-06, 9.5368e-10, 5.6616e-11, 1.0426e-08, 1.0029e-10,\n",
              "            3.1686e-06, 9.5612e-06, 1.4570e-08, 3.7090e-06, 2.4661e-05, 4.4784e-07,\n",
              "            1.5292e-05, 5.5943e-07, 3.5794e-08, 2.4288e-08, 2.7045e-06, 1.5066e-08],\n",
              "           [1.0000e+00, 1.3563e-09, 3.7369e-12, 2.8677e-08, 1.0548e-09, 1.8642e-13,\n",
              "            6.7658e-10, 2.0810e-13, 6.5628e-09, 5.4553e-10, 7.1902e-05, 1.1116e-08,\n",
              "            5.8666e-07, 5.2920e-07, 1.0673e-09, 2.0710e-09, 7.1731e-09, 3.7589e-06,\n",
              "            1.3931e-06, 6.7785e-09, 3.0142e-06, 8.8025e-06, 7.6731e-08, 2.8095e-07,\n",
              "            1.0521e-06, 1.4587e-05, 4.8487e-07, 1.4011e-04, 1.0220e-07, 2.3506e-07],\n",
              "           [9.9993e-01, 3.7276e-07, 5.8291e-08, 1.5813e-05, 4.4158e-05, 2.8018e-08,\n",
              "            2.0783e-07, 6.3076e-09, 2.4923e-06, 5.2088e-05, 5.9594e-06, 4.6699e-07,\n",
              "            2.1365e-08, 1.9074e-05, 8.8786e-07, 6.5738e-08, 1.2630e-07, 6.3257e-08,\n",
              "            1.2444e-04, 7.0189e-06, 8.2656e-06, 7.7038e-05, 1.6444e-07, 5.9382e-08,\n",
              "            9.5577e-06, 5.2083e-06, 2.2234e-06, 2.2665e-06, 2.1714e-07, 1.1337e-02],\n",
              "           [9.9997e-01, 1.4419e-07, 4.8525e-08, 1.5151e-05, 5.0104e-07, 3.0108e-09,\n",
              "            3.8155e-09, 1.9726e-11, 1.4384e-07, 2.2587e-06, 1.1912e-07, 3.9706e-06,\n",
              "            3.3555e-09, 7.1716e-06, 2.2191e-09, 1.8646e-09, 3.7483e-08, 4.8747e-10,\n",
              "            6.3055e-07, 2.5798e-05, 1.0014e-08, 2.1708e-06, 7.5820e-08, 1.1204e-07,\n",
              "            4.5720e-06, 2.5173e-06, 9.4937e-09, 2.0395e-08, 8.0086e-07, 1.7020e-05]],\n",
              "          device='cuda:0', grad_fn=<CatBackward>)],\n",
              "  5: [tensor([[9.1109e-01, 1.1706e-03, 3.1035e-03, 7.6748e-03, 3.2692e-03, 3.6345e-03,\n",
              "            5.7706e-03, 3.0696e-03, 5.7163e-03, 4.6223e-02, 1.5713e-02, 4.6612e-04,\n",
              "            6.4481e-03, 2.3743e-02, 6.9806e-04, 6.1178e-03, 4.2951e-04, 4.3952e-04,\n",
              "            4.1621e-03, 6.9975e-03, 2.1408e-03, 2.9255e-03, 8.1034e-04, 8.0679e-03,\n",
              "            4.6842e-03, 1.3496e-04, 9.4564e-04, 5.8643e-04, 6.0001e-04, 2.7310e-03,\n",
              "            3.8864e-05, 1.3062e-02, 2.1040e-04, 7.5377e-06, 2.3408e-04, 8.0858e-05,\n",
              "            6.4179e-05, 3.8047e-03, 3.2392e-02, 1.4735e-04, 6.6889e-08, 2.5277e-06,\n",
              "            2.3315e-05, 5.9174e-03, 5.0249e-05, 1.3230e-05, 9.4544e-06, 6.1643e-07,\n",
              "            9.9686e-06, 5.4625e-05],\n",
              "           [9.9770e-01, 1.1408e-04, 2.8428e-03, 2.0750e-03, 7.7548e-04, 5.5324e-04,\n",
              "            5.2772e-04, 3.1546e-04, 2.5263e-03, 5.7583e-03, 2.2811e-03, 3.4412e-04,\n",
              "            4.5658e-04, 1.9311e-03, 6.4028e-04, 2.1599e-03, 4.5385e-05, 1.6675e-04,\n",
              "            1.5840e-03, 3.5883e-04, 1.3477e-03, 4.6349e-05, 4.4962e-04, 7.6390e-04,\n",
              "            6.7278e-04, 6.1616e-06, 1.9031e-04, 2.3723e-04, 2.7236e-04, 1.2866e-04,\n",
              "            6.1811e-06, 7.8669e-04, 8.1425e-06, 4.8721e-07, 1.4054e-05, 2.1505e-05,\n",
              "            2.6832e-05, 3.9863e-04, 3.5050e-03, 1.1251e-05, 1.6952e-08, 1.2359e-07,\n",
              "            1.4670e-06, 1.1051e-03, 2.5651e-07, 4.5663e-08, 8.3925e-07, 8.7665e-08,\n",
              "            1.5492e-08, 3.6169e-07],\n",
              "           [9.9711e-01, 1.1831e-05, 5.9661e-04, 3.3436e-04, 7.3352e-04, 1.0505e-04,\n",
              "            6.1798e-04, 5.3418e-04, 1.4043e-03, 5.0456e-03, 1.1951e-03, 6.8789e-05,\n",
              "            2.1934e-03, 3.3871e-04, 1.3341e-04, 5.7418e-03, 2.6844e-05, 2.1504e-05,\n",
              "            4.2955e-05, 7.1165e-05, 5.8294e-04, 3.1983e-05, 2.4205e-05, 1.2242e-04,\n",
              "            1.9217e-03, 2.3301e-06, 6.5802e-06, 3.4843e-05, 9.4101e-05, 1.6275e-05,\n",
              "            2.6861e-06, 1.8147e-04, 4.6204e-08, 2.0671e-07, 6.5120e-06, 7.7981e-07,\n",
              "            7.5335e-07, 3.5363e-04, 8.2875e-03, 2.6722e-06, 4.7083e-10, 4.0198e-09,\n",
              "            5.6578e-05, 4.4230e-07, 1.0198e-08, 1.5229e-08, 7.1202e-08, 1.0081e-08,\n",
              "            1.3206e-10, 1.9393e-07],\n",
              "           [9.9866e-01, 8.5314e-05, 3.5297e-03, 5.8935e-04, 3.1888e-04, 9.5796e-04,\n",
              "            1.4368e-03, 6.9577e-04, 5.7425e-04, 2.7255e-03, 1.0918e-03, 1.9210e-04,\n",
              "            4.9212e-04, 1.1067e-03, 9.8474e-05, 1.8471e-03, 1.1546e-05, 4.0858e-04,\n",
              "            5.2084e-03, 1.3688e-03, 3.5741e-05, 2.4305e-04, 1.2435e-04, 1.3180e-03,\n",
              "            2.4241e-04, 1.5620e-06, 1.1403e-04, 2.5675e-04, 1.6463e-04, 4.3505e-06,\n",
              "            9.4639e-07, 5.2333e-05, 1.4691e-07, 2.8712e-07, 7.7227e-05, 1.5143e-06,\n",
              "            1.3766e-05, 5.2088e-05, 7.3718e-04, 8.4571e-06, 2.5062e-12, 7.4790e-09,\n",
              "            3.4730e-07, 9.4406e-08, 2.7800e-07, 3.0731e-09, 1.9130e-07, 3.9629e-07,\n",
              "            6.2497e-10, 6.5868e-09],\n",
              "           [9.9336e-01, 1.6342e-04, 1.2179e-02, 3.7915e-03, 5.2278e-04, 1.9378e-03,\n",
              "            8.8090e-04, 3.0151e-03, 4.4122e-03, 5.6653e-03, 3.1570e-03, 8.6794e-04,\n",
              "            9.3131e-04, 5.5301e-04, 3.0783e-04, 6.3102e-03, 1.7370e-04, 2.2948e-03,\n",
              "            5.9791e-04, 4.5837e-03, 4.9790e-04, 1.6652e-04, 7.4848e-04, 1.0093e-03,\n",
              "            5.2491e-04, 2.1114e-06, 3.5963e-03, 3.7236e-03, 1.4728e-04, 1.5014e-05,\n",
              "            2.1376e-04, 1.9723e-03, 4.1734e-07, 2.0390e-06, 4.0853e-04, 1.2726e-05,\n",
              "            3.5479e-05, 4.5196e-06, 4.4749e-04, 4.5998e-05, 1.1919e-08, 4.9841e-07,\n",
              "            2.8638e-06, 1.7145e-06, 1.8970e-06, 3.7374e-06, 1.9680e-08, 9.1521e-08,\n",
              "            7.7655e-09, 2.6093e-05],\n",
              "           [9.9818e-01, 9.4042e-05, 6.4968e-04, 7.5201e-04, 1.5588e-03, 8.6139e-04,\n",
              "            2.3566e-04, 1.6262e-03, 1.4133e-03, 4.8433e-03, 1.5086e-04, 6.7744e-05,\n",
              "            5.0263e-04, 1.3391e-03, 8.6690e-04, 1.5842e-03, 1.3636e-05, 4.4261e-04,\n",
              "            2.0985e-04, 2.4919e-03, 9.8081e-05, 3.9636e-03, 1.0696e-04, 8.3307e-05,\n",
              "            1.2098e-03, 1.2940e-06, 4.2210e-04, 9.3828e-05, 2.0774e-04, 8.3882e-05,\n",
              "            5.2184e-05, 4.1829e-04, 1.7527e-07, 1.0171e-07, 7.1358e-04, 1.4425e-06,\n",
              "            7.6149e-06, 1.6018e-05, 1.1912e-03, 2.4176e-07, 2.1230e-12, 2.0678e-06,\n",
              "            2.5681e-06, 1.4611e-05, 3.1994e-07, 4.2690e-10, 7.2574e-09, 2.7926e-08,\n",
              "            1.6961e-10, 3.7349e-06],\n",
              "           [9.8906e-01, 2.5780e-04, 2.9833e-02, 3.3814e-03, 1.6007e-03, 2.0973e-03,\n",
              "            4.4741e-03, 5.2821e-04, 9.1631e-04, 3.9548e-03, 3.3629e-03, 4.6067e-03,\n",
              "            1.5561e-03, 7.4788e-04, 1.5795e-04, 5.1808e-03, 1.1527e-04, 6.0824e-04,\n",
              "            1.1353e-02, 1.4096e-03, 1.9919e-04, 2.7724e-04, 3.4652e-03, 5.4958e-04,\n",
              "            3.9645e-04, 2.0137e-05, 3.4977e-04, 7.6293e-04, 7.7959e-04, 1.0378e-04,\n",
              "            4.8227e-06, 7.1350e-04, 1.9608e-06, 7.3075e-06, 2.8143e-04, 3.8274e-04,\n",
              "            2.4311e-04, 3.7361e-05, 1.0880e-03, 2.2798e-04, 8.4487e-10, 4.9479e-07,\n",
              "            8.9190e-07, 4.3196e-05, 1.6293e-05, 7.2021e-07, 1.0655e-05, 8.3578e-06,\n",
              "            1.7462e-08, 1.5005e-07],\n",
              "           [9.9676e-01, 1.7346e-04, 6.5098e-04, 1.7136e-03, 2.5357e-03, 4.7441e-04,\n",
              "            1.1422e-03, 7.7404e-04, 1.8754e-03, 6.0482e-03, 1.4291e-02, 3.8306e-05,\n",
              "            3.4797e-03, 1.0426e-03, 1.5021e-04, 8.6603e-04, 1.7262e-05, 3.4517e-03,\n",
              "            1.0560e-03, 4.9413e-05, 4.7529e-05, 6.5781e-05, 3.6834e-05, 1.4333e-03,\n",
              "            2.6053e-04, 2.7667e-05, 1.9886e-03, 3.2055e-04, 1.6771e-05, 4.0044e-05,\n",
              "            5.4538e-05, 5.8570e-05, 1.4917e-06, 3.3420e-07, 3.1084e-04, 5.0991e-08,\n",
              "            1.1438e-06, 2.9020e-05, 1.0466e-01, 7.6396e-06, 1.9687e-11, 2.0161e-09,\n",
              "            1.3330e-05, 1.0516e-05, 5.8214e-08, 8.0324e-06, 2.0573e-06, 7.3155e-07,\n",
              "            3.7752e-10, 6.1115e-07],\n",
              "           [9.9061e-01, 1.1963e-04, 3.3359e-03, 1.4511e-03, 1.6289e-03, 6.5654e-03,\n",
              "            9.8716e-04, 3.6388e-04, 4.1336e-04, 8.3278e-03, 3.8778e-03, 3.4136e-04,\n",
              "            1.0041e-03, 2.3836e-04, 1.0838e-04, 2.0663e-03, 3.4011e-04, 2.1448e-04,\n",
              "            1.4956e-03, 5.7133e-04, 2.4325e-04, 3.2837e-04, 1.0350e-03, 6.7181e-05,\n",
              "            2.3354e-04, 5.9587e-06, 2.1957e-04, 3.5476e-04, 2.5686e-05, 7.3265e-04,\n",
              "            2.3963e-06, 1.0722e-03, 9.1289e-07, 1.3102e-06, 1.3576e-04, 2.0704e-05,\n",
              "            5.1079e-05, 8.2226e-05, 8.7657e-04, 1.7450e-06, 1.1659e-09, 1.1604e-08,\n",
              "            1.2126e-06, 2.3205e-04, 1.5953e-06, 1.4046e-07, 1.1191e-09, 1.3002e-08,\n",
              "            2.7600e-08, 3.9515e-06],\n",
              "           [9.8997e-01, 1.0882e-04, 3.0366e-03, 1.1568e-03, 7.6263e-04, 4.6278e-03,\n",
              "            5.1943e-04, 8.6943e-05, 4.7494e-05, 3.5008e-03, 2.8495e-04, 2.6404e-04,\n",
              "            3.3786e-04, 3.5620e-04, 1.5173e-05, 3.1582e-04, 2.1960e-05, 3.7292e-05,\n",
              "            3.6060e-03, 4.4290e-04, 2.6473e-05, 3.4788e-05, 4.8751e-05, 6.7035e-05,\n",
              "            7.4560e-05, 8.0812e-07, 1.2806e-05, 6.8790e-05, 6.7662e-05, 1.1484e-04,\n",
              "            3.0401e-08, 1.0625e-04, 2.0196e-07, 9.2441e-07, 2.6467e-05, 8.8225e-06,\n",
              "            2.7305e-05, 3.7853e-06, 1.3133e-04, 1.5254e-07, 9.2978e-13, 2.6040e-09,\n",
              "            9.6712e-11, 4.6403e-06, 3.4450e-07, 9.5785e-10, 2.1591e-10, 9.8636e-09,\n",
              "            2.2300e-10, 1.0893e-08]], device='cuda:0', grad_fn=<SigmoidBackward>),\n",
              "   tensor([[9.9948e-01, 2.1611e-05, 6.6664e-07, 1.9065e-04, 5.1596e-06, 8.8803e-07,\n",
              "            2.5331e-06, 1.5160e-06, 2.7261e-05, 4.3884e-04, 2.2886e-04, 2.5145e-06,\n",
              "            3.0209e-06, 1.0647e-02, 1.4485e-05, 2.3764e-06, 8.9595e-07, 5.6571e-07,\n",
              "            1.6875e-05, 1.1432e-03, 1.5548e-05, 4.9307e-03, 7.4413e-05, 2.0912e-04,\n",
              "            1.1818e-02, 3.1406e-05, 4.9858e-05, 1.5456e-05, 6.6409e-05, 3.7935e-05,\n",
              "            2.0905e-07, 4.7484e-03, 1.6120e-07, 2.5867e-08, 2.3967e-05, 5.7685e-07,\n",
              "            3.2598e-06, 1.0993e-04, 4.4240e-04, 3.0864e-06],\n",
              "           [1.0000e+00, 1.0545e-09, 3.1139e-11, 3.4034e-09, 2.6900e-10, 1.1532e-13,\n",
              "            1.1725e-10, 2.8712e-14, 9.2055e-10, 1.0312e-09, 6.5216e-07, 9.2392e-09,\n",
              "            2.9984e-09, 4.5219e-08, 2.5594e-09, 8.5159e-09, 2.6790e-10, 8.2623e-14,\n",
              "            3.6353e-09, 2.1939e-08, 8.3651e-06, 1.7327e-06, 1.3345e-07, 5.9547e-06,\n",
              "            6.8423e-05, 2.1526e-08, 1.5055e-08, 7.8625e-08, 8.4952e-08, 3.8430e-08,\n",
              "            1.1671e-09, 5.0764e-06, 6.1035e-10, 3.3154e-10, 5.5747e-07, 9.1468e-10,\n",
              "            2.3003e-08, 5.9079e-06, 5.6538e-05, 6.6267e-08],\n",
              "           [1.0000e+00, 4.7700e-11, 1.4589e-12, 2.2735e-07, 2.7753e-09, 1.6718e-12,\n",
              "            2.8915e-10, 5.4675e-12, 2.2424e-09, 1.5231e-09, 7.0566e-08, 2.0385e-08,\n",
              "            5.5006e-07, 1.4243e-09, 2.2307e-06, 2.8538e-05, 5.6227e-10, 9.9238e-12,\n",
              "            7.2155e-10, 3.4875e-10, 3.7064e-05, 1.3357e-03, 4.8674e-07, 2.2116e-07,\n",
              "            1.3135e-04, 2.3160e-06, 1.1461e-06, 3.5536e-06, 4.9310e-07, 8.2796e-07,\n",
              "            3.5874e-07, 7.5423e-05, 7.0929e-11, 6.7563e-10, 4.9812e-07, 2.3541e-08,\n",
              "            8.2188e-08, 8.7535e-04, 1.1483e-03, 7.9793e-07],\n",
              "           [1.0000e+00, 4.5102e-09, 9.2171e-09, 1.5386e-08, 1.3560e-09, 8.7343e-11,\n",
              "            1.3473e-08, 2.6632e-11, 9.5508e-09, 8.1420e-09, 8.0417e-06, 2.7104e-06,\n",
              "            2.5582e-06, 1.7289e-06, 6.6412e-07, 2.7477e-08, 4.8623e-08, 1.4436e-09,\n",
              "            1.3932e-04, 1.9639e-06, 8.3630e-08, 1.1879e-04, 4.6372e-07, 4.7580e-06,\n",
              "            5.9315e-05, 5.0971e-06, 7.7718e-08, 3.1003e-07, 7.1468e-06, 2.0892e-07,\n",
              "            1.8279e-08, 1.6572e-06, 8.7861e-10, 1.7657e-09, 2.0499e-05, 1.7783e-08,\n",
              "            9.0077e-07, 3.5742e-06, 4.1779e-04, 3.2397e-06],\n",
              "           [1.0000e+00, 4.2889e-08, 1.8820e-07, 1.1470e-06, 1.2124e-08, 5.4738e-09,\n",
              "            5.6681e-08, 1.5625e-08, 1.3269e-06, 5.7840e-07, 7.9370e-04, 4.1719e-06,\n",
              "            2.1857e-06, 1.3179e-06, 6.8647e-06, 5.8087e-06, 5.0853e-06, 3.5645e-06,\n",
              "            1.5565e-03, 4.5606e-03, 2.4521e-04, 2.6597e-04, 1.6534e-05, 1.1269e-03,\n",
              "            6.5432e-04, 4.9374e-06, 9.4299e-05, 6.5518e-05, 6.9635e-07, 6.6520e-06,\n",
              "            2.3285e-06, 6.1214e-06, 7.4687e-09, 6.8773e-09, 8.7651e-05, 3.2725e-07,\n",
              "            1.0001e-06, 1.3447e-07, 2.1267e-03, 8.8947e-06],\n",
              "           [1.0000e+00, 6.7422e-10, 1.1289e-10, 6.4406e-07, 5.8586e-10, 8.5270e-11,\n",
              "            5.0566e-11, 5.0937e-12, 1.7348e-08, 1.3837e-08, 1.0549e-07, 1.4012e-08,\n",
              "            3.5850e-09, 1.2802e-08, 2.9198e-06, 1.9689e-08, 1.3685e-08, 2.3599e-07,\n",
              "            1.0611e-08, 1.1821e-05, 3.3744e-07, 2.8592e-04, 5.0024e-09, 2.3187e-08,\n",
              "            2.2863e-04, 5.1288e-07, 3.1099e-05, 4.9227e-07, 5.4073e-05, 1.9974e-08,\n",
              "            6.0726e-07, 5.5955e-06, 3.3323e-10, 1.2071e-10, 6.1116e-04, 8.0324e-10,\n",
              "            1.2380e-08, 3.3898e-06, 4.3688e-03, 5.9761e-09],\n",
              "           [1.0000e+00, 4.4812e-09, 1.5821e-07, 2.9381e-08, 1.3313e-08, 2.7872e-11,\n",
              "            2.7671e-09, 3.1399e-13, 4.9416e-09, 4.1317e-08, 1.0864e-06, 9.1715e-07,\n",
              "            5.6857e-09, 1.3548e-07, 6.0657e-10, 3.1229e-10, 2.2574e-08, 9.4643e-12,\n",
              "            3.9283e-07, 8.3117e-08, 5.0317e-08, 6.1939e-07, 2.8982e-07, 9.9798e-09,\n",
              "            3.3780e-06, 5.6461e-06, 1.5571e-08, 1.1007e-07, 3.9543e-06, 3.4719e-08,\n",
              "            1.4150e-09, 2.0596e-06, 4.8676e-11, 2.5428e-09, 1.1763e-06, 1.3419e-08,\n",
              "            1.1857e-06, 1.2653e-07, 5.6949e-05, 2.3271e-06],\n",
              "           [1.0000e+00, 3.3548e-08, 5.1610e-12, 6.9990e-07, 1.1073e-09, 1.3539e-11,\n",
              "            9.1148e-10, 3.9717e-11, 1.6513e-07, 1.3312e-07, 9.2876e-04, 9.5120e-09,\n",
              "            1.0697e-06, 7.8164e-05, 7.8076e-09, 2.4249e-08, 1.6308e-09, 9.7036e-08,\n",
              "            4.0583e-07, 5.7388e-09, 1.7569e-06, 7.4800e-06, 6.9111e-08, 2.3307e-08,\n",
              "            1.8923e-06, 8.0656e-07, 1.8600e-04, 4.7166e-06, 2.9984e-08, 1.6386e-08,\n",
              "            1.1533e-06, 9.5359e-05, 6.0237e-09, 1.0336e-09, 4.6788e-05, 3.5446e-09,\n",
              "            5.2606e-07, 2.2921e-07, 1.5549e-01, 3.9765e-08],\n",
              "           [9.9985e-01, 1.7422e-07, 2.7862e-08, 1.1637e-05, 4.5956e-05, 1.5953e-08,\n",
              "            5.6475e-08, 2.0992e-09, 1.5115e-06, 2.1113e-04, 5.7729e-06, 1.5027e-07,\n",
              "            1.2189e-08, 1.9204e-05, 4.5803e-08, 8.2064e-08, 2.5866e-07, 1.6170e-08,\n",
              "            3.1012e-05, 2.2001e-05, 2.0932e-05, 1.0307e-04, 2.4625e-07, 3.2256e-08,\n",
              "            1.5707e-05, 4.1425e-06, 6.5683e-06, 4.5559e-06, 1.7549e-07, 2.3880e-03,\n",
              "            6.9581e-07, 1.4475e-05, 2.7318e-08, 3.9685e-08, 1.3837e-04, 1.0521e-06,\n",
              "            1.5322e-05, 1.0245e-04, 4.6690e-02, 2.2940e-06],\n",
              "           [1.0000e+00, 6.7895e-10, 5.8545e-11, 5.2954e-09, 4.6222e-11, 1.3670e-12,\n",
              "            3.0486e-11, 1.0365e-14, 9.6298e-11, 2.7916e-08, 1.2138e-09, 2.0379e-07,\n",
              "            3.1403e-10, 1.9182e-08, 6.5372e-11, 3.1074e-11, 1.1852e-09, 4.8830e-13,\n",
              "            4.1339e-08, 5.2703e-08, 1.1039e-09, 1.7342e-07, 5.1006e-09, 4.5145e-08,\n",
              "            1.5468e-06, 3.1462e-07, 9.7341e-10, 5.7212e-09, 4.2525e-07, 4.3093e-06,\n",
              "            3.3175e-11, 1.2992e-06, 1.6784e-11, 9.7534e-10, 5.3692e-07, 5.1677e-09,\n",
              "            2.9907e-07, 1.4928e-08, 5.5152e-06, 5.7938e-08]], device='cuda:0',\n",
              "          grad_fn=<CatBackward>)],\n",
              "  6: [tensor([[8.8289e-01, 1.0784e-03, 3.3760e-03, 8.3431e-03, 4.3805e-03, 5.3576e-03,\n",
              "            4.1142e-03, 2.9339e-03, 1.3245e-02, 9.3742e-02, 7.4423e-02, 5.7284e-04,\n",
              "            9.1368e-03, 1.7792e-02, 7.8364e-04, 5.1170e-03, 6.1124e-04, 7.5646e-04,\n",
              "            1.5315e-03, 7.5653e-03, 4.3931e-03, 5.5333e-03, 8.1136e-04, 8.9894e-03,\n",
              "            3.0225e-03, 2.3723e-04, 4.0780e-03, 4.6627e-04, 8.8912e-04, 1.9971e-03,\n",
              "            1.4415e-03, 1.3451e-02, 4.8969e-04, 1.2928e-05, 1.2454e-04, 3.7168e-04,\n",
              "            2.0911e-04, 4.4293e-03, 4.3227e-02, 6.9765e-05, 3.9644e-05, 6.7464e-05,\n",
              "            7.3460e-03, 1.3950e-02, 1.4673e-04, 6.8295e-04, 2.3229e-05, 7.0519e-06,\n",
              "            3.4949e-04, 1.0879e-03, 1.5523e-05, 6.9798e-04, 2.3816e-07, 3.0045e-08,\n",
              "            1.0719e-06, 1.7400e-04, 9.2563e-09, 1.8052e-05, 4.1100e-04, 3.3733e-04],\n",
              "           [9.9125e-01, 2.5103e-04, 2.0088e-02, 2.5707e-03, 9.0987e-04, 4.9717e-04,\n",
              "            1.7698e-03, 9.0353e-04, 2.6562e-03, 8.3991e-03, 3.0456e-03, 3.1881e-04,\n",
              "            3.3957e-03, 5.6789e-04, 3.2283e-04, 2.7875e-03, 9.7053e-04, 1.8748e-03,\n",
              "            1.8799e-03, 4.6848e-04, 3.1384e-03, 1.6861e-04, 2.6369e-03, 3.2458e-05,\n",
              "            2.6211e-04, 1.7803e-05, 7.0493e-04, 8.8793e-05, 5.3855e-04, 1.0271e-03,\n",
              "            4.7968e-05, 9.0308e-05, 4.5804e-05, 3.6758e-06, 3.9195e-05, 2.7767e-04,\n",
              "            4.4023e-04, 4.4425e-05, 5.7228e-03, 1.3461e-04, 6.4695e-05, 2.0470e-07,\n",
              "            8.1001e-06, 9.0938e-04, 1.9937e-06, 7.7715e-06, 1.0639e-05, 1.1964e-04,\n",
              "            6.7812e-07, 2.1234e-05, 5.1733e-08, 3.5191e-06, 3.7552e-05, 9.0523e-08,\n",
              "            1.3501e-06, 8.3187e-08, 2.0857e-09, 1.8461e-07, 3.6611e-06, 6.6288e-10],\n",
              "           [9.9343e-01, 1.6077e-04, 8.6359e-03, 1.9510e-03, 1.4529e-03, 5.3493e-04,\n",
              "            5.0283e-03, 5.8959e-03, 7.3181e-03, 1.6714e-02, 4.3852e-03, 6.3551e-04,\n",
              "            9.6524e-03, 9.1922e-04, 2.1174e-03, 5.6796e-02, 2.2387e-03, 4.3551e-04,\n",
              "            5.7121e-04, 1.1242e-03, 1.4260e-02, 5.9938e-04, 5.5111e-04, 2.3057e-04,\n",
              "            1.4655e-02, 2.4468e-05, 5.6672e-04, 3.0265e-04, 1.4231e-03, 1.9461e-04,\n",
              "            1.1049e-03, 9.1958e-04, 3.3082e-05, 2.6936e-06, 1.3587e-04, 3.7294e-04,\n",
              "            1.1949e-04, 1.5175e-03, 2.2380e-02, 3.3911e-04, 3.1860e-04, 2.1182e-06,\n",
              "            1.4769e-02, 8.6937e-04, 2.8704e-06, 3.7815e-05, 4.6772e-05, 2.6584e-04,\n",
              "            9.9061e-07, 1.3387e-04, 4.7124e-08, 1.1495e-04, 3.0679e-06, 1.8652e-06,\n",
              "            1.2073e-06, 2.2318e-05, 1.3370e-06, 2.1946e-04, 8.4984e-08, 1.9615e-07],\n",
              "           [9.8493e-01, 6.9873e-04, 9.2812e-03, 4.5382e-03, 1.8526e-03, 1.5435e-03,\n",
              "            1.0719e-02, 2.8651e-03, 1.1366e-03, 5.2260e-03, 7.0698e-03, 3.3735e-04,\n",
              "            2.4179e-03, 3.5577e-03, 3.3671e-04, 2.5640e-03, 3.0404e-04, 8.8171e-03,\n",
              "            1.3028e-02, 2.2954e-03, 5.3686e-04, 2.4446e-03, 2.2696e-03, 1.2150e-03,\n",
              "            7.9538e-04, 6.9947e-05, 8.9248e-04, 4.2807e-04, 4.2346e-04, 4.2525e-04,\n",
              "            7.9007e-05, 2.7408e-04, 1.6120e-05, 1.8253e-05, 3.9859e-04, 4.3091e-04,\n",
              "            6.0337e-04, 4.5424e-04, 1.1817e-02, 2.7291e-04, 1.1936e-06, 4.6508e-06,\n",
              "            3.1077e-05, 3.6628e-05, 1.4383e-04, 1.1055e-04, 7.0772e-05, 2.0279e-04,\n",
              "            2.9295e-06, 1.1758e-05, 3.2664e-08, 7.0387e-06, 1.9522e-08, 3.5064e-05,\n",
              "            1.3115e-06, 1.9746e-06, 1.0576e-08, 6.8245e-05, 2.2750e-05, 1.8442e-08],\n",
              "           [9.9189e-01, 6.5473e-05, 1.2142e-02, 1.3053e-03, 6.8569e-04, 4.6183e-03,\n",
              "            9.2158e-04, 1.4556e-03, 1.6080e-03, 7.2949e-03, 3.5579e-02, 8.7769e-04,\n",
              "            1.4713e-03, 6.8955e-05, 2.0460e-04, 6.9113e-03, 7.0595e-04, 3.6675e-03,\n",
              "            6.1428e-04, 1.9493e-04, 1.2458e-03, 9.0334e-05, 9.1044e-04, 1.1380e-04,\n",
              "            4.1120e-04, 5.3091e-06, 1.4669e-03, 1.1539e-03, 5.2579e-05, 2.1256e-04,\n",
              "            1.0954e-04, 2.2445e-04, 4.2736e-06, 5.1060e-06, 7.2227e-05, 1.4453e-04,\n",
              "            4.4008e-05, 4.5647e-05, 9.7708e-04, 2.0089e-04, 7.2833e-06, 7.7640e-07,\n",
              "            3.9096e-05, 1.2142e-04, 1.7492e-05, 3.8021e-05, 7.5902e-07, 3.4112e-06,\n",
              "            2.1663e-06, 4.3855e-05, 3.2821e-09, 2.3539e-06, 3.4609e-07, 2.0105e-06,\n",
              "            1.3176e-09, 8.2791e-07, 6.6333e-10, 1.2577e-04, 6.0876e-08, 4.0770e-07],\n",
              "           [9.9196e-01, 1.2590e-03, 4.0610e-03, 4.8451e-03, 6.2819e-03, 1.3666e-03,\n",
              "            1.9397e-03, 5.6066e-03, 2.7882e-03, 1.1200e-02, 6.3328e-03, 1.1841e-04,\n",
              "            2.7590e-03, 7.3089e-03, 5.1373e-03, 1.6074e-03, 1.9765e-04, 2.5406e-03,\n",
              "            1.9502e-03, 3.9143e-03, 1.1995e-03, 1.3815e-02, 1.6126e-03, 3.0850e-04,\n",
              "            2.6296e-03, 5.6989e-05, 4.1774e-03, 2.6331e-04, 4.9691e-04, 1.2128e-03,\n",
              "            1.4830e-03, 2.1957e-03, 4.1373e-05, 3.8936e-06, 1.4128e-03, 1.4085e-04,\n",
              "            3.2229e-04, 6.9040e-04, 3.0999e-02, 4.9003e-06, 4.7749e-06, 1.2482e-04,\n",
              "            2.0132e-04, 9.6364e-04, 5.1904e-05, 1.9148e-05, 1.0278e-05, 2.7517e-05,\n",
              "            8.6121e-07, 1.4775e-04, 7.3692e-08, 5.6103e-05, 1.5297e-09, 6.3849e-06,\n",
              "            8.5590e-08, 1.2167e-07, 4.2749e-08, 8.2181e-05, 3.8431e-06, 6.6433e-06],\n",
              "           [9.7722e-01, 6.2141e-04, 3.2720e-02, 3.5114e-03, 2.3512e-03, 2.0753e-03,\n",
              "            1.0863e-02, 1.7136e-03, 9.4635e-04, 9.4922e-03, 4.1080e-03, 1.1251e-03,\n",
              "            6.4388e-03, 1.4290e-03, 2.9430e-04, 6.8969e-03, 1.6594e-03, 7.8472e-04,\n",
              "            6.6862e-03, 2.3221e-03, 1.0710e-03, 2.7421e-03, 3.4294e-03, 1.4642e-04,\n",
              "            6.2764e-04, 7.1096e-05, 4.9192e-04, 3.5021e-04, 1.3377e-03, 1.2211e-03,\n",
              "            1.2007e-04, 6.7715e-04, 2.1830e-05, 2.4138e-05, 1.6656e-04, 9.0206e-04,\n",
              "            2.2305e-03, 2.1682e-04, 4.4112e-03, 2.1303e-04, 4.7715e-05, 4.4008e-06,\n",
              "            5.5056e-05, 2.4293e-04, 1.2411e-04, 8.6477e-05, 1.2352e-05, 1.8739e-04,\n",
              "            1.8065e-06, 2.7141e-05, 1.6500e-08, 4.6155e-05, 1.6053e-06, 6.4080e-07,\n",
              "            5.2607e-06, 7.4452e-07, 4.1982e-08, 3.4238e-06, 6.5515e-06, 2.1083e-07],\n",
              "           [9.7779e-01, 1.1427e-03, 3.3370e-03, 3.2348e-03, 7.6386e-03, 1.2150e-03,\n",
              "            2.6283e-03, 2.1613e-03, 2.9393e-03, 2.0721e-02, 3.0906e-02, 3.4035e-04,\n",
              "            1.7410e-02, 4.4843e-03, 4.8541e-04, 9.0069e-04, 2.5868e-04, 5.0464e-03,\n",
              "            3.0321e-03, 1.1076e-04, 1.0456e-03, 4.2127e-04, 2.1447e-04, 1.3432e-03,\n",
              "            9.9618e-04, 6.3480e-05, 7.0492e-03, 1.5291e-03, 3.4097e-05, 6.6842e-04,\n",
              "            5.1951e-04, 2.3747e-03, 1.5420e-04, 4.3918e-06, 6.9483e-04, 3.2952e-05,\n",
              "            1.8904e-04, 5.3737e-04, 7.5863e-02, 1.3907e-05, 1.9926e-06, 7.2277e-06,\n",
              "            1.7667e-04, 4.7971e-03, 5.1918e-05, 6.3742e-04, 2.2820e-05, 9.1188e-05,\n",
              "            3.4833e-06, 1.4692e-04, 3.9964e-07, 1.3970e-02, 4.0455e-09, 7.9343e-09,\n",
              "            4.2283e-08, 8.7046e-05, 6.2129e-09, 3.3370e-03, 8.0077e-06, 2.9524e-07],\n",
              "           [9.6365e-01, 2.3566e-04, 9.6230e-03, 2.5117e-03, 3.6011e-03, 1.6720e-03,\n",
              "            2.1688e-03, 4.9224e-04, 9.2940e-05, 1.1755e-02, 3.2313e-03, 2.7649e-04,\n",
              "            2.8171e-03, 6.0109e-04, 1.6514e-04, 1.8710e-03, 5.3913e-04, 1.6433e-04,\n",
              "            1.7928e-03, 6.1599e-04, 6.1639e-04, 5.5918e-03, 1.4245e-03, 3.0079e-05,\n",
              "            5.2486e-04, 1.1164e-05, 3.6111e-04, 1.8255e-04, 1.2914e-04, 1.5244e-03,\n",
              "            1.0355e-04, 7.4020e-04, 1.1808e-05, 2.3322e-05, 1.9942e-04, 6.4005e-04,\n",
              "            7.2726e-04, 1.8203e-04, 2.4940e-02, 6.3671e-06, 4.3760e-06, 8.7526e-07,\n",
              "            1.0975e-04, 2.2616e-04, 3.1839e-05, 1.9118e-04, 9.0752e-07, 5.7023e-05,\n",
              "            1.9744e-06, 6.0913e-04, 5.1999e-09, 5.7918e-06, 1.0929e-07, 1.8913e-05,\n",
              "            1.2031e-07, 3.1165e-06, 7.3223e-08, 1.3715e-05, 1.8077e-07, 6.7896e-06],\n",
              "           [9.8452e-01, 1.2162e-04, 3.9667e-03, 3.6115e-03, 6.4047e-04, 3.1040e-03,\n",
              "            6.5689e-04, 6.7632e-05, 8.1545e-05, 4.7472e-03, 3.2963e-04, 9.6614e-05,\n",
              "            1.1126e-03, 1.3425e-04, 2.2130e-05, 2.7852e-04, 2.7861e-04, 1.5312e-04,\n",
              "            1.5685e-03, 1.2468e-04, 6.3945e-05, 1.4043e-04, 1.8007e-04, 9.1219e-06,\n",
              "            3.4866e-05, 1.4558e-06, 8.5300e-05, 5.6187e-06, 4.0004e-05, 1.5137e-03,\n",
              "            1.3927e-06, 8.8667e-05, 1.4485e-06, 4.0469e-06, 1.7134e-05, 3.2940e-05,\n",
              "            9.5230e-05, 1.3661e-06, 7.1144e-04, 1.9338e-06, 4.2463e-07, 9.6636e-09,\n",
              "            1.5013e-07, 4.8733e-05, 1.9894e-06, 8.2239e-07, 9.0065e-09, 8.0101e-06,\n",
              "            2.8424e-08, 1.3661e-06, 8.6930e-11, 5.1253e-07, 4.7679e-08, 5.1365e-09,\n",
              "            5.9453e-11, 5.6972e-09, 7.0064e-10, 2.3160e-07, 7.9023e-11, 5.9598e-10]],\n",
              "          device='cuda:0', grad_fn=<SigmoidBackward>),\n",
              "   tensor([[9.9691e-01, 1.4129e-04, 8.7632e-07, 1.4948e-03, 9.7212e-05, 6.6318e-06,\n",
              "            1.5184e-06, 2.9562e-06, 8.4292e-04, 5.6795e-04, 1.3256e-04, 8.1973e-08,\n",
              "            1.7976e-06, 2.5594e-02, 2.5607e-07, 2.6801e-07, 5.5726e-08, 5.6738e-07,\n",
              "            3.7876e-07, 6.4406e-06, 1.2899e-06, 6.9697e-04, 1.0919e-06, 7.9554e-04,\n",
              "            9.6891e-04, 1.9067e-05, 3.2315e-05, 9.7277e-07, 8.9470e-07, 3.0937e-06,\n",
              "            1.8967e-07, 2.4899e-03, 2.4699e-08, 4.6224e-09, 2.4250e-05, 2.6433e-08,\n",
              "            2.0853e-07, 1.1007e-04, 2.4591e-03, 6.6079e-08, 9.4112e-09, 1.5396e-06,\n",
              "            6.4836e-04, 5.7018e-04, 2.0221e-05, 3.7175e-06, 7.3041e-07, 2.7645e-08,\n",
              "            1.7590e-06, 5.6159e-05],\n",
              "           [1.0000e+00, 3.4104e-10, 6.5802e-11, 1.7143e-08, 1.2880e-10, 1.5455e-12,\n",
              "            1.2944e-10, 1.5664e-13, 1.3595e-09, 9.7594e-10, 1.5152e-07, 9.8074e-08,\n",
              "            1.8084e-08, 2.1177e-08, 3.7285e-08, 6.5756e-09, 1.9984e-09, 8.6011e-12,\n",
              "            1.1800e-07, 1.5027e-08, 6.4474e-06, 9.4635e-06, 6.4130e-07, 6.0994e-07,\n",
              "            2.8181e-05, 6.2896e-07, 1.6566e-08, 3.6371e-08, 8.0576e-08, 3.6942e-07,\n",
              "            1.4459e-09, 2.2643e-06, 1.5965e-10, 1.7000e-10, 3.4103e-07, 4.8663e-10,\n",
              "            7.3751e-08, 5.5147e-06, 7.0913e-06, 8.1133e-07, 8.9529e-10, 2.9783e-08,\n",
              "            6.2327e-07, 1.5283e-04, 9.7491e-08, 6.0946e-09, 4.0586e-07, 1.1399e-07,\n",
              "            3.0366e-09, 1.5612e-07],\n",
              "           [1.0000e+00, 1.2656e-09, 1.6256e-10, 4.2417e-06, 5.5116e-08, 3.7469e-10,\n",
              "            1.9573e-09, 1.9391e-10, 1.9899e-08, 3.7388e-08, 4.8529e-06, 3.0818e-07,\n",
              "            2.1055e-06, 1.3725e-07, 3.6050e-06, 5.0507e-06, 1.3885e-08, 1.3959e-09,\n",
              "            2.3015e-08, 6.4472e-09, 3.4947e-04, 6.3475e-04, 2.5003e-06, 4.3780e-07,\n",
              "            1.0187e-04, 1.1063e-05, 4.3197e-06, 1.1476e-05, 8.4391e-06, 8.1657e-07,\n",
              "            3.9218e-06, 1.9322e-04, 7.5702e-10, 1.8967e-09, 2.3429e-06, 2.9334e-08,\n",
              "            5.4342e-07, 8.5785e-04, 8.2697e-03, 3.0677e-06, 1.1930e-09, 5.1905e-08,\n",
              "            4.9679e-04, 2.4123e-06, 2.1300e-08, 9.6184e-08, 4.4036e-07, 5.5913e-08,\n",
              "            5.4639e-10, 1.2439e-06],\n",
              "           [1.0000e+00, 2.3602e-08, 2.1184e-08, 4.3339e-07, 2.8265e-08, 1.0893e-09,\n",
              "            1.0095e-07, 2.2091e-10, 2.9173e-08, 1.4672e-08, 9.6672e-06, 1.4434e-07,\n",
              "            1.8417e-07, 1.4203e-06, 5.8105e-07, 4.1531e-09, 5.7484e-08, 1.5883e-08,\n",
              "            3.7110e-03, 2.0505e-06, 7.6117e-07, 1.1536e-04, 1.3902e-06, 8.1849e-06,\n",
              "            1.1994e-05, 8.9669e-06, 1.9422e-07, 1.8955e-06, 2.1501e-06, 7.2865e-08,\n",
              "            7.1603e-09, 1.1574e-06, 3.8387e-10, 3.1546e-09, 2.5290e-05, 4.7145e-08,\n",
              "            1.1427e-06, 1.1308e-06, 1.2547e-03, 6.3432e-06, 5.5045e-11, 3.0753e-07,\n",
              "            2.3859e-06, 1.7387e-06, 2.0678e-05, 2.7796e-07, 4.5629e-05, 3.3699e-05,\n",
              "            1.0221e-07, 5.1846e-06],\n",
              "           [1.0000e+00, 2.8705e-09, 8.5043e-09, 1.1471e-08, 1.6648e-10, 3.5209e-11,\n",
              "            4.9881e-09, 1.2321e-10, 1.2016e-07, 1.0952e-08, 2.5595e-05, 8.8518e-07,\n",
              "            2.4845e-07, 2.1144e-08, 5.4367e-07, 7.5038e-07, 2.1098e-07, 3.5715e-07,\n",
              "            2.3628e-05, 9.3108e-04, 1.3445e-04, 3.3091e-06, 2.0621e-05, 7.8247e-05,\n",
              "            4.5922e-05, 9.5354e-08, 4.8234e-06, 1.2038e-05, 8.0630e-08, 1.6071e-08,\n",
              "            1.2389e-06, 3.1185e-06, 7.9797e-10, 2.6104e-10, 4.9073e-05, 2.0732e-07,\n",
              "            3.6972e-07, 5.0600e-08, 4.9351e-04, 3.5539e-06, 1.2046e-08, 4.1603e-08,\n",
              "            1.6475e-07, 2.4413e-05, 5.2927e-08, 2.1290e-07, 3.1255e-10, 7.8512e-09,\n",
              "            2.4762e-09, 8.9177e-07],\n",
              "           [1.0000e+00, 3.1176e-08, 5.8800e-09, 5.6653e-06, 2.1864e-08, 8.8540e-09,\n",
              "            8.5804e-10, 1.9542e-10, 2.6470e-08, 8.0813e-08, 5.9169e-08, 3.4047e-08,\n",
              "            6.4141e-09, 2.6899e-08, 7.4719e-07, 2.1466e-08, 5.0271e-08, 4.9740e-09,\n",
              "            1.2121e-08, 8.9858e-06, 3.4673e-06, 1.5369e-03, 9.5532e-08, 3.5796e-06,\n",
              "            1.8494e-04, 1.3023e-05, 2.1591e-04, 2.1864e-06, 2.3394e-05, 5.2245e-06,\n",
              "            1.0693e-06, 5.8324e-06, 3.6652e-10, 8.4999e-10, 1.3212e-03, 1.5021e-09,\n",
              "            3.1960e-08, 1.6924e-06, 1.5670e-04, 4.1285e-07, 4.2787e-12, 1.0162e-05,\n",
              "            1.4109e-06, 1.1233e-04, 7.3040e-07, 9.7569e-10, 1.2223e-07, 1.2928e-07,\n",
              "            2.4511e-09, 9.5957e-07],\n",
              "           [1.0000e+00, 5.2894e-09, 4.7019e-08, 1.2972e-08, 3.9302e-09, 2.5784e-11,\n",
              "            1.5916e-08, 3.7626e-13, 1.1588e-09, 8.1475e-09, 8.9667e-07, 3.2393e-05,\n",
              "            3.3658e-08, 4.2970e-08, 5.1351e-09, 3.2800e-10, 1.0392e-07, 3.1968e-10,\n",
              "            1.9560e-05, 1.5057e-06, 4.1436e-07, 9.0949e-06, 1.9256e-05, 1.8574e-07,\n",
              "            3.7993e-05, 5.9320e-06, 1.4295e-08, 1.9591e-07, 1.7793e-06, 1.5533e-06,\n",
              "            7.1547e-10, 8.1707e-06, 1.1714e-10, 1.2892e-08, 1.6073e-05, 2.7676e-07,\n",
              "            2.2095e-05, 3.7205e-07, 4.7250e-06, 8.8194e-07, 2.0192e-09, 4.7803e-07,\n",
              "            3.7204e-07, 1.0261e-04, 1.1068e-05, 8.1715e-07, 1.0798e-06, 6.8213e-06,\n",
              "            2.8565e-08, 6.8513e-07],\n",
              "           [1.0000e+00, 3.5256e-07, 5.7005e-10, 5.2089e-06, 3.7594e-07, 8.1015e-10,\n",
              "            4.8905e-08, 1.4668e-09, 6.7533e-07, 1.3644e-06, 4.2790e-05, 4.5824e-07,\n",
              "            7.2854e-05, 1.2162e-05, 3.8070e-07, 2.0436e-07, 2.2027e-07, 1.5002e-04,\n",
              "            1.0234e-05, 5.2358e-07, 4.6150e-05, 2.3364e-05, 1.6147e-06, 2.9246e-07,\n",
              "            1.8833e-06, 1.0197e-05, 1.3523e-03, 3.3143e-05, 3.2310e-07, 1.8251e-07,\n",
              "            1.4023e-05, 4.9683e-04, 2.9925e-07, 2.2326e-08, 4.8635e-05, 4.6629e-07,\n",
              "            2.0223e-06, 6.4472e-06, 7.4074e-02, 5.1168e-07, 3.1866e-11, 1.0891e-08,\n",
              "            8.7509e-07, 5.0348e-05, 1.1027e-07, 1.3484e-05, 3.0058e-06, 1.7844e-05,\n",
              "            2.5166e-09, 2.1638e-07],\n",
              "           [1.0000e+00, 1.4056e-09, 3.0522e-09, 2.1485e-08, 4.8683e-08, 2.6269e-12,\n",
              "            2.7285e-10, 2.7026e-14, 3.4810e-10, 3.8021e-09, 9.8293e-07, 1.0249e-06,\n",
              "            1.4698e-09, 1.0008e-06, 4.3928e-10, 1.9569e-09, 1.1695e-10, 4.1760e-13,\n",
              "            3.0049e-08, 8.0134e-09, 6.1933e-06, 4.1460e-05, 2.6346e-08, 1.6655e-08,\n",
              "            1.1041e-05, 2.8839e-08, 4.7489e-07, 2.5428e-06, 3.7030e-08, 2.0200e-03,\n",
              "            4.3389e-09, 2.5152e-06, 1.0794e-09, 1.3180e-09, 2.7027e-04, 2.3029e-09,\n",
              "            7.8901e-07, 8.6194e-08, 4.1837e-03, 5.4308e-08, 2.7193e-12, 3.5312e-09,\n",
              "            3.4686e-09, 6.8745e-05, 3.2359e-07, 1.4459e-07, 3.3484e-09, 3.9314e-09,\n",
              "            1.1291e-09, 4.4069e-05],\n",
              "           [9.9995e-01, 1.6036e-07, 2.6521e-09, 3.0359e-06, 6.0814e-07, 1.1189e-10,\n",
              "            1.2414e-08, 1.8314e-11, 1.9433e-07, 3.5336e-05, 2.1436e-07, 1.9489e-06,\n",
              "            1.4876e-08, 8.1911e-06, 1.4327e-09, 2.6813e-09, 6.5472e-08, 6.9205e-10,\n",
              "            1.9582e-05, 2.8429e-05, 4.3902e-08, 2.6484e-05, 2.7483e-08, 8.4729e-07,\n",
              "            2.4917e-05, 4.0470e-07, 3.9544e-08, 2.1863e-08, 2.2771e-05, 4.2784e-05,\n",
              "            6.7004e-11, 1.9020e-05, 1.1714e-11, 1.3845e-10, 2.0696e-06, 4.3964e-09,\n",
              "            5.2569e-07, 3.6211e-09, 3.0165e-07, 2.6087e-08, 2.9208e-12, 3.0816e-09,\n",
              "            4.1911e-10, 1.2977e-03, 1.5631e-06, 6.1408e-09, 3.0134e-10, 1.7059e-08,\n",
              "            1.4667e-08, 5.2817e-08]], device='cuda:0', grad_fn=<CatBackward>)],\n",
              "  7: [tensor([[8.5760e-01, 1.9248e-03, 1.7344e-03, 1.3639e-02, 5.0408e-03, 4.4330e-03,\n",
              "            5.3192e-03, 4.5892e-03, 1.1188e-02, 1.5671e-01, 4.2374e-02, 4.5401e-04,\n",
              "            1.2050e-02, 3.5256e-02, 1.2727e-03, 9.1030e-03, 4.0230e-04, 1.8815e-03,\n",
              "            3.6585e-03, 1.6254e-02, 3.7635e-03, 2.1353e-02, 1.0105e-03, 1.9524e-02,\n",
              "            5.1913e-03, 1.2795e-04, 9.0202e-03, 4.3555e-04, 8.7874e-04, 3.5810e-03,\n",
              "            3.2787e-03, 2.1100e-02, 5.1584e-04, 3.2044e-05, 4.6765e-04, 1.1751e-03,\n",
              "            1.7682e-04, 6.6708e-03, 1.0755e-01, 1.5381e-04, 8.3686e-05, 3.0753e-04,\n",
              "            1.1905e-02, 1.3844e-02, 8.8655e-04, 9.2013e-04, 1.8891e-04, 9.9015e-05,\n",
              "            2.0830e-03, 4.0536e-03, 1.2056e-04, 1.1473e-02, 2.7865e-05, 3.2020e-06,\n",
              "            4.7346e-05, 6.7149e-03, 1.7053e-05, 1.4681e-03, 1.1710e-03, 5.8252e-03,\n",
              "            1.2907e-05, 3.2088e-07, 3.0842e-05, 3.8017e-07, 4.1295e-04, 1.3378e-07,\n",
              "            2.4366e-05, 6.8855e-06, 4.9339e-03, 1.1752e-04],\n",
              "           [9.9196e-01, 7.5620e-04, 1.0928e-02, 2.5095e-03, 3.1531e-03, 1.1345e-03,\n",
              "            5.0975e-03, 6.0698e-04, 2.9537e-03, 9.2010e-03, 1.1917e-02, 5.0654e-04,\n",
              "            3.1778e-03, 1.2694e-03, 3.2910e-04, 3.3381e-03, 2.0979e-03, 2.3080e-03,\n",
              "            2.9680e-03, 6.0879e-04, 4.7353e-03, 2.4771e-04, 4.3335e-03, 1.8098e-04,\n",
              "            3.2428e-04, 1.2089e-05, 7.0763e-04, 7.8874e-04, 1.0622e-04, 2.4916e-04,\n",
              "            1.4875e-04, 2.1752e-04, 9.6084e-05, 2.1288e-05, 5.0321e-05, 1.9548e-04,\n",
              "            1.5176e-04, 2.7719e-04, 8.6102e-03, 2.8327e-04, 1.1106e-04, 3.3338e-06,\n",
              "            1.6502e-04, 8.0039e-04, 6.1670e-05, 8.9011e-05, 5.1853e-05, 2.7351e-05,\n",
              "            1.2829e-05, 6.5630e-05, 1.6897e-05, 3.1218e-05, 4.3217e-05, 1.9598e-06,\n",
              "            3.3680e-05, 2.8326e-05, 6.4276e-07, 2.3700e-05, 7.9437e-05, 3.2295e-06,\n",
              "            2.7235e-10, 1.3017e-12, 4.2544e-06, 2.8805e-07, 1.0254e-06, 1.1045e-07,\n",
              "            1.4271e-05, 4.6409e-09, 2.3543e-07, 9.5317e-06],\n",
              "           [9.7987e-01, 7.8994e-04, 6.6462e-03, 1.4080e-03, 5.5530e-03, 8.9248e-04,\n",
              "            1.6441e-02, 1.1104e-02, 6.5453e-03, 2.1828e-02, 1.2196e-02, 3.9546e-04,\n",
              "            2.7967e-02, 1.9972e-03, 2.7939e-03, 1.9343e-02, 4.4704e-03, 3.2636e-03,\n",
              "            1.5653e-03, 2.4107e-03, 1.3616e-02, 2.5608e-03, 3.5256e-03, 2.4466e-04,\n",
              "            4.3659e-03, 1.8571e-04, 1.1748e-03, 1.1705e-03, 1.6976e-03, 3.7191e-04,\n",
              "            2.2363e-03, 6.8852e-04, 2.0554e-04, 9.4437e-06, 9.6111e-05, 1.1875e-03,\n",
              "            1.0833e-03, 3.7315e-03, 1.0577e-01, 3.9400e-04, 1.4948e-03, 1.7676e-05,\n",
              "            1.9132e-02, 1.2201e-03, 5.4047e-05, 6.4156e-04, 1.1380e-03, 6.5088e-04,\n",
              "            1.2250e-05, 6.9512e-05, 9.0150e-06, 3.3984e-04, 1.7454e-04, 2.3358e-05,\n",
              "            1.8349e-03, 2.3101e-05, 5.3181e-05, 3.2365e-04, 1.0494e-03, 1.0769e-04,\n",
              "            8.3343e-08, 1.9814e-09, 1.3861e-04, 1.0134e-06, 1.1889e-05, 1.5044e-06,\n",
              "            1.1040e-05, 2.2032e-07, 2.4341e-06, 2.7393e-04],\n",
              "           [9.9230e-01, 4.7193e-04, 1.9076e-03, 4.2292e-03, 8.5849e-04, 1.8196e-03,\n",
              "            4.9086e-03, 3.0133e-03, 8.9093e-04, 1.8487e-02, 1.0243e-02, 2.8531e-04,\n",
              "            2.0719e-03, 3.3124e-03, 7.7414e-04, 1.6918e-03, 1.0916e-04, 4.7244e-03,\n",
              "            5.3392e-03, 5.7113e-03, 3.0259e-04, 5.8216e-03, 3.7759e-03, 3.4619e-03,\n",
              "            1.0404e-03, 8.0286e-06, 1.0099e-03, 2.1403e-04, 3.6702e-04, 1.2176e-04,\n",
              "            2.3793e-04, 2.7118e-04, 9.8258e-06, 4.3389e-05, 9.8251e-05, 3.5039e-04,\n",
              "            8.9767e-05, 9.8752e-04, 3.9440e-02, 6.1598e-05, 1.4125e-06, 2.8926e-05,\n",
              "            6.3514e-04, 2.9644e-05, 6.8913e-04, 2.5166e-04, 1.0258e-04, 5.5264e-05,\n",
              "            6.3620e-05, 4.6685e-05, 4.5784e-06, 2.9004e-04, 1.6681e-06, 5.5535e-05,\n",
              "            1.5027e-06, 2.7555e-04, 2.0109e-06, 9.5571e-05, 8.1740e-04, 2.5507e-05,\n",
              "            1.2645e-06, 3.2956e-10, 6.5477e-08, 3.4329e-05, 2.4663e-08, 1.2731e-07,\n",
              "            3.3983e-05, 6.4390e-10, 5.4519e-06, 4.4500e-05],\n",
              "           [9.0832e-01, 1.8994e-03, 1.0931e-02, 5.4762e-03, 4.2715e-03, 5.2758e-03,\n",
              "            2.7717e-02, 2.8136e-02, 1.4077e-02, 1.3756e-02, 3.5753e-02, 2.1862e-03,\n",
              "            6.3139e-03, 4.7063e-03, 2.3476e-03, 2.3206e-02, 2.0785e-03, 2.6589e-02,\n",
              "            9.0646e-03, 2.6196e-02, 8.1270e-03, 5.8861e-03, 5.8227e-03, 4.9764e-03,\n",
              "            6.4401e-03, 1.0649e-04, 3.0478e-02, 7.5844e-03, 9.8604e-04, 7.0881e-04,\n",
              "            7.3741e-03, 3.8665e-03, 3.8985e-04, 3.6041e-04, 8.1023e-04, 3.3049e-03,\n",
              "            7.9509e-04, 1.1444e-03, 4.3053e-02, 3.9433e-03, 2.2413e-04, 2.1553e-04,\n",
              "            1.5240e-03, 1.6055e-03, 1.9894e-03, 1.1781e-02, 1.4410e-03, 1.2348e-03,\n",
              "            1.5292e-03, 2.5591e-03, 4.8912e-04, 8.5357e-04, 3.4488e-04, 1.9332e-04,\n",
              "            2.2633e-04, 3.7053e-04, 1.0955e-04, 1.1939e-02, 3.0029e-03, 1.8780e-03,\n",
              "            1.3637e-04, 1.1832e-06, 3.8453e-05, 2.7663e-06, 5.3933e-05, 3.5091e-06,\n",
              "            5.0493e-04, 4.4092e-06, 5.1354e-05, 1.8272e-04],\n",
              "           [9.8885e-01, 1.3727e-03, 5.7090e-03, 3.1567e-03, 8.5499e-03, 8.2825e-04,\n",
              "            6.0071e-03, 3.9102e-03, 3.4022e-03, 7.8828e-03, 7.0500e-03, 1.1436e-04,\n",
              "            5.3575e-03, 5.7856e-03, 1.2795e-03, 3.8792e-03, 8.1005e-04, 4.5316e-03,\n",
              "            1.5914e-03, 4.9084e-03, 5.8578e-04, 7.9189e-03, 1.3265e-03, 2.2464e-04,\n",
              "            1.8746e-03, 3.4102e-05, 5.5989e-03, 4.1477e-04, 2.3085e-04, 3.5364e-04,\n",
              "            4.0737e-03, 5.2335e-04, 2.8245e-05, 9.5003e-06, 7.7207e-04, 1.3983e-04,\n",
              "            1.9178e-04, 3.0193e-04, 3.5936e-02, 8.0959e-05, 1.0354e-05, 3.6650e-05,\n",
              "            8.6268e-04, 6.4094e-04, 1.9247e-04, 9.8966e-05, 1.3706e-04, 6.4578e-05,\n",
              "            6.9230e-06, 8.1063e-05, 5.7618e-05, 5.5531e-04, 5.0996e-07, 2.6463e-06,\n",
              "            1.4112e-05, 3.4213e-06, 2.3674e-06, 1.3967e-04, 1.0805e-04, 2.3425e-05,\n",
              "            4.1485e-09, 9.7776e-11, 3.5177e-07, 3.8704e-07, 1.1017e-07, 4.2630e-08,\n",
              "            8.0340e-06, 2.1118e-08, 1.5624e-06, 6.3853e-06],\n",
              "           [9.8954e-01, 2.8939e-04, 1.0741e-02, 8.2862e-03, 1.1452e-03, 7.7632e-04,\n",
              "            1.8467e-02, 1.6264e-03, 1.3643e-03, 4.3277e-03, 1.4423e-02, 6.5372e-04,\n",
              "            2.3691e-03, 6.1440e-03, 2.0752e-04, 7.1565e-03, 8.4495e-04, 1.2026e-03,\n",
              "            3.7936e-03, 6.9908e-03, 3.9402e-04, 2.3372e-03, 2.0401e-03, 6.5189e-04,\n",
              "            4.2087e-04, 6.3318e-06, 9.5149e-04, 7.5711e-04, 1.3145e-03, 9.7235e-05,\n",
              "            1.4780e-04, 3.3642e-04, 1.9338e-05, 5.8517e-05, 9.2715e-05, 2.5904e-04,\n",
              "            5.1729e-04, 2.5753e-04, 1.9693e-02, 8.1326e-04, 1.0256e-05, 3.5912e-06,\n",
              "            2.3619e-04, 7.4012e-05, 1.1063e-03, 3.8132e-04, 3.0462e-04, 4.8362e-05,\n",
              "            1.1147e-05, 1.0587e-04, 8.9062e-07, 2.2201e-04, 1.7328e-05, 3.3133e-06,\n",
              "            1.5594e-05, 2.9086e-05, 3.2999e-06, 6.4217e-05, 7.4911e-04, 4.4373e-05,\n",
              "            5.2756e-09, 3.7834e-10, 4.7264e-07, 3.8912e-07, 1.7068e-07, 9.2233e-09,\n",
              "            2.9917e-03, 1.0651e-08, 5.8602e-07, 3.6079e-06],\n",
              "           [9.8424e-01, 9.0365e-04, 2.4445e-03, 1.8136e-03, 8.7461e-03, 1.0679e-03,\n",
              "            6.1520e-03, 2.3689e-03, 4.0395e-03, 2.2588e-02, 5.8938e-02, 4.3099e-04,\n",
              "            3.9421e-02, 5.0958e-03, 5.6382e-04, 1.9265e-03, 3.3991e-04, 2.3553e-03,\n",
              "            2.9025e-03, 2.7316e-04, 1.4999e-03, 6.6856e-04, 5.7405e-04, 2.5880e-03,\n",
              "            8.2976e-04, 5.3446e-05, 5.0178e-03, 5.0660e-04, 1.1517e-04, 9.6849e-04,\n",
              "            1.0235e-03, 9.2272e-04, 2.1818e-04, 2.4500e-05, 7.4945e-04, 9.9555e-05,\n",
              "            1.1687e-04, 1.3989e-03, 2.0628e-01, 3.2720e-05, 6.5805e-06, 3.4260e-05,\n",
              "            4.2007e-03, 4.7242e-03, 2.3898e-04, 1.3284e-03, 3.1585e-04, 1.2887e-04,\n",
              "            1.7730e-05, 3.7262e-04, 8.2502e-05, 3.7296e-03, 1.7709e-06, 1.7870e-06,\n",
              "            1.0872e-05, 3.7882e-04, 4.2823e-06, 8.2043e-04, 2.2338e-04, 7.7749e-04,\n",
              "            3.2136e-08, 2.5192e-09, 6.4936e-05, 8.7478e-07, 2.0086e-05, 5.7712e-07,\n",
              "            4.6454e-06, 2.9930e-08, 7.0172e-03, 1.5706e-05],\n",
              "           [9.8548e-01, 1.9650e-04, 3.6023e-03, 5.2566e-03, 1.5636e-03, 2.3546e-03,\n",
              "            2.1571e-03, 5.7070e-04, 4.1221e-04, 1.8941e-02, 1.0663e-02, 3.7399e-04,\n",
              "            2.3593e-03, 2.1519e-03, 1.4320e-04, 2.7124e-03, 7.0651e-04, 5.9558e-04,\n",
              "            8.0140e-04, 1.2325e-03, 3.5172e-04, 2.1321e-03, 1.5162e-03, 3.3066e-04,\n",
              "            5.2167e-04, 5.1263e-06, 8.0268e-04, 2.7849e-04, 7.5599e-05, 3.6317e-04,\n",
              "            1.5916e-04, 4.3022e-04, 1.1486e-05, 5.5644e-05, 9.2545e-05, 2.6607e-04,\n",
              "            9.4423e-05, 2.8327e-04, 1.7717e-02, 4.2204e-05, 3.7862e-06, 4.4863e-06,\n",
              "            3.4057e-04, 2.1663e-04, 2.4661e-04, 4.8961e-04, 8.3549e-06, 5.6354e-06,\n",
              "            1.6292e-05, 3.4031e-04, 1.1413e-06, 1.7213e-04, 3.0257e-06, 2.2644e-05,\n",
              "            6.4829e-06, 2.0097e-05, 4.8991e-07, 4.9899e-05, 5.1483e-05, 9.4590e-05,\n",
              "            3.5636e-10, 1.8385e-10, 1.7914e-07, 9.5554e-07, 8.5140e-08, 7.4000e-09,\n",
              "            1.4123e-04, 6.7958e-09, 8.0634e-06, 5.8017e-05],\n",
              "           [9.9192e-01, 5.6493e-04, 4.9520e-03, 1.4429e-03, 2.6767e-03, 1.4205e-03,\n",
              "            7.8564e-03, 5.4979e-04, 3.1560e-04, 9.1379e-03, 2.7823e-03, 3.8627e-04,\n",
              "            3.7398e-03, 1.5782e-03, 1.3546e-04, 1.5748e-03, 1.2137e-03, 6.5007e-04,\n",
              "            3.3074e-03, 9.6911e-04, 5.8533e-04, 1.1540e-03, 4.0835e-03, 9.9595e-05,\n",
              "            4.9455e-04, 4.7793e-06, 9.1118e-05, 1.1288e-04, 3.1804e-04, 3.3429e-04,\n",
              "            3.4498e-05, 8.3799e-05, 1.7857e-05, 5.6389e-05, 5.7649e-05, 5.1703e-04,\n",
              "            2.9302e-04, 8.6357e-05, 2.2601e-02, 6.2423e-05, 9.0900e-06, 1.2600e-06,\n",
              "            9.1165e-05, 7.0348e-05, 3.5854e-04, 2.5992e-05, 2.8807e-05, 5.9679e-05,\n",
              "            5.6441e-06, 3.0570e-05, 7.9625e-07, 1.0975e-04, 1.6818e-05, 2.5030e-06,\n",
              "            6.5377e-07, 3.9032e-06, 2.8541e-06, 2.3156e-05, 3.1662e-05, 6.4762e-06,\n",
              "            1.4215e-08, 1.1911e-11, 1.8001e-06, 4.6508e-08, 1.8522e-08, 1.2346e-09,\n",
              "            4.3514e-05, 1.0627e-08, 1.5725e-07, 1.8695e-06]], device='cuda:0',\n",
              "          grad_fn=<SigmoidBackward>),\n",
              "   tensor([[9.9968e-01, 1.7206e-05, 1.4568e-07, 8.4414e-05, 1.2062e-05, 3.6473e-07,\n",
              "            1.6839e-06, 3.1264e-07, 2.4113e-04, 1.3128e-04, 2.6141e-03, 2.4215e-07,\n",
              "            1.4479e-06, 9.8740e-02, 6.1901e-06, 1.2801e-06, 1.6783e-07, 5.4892e-06,\n",
              "            1.9132e-06, 1.2049e-04, 1.4893e-05, 4.3437e-03, 1.6282e-05, 4.9748e-03,\n",
              "            1.3588e-03, 1.9623e-05, 5.8514e-05, 4.5638e-06, 3.4070e-06, 2.5184e-05,\n",
              "            5.5928e-08, 5.2856e-03, 4.8725e-08, 5.2468e-09, 2.4018e-05, 1.0373e-08,\n",
              "            2.3106e-07, 2.3386e-04, 2.7388e-03, 4.0262e-07, 3.0641e-09, 1.3008e-06,\n",
              "            8.4487e-05, 3.8236e-04, 6.9968e-06, 1.8346e-06, 2.4850e-07, 2.3220e-07,\n",
              "            1.6114e-06, 1.9207e-04, 4.0428e-05, 2.4794e-03, 2.3022e-07, 3.2831e-08,\n",
              "            2.5402e-06, 2.1909e-03, 4.7453e-08, 3.1543e-05, 1.7843e-04, 6.0016e-04],\n",
              "           [1.0000e+00, 4.9232e-08, 1.8345e-08, 8.4629e-08, 5.1455e-08, 7.2885e-11,\n",
              "            1.8108e-08, 1.9561e-11, 7.5899e-07, 4.4762e-07, 2.1964e-04, 1.7669e-06,\n",
              "            6.5824e-07, 9.2186e-05, 2.7546e-07, 2.7400e-06, 3.2523e-07, 5.2348e-09,\n",
              "            1.6319e-05, 9.0610e-05, 6.7801e-05, 3.1289e-06, 2.6579e-07, 3.0629e-07,\n",
              "            3.3797e-04, 1.3052e-06, 3.7455e-07, 4.4167e-07, 3.8998e-07, 7.2200e-07,\n",
              "            6.2504e-08, 2.1888e-05, 1.1396e-08, 3.7373e-09, 1.1853e-06, 2.0932e-08,\n",
              "            7.0879e-07, 1.2781e-05, 6.0520e-04, 1.8080e-05, 6.8710e-10, 1.5846e-07,\n",
              "            5.2232e-08, 1.1324e-02, 2.8142e-08, 4.4746e-09, 1.1562e-08, 2.8121e-07,\n",
              "            7.8335e-10, 2.4104e-08, 3.1458e-07, 4.0459e-05, 8.3169e-06, 1.1347e-07,\n",
              "            2.6894e-06, 1.5514e-06, 1.0831e-09, 3.2044e-06, 2.1133e-07, 2.0980e-09],\n",
              "           [1.0000e+00, 1.4694e-08, 1.0133e-09, 1.2285e-05, 1.8761e-06, 1.5885e-09,\n",
              "            2.7029e-08, 5.5520e-09, 3.9986e-07, 1.0920e-06, 2.1007e-07, 1.6859e-08,\n",
              "            2.5917e-05, 1.7853e-08, 1.4163e-06, 9.4081e-05, 4.5084e-09, 2.9886e-10,\n",
              "            6.8294e-10, 2.2616e-10, 1.1561e-03, 7.0847e-04, 9.1924e-06, 4.5267e-07,\n",
              "            6.9889e-05, 2.5238e-05, 7.5730e-06, 9.2215e-05, 8.0055e-06, 2.1653e-06,\n",
              "            6.5114e-05, 9.5950e-04, 7.4653e-09, 1.4009e-08, 8.6728e-06, 4.5994e-07,\n",
              "            8.1604e-06, 3.5153e-03, 3.6552e-03, 4.5380e-06, 1.1563e-07, 1.2597e-07,\n",
              "            3.4687e-04, 1.5343e-05, 3.0789e-07, 8.7786e-06, 7.4151e-06, 1.0214e-05,\n",
              "            3.4308e-08, 8.5246e-06, 1.1075e-06, 1.2720e-04, 3.1545e-06, 2.3391e-06,\n",
              "            1.1398e-04, 1.0813e-04, 2.5281e-06, 8.3600e-05, 4.2243e-06, 2.2473e-07],\n",
              "           [1.0000e+00, 2.2976e-09, 9.5791e-10, 1.6321e-08, 2.7984e-10, 1.2582e-11,\n",
              "            3.5014e-09, 4.6045e-12, 3.4037e-08, 4.0854e-09, 1.5339e-04, 1.5164e-07,\n",
              "            3.6675e-07, 3.4443e-05, 1.7264e-07, 9.0294e-09, 1.0631e-08, 7.7198e-10,\n",
              "            1.6304e-04, 2.9996e-06, 1.6512e-09, 1.5236e-05, 3.3539e-08, 4.3087e-05,\n",
              "            6.3458e-06, 5.5138e-07, 5.6833e-08, 2.0346e-08, 4.8090e-07, 1.5130e-10,\n",
              "            2.9775e-08, 2.1385e-06, 3.0356e-10, 8.8338e-10, 2.9066e-06, 6.1674e-09,\n",
              "            9.7521e-07, 7.2482e-07, 3.1162e-03, 8.5989e-07, 3.9652e-12, 1.3471e-07,\n",
              "            6.8470e-07, 1.4679e-07, 2.3124e-06, 9.7684e-09, 2.0764e-07, 1.5219e-07,\n",
              "            1.7096e-09, 7.2666e-09, 1.4197e-09, 4.4462e-06, 3.4561e-10, 5.6571e-06,\n",
              "            5.2054e-08, 2.6149e-07, 8.4463e-10, 1.5666e-05, 8.4116e-05, 3.8859e-08],\n",
              "           [9.9995e-01, 7.0282e-07, 6.4608e-05, 1.7178e-05, 5.8516e-06, 1.1210e-07,\n",
              "            2.0330e-06, 1.6241e-07, 3.1625e-06, 1.1837e-06, 7.8761e-04, 4.8970e-07,\n",
              "            6.7472e-06, 9.6940e-07, 1.0227e-06, 2.2291e-06, 2.8287e-05, 5.6318e-05,\n",
              "            8.4620e-04, 3.2112e-04, 1.5857e-02, 1.8949e-06, 2.4766e-06, 1.1186e-03,\n",
              "            2.0443e-04, 6.0270e-07, 8.7567e-05, 7.7783e-05, 8.2623e-07, 6.1146e-08,\n",
              "            2.3263e-03, 2.9905e-06, 5.4144e-09, 3.2838e-09, 5.8866e-06, 1.1277e-07,\n",
              "            1.2968e-06, 1.2475e-05, 9.4444e-04, 3.7956e-05, 1.4509e-07, 2.4816e-07,\n",
              "            5.3636e-06, 3.6281e-05, 2.5063e-06, 5.6124e-03, 7.1182e-06, 4.5980e-06,\n",
              "            2.6416e-06, 4.2101e-04, 1.3581e-06, 8.8518e-06, 6.0118e-05, 9.7585e-06,\n",
              "            5.3817e-07, 5.7680e-06, 3.4097e-08, 1.6159e-03, 1.6987e-04, 7.6961e-05],\n",
              "           [1.0000e+00, 1.6764e-08, 2.0333e-09, 5.0270e-06, 6.3536e-09, 7.3294e-09,\n",
              "            5.6408e-10, 2.6849e-10, 2.1498e-08, 8.7252e-08, 3.4000e-07, 1.3743e-07,\n",
              "            1.8756e-08, 1.5674e-07, 4.3994e-06, 3.8385e-08, 1.1679e-07, 1.3176e-08,\n",
              "            4.7601e-08, 5.9795e-06, 8.2634e-07, 3.3670e-03, 1.1737e-07, 7.4426e-06,\n",
              "            1.0279e-03, 1.6013e-05, 7.4593e-05, 7.5997e-07, 2.9784e-05, 1.7308e-06,\n",
              "            1.6536e-06, 2.1980e-05, 2.5333e-09, 6.7790e-09, 9.6094e-04, 2.6920e-08,\n",
              "            1.0421e-07, 1.2366e-05, 3.5937e-04, 1.3101e-06, 5.9223e-12, 1.0582e-06,\n",
              "            5.0207e-07, 3.1304e-04, 7.4096e-07, 1.2826e-09, 3.7476e-07, 1.6902e-07,\n",
              "            7.6546e-09, 5.0803e-07, 8.8897e-08, 5.6808e-05, 1.0511e-09, 1.8759e-06,\n",
              "            1.1518e-07, 7.2294e-08, 1.3147e-08, 1.0474e-05, 4.3657e-06, 7.3055e-07],\n",
              "           [1.0000e+00, 7.1896e-10, 1.1613e-09, 1.3308e-08, 2.8522e-10, 8.8830e-13,\n",
              "            1.7202e-08, 3.8996e-14, 2.5088e-10, 4.6892e-09, 1.1360e-07, 1.6509e-06,\n",
              "            1.0352e-08, 3.4656e-07, 3.0760e-10, 1.4912e-11, 2.1520e-09, 6.1863e-12,\n",
              "            9.1983e-07, 6.0009e-07, 1.8064e-08, 6.6521e-07, 1.5204e-05, 4.6068e-08,\n",
              "            3.0187e-05, 4.2122e-07, 1.5096e-08, 3.0433e-08, 9.8407e-07, 1.2572e-08,\n",
              "            1.4075e-09, 2.5259e-05, 1.2667e-10, 3.3238e-09, 4.4602e-06, 3.2124e-06,\n",
              "            4.1917e-05, 4.9502e-08, 1.2138e-04, 6.2943e-07, 2.9188e-10, 4.0393e-07,\n",
              "            9.1621e-08, 4.0542e-05, 4.0177e-05, 9.7128e-07, 4.6288e-07, 2.4331e-06,\n",
              "            9.8961e-08, 7.0153e-07, 1.5918e-09, 1.0881e-05, 1.6008e-06, 7.7525e-07,\n",
              "            3.8078e-07, 1.2301e-07, 9.0307e-09, 2.7103e-06, 1.9539e-05, 7.9116e-08],\n",
              "           [1.0000e+00, 5.5563e-07, 1.3321e-09, 1.7945e-06, 1.0319e-07, 6.2541e-10,\n",
              "            9.0350e-08, 1.1229e-09, 3.7719e-07, 6.4339e-07, 9.0582e-05, 8.6594e-07,\n",
              "            6.6746e-04, 3.4156e-05, 2.0909e-07, 1.6511e-07, 4.1650e-08, 3.8062e-06,\n",
              "            1.7425e-05, 3.2503e-07, 3.3499e-06, 1.6568e-05, 1.0242e-06, 3.5275e-07,\n",
              "            3.1746e-06, 2.2717e-05, 3.0823e-03, 7.4670e-06, 1.1792e-06, 1.9805e-07,\n",
              "            2.7259e-06, 2.2173e-04, 2.0983e-08, 6.1300e-09, 1.9711e-05, 4.8493e-08,\n",
              "            1.4497e-06, 8.6237e-07, 3.8299e-02, 9.2404e-08, 1.4208e-10, 2.2442e-09,\n",
              "            7.2001e-05, 2.9413e-05, 1.4165e-06, 2.0306e-06, 2.0595e-05, 3.6205e-06,\n",
              "            3.0029e-09, 2.3811e-06, 3.1844e-07, 5.7643e-02, 1.0473e-08, 3.6804e-08,\n",
              "            3.0536e-08, 3.3364e-05, 3.9072e-08, 2.0740e-04, 7.0394e-05, 1.1587e-06],\n",
              "           [9.9999e-01, 2.2219e-08, 1.9896e-09, 2.8420e-06, 2.3417e-06, 1.0594e-09,\n",
              "            7.0712e-10, 2.5895e-11, 6.9810e-08, 1.4510e-05, 2.0317e-07, 2.3722e-08,\n",
              "            1.3871e-09, 1.2557e-06, 9.0635e-09, 1.8267e-08, 4.9185e-08, 1.3438e-10,\n",
              "            4.0021e-07, 7.5835e-06, 4.2334e-07, 9.2314e-06, 3.3440e-08, 8.6371e-10,\n",
              "            3.5014e-06, 1.2824e-07, 1.2819e-07, 4.2122e-07, 3.6333e-09, 8.9731e-05,\n",
              "            1.5174e-08, 5.3283e-07, 1.1248e-11, 3.1840e-10, 5.1602e-06, 3.3125e-09,\n",
              "            5.7798e-07, 9.8888e-07, 2.7515e-04, 1.5437e-08, 3.4590e-11, 1.4438e-09,\n",
              "            1.4081e-07, 4.6058e-05, 4.0230e-07, 1.0568e-08, 9.8126e-11, 3.8158e-10,\n",
              "            2.2561e-09, 7.5536e-07, 1.5315e-08, 1.5854e-04, 1.6941e-07, 4.7005e-07,\n",
              "            3.8005e-08, 4.1600e-06, 3.5966e-10, 6.2817e-07, 6.3055e-09, 4.8681e-07],\n",
              "           [1.0000e+00, 3.6234e-08, 8.3495e-08, 8.7862e-08, 2.9489e-08, 2.6652e-10,\n",
              "            4.8580e-09, 2.1569e-12, 5.9351e-09, 2.0739e-07, 3.1349e-08, 1.4274e-06,\n",
              "            4.2774e-09, 5.7307e-07, 3.0923e-09, 6.1393e-08, 8.1212e-08, 9.6838e-11,\n",
              "            1.4631e-06, 3.4028e-07, 2.7367e-08, 2.1152e-06, 5.8077e-09, 1.2873e-07,\n",
              "            4.9948e-06, 6.9965e-07, 1.1300e-09, 3.6716e-08, 1.8298e-06, 2.1394e-06,\n",
              "            1.0814e-10, 2.9016e-07, 2.4071e-11, 5.9327e-09, 1.2582e-06, 8.3965e-09,\n",
              "            3.8752e-07, 1.4718e-07, 7.4282e-06, 3.7510e-07, 3.3430e-11, 1.1491e-08,\n",
              "            2.2171e-09, 5.2087e-05, 2.1325e-06, 4.1989e-09, 7.8486e-09, 8.6940e-08,\n",
              "            1.1132e-09, 6.8157e-08, 8.8158e-10, 8.7358e-07, 5.1818e-08, 6.1939e-08,\n",
              "            2.7854e-09, 3.6010e-08, 7.9968e-09, 1.6058e-06, 4.2558e-08, 4.5688e-09]],\n",
              "          device='cuda:0', grad_fn=<CatBackward>)],\n",
              "  8: [tensor([[9.4308e-01, 1.6969e-03, 5.9912e-03, 7.7871e-03, 7.6981e-03, 4.0134e-03,\n",
              "            5.3719e-03, 9.4514e-03, 5.6826e-03, 8.1009e-02, 9.9040e-02, 1.0702e-03,\n",
              "            9.7548e-03, 1.4392e-02, 4.4638e-03, 7.5678e-03, 8.5898e-04, 2.4414e-03,\n",
              "            3.7499e-03, 7.4997e-03, 3.0166e-03, 1.1859e-02, 3.1481e-03, 5.3400e-03,\n",
              "            6.0824e-03, 3.1031e-04, 5.7328e-03, 4.7787e-04, 1.4566e-03, 1.9095e-03,\n",
              "            1.7848e-03, 3.4384e-03, 4.2011e-04, 2.9418e-04, 4.5399e-04, 1.2405e-03,\n",
              "            5.8337e-04, 7.6111e-03, 2.5756e-01, 1.3418e-04, 9.7953e-05, 3.5410e-04,\n",
              "            2.0313e-02, 3.7419e-03, 8.7271e-04, 2.8698e-03, 4.9797e-04, 1.5055e-04,\n",
              "            9.4158e-04, 1.0160e-03, 2.8769e-04, 2.3280e-03, 2.7061e-04, 3.2206e-04,\n",
              "            1.5732e-04, 2.1350e-03, 2.1308e-05, 5.3195e-04, 1.9381e-03, 8.0356e-03,\n",
              "            2.3347e-04, 1.1151e-05, 1.3145e-04, 2.7028e-05, 3.1019e-04, 3.1652e-05,\n",
              "            8.9817e-05, 1.0662e-04, 7.3734e-03, 4.7453e-04, 7.4809e-07, 1.3428e-07,\n",
              "            1.3304e-02, 2.6540e-07, 1.6141e-03, 3.6877e-09, 2.3556e-06, 1.8352e-05,\n",
              "            1.3258e-07, 1.4701e-04],\n",
              "           [9.8614e-01, 1.3109e-03, 2.3581e-02, 2.8633e-03, 3.4635e-03, 5.4196e-04,\n",
              "            1.1078e-02, 2.6177e-03, 8.0909e-03, 1.7301e-02, 2.3387e-02, 7.5468e-04,\n",
              "            1.3108e-02, 2.3864e-03, 1.0746e-03, 9.3913e-03, 2.5175e-03, 5.1850e-03,\n",
              "            3.3855e-03, 1.8511e-03, 7.6959e-03, 4.6336e-04, 2.0646e-02, 3.1522e-04,\n",
              "            7.1016e-04, 1.7143e-04, 4.0537e-03, 2.6275e-03, 4.9364e-04, 4.5354e-04,\n",
              "            1.7128e-03, 5.4326e-04, 6.8678e-04, 1.1202e-04, 2.1386e-04, 2.7407e-04,\n",
              "            1.2437e-03, 1.0241e-03, 3.0655e-02, 1.2360e-03, 2.2197e-03, 5.1814e-05,\n",
              "            4.6510e-04, 1.4973e-03, 1.1095e-04, 1.3456e-03, 1.5145e-03, 2.9357e-04,\n",
              "            2.3912e-05, 2.1774e-04, 4.7227e-04, 8.9019e-05, 3.2083e-04, 1.0866e-04,\n",
              "            3.2388e-03, 2.4704e-05, 2.4539e-05, 3.5199e-04, 1.0930e-03, 6.0589e-05,\n",
              "            5.1857e-07, 4.1612e-07, 1.8316e-04, 1.5397e-06, 1.0723e-04, 9.3734e-05,\n",
              "            4.7403e-04, 8.1533e-06, 1.2129e-05, 8.1942e-05, 2.6935e-06, 2.1854e-07,\n",
              "            1.1101e-05, 5.8804e-06, 8.2557e-09, 1.4009e-08, 5.9229e-07, 7.0805e-05,\n",
              "            1.2628e-09, 1.6259e-04],\n",
              "           [9.7506e-01, 3.4857e-04, 4.9763e-03, 6.8546e-04, 1.9751e-03, 6.6709e-04,\n",
              "            8.9399e-03, 1.9615e-02, 1.3287e-03, 5.2062e-02, 5.4385e-03, 2.8854e-04,\n",
              "            4.2968e-02, 5.8006e-04, 2.5112e-03, 8.0352e-03, 4.5674e-03, 1.6635e-03,\n",
              "            5.8377e-04, 1.9902e-03, 7.0493e-03, 3.8869e-03, 1.1303e-02, 7.0578e-05,\n",
              "            1.7068e-03, 1.4674e-04, 5.8585e-04, 1.9257e-04, 5.6884e-04, 5.6808e-04,\n",
              "            1.2225e-03, 3.4660e-04, 1.4171e-04, 1.3538e-05, 1.0156e-04, 1.0623e-03,\n",
              "            3.9055e-04, 6.8619e-03, 4.5121e-02, 1.0391e-04, 1.5231e-03, 8.3916e-05,\n",
              "            1.4735e-02, 6.1479e-04, 5.3245e-05, 1.1123e-04, 2.9211e-04, 3.1605e-04,\n",
              "            1.9758e-05, 1.2004e-04, 5.9385e-05, 2.7985e-04, 1.7485e-04, 1.1516e-04,\n",
              "            7.7251e-04, 9.1372e-05, 1.0154e-04, 2.5761e-05, 3.4242e-04, 1.2907e-04,\n",
              "            2.1913e-06, 2.6451e-07, 2.3497e-05, 3.4841e-06, 3.9611e-05, 1.9381e-04,\n",
              "            4.2797e-05, 8.6658e-05, 2.7293e-06, 4.9324e-04, 1.5405e-08, 9.5821e-08,\n",
              "            2.4224e-07, 8.7743e-07, 2.2753e-06, 5.3442e-10, 3.8053e-07, 1.9672e-06,\n",
              "            1.2582e-09, 2.7128e-05],\n",
              "           [9.9640e-01, 2.6567e-04, 1.8002e-03, 2.0001e-03, 8.4633e-04, 3.0770e-04,\n",
              "            2.8799e-03, 4.2715e-03, 1.8848e-04, 6.0365e-03, 1.5689e-02, 5.2775e-05,\n",
              "            8.0091e-04, 1.5645e-03, 2.7999e-04, 1.6630e-03, 7.1387e-05, 2.3579e-03,\n",
              "            1.9265e-03, 3.4511e-03, 6.9285e-05, 2.4253e-03, 2.7793e-03, 3.6616e-04,\n",
              "            2.9953e-04, 8.0784e-06, 1.1869e-03, 4.4884e-04, 1.2092e-04, 4.0874e-05,\n",
              "            2.5802e-04, 3.6141e-05, 1.8409e-05, 1.6313e-05, 5.3640e-05, 5.5259e-05,\n",
              "            1.5037e-04, 4.1542e-04, 3.5054e-02, 2.0558e-05, 2.4229e-06, 2.0095e-05,\n",
              "            9.3623e-05, 1.1257e-05, 1.4662e-04, 8.2610e-04, 1.0124e-04, 7.6018e-06,\n",
              "            9.7077e-06, 1.0598e-05, 8.3791e-06, 1.7474e-05, 1.9134e-06, 9.8064e-05,\n",
              "            2.1462e-05, 9.4141e-06, 3.7127e-07, 4.2563e-05, 4.1562e-04, 1.2305e-05,\n",
              "            4.8750e-07, 3.6269e-07, 9.8981e-07, 5.4176e-07, 6.5592e-08, 1.2070e-06,\n",
              "            8.4304e-05, 2.1658e-08, 9.5094e-06, 8.5164e-06, 1.9862e-08, 1.0607e-09,\n",
              "            2.0617e-05, 2.3985e-13, 3.6201e-10, 3.2427e-10, 6.0987e-10, 1.2066e-06,\n",
              "            2.9872e-10, 4.5776e-07],\n",
              "           [9.3289e-01, 1.0347e-03, 1.3682e-02, 4.8397e-03, 1.8752e-03, 7.3559e-03,\n",
              "            1.5574e-02, 2.3430e-02, 2.9477e-03, 2.4397e-02, 4.1962e-02, 7.7097e-03,\n",
              "            1.4922e-02, 3.1829e-03, 1.0936e-03, 5.8982e-03, 1.6160e-03, 1.8386e-02,\n",
              "            6.6610e-03, 7.0568e-03, 3.7405e-03, 2.3052e-03, 2.1268e-02, 5.1727e-03,\n",
              "            2.8095e-03, 1.0398e-04, 3.1916e-02, 3.9524e-03, 3.7544e-04, 4.5887e-04,\n",
              "            4.6738e-03, 1.1746e-03, 4.1528e-04, 1.1257e-03, 6.2506e-04, 7.8318e-03,\n",
              "            2.6489e-04, 9.6526e-04, 2.9644e-02, 3.1875e-03, 3.6397e-04, 4.0686e-04,\n",
              "            2.6843e-03, 7.0045e-04, 5.3003e-03, 2.9844e-03, 5.4218e-04, 1.2781e-03,\n",
              "            9.9652e-04, 9.4193e-04, 1.1848e-03, 1.7557e-03, 1.0044e-03, 6.5308e-04,\n",
              "            1.6863e-04, 9.5998e-04, 5.7496e-05, 1.0624e-03, 5.1361e-04, 2.8266e-03,\n",
              "            8.8471e-04, 2.5800e-05, 4.3461e-04, 2.0876e-05, 2.1553e-04, 1.1055e-05,\n",
              "            1.4866e-03, 2.5562e-04, 1.5243e-04, 1.1961e-04, 3.4258e-05, 1.8247e-06,\n",
              "            2.1950e-02, 1.4494e-06, 1.3393e-05, 4.5445e-08, 1.0348e-06, 7.5068e-04,\n",
              "            5.5829e-05, 1.8235e-04],\n",
              "           [9.9697e-01, 3.5543e-04, 2.1695e-03, 1.4785e-03, 3.5847e-03, 1.9473e-04,\n",
              "            1.2015e-03, 1.0719e-02, 6.9820e-04, 1.2981e-02, 3.4615e-03, 5.8750e-05,\n",
              "            2.8948e-03, 1.6494e-03, 4.6231e-03, 2.5263e-03, 1.4800e-04, 1.8093e-03,\n",
              "            3.4402e-04, 3.4637e-03, 1.1184e-04, 1.1756e-02, 1.2407e-03, 6.3130e-05,\n",
              "            2.7526e-03, 1.5619e-05, 9.1998e-03, 1.2146e-04, 2.1486e-04, 5.5411e-05,\n",
              "            9.8402e-03, 1.0103e-04, 1.4937e-05, 6.1835e-06, 3.4123e-04, 6.3220e-05,\n",
              "            4.0809e-05, 4.0106e-04, 8.6366e-02, 9.3403e-06, 4.7638e-06, 3.8060e-05,\n",
              "            1.8342e-03, 1.5472e-04, 7.0752e-05, 1.2220e-04, 7.5213e-05, 2.8026e-05,\n",
              "            6.0273e-06, 1.7682e-05, 8.4249e-05, 1.8579e-04, 8.7102e-07, 7.1981e-05,\n",
              "            1.8223e-05, 1.3055e-05, 2.1570e-06, 5.5885e-05, 6.2582e-05, 5.2499e-05,\n",
              "            6.2635e-07, 2.2007e-08, 6.0380e-07, 1.5160e-06, 6.5129e-07, 2.5839e-06,\n",
              "            2.7779e-05, 1.7704e-06, 4.6159e-06, 2.0202e-04, 3.1799e-09, 5.8062e-08,\n",
              "            4.3848e-07, 2.2538e-12, 5.3948e-07, 1.2322e-11, 1.1078e-09, 1.6958e-06,\n",
              "            6.1675e-12, 5.2219e-08],\n",
              "           [9.7552e-01, 5.5669e-04, 9.4657e-03, 1.3676e-02, 2.8971e-03, 7.0937e-04,\n",
              "            4.1131e-02, 2.8965e-03, 3.0524e-03, 1.3358e-02, 1.5802e-02, 6.5910e-04,\n",
              "            8.3502e-03, 7.4768e-03, 4.7061e-04, 2.4831e-02, 1.2145e-03, 2.1089e-03,\n",
              "            4.7546e-03, 8.6874e-03, 9.2459e-04, 2.2042e-03, 4.5602e-03, 1.3997e-03,\n",
              "            9.9126e-04, 4.3680e-05, 2.5652e-03, 1.0091e-03, 2.1285e-03, 3.6776e-04,\n",
              "            1.1618e-03, 1.2505e-03, 1.2874e-04, 8.4205e-05, 3.6129e-04, 2.1783e-04,\n",
              "            8.3247e-04, 1.2992e-03, 2.5521e-02, 1.1555e-03, 2.3192e-04, 4.8420e-05,\n",
              "            8.1090e-04, 2.7718e-04, 6.8667e-04, 7.7522e-04, 1.8561e-03, 1.7379e-04,\n",
              "            3.1222e-05, 5.2692e-04, 1.5029e-04, 1.9915e-04, 3.4502e-05, 1.7612e-05,\n",
              "            9.7630e-04, 1.7281e-04, 3.1181e-05, 3.7020e-05, 5.5331e-03, 8.6949e-05,\n",
              "            1.6553e-06, 2.0765e-06, 1.9343e-05, 1.0492e-06, 8.6678e-06, 5.3782e-05,\n",
              "            1.4433e-03, 1.7002e-05, 1.0023e-05, 7.5087e-05, 1.1457e-07, 4.0293e-09,\n",
              "            2.9606e-05, 3.2416e-08, 9.0236e-08, 1.4502e-09, 2.9475e-06, 1.3442e-06,\n",
              "            3.9773e-07, 2.6272e-04],\n",
              "           [9.8623e-01, 1.5408e-03, 4.0136e-03, 4.0613e-03, 1.1700e-02, 6.5664e-04,\n",
              "            1.0600e-02, 1.5150e-03, 2.6056e-03, 1.0542e-02, 9.7740e-02, 3.3390e-04,\n",
              "            1.8806e-02, 6.6977e-03, 4.8392e-04, 1.0928e-03, 4.8447e-04, 4.5067e-03,\n",
              "            7.9382e-03, 1.2399e-04, 1.7015e-03, 2.7596e-04, 5.9472e-04, 1.5292e-03,\n",
              "            4.5262e-04, 1.1377e-04, 6.3861e-03, 1.2976e-03, 8.1816e-05, 5.5422e-04,\n",
              "            7.1714e-04, 5.8742e-04, 5.6105e-04, 6.1204e-05, 5.9289e-04, 4.0549e-05,\n",
              "            5.4340e-04, 1.0452e-03, 2.1746e-01, 6.5626e-05, 3.4902e-05, 2.7803e-05,\n",
              "            9.1804e-04, 1.8542e-03, 2.2960e-04, 3.4032e-03, 4.0867e-04, 1.6612e-04,\n",
              "            1.1744e-05, 3.4709e-04, 3.9256e-04, 8.8260e-04, 2.3130e-05, 9.0323e-06,\n",
              "            8.4167e-05, 6.6294e-05, 4.0767e-06, 7.8251e-04, 4.0892e-04, 2.8875e-04,\n",
              "            3.1360e-06, 3.7472e-07, 3.4380e-04, 1.1417e-06, 5.2409e-05, 2.6125e-05,\n",
              "            1.4929e-05, 1.1255e-06, 8.7731e-03, 3.0006e-05, 1.0613e-07, 6.9378e-08,\n",
              "            5.2592e-03, 1.2557e-08, 7.8866e-06, 1.4724e-09, 3.1680e-09, 7.4911e-06,\n",
              "            8.9183e-09, 3.7546e-04],\n",
              "           [9.5387e-01, 3.3404e-04, 8.9344e-03, 2.6458e-03, 3.6143e-03, 4.5346e-03,\n",
              "            8.3959e-03, 2.1969e-03, 2.9310e-04, 2.7054e-02, 7.8259e-03, 8.0912e-04,\n",
              "            1.3685e-02, 1.5001e-03, 3.8254e-04, 2.8098e-03, 3.7324e-03, 9.2694e-04,\n",
              "            2.0364e-03, 1.4548e-03, 4.5294e-04, 3.1652e-03, 3.2496e-03, 2.2252e-04,\n",
              "            3.3608e-04, 4.6761e-05, 1.0825e-03, 3.5805e-04, 1.1403e-04, 4.8048e-04,\n",
              "            3.5857e-04, 1.5948e-04, 4.6703e-05, 4.6151e-04, 1.9173e-04, 3.3050e-04,\n",
              "            3.5905e-04, 2.1847e-03, 2.4816e-02, 1.1189e-04, 4.2059e-05, 1.7205e-05,\n",
              "            1.0523e-03, 2.7015e-04, 9.1240e-04, 4.5941e-04, 5.8846e-05, 1.1348e-04,\n",
              "            8.1502e-05, 4.1294e-04, 6.2991e-05, 4.4064e-04, 9.0456e-05, 8.1902e-05,\n",
              "            4.0000e-05, 4.2559e-04, 7.0318e-06, 2.7837e-05, 5.5091e-05, 3.3218e-04,\n",
              "            1.5775e-05, 3.3992e-07, 3.3222e-05, 3.1758e-06, 7.7171e-06, 3.6471e-05,\n",
              "            2.6756e-04, 3.0801e-05, 6.1091e-05, 9.0575e-05, 4.5713e-07, 1.9000e-09,\n",
              "            2.0763e-04, 2.2204e-08, 5.4442e-06, 2.2117e-10, 4.1531e-07, 1.0570e-05,\n",
              "            6.7734e-08, 7.0005e-05],\n",
              "           [9.8495e-01, 3.6151e-04, 1.4496e-03, 4.9361e-03, 1.3440e-03, 1.1974e-03,\n",
              "            5.4756e-03, 7.0155e-04, 4.3430e-04, 1.4952e-02, 2.2941e-03, 3.6386e-04,\n",
              "            5.1396e-03, 2.9121e-03, 8.5587e-05, 5.0929e-03, 2.6420e-04, 6.8767e-04,\n",
              "            1.4737e-03, 2.4386e-03, 9.8128e-05, 1.1433e-03, 9.1509e-04, 3.9278e-04,\n",
              "            3.2023e-04, 8.2986e-06, 6.6888e-04, 2.3251e-04, 3.3236e-04, 2.8164e-04,\n",
              "            2.1553e-04, 3.6256e-04, 2.6539e-05, 1.7148e-04, 8.2073e-05, 5.3300e-05,\n",
              "            1.0865e-04, 1.1269e-04, 2.5624e-02, 7.6121e-05, 1.7117e-05, 2.9619e-06,\n",
              "            8.5169e-05, 1.1078e-04, 3.1709e-04, 4.1681e-04, 4.7920e-05, 3.5512e-05,\n",
              "            1.5193e-05, 1.3317e-04, 1.1340e-05, 5.1034e-05, 1.3419e-05, 2.0641e-06,\n",
              "            1.1496e-05, 1.0110e-04, 5.6679e-06, 6.5519e-05, 3.9253e-05, 8.3295e-05,\n",
              "            1.5831e-06, 1.0931e-07, 3.2359e-06, 2.7279e-08, 4.9753e-06, 1.1016e-06,\n",
              "            1.3243e-04, 6.2487e-06, 1.8121e-06, 2.6639e-05, 4.5007e-08, 1.1243e-09,\n",
              "            4.3933e-05, 8.1461e-09, 2.4160e-08, 4.9452e-14, 1.3088e-07, 2.0312e-06,\n",
              "            2.3976e-09, 2.6576e-06]], device='cuda:0', grad_fn=<SigmoidBackward>),\n",
              "   tensor([[9.9995e-01, 3.8543e-06, 3.7210e-08, 2.7998e-04, 2.0512e-05, 6.6691e-08,\n",
              "            3.5782e-07, 8.4758e-08, 1.8237e-04, 1.7706e-05, 3.5138e-03, 1.1317e-06,\n",
              "            6.4768e-07, 6.8161e-03, 1.3220e-06, 2.9803e-06, 1.1470e-06, 5.4372e-07,\n",
              "            1.6254e-04, 1.8312e-04, 2.4752e-06, 4.6606e-05, 1.0194e-06, 5.2570e-03,\n",
              "            3.8288e-04, 2.5457e-06, 6.6563e-05, 2.6142e-07, 3.9403e-07, 7.3129e-07,\n",
              "            5.4256e-08, 1.3752e-03, 1.5161e-09, 2.3655e-09, 2.7402e-06, 2.7329e-08,\n",
              "            2.0449e-07, 2.7902e-07, 1.0307e-02, 3.8085e-08, 5.7589e-08, 3.7922e-06,\n",
              "            1.1800e-02, 1.9976e-03, 8.7775e-05, 4.2548e-06, 9.1367e-07, 1.3800e-07,\n",
              "            1.7369e-06, 2.7150e-05, 6.6856e-06, 2.0612e-03, 6.0428e-07, 2.0019e-07,\n",
              "            5.8310e-07, 1.4128e-04, 1.2140e-08, 6.9428e-05, 2.4681e-04, 1.0948e-03,\n",
              "            1.5926e-05, 7.1464e-09, 3.7409e-05, 2.0083e-05, 2.4351e-05, 6.5669e-08,\n",
              "            6.1810e-06, 3.6520e-06, 1.5456e-02, 2.2171e-04],\n",
              "           [1.0000e+00, 9.4053e-08, 8.7937e-09, 3.3226e-07, 8.8741e-08, 1.6719e-10,\n",
              "            1.2202e-08, 3.7142e-11, 1.1252e-06, 1.1779e-06, 3.8629e-05, 1.6952e-06,\n",
              "            3.9410e-07, 1.5253e-05, 1.8168e-07, 4.4161e-06, 1.1267e-06, 1.9442e-08,\n",
              "            1.9486e-05, 4.9739e-05, 1.5945e-04, 1.8670e-06, 2.4054e-06, 3.1782e-07,\n",
              "            1.8329e-04, 1.5559e-06, 1.4960e-05, 3.6864e-06, 2.8109e-06, 2.4413e-07,\n",
              "            2.6449e-07, 1.4501e-04, 9.3507e-09, 7.9092e-09, 1.2600e-06, 4.5784e-07,\n",
              "            9.3620e-06, 5.4682e-06, 2.5186e-04, 5.1157e-06, 6.8258e-09, 1.5502e-06,\n",
              "            4.6586e-07, 2.5774e-03, 5.1058e-07, 3.6559e-08, 1.9862e-07, 2.0569e-05,\n",
              "            2.3135e-08, 1.9949e-07, 1.4035e-06, 2.3318e-05, 1.3736e-04, 7.6934e-07,\n",
              "            1.5796e-05, 1.9655e-06, 2.1943e-08, 6.3629e-05, 1.9014e-05, 1.7694e-08,\n",
              "            3.2820e-09, 4.0654e-11, 1.8739e-05, 7.9312e-07, 1.5837e-06, 5.1070e-07,\n",
              "            4.4607e-05, 8.1075e-09, 4.2889e-07, 1.0146e-04],\n",
              "           [1.0000e+00, 4.1324e-09, 4.6021e-11, 6.4898e-06, 6.7102e-08, 1.6974e-10,\n",
              "            1.0111e-08, 1.1083e-09, 6.5034e-07, 2.0823e-07, 5.2708e-07, 2.4779e-07,\n",
              "            1.5499e-05, 1.5098e-05, 3.4266e-06, 1.9469e-06, 3.1823e-08, 1.4074e-09,\n",
              "            7.3219e-07, 3.4088e-07, 1.6819e-04, 3.7555e-04, 3.5587e-06, 1.4610e-06,\n",
              "            7.8943e-06, 2.4406e-05, 1.1695e-06, 4.0176e-06, 2.6596e-06, 1.5892e-03,\n",
              "            1.1230e-06, 1.8050e-04, 5.1300e-10, 2.4645e-09, 5.5102e-06, 1.3999e-08,\n",
              "            1.5458e-06, 3.7816e-05, 2.3327e-03, 3.9391e-07, 1.8454e-07, 8.1406e-07,\n",
              "            4.9291e-03, 1.6592e-05, 9.0325e-08, 3.9959e-07, 7.5091e-07, 4.1585e-06,\n",
              "            3.1299e-09, 1.0515e-05, 3.7392e-07, 1.1333e-03, 1.9652e-07, 8.5562e-08,\n",
              "            1.3862e-05, 2.3126e-05, 4.8181e-07, 7.1410e-05, 1.3861e-05, 2.7714e-07,\n",
              "            1.2093e-07, 8.5101e-09, 4.4683e-06, 9.0759e-06, 2.4726e-05, 7.6242e-06,\n",
              "            8.2390e-05, 4.5917e-06, 3.3653e-06, 1.4313e-04],\n",
              "           [1.0000e+00, 2.7745e-11, 9.8638e-12, 2.4537e-09, 3.8815e-12, 1.8392e-13,\n",
              "            3.4138e-11, 2.9719e-14, 2.9800e-10, 9.1221e-11, 7.7670e-07, 9.7454e-09,\n",
              "            1.2173e-08, 2.3472e-07, 1.3941e-08, 5.4388e-11, 5.2331e-10, 1.8892e-12,\n",
              "            2.0858e-05, 5.5174e-08, 2.7792e-10, 2.9494e-05, 1.7825e-08, 2.3028e-07,\n",
              "            8.4857e-07, 7.3048e-08, 2.8085e-09, 1.0003e-09, 1.8335e-07, 2.4063e-10,\n",
              "            1.0323e-09, 1.2631e-08, 2.5633e-12, 8.3800e-12, 1.6211e-07, 4.4563e-11,\n",
              "            1.9924e-08, 2.0965e-07, 3.6427e-04, 3.3363e-08, 1.6123e-14, 3.4795e-09,\n",
              "            2.0800e-09, 6.1225e-09, 2.2207e-08, 2.2135e-11, 1.7486e-09, 1.1053e-09,\n",
              "            2.2195e-12, 1.5090e-11, 7.9016e-13, 3.9505e-08, 9.3215e-12, 2.0233e-06,\n",
              "            3.1592e-09, 1.9993e-09, 6.1461e-12, 9.8232e-08, 4.3120e-07, 1.2162e-09,\n",
              "            1.3740e-08, 2.4971e-12, 2.8822e-09, 1.6846e-06, 8.4470e-10, 1.1118e-09,\n",
              "            2.2080e-06, 5.7458e-12, 6.4188e-08, 1.1100e-05],\n",
              "           [1.0000e+00, 2.4863e-09, 3.7890e-08, 8.0342e-08, 8.3442e-10, 9.8994e-11,\n",
              "            1.5079e-08, 1.2872e-10, 4.4617e-08, 5.8832e-09, 3.1726e-05, 3.1899e-06,\n",
              "            6.5969e-07, 1.3381e-06, 1.4833e-06, 1.0500e-06, 1.5252e-06, 3.3054e-07,\n",
              "            3.6328e-05, 1.3609e-02, 9.4915e-06, 4.1983e-04, 5.6737e-05, 1.0342e-04,\n",
              "            1.0421e-03, 1.6235e-06, 1.8496e-05, 1.4115e-05, 3.8417e-06, 1.9843e-07,\n",
              "            1.2454e-06, 8.9823e-07, 6.0152e-10, 5.1822e-10, 2.5458e-05, 1.3340e-08,\n",
              "            9.5067e-08, 1.5573e-07, 1.0621e-03, 3.1862e-05, 2.3527e-08, 3.6698e-07,\n",
              "            1.6169e-06, 1.8412e-05, 3.5400e-06, 1.2458e-05, 1.0373e-08, 1.0364e-07,\n",
              "            3.3977e-08, 1.0704e-05, 4.4034e-07, 3.3191e-05, 4.3635e-06, 4.8373e-05,\n",
              "            1.1449e-07, 3.6128e-05, 3.7043e-09, 2.8206e-03, 4.5422e-06, 3.2203e-06,\n",
              "            1.2668e-05, 1.7600e-07, 1.5664e-05, 1.2759e-05, 5.2632e-05, 1.4981e-06,\n",
              "            5.6935e-04, 6.6006e-07, 3.1444e-05, 1.2259e-04],\n",
              "           [1.0000e+00, 6.8802e-09, 7.1275e-10, 3.1137e-08, 7.5194e-10, 6.7332e-11,\n",
              "            1.5096e-09, 1.5674e-10, 3.3520e-09, 2.6925e-07, 5.5019e-06, 1.0293e-06,\n",
              "            5.1581e-07, 5.8058e-07, 9.1341e-06, 7.8345e-07, 1.7354e-07, 1.7715e-08,\n",
              "            7.7206e-07, 7.8664e-06, 1.3478e-07, 7.7339e-04, 2.2758e-08, 1.4848e-08,\n",
              "            1.3141e-04, 1.3243e-07, 5.6310e-07, 3.9980e-08, 2.9415e-05, 1.0517e-08,\n",
              "            1.9477e-07, 1.4443e-07, 1.2175e-11, 6.3647e-11, 3.3682e-06, 3.9417e-10,\n",
              "            7.7372e-08, 5.7733e-07, 2.4135e-04, 3.1303e-09, 4.3839e-12, 1.5552e-06,\n",
              "            1.6645e-05, 2.2935e-07, 7.6556e-08, 3.3937e-10, 6.0390e-08, 1.2848e-07,\n",
              "            1.8859e-10, 9.5263e-07, 2.0263e-08, 2.6432e-05, 1.2238e-11, 3.7486e-07,\n",
              "            1.9897e-09, 1.1568e-08, 2.1288e-10, 6.5519e-06, 5.1534e-08, 8.0389e-07,\n",
              "            1.2662e-08, 1.2089e-11, 2.3239e-09, 4.4050e-08, 1.5604e-08, 2.4015e-09,\n",
              "            1.5003e-06, 6.7564e-08, 3.0632e-07, 3.9776e-05],\n",
              "           [1.0000e+00, 6.0125e-10, 6.8573e-10, 8.1634e-08, 6.2866e-10, 1.9734e-12,\n",
              "            3.3121e-09, 7.4570e-14, 6.6286e-10, 1.7406e-08, 2.8339e-07, 2.4181e-06,\n",
              "            6.3475e-09, 2.0524e-08, 3.9015e-10, 3.2800e-11, 4.4937e-09, 8.4642e-12,\n",
              "            1.9651e-07, 8.0757e-07, 1.5446e-08, 2.3092e-06, 1.3749e-05, 6.6194e-08,\n",
              "            8.9313e-06, 9.7710e-07, 2.5053e-08, 3.0326e-08, 8.1466e-07, 8.4019e-08,\n",
              "            8.5187e-10, 5.3332e-06, 7.3629e-11, 2.8234e-09, 1.1210e-06, 1.5172e-07,\n",
              "            7.2702e-06, 2.8553e-07, 2.2074e-05, 4.0705e-06, 7.2810e-11, 1.1767e-07,\n",
              "            4.2065e-07, 8.1750e-05, 8.5374e-06, 4.0424e-07, 2.8395e-07, 4.4990e-06,\n",
              "            1.1985e-07, 4.1031e-07, 4.5236e-08, 1.7433e-05, 3.5602e-07, 1.3286e-06,\n",
              "            4.3971e-06, 3.1805e-06, 3.8787e-08, 1.3698e-06, 6.1680e-05, 7.6375e-07,\n",
              "            4.6592e-09, 2.2510e-10, 5.4034e-07, 1.7093e-06, 3.0087e-08, 1.2928e-08,\n",
              "            6.8055e-05, 5.0068e-10, 4.6618e-07, 8.3417e-06],\n",
              "           [1.0000e+00, 3.1227e-08, 4.9655e-11, 6.8075e-07, 1.1669e-08, 2.4256e-11,\n",
              "            3.2623e-09, 1.9238e-11, 6.2050e-08, 2.1280e-08, 2.6576e-05, 8.2531e-08,\n",
              "            2.2252e-05, 8.1314e-06, 4.7125e-08, 3.7391e-08, 2.9591e-08, 1.3458e-06,\n",
              "            4.8169e-06, 3.8172e-08, 2.7021e-05, 2.1078e-05, 1.0296e-07, 1.0411e-06,\n",
              "            1.0569e-06, 1.1004e-05, 8.3961e-05, 1.6329e-04, 3.1522e-07, 3.5020e-07,\n",
              "            1.0574e-06, 1.2782e-04, 4.2530e-08, 6.3662e-09, 5.6604e-05, 3.2895e-09,\n",
              "            1.3321e-06, 1.2995e-06, 3.4792e-02, 7.0495e-07, 9.8077e-12, 4.0289e-10,\n",
              "            8.5246e-06, 6.0714e-07, 5.5201e-08, 4.9221e-06, 3.2612e-06, 3.6876e-06,\n",
              "            6.2048e-11, 3.1803e-07, 2.1119e-08, 5.4231e-03, 1.4845e-09, 1.0536e-09,\n",
              "            1.0426e-09, 1.3409e-06, 3.9176e-09, 2.1262e-03, 5.7657e-07, 4.1086e-08,\n",
              "            1.0684e-08, 3.6794e-09, 4.2090e-05, 7.8979e-08, 2.7173e-05, 8.5113e-08,\n",
              "            1.1470e-05, 5.3237e-09, 3.8519e-03, 7.4863e-06],\n",
              "           [1.0000e+00, 6.9932e-08, 6.1757e-09, 2.5633e-07, 1.9209e-07, 1.7097e-10,\n",
              "            3.2071e-09, 7.3026e-12, 1.4059e-08, 3.7106e-07, 3.7448e-07, 2.4895e-07,\n",
              "            2.2723e-09, 3.8688e-07, 1.5765e-11, 5.4212e-08, 2.0857e-09, 1.2918e-13,\n",
              "            3.4852e-08, 2.2144e-08, 6.0391e-05, 3.0228e-06, 1.6541e-08, 1.1326e-07,\n",
              "            4.7086e-05, 8.8018e-09, 6.0401e-07, 3.8812e-06, 3.2836e-08, 1.2349e-04,\n",
              "            1.3158e-09, 2.5984e-07, 3.8397e-11, 5.7657e-11, 2.0069e-05, 5.9866e-11,\n",
              "            6.7844e-08, 2.8017e-09, 1.1067e-04, 5.3349e-08, 5.0622e-11, 1.3011e-09,\n",
              "            4.1192e-08, 1.2763e-04, 5.6285e-07, 2.8728e-07, 2.3875e-09, 7.0943e-09,\n",
              "            2.4701e-08, 7.4663e-05, 2.6212e-08, 5.2553e-05, 1.4163e-06, 2.0694e-05,\n",
              "            2.9007e-08, 3.7918e-06, 3.6722e-08, 2.6142e-05, 1.6043e-07, 1.7868e-05,\n",
              "            1.5131e-08, 8.7845e-10, 7.9473e-06, 1.3870e-06, 4.5001e-07, 6.2283e-09,\n",
              "            3.0737e-04, 4.1916e-07, 1.5818e-05, 5.6301e-06],\n",
              "           [9.9908e-01, 2.4686e-06, 1.0012e-07, 9.7268e-06, 1.5495e-05, 2.0025e-09,\n",
              "            3.1259e-07, 1.1191e-09, 2.3730e-06, 5.6846e-04, 9.4779e-07, 5.6614e-06,\n",
              "            2.6592e-08, 2.8935e-05, 8.4761e-09, 1.7907e-08, 1.9392e-07, 9.2735e-09,\n",
              "            6.9976e-05, 4.6603e-05, 3.0517e-08, 7.9450e-06, 3.1874e-09, 2.7599e-07,\n",
              "            6.9577e-06, 9.8038e-08, 2.4853e-08, 1.4453e-08, 4.6981e-06, 9.8826e-05,\n",
              "            7.3242e-11, 1.0158e-05, 2.0952e-11, 2.8253e-10, 3.0429e-06, 8.4373e-09,\n",
              "            3.8399e-07, 2.7019e-09, 8.8411e-07, 3.7349e-08, 1.5131e-12, 2.7576e-09,\n",
              "            1.4064e-10, 1.1535e-03, 1.7190e-06, 1.4252e-08, 2.0807e-10, 1.5373e-08,\n",
              "            3.2981e-08, 7.7455e-08, 1.3849e-10, 5.2133e-07, 1.6189e-07, 3.9482e-09,\n",
              "            1.0246e-10, 2.1076e-09, 1.3844e-09, 4.7442e-07, 2.4197e-10, 2.7533e-09,\n",
              "            7.9573e-10, 3.5811e-12, 2.2580e-07, 1.5613e-08, 3.0426e-08, 2.1594e-10,\n",
              "            2.7919e-05, 1.0155e-08, 7.9849e-08, 1.5416e-06]], device='cuda:0',\n",
              "          grad_fn=<CatBackward>)],\n",
              "  9: [tensor([[9.1711e-01, 1.0010e-03, 2.9850e-03, 4.3067e-03, 9.6675e-03, 4.2705e-03,\n",
              "            4.3700e-03, 4.4590e-03, 3.3410e-03, 9.2555e-02, 6.7271e-02, 1.4341e-03,\n",
              "            1.3616e-02, 2.2734e-02, 1.5304e-03, 5.3759e-03, 3.8469e-04, 3.8317e-03,\n",
              "            2.5059e-03, 3.5212e-03, 3.2598e-03, 3.4173e-03, 4.0834e-03, 7.0849e-03,\n",
              "            2.9551e-03, 3.2065e-04, 1.4053e-03, 7.5724e-04, 1.0811e-03, 5.7240e-03,\n",
              "            8.4250e-04, 5.2245e-03, 5.8078e-04, 2.7282e-04, 2.6425e-04, 1.3326e-03,\n",
              "            1.7501e-04, 1.9365e-02, 1.0328e-01, 3.6375e-04, 4.1844e-04, 2.8159e-04,\n",
              "            1.0474e-02, 4.8729e-03, 1.2269e-03, 1.2828e-03, 4.6640e-04, 9.8948e-05,\n",
              "            9.7559e-04, 7.7003e-04, 3.4308e-04, 4.1613e-03, 1.0883e-03, 1.8371e-04,\n",
              "            2.6144e-04, 1.2900e-03, 4.6879e-05, 3.4565e-04, 1.2521e-03, 1.1276e-02,\n",
              "            1.2117e-04, 2.1633e-05, 3.7097e-04, 4.4541e-05, 2.5575e-03, 1.0392e-04,\n",
              "            2.3488e-04, 8.1360e-04, 1.9419e-03, 4.1325e-04, 6.3988e-06, 6.0376e-05,\n",
              "            4.5467e-03, 2.1710e-05, 2.3453e-03, 4.5627e-06, 1.1446e-05, 2.6601e-04,\n",
              "            6.7132e-05, 2.1671e-03, 2.1455e-07, 4.7834e-05, 1.2080e-08, 6.7917e-04,\n",
              "            1.4877e-05, 4.3658e-07, 1.4592e-05, 4.6550e-04, 2.6897e-09, 2.0758e-04],\n",
              "           [9.8823e-01, 1.0003e-03, 1.5907e-02, 1.3114e-03, 7.7452e-03, 2.0122e-04,\n",
              "            1.3319e-02, 4.0391e-03, 7.6404e-03, 1.8415e-02, 2.7052e-02, 9.7337e-04,\n",
              "            2.2777e-02, 3.5109e-03, 1.6707e-03, 5.3010e-03, 8.1128e-04, 5.9936e-03,\n",
              "            3.9368e-03, 1.2546e-03, 2.7505e-02, 2.4494e-03, 4.9367e-03, 6.0558e-04,\n",
              "            1.5756e-03, 2.0179e-04, 2.5337e-03, 1.5572e-03, 7.1438e-04, 1.0764e-03,\n",
              "            4.4489e-03, 1.2303e-03, 1.6154e-03, 5.5858e-05, 1.3489e-04, 1.0720e-03,\n",
              "            8.1980e-04, 5.4979e-03, 2.2018e-01, 1.3588e-03, 7.7695e-03, 2.5131e-04,\n",
              "            4.4171e-03, 2.1587e-03, 1.3432e-04, 8.7588e-04, 1.4394e-03, 1.4181e-03,\n",
              "            6.4061e-05, 2.5139e-04, 1.5558e-03, 5.1485e-04, 1.5736e-03, 5.4944e-04,\n",
              "            1.7462e-03, 7.7466e-05, 2.6704e-04, 5.6325e-04, 7.0358e-04, 9.8463e-04,\n",
              "            2.6989e-05, 2.9362e-06, 9.6763e-04, 2.8930e-05, 1.9670e-03, 9.7301e-05,\n",
              "            4.6234e-04, 2.7209e-04, 1.9450e-04, 2.7940e-04, 1.9293e-05, 3.1882e-04,\n",
              "            3.0777e-04, 3.1422e-04, 7.6355e-06, 2.8728e-05, 5.3991e-06, 4.6953e-03,\n",
              "            5.8800e-06, 3.7991e-03, 3.5583e-04, 8.7017e-07, 1.7790e-06, 3.2651e-05,\n",
              "            3.6296e-06, 4.9355e-05, 7.8275e-06, 3.0410e-04, 2.1874e-07, 2.2250e-05],\n",
              "           [9.6161e-01, 4.5023e-04, 7.7009e-03, 1.2093e-03, 5.4437e-03, 3.4461e-04,\n",
              "            1.6401e-02, 2.3887e-02, 4.6167e-03, 2.2577e-02, 1.4909e-02, 6.3082e-04,\n",
              "            6.2737e-02, 1.7520e-03, 4.7185e-03, 1.0174e-02, 1.9194e-03, 2.9479e-03,\n",
              "            7.8251e-04, 1.0709e-03, 5.6524e-03, 3.4388e-03, 6.2081e-03, 2.6702e-04,\n",
              "            2.8832e-03, 1.0215e-03, 1.2481e-03, 7.1039e-04, 5.9581e-04, 8.4564e-04,\n",
              "            3.3089e-03, 9.9975e-04, 2.7830e-04, 2.3013e-05, 4.7074e-04, 1.0505e-03,\n",
              "            3.8093e-04, 1.6833e-02, 6.7556e-02, 5.7785e-04, 1.2843e-03, 2.7320e-04,\n",
              "            2.7280e-02, 1.6838e-03, 9.7255e-05, 4.9843e-04, 1.4503e-03, 9.9595e-04,\n",
              "            3.6133e-05, 1.0402e-04, 4.8291e-04, 1.0505e-03, 8.8653e-05, 6.8041e-04,\n",
              "            6.9025e-03, 1.5297e-04, 2.2175e-04, 2.2346e-04, 3.0184e-03, 4.7027e-04,\n",
              "            2.1300e-05, 1.2560e-05, 8.4706e-04, 2.8062e-05, 1.2594e-04, 6.3286e-04,\n",
              "            6.6629e-05, 5.0504e-05, 7.5053e-05, 5.9458e-04, 3.3466e-06, 3.4235e-05,\n",
              "            4.6686e-05, 6.3546e-06, 1.5481e-05, 5.2941e-05, 3.4310e-06, 3.0208e-04,\n",
              "            7.4664e-06, 1.8537e-04, 7.6302e-07, 1.6768e-07, 9.5593e-08, 1.1992e-04,\n",
              "            5.1803e-07, 4.9380e-06, 5.1964e-07, 1.2657e-06, 2.9567e-07, 1.4457e-05],\n",
              "           [9.6688e-01, 2.1980e-03, 1.3638e-02, 7.0172e-03, 4.9016e-03, 1.9688e-03,\n",
              "            3.1275e-02, 1.7625e-02, 1.2726e-03, 1.0381e-02, 1.8133e-02, 1.2214e-03,\n",
              "            1.0495e-02, 1.0325e-02, 2.0561e-03, 3.0607e-03, 7.1460e-04, 1.3293e-02,\n",
              "            2.4309e-02, 8.2316e-03, 1.1448e-03, 1.3915e-02, 1.1981e-02, 2.9346e-03,\n",
              "            1.7882e-03, 1.2340e-04, 7.5622e-03, 1.7124e-03, 8.3816e-04, 1.0656e-03,\n",
              "            2.5933e-03, 8.8672e-04, 2.5513e-04, 2.5811e-04, 2.3032e-03, 2.0878e-03,\n",
              "            1.1153e-03, 2.8094e-03, 8.1746e-02, 5.2358e-04, 1.4668e-04, 7.3809e-04,\n",
              "            2.3325e-03, 3.1953e-04, 2.3527e-03, 1.1273e-03, 1.0329e-03, 1.3155e-03,\n",
              "            1.7280e-04, 2.0725e-04, 5.2099e-04, 3.0421e-03, 1.0325e-04, 1.4445e-03,\n",
              "            1.5060e-04, 1.5897e-04, 1.3892e-04, 4.8615e-04, 2.2367e-03, 4.4547e-04,\n",
              "            2.1831e-04, 6.1462e-05, 1.0088e-04, 7.8136e-05, 3.6164e-05, 1.5768e-04,\n",
              "            3.3599e-03, 2.6820e-05, 6.6461e-04, 1.9939e-04, 2.2300e-05, 7.8091e-05,\n",
              "            8.0393e-04, 4.4948e-07, 9.7120e-05, 1.8674e-05, 4.3931e-06, 4.3405e-04,\n",
              "            2.0675e-05, 9.1487e-05, 2.3799e-06, 4.5463e-07, 1.0070e-06, 7.5293e-06,\n",
              "            6.6177e-07, 7.0287e-06, 1.8625e-06, 6.8329e-05, 3.4067e-06, 1.5572e-06],\n",
              "           [9.3015e-01, 2.1857e-03, 2.0865e-02, 7.8275e-03, 6.6724e-03, 5.3074e-03,\n",
              "            1.2594e-02, 5.7089e-02, 8.6756e-03, 1.5385e-02, 8.1017e-02, 6.3789e-03,\n",
              "            1.3207e-02, 6.9315e-03, 7.9827e-03, 1.0227e-02, 1.2117e-03, 4.6871e-02,\n",
              "            6.7880e-03, 6.2191e-03, 7.0073e-03, 6.2950e-03, 1.7086e-02, 9.4933e-03,\n",
              "            5.0171e-03, 5.8494e-04, 5.3913e-02, 1.1178e-02, 8.8974e-04, 1.2896e-03,\n",
              "            1.7022e-02, 3.0007e-03, 1.0717e-03, 8.2749e-04, 1.8435e-03, 1.1413e-02,\n",
              "            5.4737e-04, 5.4242e-03, 6.1530e-02, 3.3063e-03, 1.3618e-03, 1.6114e-03,\n",
              "            1.6030e-02, 1.9762e-03, 5.0185e-03, 9.1918e-03, 1.7148e-03, 1.9985e-03,\n",
              "            1.6088e-03, 1.1683e-03, 6.6904e-03, 3.2227e-03, 2.1280e-03, 7.5081e-03,\n",
              "            9.0095e-04, 2.4619e-03, 4.5818e-04, 4.5602e-03, 2.6267e-03, 3.0602e-03,\n",
              "            2.2776e-03, 8.5371e-05, 2.0115e-03, 4.5407e-04, 1.4996e-03, 4.8977e-04,\n",
              "            4.1680e-03, 6.0431e-04, 1.1565e-03, 6.2601e-04, 2.0180e-04, 8.3425e-04,\n",
              "            8.5401e-03, 6.7228e-05, 9.2041e-04, 6.8828e-04, 4.6154e-05, 1.2259e-03,\n",
              "            6.5790e-04, 5.7310e-03, 5.2390e-04, 4.0174e-06, 9.5671e-07, 5.2296e-04,\n",
              "            2.9926e-05, 2.9043e-04, 1.3694e-04, 1.6519e-04, 4.5518e-04, 7.7946e-04],\n",
              "           [9.9154e-01, 4.8844e-04, 5.1979e-03, 2.0213e-03, 8.0798e-03, 2.0518e-04,\n",
              "            3.1996e-03, 2.0363e-02, 1.7466e-03, 1.4460e-02, 1.1441e-02, 1.7134e-04,\n",
              "            1.2768e-02, 7.3745e-03, 3.5262e-03, 2.1754e-03, 2.7967e-04, 1.1812e-02,\n",
              "            9.8841e-04, 4.0629e-03, 1.0166e-03, 2.1418e-02, 1.4499e-03, 4.0895e-04,\n",
              "            6.2662e-03, 9.5776e-05, 1.5170e-02, 9.3584e-04, 3.0259e-04, 3.6403e-04,\n",
              "            1.9603e-02, 9.0770e-04, 1.7815e-04, 1.8056e-05, 7.8759e-04, 4.2453e-04,\n",
              "            9.9721e-05, 2.0361e-03, 2.4384e-01, 1.8885e-04, 1.8781e-04, 4.3375e-04,\n",
              "            5.4198e-03, 6.8650e-04, 3.9648e-04, 7.5535e-04, 3.9223e-04, 3.4189e-04,\n",
              "            3.5732e-05, 1.4437e-04, 8.6084e-04, 1.3369e-03, 4.3833e-05, 3.5373e-04,\n",
              "            1.1076e-04, 7.6251e-05, 7.1608e-05, 5.7108e-04, 2.4657e-04, 2.0879e-03,\n",
              "            1.8814e-05, 2.8161e-06, 3.6558e-05, 3.8405e-05, 1.5460e-04, 2.0478e-05,\n",
              "            7.4715e-04, 1.0026e-04, 1.7387e-04, 1.8291e-04, 6.9562e-06, 1.1339e-04,\n",
              "            6.3611e-04, 1.1480e-06, 3.5075e-04, 1.0432e-05, 3.1910e-07, 4.9007e-04,\n",
              "            1.4031e-06, 5.1939e-05, 7.4980e-04, 3.9148e-08, 1.3370e-08, 1.4394e-06,\n",
              "            1.5273e-06, 1.3286e-07, 1.5073e-06, 7.1971e-05, 8.9996e-07, 2.2124e-06],\n",
              "           [9.7489e-01, 5.0468e-04, 9.1569e-03, 9.2901e-03, 6.6405e-03, 4.0770e-04,\n",
              "            3.8753e-02, 4.2500e-03, 8.6792e-04, 5.4301e-03, 1.1541e-02, 1.0807e-03,\n",
              "            7.4427e-03, 8.4811e-03, 3.9979e-04, 4.1591e-03, 3.9630e-04, 1.0153e-02,\n",
              "            7.1530e-03, 2.5960e-03, 6.2576e-04, 2.0869e-03, 4.7744e-03, 1.0506e-03,\n",
              "            9.9518e-04, 3.6497e-05, 3.0112e-03, 1.1544e-03, 5.9165e-04, 1.1223e-03,\n",
              "            1.6535e-03, 1.7131e-03, 1.5425e-04, 1.1321e-04, 5.5596e-04, 3.7894e-04,\n",
              "            7.0241e-04, 1.1762e-03, 2.4723e-02, 9.1865e-04, 2.6063e-04, 6.6612e-05,\n",
              "            5.8708e-04, 3.4879e-04, 1.2017e-03, 3.9968e-04, 7.7914e-04, 4.4285e-04,\n",
              "            3.7430e-05, 2.3852e-04, 5.6067e-04, 1.5306e-03, 1.5035e-04, 7.0854e-05,\n",
              "            2.2522e-04, 2.5200e-05, 7.4763e-05, 4.8351e-05, 2.3296e-03, 9.8424e-05,\n",
              "            3.0215e-05, 4.5637e-06, 1.5523e-04, 1.2504e-05, 1.7878e-05, 8.4747e-05,\n",
              "            3.0142e-03, 1.1744e-04, 5.8863e-05, 3.2607e-05, 1.0191e-05, 3.5890e-06,\n",
              "            1.2741e-03, 9.6195e-07, 2.7706e-06, 6.3097e-06, 9.8562e-06, 4.4204e-05,\n",
              "            3.0057e-05, 2.4578e-04, 9.5493e-06, 7.3681e-07, 9.0218e-07, 2.9223e-04,\n",
              "            4.3100e-09, 1.1821e-07, 2.3263e-08, 4.7509e-05, 1.3145e-07, 1.4226e-07],\n",
              "           [9.6882e-01, 9.8827e-04, 4.6446e-03, 5.0450e-03, 8.0317e-03, 1.0137e-03,\n",
              "            1.3395e-02, 3.8505e-03, 2.3825e-03, 2.7827e-02, 1.3194e-01, 6.5746e-04,\n",
              "            4.3756e-02, 1.4028e-02, 1.0366e-03, 1.4748e-03, 3.2026e-04, 2.7197e-03,\n",
              "            8.8438e-03, 5.4699e-04, 1.4652e-03, 1.0447e-03, 1.5880e-03, 4.3574e-03,\n",
              "            5.1273e-04, 3.6991e-04, 5.7032e-03, 1.1487e-03, 2.9706e-04, 1.1603e-03,\n",
              "            1.7154e-03, 1.3446e-03, 3.6110e-04, 2.1099e-04, 1.1211e-03, 1.8495e-04,\n",
              "            1.5722e-04, 6.4819e-03, 2.5838e-01, 2.2066e-04, 1.5489e-04, 3.7068e-04,\n",
              "            5.2041e-03, 2.7529e-03, 4.7270e-04, 2.0425e-03, 6.9287e-04, 3.7818e-04,\n",
              "            5.5204e-05, 1.1074e-03, 7.2996e-04, 7.0162e-04, 5.6425e-05, 3.4223e-04,\n",
              "            1.1373e-04, 3.7295e-04, 3.3031e-05, 9.1048e-04, 1.4205e-03, 6.4006e-03,\n",
              "            2.3067e-05, 1.2772e-05, 4.4753e-04, 8.0976e-05, 6.2572e-04, 7.3427e-05,\n",
              "            8.7490e-05, 4.4185e-05, 2.1092e-02, 9.9245e-05, 7.8117e-06, 4.0309e-05,\n",
              "            9.5159e-03, 1.6777e-05, 2.0896e-04, 8.4745e-06, 3.5957e-06, 5.9918e-03,\n",
              "            4.8502e-06, 8.8648e-04, 2.0483e-05, 7.1405e-07, 2.6265e-07, 4.0342e-07,\n",
              "            2.0433e-02, 8.7856e-06, 1.8866e-03, 2.5797e-04, 6.2815e-08, 3.9771e-06],\n",
              "           [9.0755e-01, 9.0974e-04, 4.1858e-02, 1.0816e-02, 9.1266e-03, 9.1146e-03,\n",
              "            1.2061e-02, 3.5740e-02, 3.5240e-03, 4.0801e-02, 3.7978e-02, 1.5316e-02,\n",
              "            1.0678e-02, 1.3756e-02, 7.7507e-03, 9.1767e-03, 2.5517e-03, 2.0397e-02,\n",
              "            5.5274e-03, 1.4609e-02, 5.3045e-03, 2.4224e-02, 1.4905e-02, 6.3370e-03,\n",
              "            7.7243e-03, 4.7850e-04, 2.5453e-02, 1.7608e-03, 2.6367e-03, 3.7058e-03,\n",
              "            5.2457e-03, 2.4568e-03, 5.4998e-04, 5.9156e-03, 1.2417e-03, 1.5712e-02,\n",
              "            9.6542e-04, 6.3795e-03, 1.4326e-01, 4.5866e-03, 8.1429e-04, 9.4325e-04,\n",
              "            1.1113e-02, 2.0783e-03, 1.8990e-02, 3.9697e-03, 1.0535e-03, 2.0466e-03,\n",
              "            5.1831e-03, 3.2465e-03, 4.4922e-03, 6.2555e-03, 4.8855e-03, 9.9823e-03,\n",
              "            5.0969e-04, 4.5807e-03, 4.8476e-04, 4.8764e-04, 1.4968e-03, 1.0912e-02,\n",
              "            2.1983e-03, 1.0154e-04, 5.3146e-04, 7.2580e-04, 3.1422e-03, 7.9724e-04,\n",
              "            2.4083e-02, 4.3651e-03, 2.8891e-03, 2.5372e-03, 2.3270e-04, 5.6523e-04,\n",
              "            5.0415e-02, 1.1188e-04, 5.0022e-03, 4.7912e-04, 1.0221e-03, 1.7698e-03,\n",
              "            6.0669e-04, 2.3459e-03, 2.1274e-03, 1.7852e-06, 8.3191e-05, 1.2768e-03,\n",
              "            5.5910e-03, 4.2627e-05, 1.3283e-04, 1.8549e-03, 1.2477e-04, 8.2422e-04],\n",
              "           [9.9659e-01, 9.9988e-05, 2.7562e-03, 1.6506e-03, 1.1031e-03, 6.6678e-05,\n",
              "            3.7632e-03, 4.8857e-04, 1.3065e-04, 2.9146e-03, 1.4494e-03, 1.2309e-04,\n",
              "            2.0133e-03, 3.0173e-03, 3.7704e-05, 7.1642e-04, 6.2242e-05, 2.3234e-03,\n",
              "            6.8653e-04, 5.8913e-04, 1.7560e-04, 9.0725e-04, 8.5801e-04, 1.1064e-04,\n",
              "            2.2841e-04, 2.2579e-06, 2.4474e-04, 8.4441e-05, 1.2125e-04, 2.6566e-04,\n",
              "            1.3444e-04, 2.7682e-04, 1.3624e-05, 8.3291e-06, 3.7412e-05, 7.3785e-05,\n",
              "            7.6289e-05, 1.2956e-04, 5.9243e-02, 9.3485e-05, 4.0475e-05, 2.7217e-06,\n",
              "            1.9663e-04, 4.0591e-05, 1.3290e-04, 4.5788e-05, 6.7731e-05, 3.9036e-05,\n",
              "            1.3160e-06, 1.3462e-05, 1.9565e-05, 2.6119e-04, 1.6297e-05, 4.5729e-06,\n",
              "            1.9220e-05, 2.2146e-06, 8.3672e-06, 5.7262e-06, 9.9817e-05, 2.4808e-05,\n",
              "            1.5341e-06, 6.3370e-08, 1.1457e-05, 1.7743e-07, 2.2563e-06, 1.9828e-06,\n",
              "            4.5867e-04, 6.6181e-06, 5.0997e-06, 4.0477e-06, 4.1308e-07, 1.1524e-06,\n",
              "            4.7731e-05, 2.0896e-08, 6.3924e-07, 3.8762e-08, 7.5432e-08, 1.5409e-05,\n",
              "            1.6040e-07, 7.4333e-06, 8.2627e-07, 2.0538e-10, 1.6219e-09, 3.8425e-06,\n",
              "            3.2495e-10, 1.6146e-08, 5.5142e-11, 1.1678e-06, 7.4937e-11, 1.2263e-05]],\n",
              "          device='cuda:0', grad_fn=<SigmoidBackward>),\n",
              "   tensor([[1.0000e+00, 1.7307e-07, 3.0456e-09, 1.7270e-05, 6.4998e-08, 6.8176e-09,\n",
              "            5.9874e-09, 2.5287e-09, 6.5237e-07, 3.3236e-06, 1.2421e-05, 1.7091e-07,\n",
              "            3.2444e-07, 2.6255e-04, 3.1532e-08, 7.4034e-08, 5.6564e-09, 3.1431e-09,\n",
              "            3.1382e-07, 1.0633e-05, 7.6830e-08, 9.3520e-05, 2.8754e-07, 2.3557e-05,\n",
              "            2.4110e-03, 2.6864e-07, 1.0244e-06, 1.0995e-07, 5.5776e-06, 1.2585e-06,\n",
              "            1.7406e-08, 3.3394e-04, 1.0670e-09, 6.8570e-10, 1.1969e-06, 8.4320e-08,\n",
              "            1.2980e-07, 2.7753e-06, 2.6379e-04, 8.0851e-09, 2.2960e-09, 8.8976e-08,\n",
              "            3.5998e-05, 1.0492e-03, 7.6911e-06, 6.3475e-07, 7.2589e-08, 1.3666e-09,\n",
              "            1.1965e-07, 1.1938e-06, 5.8216e-06, 3.0701e-04, 1.1415e-07, 3.9282e-08,\n",
              "            1.5075e-06, 4.5404e-04, 1.6990e-09, 8.5154e-06, 1.6629e-05, 1.8363e-04,\n",
              "            1.0162e-07, 1.7673e-09, 2.0774e-05, 1.1290e-06, 1.5822e-05, 3.2373e-09,\n",
              "            3.4438e-06, 6.7343e-07, 6.8490e-04, 2.7392e-04, 1.5062e-07, 3.7817e-08,\n",
              "            1.1136e-03, 3.3599e-08, 7.5391e-04, 1.1709e-10, 1.8294e-07, 4.4786e-06,\n",
              "            9.7231e-07, 9.3916e-05],\n",
              "           [1.0000e+00, 5.6687e-08, 2.3314e-07, 1.5637e-07, 2.3377e-07, 6.9954e-10,\n",
              "            4.6306e-08, 1.1150e-10, 8.5839e-08, 8.5228e-07, 1.4683e-06, 3.7546e-06,\n",
              "            2.4960e-08, 1.2130e-06, 1.4796e-07, 3.5193e-07, 2.3644e-07, 7.1231e-10,\n",
              "            2.8312e-06, 6.6866e-06, 1.0420e-06, 8.8771e-07, 5.5844e-08, 8.4978e-09,\n",
              "            4.4987e-05, 1.7308e-07, 7.2787e-08, 2.7608e-08, 1.5770e-06, 1.8874e-07,\n",
              "            5.6410e-08, 8.1004e-05, 4.0612e-10, 7.8802e-10, 7.7220e-08, 7.2264e-09,\n",
              "            6.0349e-07, 3.5373e-06, 2.8170e-04, 3.4480e-06, 3.2356e-09, 2.8729e-07,\n",
              "            1.1758e-06, 2.8772e-03, 9.5136e-07, 1.0006e-07, 6.9579e-07, 5.2979e-06,\n",
              "            2.7203e-08, 1.4938e-07, 1.0109e-06, 3.2599e-05, 1.8210e-05, 1.0756e-07,\n",
              "            1.2285e-04, 2.1479e-06, 1.7775e-08, 4.5502e-06, 6.2349e-06, 6.4277e-08,\n",
              "            1.2531e-09, 1.8897e-11, 3.1836e-06, 3.7870e-07, 2.9255e-06, 1.8184e-08,\n",
              "            1.2046e-05, 1.1944e-08, 2.7154e-07, 3.0862e-05, 5.2705e-07, 2.3448e-07,\n",
              "            9.0712e-06, 6.2016e-06, 1.2243e-08, 1.6188e-10, 2.5973e-07, 3.3591e-05,\n",
              "            1.4162e-10, 2.6119e-04],\n",
              "           [1.0000e+00, 6.4335e-10, 2.7529e-11, 4.3847e-06, 4.7453e-08, 1.4095e-10,\n",
              "            4.2653e-10, 1.2966e-10, 2.3893e-08, 3.6964e-08, 4.4640e-07, 5.7526e-08,\n",
              "            1.6388e-06, 1.0420e-08, 2.6548e-07, 3.0569e-06, 3.3613e-09, 1.6369e-10,\n",
              "            9.2545e-10, 3.5170e-10, 3.1025e-04, 2.8433e-04, 1.6784e-06, 1.6670e-07,\n",
              "            3.7840e-05, 4.4432e-06, 1.6802e-06, 1.1756e-05, 1.1824e-05, 4.7410e-07,\n",
              "            7.3567e-06, 7.0479e-04, 5.1607e-10, 5.2940e-10, 1.3141e-06, 8.8372e-09,\n",
              "            3.0710e-07, 9.4764e-05, 1.8930e-02, 7.3451e-07, 4.0842e-09, 8.9730e-08,\n",
              "            3.9214e-04, 1.8301e-05, 1.0239e-07, 8.0049e-07, 8.3292e-07, 3.0837e-07,\n",
              "            8.3475e-10, 2.0211e-06, 3.4765e-07, 2.3004e-05, 2.0317e-06, 2.3916e-06,\n",
              "            1.0807e-05, 2.4795e-05, 8.6539e-07, 3.6952e-04, 2.4683e-07, 2.3177e-07,\n",
              "            1.4795e-08, 3.6690e-09, 1.9022e-05, 2.0668e-06, 8.8783e-06, 7.0601e-07,\n",
              "            4.2024e-06, 7.5339e-07, 1.5651e-06, 8.2154e-05, 3.7737e-09, 1.7097e-09,\n",
              "            2.7161e-08, 1.4632e-08, 3.4014e-09, 4.3994e-09, 2.7264e-08, 1.1827e-04,\n",
              "            7.5123e-10, 1.9875e-04],\n",
              "           [1.0000e+00, 3.9725e-08, 4.9600e-08, 2.6120e-07, 6.6990e-08, 1.0657e-09,\n",
              "            8.6575e-08, 2.9005e-10, 2.7567e-08, 1.9628e-08, 1.7095e-04, 1.3893e-06,\n",
              "            1.0397e-06, 1.6851e-04, 1.7863e-06, 6.2991e-08, 2.1574e-07, 2.2576e-08,\n",
              "            1.7012e-03, 1.0927e-05, 1.6072e-07, 9.5923e-04, 8.1717e-08, 9.3692e-05,\n",
              "            9.4765e-06, 3.0300e-06, 2.0920e-07, 5.0306e-07, 7.5311e-07, 8.5763e-09,\n",
              "            4.8808e-09, 2.6626e-06, 9.2247e-10, 1.2025e-08, 1.6568e-05, 9.2505e-08,\n",
              "            3.0814e-06, 7.5476e-07, 5.8927e-04, 3.8798e-06, 5.5796e-11, 1.0214e-06,\n",
              "            4.7684e-06, 4.2325e-07, 6.8270e-05, 1.4968e-07, 9.3778e-06, 3.0007e-06,\n",
              "            2.2971e-08, 6.8301e-07, 1.4727e-08, 5.8688e-05, 4.2510e-08, 1.4188e-05,\n",
              "            5.6649e-07, 1.3345e-06, 7.9929e-09, 3.2916e-04, 1.0531e-04, 6.0229e-07,\n",
              "            1.2984e-05, 2.6460e-09, 3.9050e-07, 3.6180e-05, 3.5561e-08, 1.0975e-06,\n",
              "            4.1348e-04, 1.3616e-09, 9.7608e-06, 3.9015e-05, 2.4561e-06, 1.3719e-07,\n",
              "            1.1077e-04, 8.3714e-10, 4.2956e-06, 1.7147e-08, 6.9571e-07, 1.8011e-05,\n",
              "            9.3387e-07, 2.5527e-06],\n",
              "           [1.0000e+00, 1.4767e-08, 6.7556e-07, 4.4814e-07, 7.5479e-09, 3.6617e-09,\n",
              "            7.3103e-08, 7.7175e-09, 3.5223e-08, 2.8515e-08, 1.9228e-04, 1.5999e-07,\n",
              "            2.5528e-07, 8.4291e-08, 1.1806e-08, 5.4516e-08, 3.8836e-06, 1.8132e-08,\n",
              "            3.7518e-05, 5.5312e-06, 1.6626e-04, 3.4101e-07, 2.0920e-07, 2.8025e-04,\n",
              "            5.8000e-05, 3.6045e-08, 7.8781e-07, 6.7230e-05, 1.6985e-07, 5.5669e-09,\n",
              "            4.7942e-05, 6.9447e-07, 8.3861e-10, 2.7245e-10, 1.7964e-06, 1.8531e-09,\n",
              "            8.4360e-08, 1.6672e-06, 2.0970e-04, 1.9887e-05, 1.6205e-09, 4.6460e-08,\n",
              "            6.8882e-07, 9.4000e-07, 1.1670e-07, 3.1426e-04, 3.0751e-08, 2.6966e-08,\n",
              "            1.7633e-08, 3.7940e-06, 8.6738e-08, 9.0060e-05, 2.3147e-06, 7.5384e-07,\n",
              "            1.7377e-08, 1.1620e-06, 1.5013e-08, 4.9261e-03, 1.9880e-06, 8.3627e-05,\n",
              "            5.9090e-05, 1.3653e-07, 7.0305e-06, 1.2458e-06, 1.6171e-05, 7.1519e-08,\n",
              "            9.4323e-05, 4.1079e-07, 2.4327e-05, 2.7158e-05, 1.4356e-05, 1.8153e-05,\n",
              "            4.7081e-02, 3.1397e-07, 2.7707e-05, 2.9734e-06, 5.9111e-07, 1.0352e-04,\n",
              "            1.3676e-05, 8.5559e-04],\n",
              "           [1.0000e+00, 9.0956e-09, 9.7896e-10, 6.6439e-08, 1.5122e-09, 1.7823e-10,\n",
              "            1.7454e-09, 1.8147e-10, 5.5038e-09, 1.2356e-07, 1.6634e-05, 5.7499e-08,\n",
              "            4.1851e-08, 5.2381e-08, 2.4565e-06, 1.3896e-07, 1.1365e-07, 2.8163e-09,\n",
              "            1.1337e-07, 1.0946e-06, 3.1336e-07, 5.4544e-04, 2.5713e-08, 3.5534e-08,\n",
              "            1.0678e-04, 8.3572e-07, 4.5677e-07, 1.5959e-07, 9.4330e-05, 3.5386e-08,\n",
              "            6.7805e-08, 3.6187e-07, 9.8466e-12, 1.1427e-10, 4.9841e-06, 2.4054e-09,\n",
              "            1.5039e-07, 3.8527e-07, 2.6960e-04, 1.1514e-08, 1.9833e-11, 8.4971e-06,\n",
              "            1.7111e-05, 1.3014e-06, 1.8390e-07, 8.3416e-10, 2.2187e-07, 3.6878e-07,\n",
              "            3.1466e-10, 8.8528e-07, 1.4549e-08, 3.4590e-05, 2.9277e-11, 6.3737e-07,\n",
              "            7.7764e-09, 2.9943e-08, 3.0751e-10, 2.4657e-06, 2.3067e-07, 2.3045e-06,\n",
              "            1.2675e-08, 7.5351e-12, 5.8213e-09, 2.7340e-08, 2.0862e-08, 3.2558e-09,\n",
              "            1.7092e-06, 1.0314e-07, 2.9484e-07, 9.5541e-06, 7.1577e-09, 1.0756e-07,\n",
              "            1.8580e-06, 8.4028e-12, 4.3610e-07, 8.8655e-11, 2.6282e-09, 2.8209e-06,\n",
              "            1.0743e-10, 1.9785e-07],\n",
              "           [1.0000e+00, 2.7283e-10, 2.1313e-09, 6.7566e-09, 2.0766e-10, 1.2308e-12,\n",
              "            5.8248e-10, 8.8433e-15, 3.8932e-11, 1.1601e-09, 2.7192e-07, 1.8540e-06,\n",
              "            7.8588e-09, 6.6913e-09, 5.8648e-10, 1.7773e-11, 4.6060e-09, 1.0733e-11,\n",
              "            1.1018e-06, 4.0837e-07, 7.7928e-08, 4.9772e-06, 3.2773e-06, 4.8775e-08,\n",
              "            1.9293e-05, 1.8773e-06, 5.7542e-09, 6.9951e-08, 1.6006e-06, 2.6771e-07,\n",
              "            3.4254e-10, 2.8117e-06, 1.9554e-11, 4.8368e-09, 2.3087e-06, 1.2121e-07,\n",
              "            9.2126e-06, 1.9328e-07, 6.5704e-06, 4.5515e-07, 1.2453e-10, 2.0510e-07,\n",
              "            2.8454e-07, 5.8800e-05, 1.1326e-05, 3.2217e-07, 8.7400e-07, 5.6583e-06,\n",
              "            5.0955e-08, 3.1779e-07, 2.5654e-09, 7.3172e-06, 2.1878e-07, 3.2130e-07,\n",
              "            1.5988e-06, 1.3720e-07, 8.5341e-09, 1.9395e-06, 3.9823e-06, 8.0884e-08,\n",
              "            8.4239e-10, 7.7942e-10, 4.7964e-07, 1.4320e-07, 4.0046e-08, 4.0946e-09,\n",
              "            7.9764e-05, 1.3059e-09, 1.0849e-07, 3.1876e-06, 1.1187e-07, 2.6021e-09,\n",
              "            1.1719e-05, 2.4522e-08, 9.8504e-09, 2.4103e-09, 5.9507e-06, 2.6456e-06,\n",
              "            3.2082e-07, 5.0343e-04],\n",
              "           [1.0000e+00, 1.7962e-07, 8.8030e-11, 1.1026e-06, 2.5077e-08, 1.0602e-10,\n",
              "            1.0758e-08, 2.8609e-10, 1.8399e-07, 1.2039e-06, 3.1150e-04, 1.0810e-07,\n",
              "            4.4190e-05, 6.8193e-05, 1.9839e-07, 2.1294e-07, 1.7606e-08, 1.3437e-06,\n",
              "            2.6668e-06, 9.9541e-08, 1.1876e-05, 5.7434e-05, 8.7175e-07, 2.0406e-06,\n",
              "            9.7133e-06, 1.2217e-04, 4.5253e-04, 8.2315e-06, 8.4298e-07, 3.3284e-06,\n",
              "            1.0142e-05, 2.9931e-04, 5.6493e-08, 1.3644e-08, 2.2370e-04, 5.5547e-08,\n",
              "            1.0751e-06, 3.7103e-05, 1.2171e-02, 6.1725e-08, 1.0488e-10, 1.0067e-09,\n",
              "            6.9537e-05, 1.2847e-04, 9.5372e-07, 3.0062e-06, 5.2161e-06, 1.9735e-06,\n",
              "            5.1099e-09, 3.6177e-06, 1.5957e-06, 5.6662e-02, 1.2434e-08, 5.8738e-08,\n",
              "            6.1450e-08, 6.1140e-05, 3.2020e-08, 1.0629e-04, 1.0831e-04, 4.4367e-06,\n",
              "            1.1762e-07, 1.0309e-08, 9.0983e-05, 1.3766e-06, 9.8791e-05, 2.5262e-06,\n",
              "            2.6297e-06, 1.3671e-07, 4.1500e-02, 7.4607e-06, 3.3381e-07, 1.0551e-07,\n",
              "            3.8679e-02, 1.0229e-07, 1.4107e-04, 1.9483e-08, 2.2838e-08, 4.1105e-05,\n",
              "            2.7559e-08, 2.6325e-04],\n",
              "           [9.9996e-01, 4.2634e-06, 7.2434e-07, 1.3512e-04, 1.4998e-05, 8.8217e-07,\n",
              "            5.9380e-07, 8.6147e-08, 4.9744e-05, 5.4125e-05, 6.2127e-05, 3.0378e-06,\n",
              "            1.3535e-06, 4.2090e-05, 2.8623e-06, 2.4983e-06, 3.2392e-07, 9.2404e-08,\n",
              "            2.1696e-05, 1.1615e-04, 1.9161e-05, 9.4272e-05, 2.0137e-06, 5.4964e-06,\n",
              "            1.6900e-04, 6.9894e-06, 1.0904e-04, 8.0016e-06, 1.3445e-06, 8.4311e-04,\n",
              "            3.2648e-07, 1.4232e-05, 7.6939e-08, 4.4996e-08, 1.0528e-04, 1.6220e-06,\n",
              "            1.2671e-05, 1.5220e-05, 2.1231e-03, 1.1919e-05, 5.3373e-08, 1.0245e-06,\n",
              "            1.9980e-06, 2.7413e-03, 6.0731e-06, 6.1659e-08, 6.1440e-09, 2.3521e-07,\n",
              "            2.2897e-07, 2.0849e-05, 8.9530e-07, 6.6472e-05, 6.8041e-06, 3.0007e-05,\n",
              "            4.1650e-06, 4.0209e-04, 3.2761e-09, 1.9308e-06, 3.7434e-07, 1.0432e-05,\n",
              "            1.5129e-07, 9.1802e-09, 4.8426e-06, 5.1530e-05, 4.3672e-06, 2.8591e-06,\n",
              "            2.3537e-03, 1.4590e-07, 9.8066e-05, 1.0384e-03, 3.5929e-05, 1.3567e-06,\n",
              "            5.7470e-03, 1.2769e-06, 9.9665e-04, 2.8710e-07, 5.3789e-04, 2.9985e-04,\n",
              "            4.2118e-06, 5.5037e-03],\n",
              "           [1.0000e+00, 3.3967e-09, 2.4267e-10, 2.6190e-07, 4.2031e-09, 5.8121e-12,\n",
              "            1.1151e-10, 9.0963e-14, 6.7375e-09, 1.9273e-07, 7.9171e-09, 1.4996e-07,\n",
              "            6.2101e-10, 2.3231e-06, 7.8317e-11, 7.8098e-11, 4.4621e-09, 2.2019e-11,\n",
              "            3.4116e-07, 3.1688e-05, 1.7586e-09, 1.5653e-06, 2.6506e-09, 1.9544e-08,\n",
              "            3.4458e-06, 3.9300e-08, 8.3244e-09, 4.6746e-09, 3.5842e-06, 8.6202e-07,\n",
              "            3.4535e-11, 1.8573e-05, 1.1374e-12, 8.8303e-11, 3.6727e-07, 1.5608e-09,\n",
              "            2.1732e-07, 3.1533e-10, 2.4016e-06, 1.3866e-08, 8.3776e-13, 3.2381e-10,\n",
              "            1.9440e-09, 2.0879e-04, 7.6539e-07, 3.4337e-09, 7.0637e-10, 1.2778e-08,\n",
              "            1.5219e-09, 2.0740e-08, 1.6004e-12, 1.7432e-07, 7.4693e-08, 1.0938e-09,\n",
              "            9.4434e-12, 3.4348e-10, 7.3909e-11, 1.5652e-07, 1.1365e-10, 3.0410e-10,\n",
              "            1.3168e-10, 1.8963e-12, 1.7055e-07, 6.9168e-09, 3.4384e-08, 1.9791e-10,\n",
              "            1.8407e-05, 7.2473e-09, 3.5226e-08, 5.4828e-07, 2.3177e-08, 3.8219e-10,\n",
              "            1.6682e-05, 3.5542e-09, 5.9894e-09, 5.2165e-14, 1.2231e-08, 4.2818e-07,\n",
              "            1.0237e-09, 3.1627e-05]], device='cuda:0', grad_fn=<CatBackward>)]},\n",
              " {1: [tensor([[9.9675e-01, 1.9405e-03, 2.9267e-03, 2.2958e-05, 7.6831e-04, 3.9533e-04,\n",
              "            3.6149e-04, 7.9860e-03, 5.9478e-04, 1.0889e-04],\n",
              "           [1.0000e+00, 3.9136e-08, 7.2778e-09, 3.1283e-10, 1.8783e-05, 2.5041e-09,\n",
              "            2.1833e-05, 5.4088e-07, 1.0370e-09, 1.8149e-08],\n",
              "           [1.0000e+00, 3.7585e-05, 1.1283e-06, 3.6188e-08, 2.0992e-05, 2.4672e-07,\n",
              "            1.3998e-06, 6.5545e-06, 5.2690e-07, 7.9246e-07],\n",
              "           [1.0000e+00, 1.1913e-06, 1.8508e-06, 9.6649e-09, 5.0319e-06, 1.8961e-07,\n",
              "            3.8241e-07, 1.1612e-06, 2.2529e-07, 2.0893e-06],\n",
              "           [1.0000e+00, 5.5362e-08, 5.3834e-07, 2.4824e-09, 3.5232e-06, 1.3453e-07,\n",
              "            5.7396e-07, 1.5680e-06, 4.6706e-08, 3.5064e-08],\n",
              "           [1.0000e+00, 3.3735e-06, 3.2294e-06, 3.3591e-08, 2.5237e-06, 6.6707e-07,\n",
              "            2.7052e-06, 1.7723e-05, 1.7670e-06, 8.0426e-07],\n",
              "           [1.0000e+00, 3.9221e-05, 6.3970e-08, 9.5927e-09, 8.8523e-06, 1.5219e-08,\n",
              "            1.8456e-05, 1.2740e-07, 3.9835e-08, 2.9568e-06],\n",
              "           [1.0000e+00, 3.1334e-08, 1.8194e-07, 5.3577e-10, 3.4858e-06, 8.8925e-09,\n",
              "            4.8822e-09, 8.5618e-08, 3.2582e-08, 1.2637e-06],\n",
              "           [9.9999e-01, 1.3771e-06, 4.0884e-05, 2.3278e-08, 1.8647e-06, 1.1383e-06,\n",
              "            1.5389e-06, 2.8489e-06, 1.0478e-06, 2.5620e-06],\n",
              "           [9.9997e-01, 9.6893e-06, 1.7038e-05, 2.3080e-07, 1.3176e-03, 7.5329e-06,\n",
              "            1.0037e-05, 5.8992e-05, 6.3828e-06, 2.7492e-05]], device='cuda:0',\n",
              "          grad_fn=<SigmoidBackward>),\n",
              "   tensor([[9.9675e-01, 1.9405e-03, 2.9267e-03, 2.2958e-05, 7.6831e-04, 3.9533e-04,\n",
              "            3.6149e-04, 7.9860e-03, 5.9478e-04, 1.0889e-04],\n",
              "           [1.0000e+00, 3.9136e-08, 7.2778e-09, 3.1283e-10, 1.8783e-05, 2.5041e-09,\n",
              "            2.1833e-05, 5.4088e-07, 1.0370e-09, 1.8149e-08],\n",
              "           [1.0000e+00, 3.7585e-05, 1.1283e-06, 3.6188e-08, 2.0992e-05, 2.4672e-07,\n",
              "            1.3998e-06, 6.5545e-06, 5.2690e-07, 7.9246e-07],\n",
              "           [1.0000e+00, 1.1913e-06, 1.8508e-06, 9.6649e-09, 5.0319e-06, 1.8961e-07,\n",
              "            3.8241e-07, 1.1612e-06, 2.2529e-07, 2.0893e-06],\n",
              "           [1.0000e+00, 5.5362e-08, 5.3834e-07, 2.4824e-09, 3.5232e-06, 1.3453e-07,\n",
              "            5.7396e-07, 1.5680e-06, 4.6706e-08, 3.5064e-08],\n",
              "           [1.0000e+00, 3.3735e-06, 3.2294e-06, 3.3591e-08, 2.5237e-06, 6.6707e-07,\n",
              "            2.7052e-06, 1.7723e-05, 1.7670e-06, 8.0426e-07],\n",
              "           [1.0000e+00, 3.9221e-05, 6.3970e-08, 9.5927e-09, 8.8523e-06, 1.5219e-08,\n",
              "            1.8456e-05, 1.2740e-07, 3.9835e-08, 2.9568e-06],\n",
              "           [1.0000e+00, 3.1334e-08, 1.8194e-07, 5.3577e-10, 3.4858e-06, 8.8925e-09,\n",
              "            4.8822e-09, 8.5618e-08, 3.2582e-08, 1.2637e-06],\n",
              "           [9.9999e-01, 1.3771e-06, 4.0884e-05, 2.3278e-08, 1.8647e-06, 1.1383e-06,\n",
              "            1.5389e-06, 2.8489e-06, 1.0478e-06, 2.5620e-06],\n",
              "           [9.9997e-01, 9.6893e-06, 1.7038e-05, 2.3080e-07, 1.3176e-03, 7.5329e-06,\n",
              "            1.0037e-05, 5.8992e-05, 6.3828e-06, 2.7492e-05]], device='cuda:0',\n",
              "          grad_fn=<SigmoidBackward>)],\n",
              "  2: [tensor([[9.9576e-01, 5.6356e-03, 5.1784e-03, 2.7833e-05, 1.3690e-03, 4.1772e-04,\n",
              "            2.6829e-03, 6.6040e-03, 7.3081e-04, 3.3454e-04, 3.9820e-05, 1.2683e-02,\n",
              "            1.4226e-05, 2.2656e-04, 1.7503e-04, 5.3236e-07, 2.2348e-05, 9.4289e-04,\n",
              "            8.2729e-05, 1.4333e-03],\n",
              "           [9.9984e-01, 8.8776e-06, 8.9419e-06, 5.4175e-07, 2.5605e-03, 3.5509e-06,\n",
              "            1.0875e-04, 6.2581e-05, 5.2045e-07, 4.1386e-06, 4.0294e-08, 7.7502e-07,\n",
              "            1.1723e-09, 3.8523e-08, 2.7014e-08, 1.6345e-11, 2.1542e-07, 3.7851e-06,\n",
              "            7.5020e-07, 1.1481e-06],\n",
              "           [9.9984e-01, 1.4393e-04, 1.2851e-05, 2.1621e-06, 1.8695e-03, 1.3385e-05,\n",
              "            1.5781e-04, 4.0013e-05, 4.3783e-06, 4.4051e-06, 4.5503e-08, 7.3673e-07,\n",
              "            3.2650e-07, 3.4725e-05, 3.7635e-09, 1.7517e-10, 9.7944e-08, 1.9125e-04,\n",
              "            3.4698e-09, 3.7376e-06],\n",
              "           [9.9992e-01, 3.2906e-05, 3.2963e-05, 1.5644e-06, 4.2078e-04, 3.5267e-06,\n",
              "            6.8188e-05, 1.0116e-05, 1.6289e-06, 3.3045e-05, 8.8960e-07, 5.8938e-07,\n",
              "            5.5091e-09, 2.8425e-04, 2.9692e-10, 2.3806e-09, 2.9855e-07, 1.7486e-08,\n",
              "            2.5218e-10, 1.9756e-07],\n",
              "           [9.9986e-01, 1.6137e-05, 2.7790e-05, 6.4894e-07, 2.9610e-04, 3.4952e-06,\n",
              "            8.6011e-05, 2.9024e-05, 2.6463e-06, 1.6302e-06, 1.0745e-07, 1.1834e-09,\n",
              "            1.1576e-09, 1.4385e-07, 1.2554e-09, 6.3223e-12, 8.5600e-10, 3.3882e-06,\n",
              "            1.2006e-09, 2.2862e-05],\n",
              "           [9.9999e-01, 8.5245e-06, 1.3647e-05, 6.1132e-07, 1.0319e-04, 1.4375e-06,\n",
              "            1.4362e-05, 1.0928e-05, 5.1880e-07, 1.6788e-06, 3.6971e-06, 2.7502e-08,\n",
              "            1.1650e-08, 1.3757e-07, 7.4059e-11, 5.9853e-12, 1.0773e-07, 5.3514e-08,\n",
              "            6.8858e-11, 7.9017e-07],\n",
              "           [9.9988e-01, 1.5405e-04, 3.8556e-05, 7.4754e-06, 1.9045e-03, 2.0296e-05,\n",
              "            2.4065e-04, 9.3337e-05, 5.2035e-06, 3.1621e-06, 2.6194e-07, 1.2176e-07,\n",
              "            4.0942e-07, 2.5713e-04, 4.7038e-09, 4.7090e-10, 1.0648e-07, 7.0159e-04,\n",
              "            7.4982e-09, 1.0849e-05],\n",
              "           [9.9994e-01, 5.3046e-06, 1.6588e-05, 6.5041e-07, 3.1737e-04, 1.0656e-06,\n",
              "            1.4958e-05, 3.4092e-06, 4.5773e-07, 9.9720e-06, 3.3355e-08, 1.1425e-07,\n",
              "            2.3886e-09, 6.5693e-07, 3.9801e-10, 5.3662e-11, 1.5949e-09, 4.0150e-09,\n",
              "            1.4452e-11, 8.2960e-07],\n",
              "           [9.9997e-01, 3.2125e-05, 5.7967e-05, 3.6462e-07, 2.9532e-05, 8.1232e-06,\n",
              "            6.3658e-06, 2.3678e-05, 8.4487e-06, 3.1693e-06, 4.0102e-07, 1.2584e-06,\n",
              "            3.7116e-10, 5.4485e-09, 2.8310e-09, 5.8144e-11, 7.2360e-09, 7.7373e-08,\n",
              "            3.9706e-08, 1.0055e-05],\n",
              "           [9.9865e-01, 7.1700e-04, 1.7421e-04, 1.0446e-05, 1.1263e-03, 3.9279e-05,\n",
              "            8.6711e-04, 1.1585e-04, 2.1755e-05, 6.3026e-05, 1.2658e-04, 1.0026e-05,\n",
              "            1.4193e-07, 1.0592e-04, 1.8455e-08, 1.7444e-07, 7.8008e-06, 1.3432e-06,\n",
              "            3.1778e-08, 5.8806e-06]], device='cuda:0', grad_fn=<SigmoidBackward>),\n",
              "   tensor([[9.9827e-01, 2.9183e-03, 1.8905e-03, 2.5136e-05, 6.7528e-04, 2.3172e-04,\n",
              "            2.9385e-04, 4.2130e-03, 4.8867e-04, 6.6612e-05],\n",
              "           [9.9999e-01, 5.4751e-07, 1.1815e-08, 2.3711e-09, 4.1564e-04, 1.2911e-08,\n",
              "            6.2294e-07, 2.4553e-05, 1.6831e-08, 5.0345e-08],\n",
              "           [9.9999e-01, 1.1651e-04, 4.1824e-06, 1.8877e-07, 2.1016e-03, 1.6216e-06,\n",
              "            9.8692e-05, 1.1898e-05, 1.1013e-06, 9.3140e-06],\n",
              "           [1.0000e+00, 5.8748e-06, 6.8655e-06, 7.3922e-08, 1.4613e-04, 1.9687e-06,\n",
              "            1.2051e-05, 2.7613e-06, 7.9749e-07, 1.3474e-05],\n",
              "           [1.0000e+00, 2.3167e-07, 8.5377e-06, 2.4754e-08, 1.3561e-05, 9.1074e-07,\n",
              "            2.3662e-05, 3.1505e-05, 6.2991e-07, 9.7880e-08],\n",
              "           [1.0000e+00, 3.1046e-05, 1.2751e-07, 3.7446e-09, 3.0354e-07, 4.1198e-09,\n",
              "            7.4486e-07, 1.0333e-07, 1.1081e-08, 5.9495e-08],\n",
              "           [1.0000e+00, 2.6165e-06, 1.6633e-06, 3.6293e-08, 1.9558e-04, 3.3095e-07,\n",
              "            3.1514e-06, 3.4841e-06, 1.6232e-07, 5.1189e-07],\n",
              "           [1.0000e+00, 1.7186e-08, 3.1150e-07, 1.8521e-09, 3.1228e-05, 7.0362e-08,\n",
              "            9.7707e-08, 1.1864e-07, 5.9518e-08, 5.8582e-06],\n",
              "           [1.0000e+00, 1.3397e-06, 4.0085e-06, 7.8311e-09, 7.8508e-06, 2.7688e-07,\n",
              "            4.2477e-07, 3.3033e-06, 3.6790e-07, 3.9823e-07],\n",
              "           [9.9998e-01, 7.1278e-05, 1.8846e-05, 1.6921e-06, 2.0342e-04, 1.6118e-05,\n",
              "            1.2092e-04, 2.2558e-04, 2.8075e-05, 1.5930e-05]], device='cuda:0',\n",
              "          grad_fn=<SigmoidBackward>)],\n",
              "  3: [tensor([[9.9503e-01, 8.4993e-03, 2.8418e-03, 1.3949e-05, 2.0869e-03, 4.8083e-04,\n",
              "            7.2865e-03, 2.0297e-03, 5.1354e-04, 3.7172e-04, 5.2104e-04, 2.1280e-02,\n",
              "            3.1946e-05, 1.6704e-04, 1.4777e-04, 2.2933e-05, 9.3523e-04, 3.8875e-04,\n",
              "            8.2627e-05, 4.3269e-03, 3.1947e-04, 1.2741e-06, 3.6073e-07, 5.1585e-04,\n",
              "            2.6785e-08, 1.2847e-07, 1.9966e-08, 1.3543e-07, 1.0941e-04, 6.6827e-07],\n",
              "           [9.9931e-01, 2.8303e-04, 1.1631e-04, 1.0430e-05, 7.0295e-04, 6.9354e-05,\n",
              "            1.1650e-03, 1.8328e-03, 6.8371e-05, 1.4154e-05, 5.7736e-06, 2.2837e-05,\n",
              "            9.1936e-08, 6.0962e-05, 3.3669e-07, 1.2953e-07, 3.1803e-05, 3.9351e-04,\n",
              "            2.6157e-05, 5.2331e-05, 2.1512e-08, 1.6242e-11, 1.2055e-09, 9.3072e-07,\n",
              "            9.0996e-10, 9.3384e-10, 1.2027e-11, 5.9412e-07, 7.0583e-06, 4.6345e-10],\n",
              "           [9.9228e-01, 6.7129e-03, 1.1457e-03, 3.7621e-05, 5.9777e-03, 1.1287e-03,\n",
              "            9.1497e-03, 1.9463e-03, 1.0652e-03, 1.1428e-04, 2.8567e-04, 1.5897e-03,\n",
              "            1.3597e-05, 2.7525e-03, 1.3696e-04, 1.4273e-06, 2.6253e-04, 7.2817e-04,\n",
              "            4.0369e-05, 2.2704e-03, 1.6133e-06, 1.9558e-08, 5.0992e-05, 1.4185e-03,\n",
              "            4.7836e-08, 2.1410e-06, 2.6764e-06, 1.3003e-04, 1.3130e-05, 2.7437e-08],\n",
              "           [9.9953e-01, 1.0698e-03, 7.2732e-04, 5.8218e-06, 6.0847e-04, 1.7425e-04,\n",
              "            2.3769e-04, 8.1146e-05, 2.9773e-04, 6.6919e-05, 2.5941e-04, 1.0977e-04,\n",
              "            1.0553e-07, 1.9915e-04, 3.2977e-06, 5.9093e-08, 2.9342e-05, 2.7776e-05,\n",
              "            9.2280e-06, 2.5439e-03, 2.3394e-08, 2.8444e-10, 3.4991e-07, 2.3408e-04,\n",
              "            6.5249e-09, 3.2697e-08, 2.7506e-10, 6.8546e-08, 9.9629e-07, 5.2957e-09],\n",
              "           [9.9833e-01, 3.2175e-04, 9.7046e-04, 3.2129e-05, 9.6789e-04, 2.7227e-04,\n",
              "            5.1882e-04, 1.6085e-03, 1.6680e-04, 3.9645e-05, 2.0164e-04, 1.4210e-05,\n",
              "            2.0438e-07, 1.3859e-04, 1.2309e-06, 7.5924e-08, 8.8493e-06, 1.2451e-03,\n",
              "            1.1119e-04, 8.8993e-05, 2.9417e-08, 1.8468e-10, 9.6302e-08, 2.4429e-07,\n",
              "            1.4767e-09, 2.1477e-08, 9.7230e-10, 4.7270e-06, 5.6098e-05, 4.4138e-10],\n",
              "           [9.9995e-01, 9.7342e-05, 2.8991e-05, 1.1838e-06, 2.2432e-04, 2.8845e-05,\n",
              "            1.6373e-05, 1.4316e-04, 1.1820e-05, 5.4785e-07, 9.3627e-07, 7.7587e-07,\n",
              "            1.1408e-09, 5.7174e-05, 5.0176e-09, 7.0010e-11, 9.8490e-08, 4.9134e-06,\n",
              "            5.1615e-08, 6.0093e-06, 1.5534e-13, 1.3353e-15, 1.4721e-12, 9.7821e-09,\n",
              "            2.4624e-14, 4.0016e-14, 1.0587e-12, 2.6132e-09, 4.7635e-10, 2.0690e-14],\n",
              "           [9.9850e-01, 1.0332e-03, 2.1986e-03, 1.3698e-05, 4.6563e-03, 6.4156e-04,\n",
              "            8.2740e-04, 1.8798e-03, 2.4848e-04, 2.7543e-05, 4.4739e-04, 1.3259e-05,\n",
              "            4.3685e-07, 3.1989e-03, 1.0785e-06, 7.4960e-08, 9.7972e-05, 2.8470e-03,\n",
              "            1.7670e-05, 1.8176e-03, 2.9934e-07, 4.7599e-10, 1.2395e-06, 9.6842e-05,\n",
              "            3.4658e-08, 4.6134e-07, 1.3975e-08, 1.1047e-05, 7.9402e-06, 1.6338e-10],\n",
              "           [9.9813e-01, 2.4486e-04, 3.0849e-04, 1.0803e-05, 1.4498e-03, 9.2054e-05,\n",
              "            5.3037e-04, 2.4014e-04, 1.6976e-04, 3.3828e-05, 1.2613e-05, 9.3269e-05,\n",
              "            1.2375e-06, 4.4656e-05, 1.2270e-06, 4.7148e-08, 4.9571e-06, 1.1231e-05,\n",
              "            4.1914e-07, 5.8704e-04, 7.2166e-10, 7.0118e-12, 1.1869e-07, 1.3125e-04,\n",
              "            1.0555e-09, 4.3480e-09, 2.8742e-10, 2.9181e-08, 7.5798e-08, 1.7984e-09],\n",
              "           [9.9901e-01, 8.0005e-04, 6.7738e-04, 6.9876e-06, 1.0963e-03, 2.2719e-04,\n",
              "            6.2372e-05, 4.1850e-04, 2.1361e-04, 4.1456e-05, 1.0130e-06, 5.0184e-04,\n",
              "            1.2799e-07, 1.2192e-05, 2.5164e-07, 1.9537e-07, 3.4819e-06, 7.5815e-05,\n",
              "            1.8209e-04, 5.2066e-05, 6.5873e-10, 7.0504e-11, 1.8832e-08, 4.6080e-05,\n",
              "            1.5310e-11, 3.5106e-10, 7.9916e-12, 1.7896e-08, 3.3186e-06, 2.1786e-10],\n",
              "           [9.9983e-01, 1.7374e-04, 3.2194e-04, 5.4866e-06, 8.1546e-04, 1.0699e-04,\n",
              "            7.4595e-05, 2.5189e-04, 7.2103e-05, 6.9897e-06, 3.3545e-05, 1.3324e-06,\n",
              "            2.5127e-08, 6.5214e-05, 1.1111e-07, 1.0391e-08, 2.2142e-06, 9.5226e-06,\n",
              "            1.4172e-05, 6.3561e-05, 1.1197e-11, 1.5489e-10, 8.0193e-10, 1.0038e-06,\n",
              "            1.3602e-11, 4.3504e-11, 2.6325e-12, 2.3741e-09, 1.2195e-06, 2.8637e-12]],\n",
              "          device='cuda:0', grad_fn=<SigmoidBackward>),\n",
              "   tensor([[9.9975e-01, 5.1315e-04, 1.7071e-04, 1.2916e-06, 1.7883e-04, 1.0117e-05,\n",
              "            2.2378e-05, 1.9019e-04, 2.4197e-05, 1.9729e-05, 7.7432e-07, 2.0611e-03,\n",
              "            9.9372e-08, 5.9699e-05, 3.0192e-06, 3.8196e-09, 1.3525e-06, 7.0448e-05,\n",
              "            1.9804e-07, 2.1485e-04],\n",
              "           [1.0000e+00, 5.1324e-07, 3.0047e-07, 1.9429e-08, 1.0331e-04, 3.6185e-07,\n",
              "            1.2612e-05, 2.8056e-05, 2.7405e-07, 5.4235e-07, 3.5129e-07, 9.7815e-07,\n",
              "            1.1971e-07, 3.3625e-07, 3.1900e-08, 3.8222e-10, 4.0482e-07, 4.4078e-06,\n",
              "            4.2083e-07, 7.9146e-06],\n",
              "           [9.9999e-01, 4.6443e-05, 2.0310e-05, 1.5277e-06, 2.6935e-04, 1.9346e-05,\n",
              "            9.9036e-05, 7.5857e-05, 2.0895e-05, 2.1258e-05, 4.5642e-05, 1.7690e-04,\n",
              "            1.9497e-06, 1.2515e-03, 1.3614e-05, 1.0484e-07, 1.7067e-05, 2.2162e-04,\n",
              "            1.9527e-06, 6.1075e-04],\n",
              "           [1.0000e+00, 4.8159e-06, 8.1106e-06, 5.5551e-08, 4.0566e-05, 1.6605e-06,\n",
              "            4.1070e-06, 1.1172e-05, 1.5542e-06, 7.8217e-06, 8.6537e-06, 4.1749e-04,\n",
              "            4.3665e-08, 6.3561e-05, 7.3827e-07, 6.5287e-09, 1.8306e-06, 9.6678e-07,\n",
              "            2.9811e-07, 1.6225e-05],\n",
              "           [9.9997e-01, 5.2654e-06, 1.2425e-04, 1.4041e-06, 1.3760e-04, 7.8537e-05,\n",
              "            3.2814e-05, 9.6733e-04, 6.8258e-05, 4.8839e-05, 7.4629e-06, 8.1491e-07,\n",
              "            5.9801e-07, 2.0407e-05, 6.6087e-07, 1.1304e-08, 2.6843e-06, 1.0994e-02,\n",
              "            2.4617e-07, 1.6353e-04],\n",
              "           [1.0000e+00, 4.5976e-06, 2.8846e-08, 1.6925e-09, 1.6193e-06, 4.5994e-09,\n",
              "            7.3610e-07, 7.3348e-08, 4.4083e-09, 5.0489e-08, 2.4480e-08, 1.7592e-08,\n",
              "            4.9662e-10, 4.9390e-07, 8.3069e-11, 1.2682e-12, 1.7818e-08, 3.6706e-07,\n",
              "            8.2752e-11, 2.0072e-07],\n",
              "           [1.0000e+00, 4.0728e-06, 2.8490e-06, 8.8488e-08, 6.8586e-05, 6.9147e-07,\n",
              "            4.8332e-05, 3.3041e-06, 5.9325e-07, 3.5570e-06, 3.4698e-06, 2.7940e-08,\n",
              "            9.3258e-08, 1.1164e-04, 1.3682e-09, 6.0882e-10, 5.4214e-07, 3.3565e-05,\n",
              "            2.1526e-09, 1.2690e-05],\n",
              "           [9.9991e-01, 1.0231e-06, 2.3174e-06, 1.2266e-07, 2.8928e-04, 9.2582e-07,\n",
              "            1.0064e-06, 5.2345e-06, 1.1800e-06, 3.8728e-04, 1.4835e-07, 7.7331e-06,\n",
              "            6.4413e-08, 2.1638e-06, 1.5097e-08, 4.0719e-10, 3.6983e-08, 8.6296e-08,\n",
              "            4.8588e-09, 3.1188e-05],\n",
              "           [1.0000e+00, 6.3628e-06, 1.7057e-05, 1.0489e-08, 3.6562e-06, 2.5651e-07,\n",
              "            3.7365e-07, 1.0441e-06, 3.1573e-07, 5.8169e-07, 6.5544e-07, 4.0966e-06,\n",
              "            5.2929e-10, 3.6034e-08, 1.0295e-08, 1.3253e-10, 6.0610e-09, 9.3168e-08,\n",
              "            1.2113e-07, 1.5345e-05],\n",
              "           [1.0000e+00, 2.1522e-06, 7.1459e-07, 1.6334e-08, 2.8384e-06, 7.0501e-08,\n",
              "            5.6469e-07, 1.5554e-06, 1.5645e-07, 1.7409e-07, 9.0906e-06, 3.0557e-08,\n",
              "            3.2501e-10, 1.4586e-07, 1.8648e-09, 1.1328e-10, 8.9617e-08, 4.0888e-08,\n",
              "            9.6390e-09, 1.0606e-06]], device='cuda:0', grad_fn=<CatBackward>)],\n",
              "  4: [tensor([[9.7729e-01, 4.1358e-02, 5.9934e-03, 3.8451e-05, 7.4464e-03, 1.5540e-03,\n",
              "            9.4944e-03, 4.3170e-03, 6.6100e-04, 2.5680e-03, 1.0830e-02, 2.4720e-02,\n",
              "            7.9576e-05, 5.6113e-04, 6.7674e-04, 3.6942e-05, 8.3344e-04, 1.4701e-03,\n",
              "            6.9450e-04, 1.8492e-02, 1.0188e-02, 2.7228e-05, 3.0767e-04, 5.7422e-03,\n",
              "            4.5415e-06, 7.8245e-06, 5.4848e-06, 8.3199e-05, 9.7906e-04, 5.8553e-05,\n",
              "            4.1034e-08, 3.4510e-06, 1.0485e-07, 4.3902e-07, 7.3744e-08, 3.6245e-10,\n",
              "            1.5575e-03, 1.3520e-06, 1.0893e-03, 1.5539e-06],\n",
              "           [9.9731e-01, 2.1486e-04, 4.9209e-04, 7.8332e-06, 1.1318e-03, 1.4855e-04,\n",
              "            7.2813e-03, 8.2162e-04, 1.8599e-05, 2.8585e-05, 3.8336e-05, 7.3996e-05,\n",
              "            6.1298e-08, 8.8483e-05, 5.4609e-06, 2.2726e-06, 1.0963e-04, 5.1165e-03,\n",
              "            3.8746e-05, 1.0748e-04, 7.7850e-06, 3.1281e-08, 5.5739e-05, 5.4466e-05,\n",
              "            5.5671e-08, 2.3372e-08, 5.2119e-08, 5.3451e-06, 7.8698e-05, 1.0754e-08,\n",
              "            2.8913e-13, 5.9628e-09, 1.5150e-11, 6.8567e-07, 2.2849e-11, 2.7943e-11,\n",
              "            5.3393e-10, 1.3971e-08, 4.5320e-09, 1.0189e-06],\n",
              "           [9.9552e-01, 2.2545e-03, 1.3943e-03, 1.2455e-05, 2.8243e-03, 7.3786e-04,\n",
              "            1.2005e-03, 5.9869e-04, 3.4605e-04, 1.6008e-04, 3.1328e-04, 1.1262e-03,\n",
              "            3.7898e-06, 1.7685e-04, 6.4193e-06, 1.1745e-05, 1.4792e-04, 3.0122e-03,\n",
              "            1.7863e-04, 6.7229e-04, 4.9537e-06, 9.8107e-07, 3.8180e-04, 2.1441e-03,\n",
              "            4.6421e-07, 1.2716e-06, 8.0712e-07, 2.3278e-04, 4.5080e-05, 1.9245e-07,\n",
              "            5.1284e-08, 1.3827e-08, 1.2276e-09, 1.3859e-07, 1.7933e-11, 1.3518e-08,\n",
              "            4.7049e-09, 2.7541e-05, 2.4249e-07, 1.4917e-05],\n",
              "           [9.9945e-01, 3.0222e-03, 4.1069e-04, 4.7861e-06, 1.3710e-03, 8.8137e-04,\n",
              "            2.0135e-04, 1.6422e-04, 6.5591e-05, 5.9231e-05, 4.6333e-04, 1.3976e-04,\n",
              "            6.3152e-07, 1.1122e-03, 1.7859e-06, 2.3419e-06, 1.1740e-05, 3.1908e-04,\n",
              "            2.7295e-05, 5.6427e-04, 2.9370e-07, 7.8366e-07, 6.0658e-05, 5.1399e-04,\n",
              "            6.0887e-08, 9.0224e-08, 3.4104e-07, 1.6791e-06, 8.7124e-06, 2.4569e-08,\n",
              "            3.7769e-08, 4.6322e-08, 8.5970e-11, 4.2865e-10, 1.5993e-12, 3.8961e-12,\n",
              "            5.8745e-07, 4.9287e-07, 1.2467e-09, 1.6952e-06],\n",
              "           [9.9933e-01, 4.1686e-04, 6.2118e-04, 8.4446e-06, 1.6214e-03, 6.0224e-04,\n",
              "            3.3388e-04, 5.8383e-04, 5.8334e-05, 5.0665e-05, 6.5414e-04, 1.3695e-05,\n",
              "            1.8696e-07, 1.6291e-03, 6.7536e-07, 5.7294e-07, 1.2802e-05, 1.1154e-03,\n",
              "            2.0363e-04, 2.2570e-04, 3.9765e-07, 1.7507e-07, 4.7663e-06, 1.0337e-04,\n",
              "            3.0739e-08, 2.2652e-08, 7.8004e-07, 4.5640e-06, 9.8494e-06, 1.0841e-08,\n",
              "            1.4216e-10, 2.4124e-10, 1.7866e-11, 1.4899e-09, 1.2508e-12, 3.4960e-10,\n",
              "            4.7851e-10, 3.4244e-07, 8.2674e-11, 8.5580e-07],\n",
              "           [9.9975e-01, 3.0494e-04, 1.8278e-04, 5.6341e-06, 5.8597e-04, 1.5693e-04,\n",
              "            2.4201e-04, 8.5013e-04, 2.6623e-05, 7.2694e-06, 4.8095e-05, 4.5725e-05,\n",
              "            1.3718e-07, 9.9958e-05, 1.9611e-07, 2.4462e-07, 1.3049e-05, 3.0867e-04,\n",
              "            3.1735e-05, 1.0075e-04, 1.2234e-07, 9.6179e-09, 5.7289e-07, 3.9184e-04,\n",
              "            1.2436e-08, 9.7028e-09, 4.6270e-07, 1.5944e-06, 1.8816e-06, 4.1686e-09,\n",
              "            6.6637e-11, 1.6493e-10, 2.2817e-11, 2.3550e-12, 4.0281e-14, 4.4441e-11,\n",
              "            6.0455e-11, 4.9354e-07, 6.0115e-07, 3.6466e-08],\n",
              "           [9.9649e-01, 3.4186e-03, 1.6506e-03, 1.2641e-05, 1.5234e-03, 6.2932e-04,\n",
              "            2.7040e-03, 7.3766e-04, 1.8486e-04, 1.4118e-04, 1.6752e-03, 1.6372e-04,\n",
              "            2.5193e-06, 3.7316e-04, 5.7218e-06, 5.3567e-06, 8.3636e-05, 1.3376e-02,\n",
              "            1.4150e-04, 1.2198e-03, 3.2688e-06, 7.4681e-06, 3.0616e-04, 7.5841e-04,\n",
              "            1.3584e-06, 9.4178e-07, 1.2049e-06, 8.4190e-05, 5.5579e-05, 2.4413e-07,\n",
              "            8.6154e-07, 5.2764e-09, 1.5527e-08, 2.7888e-07, 6.6174e-10, 2.2611e-07,\n",
              "            5.2546e-08, 1.4465e-07, 7.4548e-09, 8.6475e-05],\n",
              "           [9.9822e-01, 9.3057e-04, 1.6653e-03, 1.2460e-06, 5.9194e-04, 3.0653e-04,\n",
              "            1.3156e-04, 1.7165e-04, 5.5576e-05, 1.1301e-04, 1.0928e-04, 1.7681e-04,\n",
              "            1.3696e-07, 2.0484e-05, 8.8538e-07, 9.2863e-07, 2.8136e-06, 7.1707e-05,\n",
              "            3.3375e-06, 5.5485e-03, 3.3924e-07, 6.4187e-09, 1.0896e-04, 7.5755e-05,\n",
              "            1.0820e-08, 3.3856e-08, 3.6739e-08, 2.0693e-06, 9.9172e-07, 4.4499e-09,\n",
              "            1.7230e-08, 6.7578e-08, 3.1859e-11, 2.3359e-10, 3.5502e-13, 5.0145e-13,\n",
              "            3.4985e-09, 2.4281e-09, 1.1983e-07, 2.4369e-10],\n",
              "           [9.9319e-01, 7.4407e-03, 1.6501e-03, 2.6199e-05, 2.7478e-03, 1.1248e-03,\n",
              "            2.0257e-03, 6.5484e-04, 4.5499e-04, 5.0490e-04, 7.6048e-04, 2.3016e-03,\n",
              "            5.3688e-06, 3.6434e-04, 2.8416e-05, 2.7125e-05, 8.5093e-05, 2.1589e-03,\n",
              "            1.5274e-03, 5.3793e-04, 2.9985e-06, 1.1829e-06, 4.5475e-04, 5.4606e-03,\n",
              "            1.5027e-07, 3.5950e-07, 1.6755e-05, 2.4509e-04, 7.5605e-05, 9.7103e-07,\n",
              "            2.1528e-09, 1.4581e-09, 6.0916e-10, 6.8084e-08, 2.9966e-11, 2.0679e-08,\n",
              "            2.4650e-08, 1.0027e-04, 2.8678e-06, 4.0156e-06],\n",
              "           [9.9816e-01, 2.8903e-03, 1.1572e-03, 1.7467e-05, 2.7955e-03, 8.9984e-04,\n",
              "            5.6126e-04, 1.7253e-03, 1.7576e-04, 1.1295e-04, 9.4125e-04, 5.7194e-05,\n",
              "            1.8767e-06, 1.7087e-03, 7.4741e-06, 9.8153e-06, 4.3283e-05, 6.5028e-04,\n",
              "            1.5772e-04, 8.7344e-04, 8.0007e-07, 7.2594e-07, 4.5188e-05, 3.0800e-04,\n",
              "            1.9294e-07, 2.4977e-07, 3.3951e-06, 7.5919e-06, 1.7997e-05, 1.1903e-07,\n",
              "            3.1491e-09, 6.6047e-07, 5.3946e-11, 1.7905e-08, 3.9008e-12, 9.9466e-10,\n",
              "            1.3732e-07, 6.4043e-07, 5.6584e-09, 2.6020e-07]], device='cuda:0',\n",
              "          grad_fn=<SigmoidBackward>),\n",
              "   tensor([[9.9675e-01, 1.9405e-03, 2.9267e-03, 2.2958e-05, 7.6831e-04, 3.9533e-04,\n",
              "            3.6149e-04, 7.9860e-03, 5.9478e-04, 1.0889e-04, 4.7229e-04, 1.9576e-03,\n",
              "            1.0670e-04, 1.1273e-03, 1.1077e-05, 8.1197e-07, 1.0775e-04, 6.5548e-04,\n",
              "            1.8181e-05, 2.4716e-03, 3.0095e-04, 3.0275e-06, 1.1399e-07, 5.6137e-04,\n",
              "            4.2913e-07, 3.8367e-07, 3.5724e-08, 1.2737e-06, 1.8378e-05, 4.8027e-06],\n",
              "           [1.0000e+00, 3.7998e-07, 4.3262e-08, 9.9352e-10, 2.8273e-06, 7.3927e-09,\n",
              "            1.5353e-06, 6.1452e-07, 6.5618e-09, 2.2082e-08, 1.2664e-08, 4.8213e-06,\n",
              "            5.0238e-10, 9.9615e-08, 3.1846e-07, 2.1113e-11, 8.7905e-09, 1.2943e-06,\n",
              "            4.4205e-09, 1.2963e-06, 7.5218e-09, 2.2162e-12, 3.8212e-09, 5.6382e-07,\n",
              "            4.4898e-10, 9.3348e-10, 8.3981e-13, 1.7742e-07, 1.6781e-05, 2.4430e-10],\n",
              "           [1.0000e+00, 1.0841e-06, 4.3666e-06, 2.3677e-08, 5.3873e-05, 8.3908e-07,\n",
              "            3.0427e-06, 5.6047e-06, 6.1908e-07, 8.7366e-07, 1.6861e-07, 3.2178e-06,\n",
              "            1.8905e-08, 3.9509e-05, 1.3450e-08, 7.3527e-11, 1.9878e-08, 3.0896e-05,\n",
              "            4.8660e-09, 1.2600e-05, 1.5844e-09, 3.2405e-11, 5.4293e-06, 4.7892e-06,\n",
              "            1.9524e-10, 2.1426e-08, 4.6254e-09, 1.2256e-05, 1.7968e-06, 2.5308e-10],\n",
              "           [1.0000e+00, 7.7094e-08, 1.4917e-06, 3.5804e-09, 1.2766e-04, 2.9342e-07,\n",
              "            1.9051e-07, 1.1386e-06, 1.7690e-07, 2.3016e-06, 6.2241e-09, 3.4120e-06,\n",
              "            7.1443e-10, 4.5323e-07, 2.9176e-09, 1.2879e-11, 1.7194e-09, 3.1457e-08,\n",
              "            2.0008e-10, 5.4015e-07, 3.8158e-10, 6.8013e-12, 1.9826e-07, 4.5536e-06,\n",
              "            1.1184e-10, 1.8851e-09, 1.4891e-11, 1.5446e-08, 1.3878e-06, 1.1798e-10],\n",
              "           [1.0000e+00, 3.6720e-07, 1.0637e-05, 3.0444e-08, 1.8279e-05, 1.0387e-06,\n",
              "            1.5158e-06, 6.5379e-06, 3.6878e-07, 1.2611e-07, 6.4186e-08, 2.9194e-09,\n",
              "            3.7437e-09, 5.1739e-07, 3.9134e-11, 6.4861e-12, 9.3017e-09, 7.6671e-06,\n",
              "            4.7543e-10, 5.3478e-06, 8.8714e-11, 1.5113e-13, 6.7334e-10, 7.1619e-08,\n",
              "            6.9523e-12, 6.9923e-10, 7.7202e-11, 3.9892e-07, 1.5392e-07, 1.1532e-12],\n",
              "           [1.0000e+00, 7.1625e-07, 6.5400e-07, 1.6662e-09, 6.7108e-07, 2.0835e-08,\n",
              "            3.3150e-07, 3.2268e-07, 7.5809e-08, 1.0026e-07, 4.9565e-10, 3.2335e-09,\n",
              "            3.4885e-10, 5.1344e-08, 2.8151e-10, 1.0361e-12, 2.2043e-10, 6.0717e-07,\n",
              "            2.6509e-10, 1.2502e-06, 2.0971e-12, 2.3520e-14, 8.9682e-12, 2.9962e-07,\n",
              "            8.7709e-13, 1.2289e-11, 2.0295e-11, 4.0653e-09, 1.7805e-09, 3.8931e-12],\n",
              "           [1.0000e+00, 2.5234e-04, 1.0141e-06, 1.3677e-07, 2.0420e-05, 2.2664e-07,\n",
              "            1.0308e-04, 3.4210e-06, 5.3894e-07, 5.4590e-06, 2.4490e-06, 5.7135e-07,\n",
              "            3.5165e-08, 2.8242e-06, 2.0807e-09, 1.3512e-10, 4.1164e-07, 4.4318e-05,\n",
              "            9.4875e-09, 2.0377e-06, 7.8802e-10, 1.2806e-10, 1.2628e-06, 2.6845e-06,\n",
              "            1.0472e-09, 1.5630e-08, 7.2660e-09, 5.3122e-06, 2.2561e-06, 7.2112e-11],\n",
              "           [1.0000e+00, 3.2420e-08, 6.4797e-07, 9.5303e-10, 1.4385e-05, 2.6152e-08,\n",
              "            6.0016e-08, 2.2277e-07, 3.9362e-08, 5.6378e-07, 2.7354e-08, 3.8381e-07,\n",
              "            3.5030e-08, 8.1118e-07, 2.9356e-09, 7.0476e-11, 2.3461e-09, 1.3150e-06,\n",
              "            2.4049e-10, 4.8116e-06, 3.3782e-10, 1.7720e-11, 2.9966e-08, 3.2430e-05,\n",
              "            1.4607e-10, 8.0186e-10, 6.2635e-11, 1.3992e-08, 1.3471e-07, 1.0069e-10],\n",
              "           [9.9995e-01, 5.4302e-06, 4.7076e-05, 5.5716e-08, 2.4280e-05, 1.8178e-06,\n",
              "            2.8050e-06, 6.2149e-06, 2.5192e-06, 1.5529e-06, 8.8824e-07, 1.3995e-05,\n",
              "            3.2853e-09, 2.1982e-07, 3.5518e-08, 2.7318e-09, 1.8335e-08, 7.1371e-08,\n",
              "            2.5822e-06, 1.2769e-05, 5.9641e-09, 8.7913e-09, 4.3610e-07, 1.6578e-04,\n",
              "            2.4007e-10, 9.2807e-09, 1.5053e-09, 1.8628e-07, 4.4919e-06, 2.4081e-09],\n",
              "           [1.0000e+00, 1.5304e-05, 1.9115e-06, 9.1234e-08, 9.7628e-06, 5.1401e-07,\n",
              "            4.5374e-06, 5.6598e-06, 1.2179e-06, 5.6253e-06, 9.2211e-06, 5.6363e-08,\n",
              "            2.9524e-09, 2.4728e-07, 1.8444e-09, 3.1184e-10, 1.0226e-07, 6.6529e-07,\n",
              "            3.3009e-09, 3.0251e-06, 5.9326e-10, 2.9708e-09, 3.0257e-08, 3.1521e-05,\n",
              "            8.8196e-10, 1.8862e-09, 2.4048e-10, 3.1238e-08, 5.4142e-06, 6.9621e-11]],\n",
              "          device='cuda:0', grad_fn=<CatBackward>)],\n",
              "  5: [tensor([[9.7427e-01, 3.0776e-02, 7.0236e-03, 3.5646e-05, 5.3765e-03, 7.2342e-04,\n",
              "            8.0844e-03, 8.6134e-03, 1.0386e-03, 1.0995e-03, 8.0710e-03, 9.8909e-03,\n",
              "            2.1445e-04, 5.3387e-04, 2.6659e-04, 3.9863e-05, 9.7419e-04, 3.9525e-03,\n",
              "            1.8314e-03, 4.4058e-02, 9.6799e-03, 5.3028e-05, 1.8372e-03, 4.4518e-02,\n",
              "            4.7671e-05, 3.5197e-05, 4.2662e-05, 2.7761e-04, 6.1002e-04, 7.7841e-05,\n",
              "            1.5200e-05, 1.8990e-04, 3.8564e-06, 3.2046e-05, 1.2048e-05, 1.0820e-06,\n",
              "            1.5212e-02, 8.2539e-05, 2.3523e-03, 7.8170e-04, 9.1295e-06, 8.5012e-07,\n",
              "            4.4814e-07, 7.1689e-05, 1.9464e-04, 2.9712e-04, 1.6519e-02, 2.2220e-09,\n",
              "            1.3704e-06, 7.6322e-07],\n",
              "           [9.8047e-01, 1.0116e-03, 1.3827e-03, 1.0962e-05, 3.1044e-03, 3.2904e-04,\n",
              "            7.4766e-02, 6.6022e-03, 2.3236e-04, 2.5314e-04, 5.7985e-04, 3.8391e-04,\n",
              "            2.4582e-06, 1.0661e-03, 8.0700e-05, 2.2731e-05, 1.5098e-03, 9.5198e-03,\n",
              "            3.5104e-04, 2.4521e-03, 7.0741e-05, 6.5015e-06, 1.2863e-03, 6.2154e-04,\n",
              "            4.7540e-06, 1.0765e-05, 7.8909e-05, 4.0390e-04, 2.7516e-04, 8.4343e-07,\n",
              "            8.0025e-08, 1.1486e-04, 7.5119e-06, 3.4075e-04, 7.3357e-06, 5.8929e-06,\n",
              "            1.5015e-05, 2.4813e-05, 1.1964e-05, 6.6534e-05, 4.2757e-04, 4.0046e-07,\n",
              "            3.3056e-09, 7.4960e-09, 2.9999e-08, 9.1933e-04, 4.8156e-06, 4.6560e-08,\n",
              "            1.6903e-06, 6.6629e-07],\n",
              "           [9.8667e-01, 4.4180e-03, 1.6255e-03, 3.5491e-05, 2.9416e-02, 1.1417e-03,\n",
              "            4.7438e-03, 3.3079e-03, 9.5721e-05, 5.5254e-04, 1.2983e-03, 5.0247e-04,\n",
              "            6.9176e-06, 3.5990e-02, 1.7484e-05, 2.2020e-05, 1.2195e-03, 1.2592e-02,\n",
              "            4.7516e-04, 6.8679e-03, 2.7559e-05, 1.7406e-05, 4.5730e-04, 5.9616e-03,\n",
              "            2.2940e-05, 4.0800e-06, 6.1670e-05, 3.9694e-04, 2.3974e-04, 2.0545e-06,\n",
              "            8.8773e-07, 8.7051e-05, 1.1536e-05, 6.0760e-07, 7.6686e-06, 1.6588e-06,\n",
              "            2.1659e-05, 9.4796e-05, 1.2733e-06, 1.1948e-03, 3.4780e-07, 9.0219e-08,\n",
              "            2.5965e-08, 4.3246e-07, 3.3075e-08, 2.8555e-04, 8.5335e-07, 9.6700e-08,\n",
              "            6.5534e-06, 1.5472e-06],\n",
              "           [9.9887e-01, 1.9625e-03, 1.0324e-03, 2.4073e-06, 2.7510e-03, 3.8416e-04,\n",
              "            4.8301e-04, 1.5673e-03, 2.9597e-05, 1.7613e-04, 1.3592e-03, 2.1381e-04,\n",
              "            1.3918e-06, 5.8288e-03, 2.4209e-06, 4.5551e-06, 8.4799e-05, 1.5202e-03,\n",
              "            3.4539e-04, 1.0263e-02, 6.4754e-06, 2.4590e-06, 3.5882e-05, 2.7042e-03,\n",
              "            6.8641e-06, 3.8417e-07, 4.0343e-05, 1.2712e-05, 1.1471e-04, 2.0038e-06,\n",
              "            1.3623e-07, 4.7015e-05, 4.9722e-07, 1.5112e-07, 6.1201e-08, 4.7672e-08,\n",
              "            4.1246e-04, 4.4998e-05, 3.9027e-07, 6.6273e-05, 2.7022e-08, 1.6004e-08,\n",
              "            1.6777e-08, 5.4611e-06, 1.0109e-09, 3.6221e-07, 9.5163e-07, 1.6948e-09,\n",
              "            8.4265e-07, 4.0055e-09],\n",
              "           [9.9805e-01, 2.5899e-04, 2.6496e-03, 6.3194e-06, 3.3980e-03, 3.0473e-04,\n",
              "            4.8717e-04, 2.4405e-03, 4.4710e-05, 1.4312e-04, 2.7609e-04, 1.5120e-05,\n",
              "            4.3333e-07, 7.1339e-03, 2.6615e-06, 1.1106e-06, 2.0470e-04, 1.1462e-02,\n",
              "            6.4113e-04, 3.2908e-03, 6.8279e-06, 8.2659e-07, 2.1873e-05, 1.7782e-04,\n",
              "            2.8333e-06, 2.9107e-07, 1.1464e-04, 1.9974e-05, 2.4312e-05, 9.1035e-08,\n",
              "            2.2369e-09, 5.4859e-05, 3.7039e-07, 1.6628e-07, 8.1310e-08, 7.0495e-07,\n",
              "            2.0328e-06, 3.5834e-06, 2.6188e-08, 6.4921e-05, 3.8875e-08, 1.2010e-08,\n",
              "            4.9505e-11, 1.8100e-08, 1.6469e-10, 4.1260e-07, 1.8124e-10, 2.5807e-11,\n",
              "            7.2122e-08, 1.7154e-08],\n",
              "           [9.9866e-01, 7.7404e-04, 7.5264e-04, 3.2347e-06, 3.1223e-03, 1.8531e-04,\n",
              "            2.4961e-03, 4.5260e-03, 5.2135e-05, 6.7846e-05, 7.7655e-05, 4.9980e-04,\n",
              "            5.0404e-07, 1.6001e-03, 6.4850e-06, 1.9174e-06, 1.0493e-03, 1.2063e-02,\n",
              "            1.3144e-04, 1.9986e-03, 2.1640e-05, 7.4791e-07, 2.7173e-05, 4.3530e-03,\n",
              "            2.5983e-06, 1.1837e-06, 6.3898e-05, 8.2497e-05, 5.0616e-05, 5.5897e-07,\n",
              "            2.8251e-08, 3.8659e-05, 5.8369e-07, 2.4815e-06, 4.7415e-07, 5.2436e-07,\n",
              "            6.5067e-06, 7.5160e-05, 1.5049e-06, 3.4978e-04, 1.8759e-07, 1.2487e-06,\n",
              "            1.2612e-09, 4.2602e-07, 2.9396e-08, 2.5525e-06, 1.5468e-06, 6.0744e-09,\n",
              "            4.4164e-07, 6.2397e-07],\n",
              "           [9.8067e-01, 3.9320e-03, 5.5441e-03, 3.7928e-05, 1.1694e-02, 4.1678e-04,\n",
              "            2.9617e-03, 2.4609e-03, 1.3529e-04, 1.3763e-03, 5.4846e-03, 2.8077e-04,\n",
              "            7.5701e-06, 1.1130e-02, 8.3052e-06, 2.9967e-05, 5.8038e-04, 5.2058e-03,\n",
              "            4.5779e-04, 1.4474e-02, 5.5267e-05, 1.2408e-05, 1.8452e-03, 2.2126e-03,\n",
              "            1.5503e-05, 1.4423e-05, 2.7933e-05, 1.4353e-04, 1.1819e-04, 3.0155e-06,\n",
              "            3.2229e-06, 1.7110e-04, 4.5228e-06, 3.7270e-06, 3.2476e-06, 2.3062e-06,\n",
              "            5.2864e-05, 1.0270e-05, 2.9832e-06, 9.1799e-04, 5.5253e-06, 6.6766e-08,\n",
              "            3.8085e-08, 1.1452e-06, 5.1491e-09, 3.5954e-05, 2.7291e-06, 1.0334e-08,\n",
              "            1.2333e-05, 1.7548e-06],\n",
              "           [9.9539e-01, 1.3962e-03, 2.6764e-03, 2.4272e-06, 1.0290e-03, 2.0007e-04,\n",
              "            3.6801e-04, 8.0751e-04, 7.2013e-05, 3.3203e-04, 3.2059e-04, 5.2902e-04,\n",
              "            6.7683e-07, 2.2409e-04, 1.7272e-06, 3.8193e-06, 4.3456e-05, 7.2463e-04,\n",
              "            6.2658e-05, 5.1689e-03, 5.0929e-06, 5.2542e-07, 6.1036e-04, 1.9572e-04,\n",
              "            4.6719e-07, 1.0208e-06, 7.7140e-06, 4.7055e-05, 1.6017e-05, 1.1382e-07,\n",
              "            9.0405e-08, 3.2302e-05, 3.5748e-07, 1.3952e-06, 1.3039e-08, 4.3979e-08,\n",
              "            2.2613e-06, 7.2308e-06, 6.0926e-07, 1.0921e-04, 2.0608e-05, 2.0277e-08,\n",
              "            1.0195e-10, 5.6932e-09, 7.1085e-09, 2.7190e-08, 8.9348e-06, 2.5550e-10,\n",
              "            4.9443e-08, 2.2113e-08],\n",
              "           [9.9543e-01, 4.1715e-03, 3.9521e-03, 8.4711e-05, 2.6786e-03, 7.6149e-04,\n",
              "            3.7331e-03, 1.0469e-02, 1.0267e-03, 1.0760e-03, 3.6054e-03, 3.2299e-03,\n",
              "            2.4792e-05, 1.0517e-03, 4.6656e-05, 5.3500e-05, 3.3977e-04, 1.0090e-02,\n",
              "            5.6219e-03, 8.0685e-03, 3.3813e-04, 1.3588e-05, 1.6540e-03, 1.2335e-02,\n",
              "            1.3387e-05, 1.5806e-05, 2.8738e-04, 5.5375e-04, 1.6890e-04, 2.5373e-05,\n",
              "            1.5204e-06, 1.2933e-04, 8.2829e-06, 1.3759e-05, 2.2608e-06, 1.1317e-05,\n",
              "            1.8129e-04, 4.1412e-04, 6.6509e-04, 2.4634e-03, 3.7217e-05, 2.5528e-05,\n",
              "            3.1567e-07, 1.7912e-05, 8.6489e-07, 9.6095e-07, 2.1971e-03, 1.3147e-07,\n",
              "            6.0852e-06, 1.1183e-05],\n",
              "           [9.9523e-01, 6.3780e-03, 1.9487e-03, 3.6397e-05, 4.1828e-03, 1.1065e-03,\n",
              "            3.7233e-03, 5.0076e-03, 2.5382e-04, 3.4411e-04, 2.6525e-03, 3.9908e-04,\n",
              "            7.4534e-06, 1.1256e-02, 2.5580e-05, 4.1376e-05, 1.1283e-03, 2.1366e-02,\n",
              "            1.8465e-03, 3.1439e-03, 5.7436e-05, 4.6339e-05, 3.7718e-04, 3.4121e-03,\n",
              "            2.7003e-05, 6.3926e-06, 3.2500e-04, 2.5395e-04, 5.4979e-04, 5.8004e-06,\n",
              "            7.1882e-07, 1.4939e-04, 2.0523e-05, 1.1867e-05, 2.1670e-06, 1.5705e-05,\n",
              "            2.5601e-04, 2.5186e-04, 1.9378e-06, 1.9341e-03, 8.0535e-06, 1.8048e-06,\n",
              "            2.5225e-07, 1.8194e-05, 3.0471e-07, 5.5378e-06, 2.1559e-06, 3.7847e-07,\n",
              "            8.7585e-06, 1.3705e-06]], device='cuda:0', grad_fn=<SigmoidBackward>),\n",
              "   tensor([[9.9930e-01, 3.4964e-03, 1.3492e-03, 1.9468e-05, 3.3885e-04, 1.7016e-04,\n",
              "            2.5638e-04, 2.0690e-03, 4.1084e-04, 5.1789e-05, 4.1604e-05, 1.6871e-03,\n",
              "            2.1531e-06, 4.7367e-04, 8.2909e-06, 8.6476e-08, 3.1004e-06, 1.5432e-04,\n",
              "            1.3575e-05, 3.9793e-04, 1.2780e-04, 1.4848e-07, 1.0319e-07, 4.0423e-03,\n",
              "            1.7793e-08, 4.1139e-08, 3.8377e-09, 6.3258e-08, 4.1069e-05, 3.9185e-07,\n",
              "            1.5468e-07, 8.0581e-06, 1.3119e-08, 1.8022e-06, 3.8311e-09, 7.7896e-10,\n",
              "            3.6196e-03, 1.5581e-07, 3.4528e-05, 9.7702e-07],\n",
              "           [9.9999e-01, 4.3620e-07, 4.6028e-06, 2.8427e-08, 4.3693e-05, 1.1600e-06,\n",
              "            6.9035e-05, 1.5974e-05, 2.0386e-07, 1.5677e-07, 1.5428e-06, 2.6904e-05,\n",
              "            5.0124e-08, 1.0439e-05, 1.5219e-07, 1.1908e-09, 2.2039e-07, 4.3269e-06,\n",
              "            4.8003e-08, 2.1537e-06, 3.6123e-08, 7.4214e-10, 1.8802e-07, 3.1387e-06,\n",
              "            6.2190e-09, 1.9719e-08, 3.3745e-11, 5.5549e-07, 5.5277e-05, 2.7344e-09,\n",
              "            1.7280e-11, 3.1551e-08, 3.0665e-10, 1.5709e-05, 2.5999e-10, 8.0038e-10,\n",
              "            7.2878e-09, 7.1448e-08, 8.2714e-09, 2.9798e-05],\n",
              "           [9.9995e-01, 1.5602e-04, 8.6879e-06, 4.1921e-07, 5.8993e-03, 4.2933e-06,\n",
              "            1.7177e-04, 3.3202e-05, 2.9379e-06, 1.9037e-05, 9.8925e-08, 3.0141e-06,\n",
              "            4.9315e-07, 7.2444e-05, 1.2685e-08, 3.6499e-10, 2.3192e-07, 3.3128e-04,\n",
              "            1.4199e-08, 6.1670e-06, 1.4746e-07, 3.2350e-09, 7.7852e-06, 1.5856e-04,\n",
              "            1.4888e-08, 4.9276e-07, 4.6972e-08, 7.4957e-05, 7.5583e-06, 1.0418e-09,\n",
              "            4.8482e-07, 2.0623e-07, 3.1761e-09, 1.7007e-08, 4.7234e-09, 9.7949e-09,\n",
              "            5.3210e-09, 1.4460e-05, 2.3754e-08, 2.0618e-04],\n",
              "           [1.0000e+00, 3.3795e-07, 7.8053e-07, 7.3021e-09, 2.0321e-04, 4.1474e-07,\n",
              "            5.3281e-07, 8.6795e-07, 2.0570e-07, 7.4097e-06, 6.4485e-08, 6.1867e-06,\n",
              "            1.2504e-08, 9.6209e-05, 2.3024e-09, 2.7541e-10, 1.6890e-07, 3.4789e-08,\n",
              "            3.1825e-10, 1.9851e-06, 1.0361e-10, 7.9037e-11, 1.2290e-07, 2.4795e-06,\n",
              "            8.9808e-11, 1.4452e-09, 7.8110e-12, 2.5217e-08, 5.0534e-07, 1.7223e-11,\n",
              "            2.7415e-08, 1.0082e-07, 9.4611e-10, 1.0336e-08, 4.4469e-11, 1.7595e-11,\n",
              "            1.3172e-06, 1.3895e-05, 2.2550e-08, 1.4882e-05],\n",
              "           [1.0000e+00, 2.1921e-08, 1.3687e-06, 1.6492e-09, 1.3798e-06, 6.1836e-08,\n",
              "            2.0309e-07, 7.0326e-07, 3.4976e-08, 1.5905e-08, 6.5481e-09, 5.4095e-11,\n",
              "            2.5282e-11, 1.1455e-07, 4.4991e-12, 1.0406e-13, 4.9013e-11, 4.6626e-06,\n",
              "            3.0637e-11, 2.3787e-07, 7.1367e-11, 2.5262e-14, 3.0519e-11, 8.8912e-09,\n",
              "            2.4552e-12, 9.0621e-12, 9.1216e-13, 2.0793e-08, 1.4650e-06, 3.3957e-14,\n",
              "            2.0978e-12, 6.4689e-11, 3.8498e-11, 1.0870e-10, 6.7457e-10, 5.0096e-10,\n",
              "            3.5900e-09, 1.0174e-06, 3.7562e-11, 2.3541e-08],\n",
              "           [1.0000e+00, 4.5348e-05, 2.5893e-07, 8.4339e-09, 1.0580e-05, 2.7988e-08,\n",
              "            3.3975e-06, 3.6015e-07, 2.7474e-08, 2.5606e-07, 8.1708e-06, 7.8409e-07,\n",
              "            3.0773e-09, 8.4091e-05, 2.3090e-09, 2.3010e-10, 1.0470e-06, 8.7956e-06,\n",
              "            1.9499e-09, 1.2790e-06, 3.6366e-12, 7.4241e-13, 1.3919e-10, 2.3338e-07,\n",
              "            1.5636e-12, 1.9618e-12, 7.0751e-11, 1.3343e-08, 1.5987e-08, 1.3159e-12,\n",
              "            1.8397e-10, 2.1634e-08, 2.4879e-12, 4.9086e-10, 3.0545e-12, 3.8362e-10,\n",
              "            3.9457e-09, 2.9960e-07, 4.9722e-09, 6.9648e-08],\n",
              "           [1.0000e+00, 4.4549e-06, 1.6793e-06, 4.8367e-08, 5.9806e-05, 2.9915e-07,\n",
              "            4.7451e-05, 2.8241e-06, 1.6745e-07, 7.4010e-07, 1.4792e-06, 1.6820e-07,\n",
              "            1.8842e-07, 2.7761e-05, 3.8662e-09, 7.4129e-10, 7.7214e-07, 9.8708e-06,\n",
              "            6.8132e-09, 1.2586e-05, 7.2130e-08, 8.7902e-11, 8.9592e-08, 1.9448e-04,\n",
              "            6.4793e-09, 7.4679e-08, 2.1727e-08, 8.8417e-07, 4.8827e-07, 9.3565e-11,\n",
              "            6.6563e-07, 1.4157e-06, 1.1786e-09, 1.2155e-06, 2.0898e-08, 1.1963e-07,\n",
              "            1.3366e-08, 1.0636e-06, 4.5474e-08, 5.5819e-04],\n",
              "           [1.0000e+00, 1.1522e-07, 6.6042e-07, 3.1719e-09, 2.4061e-05, 7.5488e-08,\n",
              "            5.0119e-08, 2.4231e-07, 1.4487e-07, 1.0403e-05, 4.8204e-08, 5.1648e-06,\n",
              "            1.3413e-08, 2.2874e-06, 1.4565e-08, 2.3932e-10, 4.6539e-09, 1.2435e-08,\n",
              "            1.5930e-10, 4.1276e-06, 4.7770e-11, 5.2642e-12, 1.2320e-08, 1.6839e-06,\n",
              "            7.9093e-12, 1.0308e-10, 2.8893e-10, 1.0572e-08, 3.2462e-08, 2.2304e-11,\n",
              "            9.1616e-08, 2.7458e-07, 3.9305e-11, 9.5174e-09, 1.2614e-13, 2.3075e-11,\n",
              "            9.1532e-09, 1.2189e-08, 1.3360e-07, 2.6581e-09],\n",
              "           [1.0000e+00, 3.8530e-07, 3.2506e-06, 1.6358e-08, 2.6320e-05, 7.7503e-07,\n",
              "            7.3533e-07, 1.3253e-05, 1.1778e-06, 7.4081e-07, 4.6852e-07, 2.0589e-05,\n",
              "            1.8072e-09, 7.0578e-08, 2.8628e-08, 1.1880e-10, 4.3551e-08, 2.3032e-07,\n",
              "            8.1511e-08, 3.9765e-05, 3.1951e-09, 1.3875e-10, 4.2106e-07, 1.9214e-05,\n",
              "            1.3547e-10, 4.6571e-09, 1.0997e-10, 1.0589e-07, 1.9830e-06, 7.2109e-09,\n",
              "            2.8308e-09, 1.5366e-07, 2.6077e-09, 5.8049e-08, 2.1955e-10, 3.5720e-09,\n",
              "            5.7942e-07, 5.8262e-06, 1.9028e-04, 4.8196e-07],\n",
              "           [1.0000e+00, 1.7178e-05, 1.2843e-06, 1.1430e-07, 6.5136e-05, 6.7932e-07,\n",
              "            1.1452e-05, 7.2508e-06, 1.0122e-06, 4.2808e-06, 8.7652e-06, 7.3405e-07,\n",
              "            6.0894e-08, 2.1898e-05, 8.8198e-09, 2.2325e-09, 1.9128e-07, 8.1886e-07,\n",
              "            4.2345e-08, 3.2956e-06, 5.0887e-09, 2.5340e-08, 1.5552e-06, 2.4872e-04,\n",
              "            2.3543e-09, 2.1709e-08, 1.5488e-09, 1.8957e-07, 1.0603e-05, 4.0461e-10,\n",
              "            4.0522e-08, 3.2204e-07, 1.0033e-09, 9.5300e-08, 1.2791e-10, 7.0067e-09,\n",
              "            2.6234e-06, 9.4838e-06, 1.2595e-08, 1.1147e-06]], device='cuda:0',\n",
              "          grad_fn=<CatBackward>)],\n",
              "  6: [tensor([[9.6625e-01, 2.0775e-02, 5.3275e-03, 1.9789e-04, 1.6800e-02, 8.2670e-04,\n",
              "            6.9812e-02, 1.8075e-02, 1.1841e-03, 3.3188e-03, 1.3076e-02, 5.0121e-02,\n",
              "            2.3304e-04, 1.2598e-03, 1.3182e-03, 9.6500e-05, 6.8688e-03, 1.0209e-02,\n",
              "            3.6041e-03, 1.9661e-02, 1.0991e-02, 5.9641e-04, 1.0135e-03, 1.4027e-01,\n",
              "            9.4138e-05, 5.2635e-04, 6.2610e-04, 9.0894e-04, 6.8034e-04, 4.0973e-04,\n",
              "            1.0714e-04, 6.6983e-04, 1.3095e-04, 8.9184e-04, 2.1723e-04, 6.0595e-05,\n",
              "            1.0168e-01, 3.0869e-03, 1.9115e-02, 5.2460e-04, 2.6470e-03, 7.4283e-05,\n",
              "            5.5138e-04, 6.4523e-03, 7.9567e-04, 1.3789e-03, 5.8797e-02, 6.7361e-05,\n",
              "            4.1947e-05, 1.2245e-04, 7.9683e-04, 6.8793e-05, 4.4075e-03, 5.6924e-05,\n",
              "            2.6535e-04, 1.3077e-06, 2.3948e-06, 1.4012e-06, 1.4679e-05, 6.4401e-02],\n",
              "           [9.6298e-01, 1.8741e-03, 1.2137e-03, 5.4873e-05, 1.2967e-02, 3.1700e-04,\n",
              "            5.8401e-02, 7.9002e-03, 4.6629e-04, 1.9188e-03, 1.8103e-03, 1.4593e-03,\n",
              "            2.5851e-06, 3.3331e-03, 1.8843e-04, 1.8536e-04, 1.0823e-03, 1.4119e-02,\n",
              "            5.1937e-04, 2.5261e-03, 1.2942e-04, 8.1549e-06, 5.6557e-03, 6.3168e-03,\n",
              "            5.7812e-06, 2.8835e-05, 1.2557e-04, 3.5289e-04, 1.4762e-04, 3.2299e-06,\n",
              "            3.9482e-06, 3.2673e-04, 5.6148e-05, 1.2883e-04, 2.7505e-05, 5.6783e-06,\n",
              "            2.6581e-05, 2.7946e-04, 1.9952e-05, 5.7748e-04, 3.1884e-04, 2.7543e-06,\n",
              "            1.9507e-06, 4.9624e-06, 3.6924e-07, 3.5154e-04, 7.6907e-04, 1.2366e-05,\n",
              "            8.5343e-06, 1.4806e-05, 1.0774e-06, 3.1536e-09, 4.4162e-05, 2.8537e-08,\n",
              "            3.7939e-08, 1.2981e-07, 1.2211e-07, 1.4176e-09, 2.4146e-03, 1.7992e-04],\n",
              "           [9.6150e-01, 1.2608e-02, 4.0384e-03, 6.9556e-04, 1.5439e-02, 1.1947e-03,\n",
              "            4.0834e-02, 5.0562e-03, 1.1662e-03, 6.2005e-03, 8.3935e-03, 1.5060e-02,\n",
              "            7.4204e-05, 1.3235e-02, 2.6616e-04, 3.1836e-04, 9.6329e-04, 4.1558e-02,\n",
              "            2.4830e-03, 9.1242e-03, 3.0428e-04, 1.1207e-04, 5.4101e-03, 8.5781e-02,\n",
              "            2.1231e-04, 4.1865e-04, 1.8773e-03, 6.6026e-04, 2.5622e-04, 4.4230e-05,\n",
              "            2.6971e-04, 3.9487e-04, 2.2936e-04, 1.0833e-04, 7.0471e-05, 1.9137e-04,\n",
              "            3.5253e-03, 2.3961e-03, 2.3677e-04, 2.0326e-03, 4.3591e-04, 1.8634e-05,\n",
              "            1.9339e-05, 8.0228e-03, 1.8811e-05, 1.7913e-04, 1.6588e-03, 1.4097e-04,\n",
              "            7.9835e-05, 2.2357e-04, 4.6760e-06, 5.1502e-08, 9.0037e-04, 1.7102e-05,\n",
              "            4.8179e-07, 6.9494e-06, 5.8413e-05, 9.7174e-07, 5.9664e-04, 5.4727e-03],\n",
              "           [9.9322e-01, 7.3035e-03, 4.5330e-03, 1.4029e-04, 7.8861e-03, 4.0220e-04,\n",
              "            2.6182e-03, 4.0484e-03, 1.2452e-04, 4.8710e-04, 4.0570e-03, 1.5277e-03,\n",
              "            3.2901e-06, 3.0170e-03, 3.7307e-05, 4.2105e-05, 2.1767e-04, 2.5407e-03,\n",
              "            4.0670e-04, 1.5992e-02, 4.7359e-05, 5.7288e-06, 1.4670e-03, 2.9161e-03,\n",
              "            2.4194e-05, 3.8925e-06, 2.3995e-04, 1.4778e-05, 5.8929e-05, 7.6021e-06,\n",
              "            1.1333e-06, 1.1850e-04, 1.4804e-05, 1.6790e-06, 2.9051e-06, 2.9562e-07,\n",
              "            2.0706e-03, 6.7126e-05, 9.2882e-06, 2.0202e-04, 4.7668e-05, 9.3179e-07,\n",
              "            8.9660e-06, 1.9104e-05, 6.2623e-07, 1.4444e-05, 1.1501e-04, 1.5904e-07,\n",
              "            1.0464e-06, 4.3757e-07, 5.7486e-06, 9.8677e-11, 2.6075e-07, 4.8342e-07,\n",
              "            2.5039e-09, 2.1072e-11, 1.6851e-07, 6.8819e-09, 1.6363e-05, 2.4883e-06],\n",
              "           [9.9642e-01, 2.3487e-04, 2.7474e-03, 8.7630e-05, 2.2165e-03, 5.2773e-05,\n",
              "            4.8777e-04, 2.9871e-03, 1.2336e-04, 2.3388e-04, 1.5260e-04, 3.9283e-05,\n",
              "            8.2979e-08, 2.2421e-03, 1.8502e-06, 9.1344e-06, 8.3281e-05, 2.1330e-02,\n",
              "            4.2565e-04, 2.1043e-03, 1.0978e-05, 4.0099e-08, 4.0695e-05, 1.1124e-04,\n",
              "            4.5415e-06, 6.9619e-07, 2.5004e-04, 4.5484e-06, 4.3600e-06, 2.9041e-08,\n",
              "            1.2104e-08, 2.8077e-04, 5.5769e-07, 5.1161e-07, 3.8921e-08, 1.1463e-06,\n",
              "            6.3901e-07, 1.5093e-05, 1.0890e-07, 3.5126e-05, 3.8857e-07, 1.8089e-08,\n",
              "            2.2252e-09, 9.3749e-07, 3.0724e-08, 5.5582e-08, 8.7278e-08, 1.5567e-09,\n",
              "            7.4877e-08, 2.7417e-06, 5.7347e-12, 1.6669e-13, 3.1959e-09, 1.3979e-10,\n",
              "            1.3096e-10, 1.1758e-09, 1.9429e-13, 9.6697e-13, 8.2892e-07, 2.5372e-07],\n",
              "           [9.9421e-01, 2.0304e-03, 7.7034e-04, 1.0829e-04, 3.8973e-03, 9.9023e-05,\n",
              "            6.4473e-03, 6.2263e-03, 2.8466e-04, 5.2116e-04, 4.5086e-04, 1.2543e-03,\n",
              "            1.0991e-06, 1.3278e-03, 1.6740e-05, 4.9061e-05, 9.5803e-04, 3.3165e-02,\n",
              "            3.7219e-04, 1.7506e-03, 1.0294e-04, 2.6763e-06, 2.9184e-04, 9.3230e-03,\n",
              "            1.1559e-05, 1.4955e-05, 2.9554e-04, 5.2819e-05, 3.4575e-05, 7.6626e-07,\n",
              "            7.4034e-07, 2.3901e-04, 1.3835e-05, 1.6163e-05, 2.6288e-06, 2.1044e-05,\n",
              "            3.6155e-05, 2.4669e-04, 1.9964e-05, 1.3417e-03, 5.3273e-05, 8.3472e-06,\n",
              "            5.8155e-07, 3.5475e-05, 1.0817e-06, 2.7542e-05, 4.7553e-05, 8.7210e-07,\n",
              "            3.9048e-06, 1.9667e-05, 9.9815e-08, 1.5222e-09, 5.8771e-06, 3.3312e-07,\n",
              "            1.5390e-09, 4.8114e-07, 1.5687e-09, 3.0318e-09, 6.0314e-03, 3.8206e-05],\n",
              "           [9.8483e-01, 2.7494e-03, 7.9441e-03, 2.1807e-04, 7.8013e-03, 2.5638e-04,\n",
              "            8.7375e-03, 2.2215e-03, 3.3087e-04, 2.2806e-03, 3.6793e-03, 1.7346e-03,\n",
              "            5.4887e-06, 2.7878e-03, 2.3769e-05, 7.2475e-05, 3.0167e-04, 5.3036e-02,\n",
              "            6.6804e-04, 5.8231e-03, 1.0611e-04, 1.8615e-05, 3.8125e-03, 3.4588e-03,\n",
              "            3.0797e-05, 3.0019e-05, 1.7822e-04, 6.8900e-05, 6.1815e-05, 2.6259e-06,\n",
              "            4.4798e-06, 8.0441e-05, 3.8872e-05, 2.4489e-05, 1.1458e-05, 1.4263e-05,\n",
              "            9.5881e-05, 4.3999e-05, 4.5415e-05, 4.3623e-04, 6.1643e-05, 2.6713e-06,\n",
              "            7.2182e-07, 1.5917e-05, 1.3567e-06, 1.2609e-04, 6.4622e-05, 2.8418e-06,\n",
              "            6.1941e-06, 1.2270e-05, 3.6608e-07, 6.0311e-10, 2.9133e-06, 1.5315e-08,\n",
              "            9.5163e-10, 3.6805e-09, 2.2210e-07, 1.4165e-07, 9.3266e-05, 1.2332e-05],\n",
              "           [9.9304e-01, 4.7494e-04, 3.4960e-03, 3.0287e-05, 1.4881e-03, 5.8918e-05,\n",
              "            9.0730e-04, 1.5930e-03, 1.5759e-04, 1.2929e-03, 9.9918e-04, 4.2795e-04,\n",
              "            4.0693e-07, 1.8131e-04, 3.6603e-06, 7.7974e-06, 4.2304e-05, 1.7192e-03,\n",
              "            2.7080e-04, 9.8790e-03, 2.2877e-05, 2.1297e-07, 5.1070e-04, 6.9354e-04,\n",
              "            1.0366e-06, 2.9027e-06, 1.7000e-05, 1.0349e-05, 5.2052e-06, 4.2915e-07,\n",
              "            5.2195e-07, 2.9761e-05, 3.7380e-06, 4.3802e-06, 4.8972e-08, 4.6803e-07,\n",
              "            9.9734e-06, 8.3759e-06, 2.5090e-05, 2.5751e-05, 1.0067e-04, 3.5222e-08,\n",
              "            5.5617e-08, 1.0296e-06, 4.2528e-08, 3.6971e-08, 9.0960e-05, 5.8581e-08,\n",
              "            4.1348e-07, 1.9999e-06, 1.1372e-09, 5.6993e-12, 1.6046e-07, 4.5739e-07,\n",
              "            3.5184e-10, 8.8343e-12, 1.8374e-10, 4.0020e-14, 3.9617e-06, 3.4470e-05],\n",
              "           [9.8497e-01, 8.5363e-03, 5.1783e-03, 2.1356e-04, 5.8493e-03, 6.3799e-04,\n",
              "            1.1815e-02, 1.7349e-02, 1.7490e-03, 2.6033e-03, 1.0798e-02, 8.3146e-03,\n",
              "            3.5999e-05, 1.4963e-03, 2.2232e-04, 2.4122e-04, 1.4187e-03, 1.9877e-02,\n",
              "            2.5954e-03, 1.2077e-02, 1.4288e-03, 1.9764e-05, 4.2384e-03, 2.2270e-02,\n",
              "            6.2980e-05, 1.9504e-04, 6.4221e-04, 6.1871e-04, 3.3199e-04, 6.4309e-05,\n",
              "            2.4594e-05, 1.3561e-03, 5.9229e-05, 2.5389e-04, 5.6881e-05, 6.7459e-05,\n",
              "            8.1814e-04, 3.1866e-03, 7.2940e-04, 1.1255e-03, 5.0113e-04, 6.7082e-05,\n",
              "            5.0726e-05, 6.3248e-04, 2.9486e-06, 1.0603e-04, 3.8714e-03, 7.5288e-05,\n",
              "            1.4838e-04, 4.6203e-05, 4.3122e-06, 1.0585e-07, 1.0120e-03, 8.6222e-05,\n",
              "            5.0389e-07, 1.6962e-07, 4.8317e-06, 6.3460e-08, 3.1749e-04, 6.5976e-03],\n",
              "           [9.9081e-01, 3.6028e-03, 3.6458e-03, 3.7525e-04, 9.8203e-03, 5.8957e-04,\n",
              "            6.7820e-03, 1.4282e-02, 1.0498e-03, 1.0209e-03, 5.8081e-03, 7.6709e-04,\n",
              "            1.1199e-05, 1.1496e-02, 6.0918e-05, 1.3755e-04, 1.2248e-03, 3.8463e-02,\n",
              "            2.2468e-03, 6.8618e-03, 4.2708e-04, 3.0592e-05, 1.1631e-03, 8.5915e-03,\n",
              "            3.3837e-05, 4.0464e-05, 1.8803e-03, 1.5436e-04, 1.8130e-04, 7.1308e-06,\n",
              "            5.8713e-06, 8.6676e-04, 6.4513e-05, 6.0188e-05, 2.6017e-05, 1.2153e-04,\n",
              "            3.5927e-04, 5.5165e-04, 2.0969e-05, 1.2696e-03, 1.3183e-04, 1.6172e-05,\n",
              "            4.6421e-06, 1.0909e-04, 1.5207e-05, 6.9595e-05, 5.1274e-05, 8.0311e-06,\n",
              "            2.0533e-05, 9.3688e-05, 6.9494e-07, 1.2494e-08, 9.2789e-06, 1.2598e-06,\n",
              "            1.2486e-06, 1.2904e-07, 1.2058e-07, 4.0549e-07, 2.1010e-04, 9.2947e-05]],\n",
              "          device='cuda:0', grad_fn=<SigmoidBackward>),\n",
              "   tensor([[9.9952e-01, 3.8379e-04, 4.9068e-04, 4.1837e-06, 2.0100e-04, 8.2541e-05,\n",
              "            1.1129e-04, 2.0430e-03, 2.4704e-04, 2.6966e-04, 2.9582e-04, 5.1474e-03,\n",
              "            2.4370e-05, 1.0196e-04, 2.6103e-06, 2.6148e-08, 1.6155e-05, 9.2343e-04,\n",
              "            1.1529e-05, 1.7585e-03, 4.8872e-04, 1.7593e-05, 1.0673e-06, 1.6827e-03,\n",
              "            4.4533e-07, 1.2285e-06, 1.8523e-07, 3.2338e-06, 3.0983e-05, 4.7807e-05,\n",
              "            3.5817e-07, 2.8352e-06, 1.6202e-07, 1.2518e-06, 4.4427e-08, 2.6378e-09,\n",
              "            1.2230e-02, 7.4272e-07, 1.8298e-03, 3.3777e-07, 2.2758e-05, 1.0237e-06,\n",
              "            1.0931e-04, 2.5701e-04, 1.9300e-05, 2.0782e-03, 4.0177e-02, 1.0862e-07,\n",
              "            4.3463e-07, 2.3999e-06],\n",
              "           [1.0000e+00, 5.5440e-07, 1.7854e-06, 1.2413e-08, 2.0628e-05, 3.8874e-07,\n",
              "            1.0352e-05, 4.8212e-06, 8.6769e-08, 6.3413e-08, 1.2988e-07, 2.8470e-05,\n",
              "            9.4089e-10, 7.5026e-07, 9.2082e-07, 1.4362e-10, 4.6063e-08, 3.9451e-06,\n",
              "            3.9425e-08, 1.6008e-06, 4.1239e-08, 5.5319e-11, 6.9609e-08, 6.0140e-07,\n",
              "            2.3894e-09, 1.1438e-08, 3.6823e-11, 7.0807e-07, 4.9564e-05, 9.1147e-10,\n",
              "            3.2170e-12, 2.9948e-08, 5.9315e-11, 2.8718e-06, 1.2815e-10, 3.4184e-10,\n",
              "            1.3231e-09, 1.0908e-07, 5.0081e-08, 9.8665e-06, 6.1158e-05, 3.3555e-07,\n",
              "            2.1264e-09, 3.7039e-09, 1.6695e-08, 3.2358e-03, 6.1952e-06, 4.0028e-08,\n",
              "            7.2554e-07, 4.4508e-07],\n",
              "           [9.9999e-01, 4.0428e-05, 2.9621e-05, 1.0985e-06, 3.7832e-04, 1.9881e-05,\n",
              "            8.8371e-05, 1.0079e-04, 1.9430e-05, 1.5589e-05, 5.1752e-05, 2.9459e-04,\n",
              "            4.6144e-06, 2.0224e-03, 2.1265e-05, 1.3020e-07, 3.8347e-05, 3.1758e-04,\n",
              "            3.3176e-06, 1.4347e-03, 8.4443e-07, 7.8736e-09, 6.6547e-05, 1.6354e-03,\n",
              "            3.5564e-08, 1.2310e-06, 1.5254e-06, 7.4639e-05, 7.1971e-06, 2.1031e-08,\n",
              "            3.6481e-05, 1.2919e-06, 6.4757e-08, 4.5643e-06, 2.5232e-08, 6.9255e-06,\n",
              "            1.7416e-06, 3.1580e-04, 1.2545e-06, 6.4945e-04, 2.1865e-04, 3.8538e-06,\n",
              "            3.1291e-06, 3.4071e-04, 2.0037e-06, 7.6282e-05, 2.2304e-04, 1.3907e-06,\n",
              "            4.3008e-04, 3.5910e-05],\n",
              "           [1.0000e+00, 9.5768e-07, 1.4170e-05, 2.2414e-08, 2.4437e-04, 2.7864e-06,\n",
              "            1.4355e-06, 5.1029e-06, 7.9092e-07, 8.5866e-06, 3.1734e-07, 4.7212e-06,\n",
              "            6.8808e-09, 1.0647e-04, 1.3301e-09, 4.3633e-10, 3.4840e-07, 1.0670e-08,\n",
              "            8.5234e-11, 7.7653e-07, 3.6506e-10, 7.0840e-11, 6.8726e-08, 2.2492e-07,\n",
              "            1.2103e-10, 1.1841e-09, 3.6439e-12, 1.7548e-08, 8.4871e-07, 4.7587e-11,\n",
              "            4.3908e-09, 1.2491e-07, 4.8760e-10, 1.0874e-08, 3.0048e-11, 1.5980e-11,\n",
              "            5.8613e-06, 4.8613e-06, 4.9100e-08, 1.0567e-05, 6.0393e-08, 2.2328e-09,\n",
              "            4.3719e-09, 4.1088e-07, 1.7065e-09, 1.8240e-06, 8.5372e-07, 1.7087e-10,\n",
              "            1.3910e-07, 3.9557e-10],\n",
              "           [1.0000e+00, 2.7254e-08, 4.5132e-07, 1.3151e-09, 2.5432e-06, 7.6345e-08,\n",
              "            3.4961e-07, 7.0405e-07, 2.3267e-08, 1.7591e-08, 6.8408e-10, 2.8742e-10,\n",
              "            1.7014e-10, 8.5509e-06, 7.4140e-12, 1.1872e-13, 4.0537e-11, 1.4030e-06,\n",
              "            1.5792e-11, 1.9506e-07, 5.8831e-12, 1.1636e-15, 1.8577e-11, 8.3228e-09,\n",
              "            5.2817e-13, 7.6163e-12, 8.8378e-13, 3.7880e-08, 5.0820e-09, 6.5924e-14,\n",
              "            2.3553e-13, 9.6396e-12, 2.6218e-12, 2.3322e-11, 1.0560e-13, 4.3313e-11,\n",
              "            2.8338e-11, 2.3310e-07, 3.7045e-12, 9.5814e-08, 9.7403e-09, 1.3800e-09,\n",
              "            5.1967e-12, 6.3960e-10, 2.3389e-11, 1.4249e-08, 5.4877e-11, 1.4541e-12,\n",
              "            9.3970e-09, 5.0772e-09],\n",
              "           [1.0000e+00, 1.4385e-05, 1.9928e-06, 1.0192e-07, 7.4869e-06, 5.9494e-07,\n",
              "            6.1088e-06, 1.6799e-05, 7.6193e-07, 7.3363e-07, 1.4575e-05, 3.0081e-07,\n",
              "            6.3097e-07, 4.3300e-06, 4.7598e-08, 1.1345e-09, 4.7483e-05, 4.4832e-05,\n",
              "            1.9985e-08, 5.0649e-06, 8.9523e-10, 1.0545e-11, 7.2189e-09, 8.0529e-06,\n",
              "            1.9622e-10, 3.0827e-10, 4.2762e-10, 1.1814e-06, 1.0876e-07, 2.7690e-10,\n",
              "            2.9446e-09, 2.1546e-07, 1.3331e-10, 7.3244e-10, 9.5984e-11, 5.1191e-08,\n",
              "            4.2319e-08, 4.5917e-05, 6.4756e-08, 2.8315e-06, 9.1961e-07, 1.6563e-06,\n",
              "            2.0412e-09, 4.9912e-07, 5.1309e-08, 5.7753e-06, 8.0029e-08, 9.5472e-09,\n",
              "            1.0590e-07, 9.2459e-08],\n",
              "           [1.0000e+00, 2.0436e-05, 1.1888e-06, 1.0836e-07, 8.7785e-06, 2.9152e-07,\n",
              "            3.5452e-05, 2.9310e-06, 7.8503e-07, 2.7943e-06, 8.5756e-07, 6.2397e-07,\n",
              "            4.0522e-08, 3.1617e-05, 4.3260e-09, 1.6207e-10, 1.6288e-07, 1.2459e-04,\n",
              "            2.0422e-08, 1.8717e-06, 2.8711e-09, 8.2174e-11, 5.2639e-06, 4.9298e-06,\n",
              "            2.7388e-09, 9.1333e-08, 1.2400e-08, 5.4151e-06, 3.7794e-06, 1.4277e-09,\n",
              "            1.2465e-07, 6.8673e-09, 8.7136e-09, 4.4000e-06, 1.4242e-10, 1.2751e-07,\n",
              "            1.0456e-08, 1.4044e-07, 4.7109e-08, 1.8316e-04, 8.4835e-06, 4.1445e-08,\n",
              "            2.4261e-08, 2.8669e-08, 1.7157e-08, 1.2315e-04, 1.3966e-06, 1.4509e-08,\n",
              "            2.4306e-06, 1.1572e-07],\n",
              "           [1.0000e+00, 5.3200e-08, 3.0020e-07, 2.1703e-09, 1.1181e-05, 3.1172e-08,\n",
              "            2.6702e-08, 1.2566e-07, 6.6592e-08, 3.6039e-06, 1.3716e-08, 8.7712e-08,\n",
              "            6.6032e-10, 4.4768e-07, 3.3748e-10, 8.2430e-12, 2.6901e-10, 6.7826e-10,\n",
              "            4.9494e-12, 4.0461e-07, 1.3133e-11, 2.1575e-12, 4.1637e-09, 5.5627e-07,\n",
              "            5.1064e-12, 5.2304e-11, 3.1740e-10, 5.7974e-09, 1.1446e-08, 7.1297e-12,\n",
              "            2.5745e-09, 3.7485e-08, 6.7526e-12, 4.0804e-09, 1.0346e-15, 2.7337e-12,\n",
              "            1.4547e-09, 3.4924e-09, 1.1324e-07, 3.2316e-10, 1.3823e-05, 4.0842e-09,\n",
              "            1.3744e-11, 1.0102e-09, 5.1775e-10, 4.8041e-09, 3.2120e-06, 1.2489e-11,\n",
              "            5.7364e-09, 2.1949e-09],\n",
              "           [1.0000e+00, 1.3200e-07, 8.4691e-06, 1.4428e-08, 2.6564e-06, 1.1860e-06,\n",
              "            7.1725e-07, 3.7994e-05, 1.0483e-06, 2.0940e-06, 4.5225e-07, 4.3981e-05,\n",
              "            1.3565e-08, 3.1343e-08, 7.6152e-08, 2.4247e-10, 5.2894e-08, 1.2118e-06,\n",
              "            8.1348e-08, 3.2324e-05, 7.8595e-09, 6.3630e-11, 2.0036e-06, 4.8471e-05,\n",
              "            2.9303e-09, 3.1534e-08, 3.1763e-10, 1.1838e-07, 3.3908e-06, 1.1483e-07,\n",
              "            5.5143e-08, 1.2050e-07, 1.6613e-08, 3.0658e-07, 1.0489e-09, 8.5696e-09,\n",
              "            4.2322e-08, 3.9969e-05, 5.7404e-06, 5.2512e-06, 5.5439e-05, 2.0501e-04,\n",
              "            4.8283e-07, 5.8207e-05, 5.0129e-08, 2.4042e-05, 1.8372e-03, 2.5727e-06,\n",
              "            2.9215e-05, 5.5780e-07],\n",
              "           [1.0000e+00, 9.2703e-06, 2.4333e-06, 5.8691e-08, 3.1374e-04, 1.0841e-06,\n",
              "            2.0841e-05, 7.4839e-06, 7.3218e-07, 4.6094e-06, 1.0454e-04, 1.2844e-06,\n",
              "            9.7351e-09, 5.0707e-05, 1.0702e-08, 8.3378e-09, 1.9667e-06, 5.4913e-07,\n",
              "            1.1242e-07, 2.5546e-06, 4.1393e-10, 2.2214e-09, 1.3380e-07, 1.2005e-04,\n",
              "            6.0941e-10, 2.6558e-09, 3.9145e-10, 5.2710e-08, 2.8451e-06, 2.3006e-10,\n",
              "            4.5127e-10, 4.0500e-08, 1.1807e-10, 3.5473e-09, 1.9427e-12, 2.9869e-09,\n",
              "            3.7667e-07, 2.3765e-05, 4.7875e-10, 5.0180e-08, 7.7936e-07, 3.5060e-07,\n",
              "            1.5464e-08, 2.0762e-06, 5.4587e-08, 2.2451e-07, 3.1058e-07, 3.1519e-07,\n",
              "            1.4051e-06, 5.2134e-08]], device='cuda:0', grad_fn=<CatBackward>)],\n",
              "  7: [tensor([[9.6890e-01, 2.7504e-02, 7.3392e-03, 1.6639e-04, 1.7602e-02, 9.2176e-04,\n",
              "            3.1049e-02, 1.1750e-02, 1.2160e-03, 2.9780e-03, 1.1196e-02, 5.1184e-02,\n",
              "            2.5170e-04, 1.0196e-03, 5.0897e-04, 5.7380e-05, 5.3814e-03, 1.3460e-02,\n",
              "            2.1771e-03, 3.3553e-02, 1.4872e-02, 7.7254e-04, 1.0087e-03, 1.2713e-01,\n",
              "            2.6434e-04, 2.9501e-04, 3.3916e-04, 3.2965e-04, 4.7571e-04, 2.9128e-04,\n",
              "            8.2374e-05, 3.9244e-04, 7.8331e-05, 3.1398e-04, 2.0043e-04, 6.3160e-05,\n",
              "            1.2306e-01, 1.5489e-03, 1.2342e-02, 1.1666e-03, 7.3488e-04, 6.8453e-05,\n",
              "            2.3313e-04, 8.7195e-03, 9.5063e-04, 8.4867e-03, 2.2051e-02, 1.7614e-05,\n",
              "            2.4989e-05, 9.5908e-05, 1.0205e-04, 1.6967e-04, 4.3908e-03, 2.0253e-04,\n",
              "            3.3922e-04, 6.5394e-06, 9.3987e-06, 4.3554e-05, 1.3034e-05, 3.7712e-03,\n",
              "            3.9286e-09, 3.8041e-06, 5.1098e-03, 2.4826e-05, 3.0955e-04, 1.5223e-05,\n",
              "            6.1184e-08, 2.1137e-06, 9.1405e-07, 2.3657e-02],\n",
              "           [9.7226e-01, 1.1449e-03, 1.5333e-03, 1.1770e-04, 6.7839e-03, 1.6818e-04,\n",
              "            3.1403e-02, 7.6381e-03, 3.2528e-04, 7.8978e-04, 5.8502e-04, 1.6101e-03,\n",
              "            1.1620e-06, 1.1891e-03, 8.5433e-05, 8.4880e-05, 9.9797e-04, 2.4716e-02,\n",
              "            9.8939e-04, 2.3063e-03, 4.9451e-04, 9.7193e-06, 7.3805e-04, 9.2207e-03,\n",
              "            2.3399e-05, 2.5692e-05, 7.2339e-05, 3.6547e-05, 8.2076e-05, 5.5808e-06,\n",
              "            4.5549e-06, 3.4567e-04, 4.0731e-05, 2.5440e-05, 5.2065e-05, 6.0322e-06,\n",
              "            1.6269e-04, 2.4195e-04, 1.0232e-04, 6.3976e-05, 1.1178e-04, 1.5223e-05,\n",
              "            3.1859e-06, 2.2751e-05, 1.1785e-06, 4.8230e-04, 1.4767e-03, 1.3890e-05,\n",
              "            2.5153e-06, 6.0142e-06, 1.0838e-06, 2.6549e-07, 1.4331e-04, 4.3262e-06,\n",
              "            1.3205e-06, 2.6211e-05, 4.1147e-06, 1.6961e-07, 3.8454e-04, 3.2353e-04,\n",
              "            8.0329e-08, 3.6930e-06, 5.3673e-04, 4.5622e-07, 5.6224e-06, 2.5101e-09,\n",
              "            4.4664e-09, 6.2443e-08, 6.7195e-06, 1.8233e-09],\n",
              "           [9.9225e-01, 3.6034e-03, 1.6549e-03, 2.7650e-05, 5.6457e-03, 3.9422e-04,\n",
              "            6.9643e-03, 5.5329e-03, 7.3684e-04, 8.9164e-04, 3.0528e-03, 1.3793e-03,\n",
              "            2.0257e-06, 5.5171e-03, 3.0176e-05, 2.3178e-05, 1.6379e-03, 1.8171e-02,\n",
              "            8.0553e-04, 1.4300e-02, 6.3283e-05, 1.1260e-05, 2.1664e-03, 5.2773e-03,\n",
              "            4.7477e-05, 5.9961e-05, 5.2906e-04, 3.3589e-04, 2.4293e-05, 1.9800e-06,\n",
              "            2.1469e-05, 7.9692e-04, 7.6568e-05, 2.6158e-05, 7.9562e-05, 6.2525e-05,\n",
              "            4.8070e-05, 3.7495e-04, 4.7565e-05, 8.2162e-04, 6.0791e-05, 1.4447e-06,\n",
              "            6.5501e-06, 3.6947e-04, 2.9505e-06, 2.1528e-04, 1.9578e-04, 7.4936e-05,\n",
              "            2.4968e-06, 1.3911e-04, 1.7061e-06, 1.2508e-08, 1.6827e-04, 1.6317e-04,\n",
              "            4.2256e-06, 8.7007e-06, 6.1258e-06, 3.2721e-07, 9.2180e-05, 3.1198e-03,\n",
              "            6.3403e-10, 5.1926e-05, 2.1596e-05, 5.6546e-06, 1.6546e-06, 4.2116e-07,\n",
              "            2.7522e-08, 2.7655e-08, 2.5018e-06, 2.0765e-06],\n",
              "           [9.8614e-01, 2.3275e-02, 9.2989e-03, 4.8744e-04, 1.3938e-02, 6.2693e-04,\n",
              "            4.6314e-03, 4.1991e-03, 5.5129e-04, 1.2492e-03, 3.5697e-03, 8.5660e-03,\n",
              "            3.0122e-05, 3.7733e-03, 1.3446e-04, 1.7427e-04, 1.1902e-03, 1.3519e-02,\n",
              "            8.8381e-04, 3.7773e-02, 3.4520e-04, 3.6328e-05, 2.0684e-03, 5.4440e-02,\n",
              "            6.0822e-04, 1.2959e-04, 7.0011e-04, 2.9171e-05, 8.2950e-05, 9.4336e-05,\n",
              "            1.0272e-04, 2.8550e-04, 1.2688e-04, 1.7722e-05, 7.4225e-05, 9.5188e-06,\n",
              "            2.2821e-02, 3.5761e-04, 3.5482e-04, 6.7863e-04, 1.5733e-04, 2.8905e-05,\n",
              "            1.1885e-04, 1.5449e-03, 1.5079e-05, 6.1605e-04, 1.1885e-03, 5.3964e-06,\n",
              "            9.6603e-06, 9.2124e-06, 5.8185e-05, 8.0959e-07, 6.4100e-04, 1.4758e-04,\n",
              "            2.1984e-06, 5.1387e-06, 5.4351e-05, 3.7123e-06, 1.7632e-04, 1.1324e-04,\n",
              "            1.3704e-09, 5.2993e-05, 9.8574e-05, 3.8937e-05, 2.3171e-03, 9.0543e-08,\n",
              "            2.6471e-09, 3.2383e-08, 5.5599e-06, 3.5732e-06],\n",
              "           [9.3834e-01, 5.7781e-03, 1.1019e-02, 1.3435e-03, 8.4325e-02, 1.4811e-03,\n",
              "            4.2479e-02, 2.9150e-02, 2.3882e-03, 2.3234e-03, 1.3623e-03, 1.2728e-03,\n",
              "            5.2731e-05, 1.1063e-01, 3.4457e-03, 7.0528e-04, 5.9151e-03, 1.2401e-01,\n",
              "            6.7814e-03, 2.1819e-02, 2.4741e-03, 2.9721e-04, 3.0372e-03, 1.7611e-02,\n",
              "            2.2775e-03, 1.4072e-03, 1.4206e-02, 4.4413e-04, 3.0312e-04, 1.0905e-04,\n",
              "            3.8106e-04, 6.5005e-03, 6.1825e-04, 2.1956e-04, 2.1152e-03, 1.0470e-03,\n",
              "            1.5848e-03, 3.4130e-03, 1.5207e-04, 1.4043e-03, 1.8804e-04, 4.0857e-04,\n",
              "            1.9150e-04, 1.8341e-03, 3.5432e-04, 2.1809e-03, 1.1978e-04, 1.0401e-03,\n",
              "            8.7301e-05, 4.2017e-04, 2.2508e-04, 5.2261e-06, 1.2285e-03, 2.5135e-04,\n",
              "            5.6229e-05, 1.0512e-02, 8.4570e-05, 1.2083e-04, 2.7217e-03, 7.7639e-04,\n",
              "            1.7534e-05, 3.0050e-03, 4.0949e-04, 1.0236e-04, 9.3887e-05, 2.6311e-04,\n",
              "            1.9649e-05, 1.0731e-06, 7.0074e-05, 2.0413e-06],\n",
              "           [9.9174e-01, 3.0766e-03, 2.2971e-03, 2.0347e-04, 9.9685e-03, 2.6115e-04,\n",
              "            1.0520e-02, 9.9004e-03, 1.1486e-03, 4.3231e-04, 1.6676e-03, 2.8145e-03,\n",
              "            4.2457e-06, 5.1522e-03, 4.0769e-05, 1.2102e-04, 7.7810e-04, 4.9823e-02,\n",
              "            1.0014e-03, 7.6579e-03, 1.3175e-04, 1.3351e-05, 9.4745e-04, 2.9949e-02,\n",
              "            1.0186e-04, 1.2996e-04, 6.2517e-04, 6.5393e-05, 4.1619e-05, 9.0002e-06,\n",
              "            3.2517e-05, 7.3501e-04, 5.9941e-05, 1.5092e-05, 1.9275e-04, 9.2489e-05,\n",
              "            2.7071e-04, 3.3380e-04, 1.2730e-04, 4.1720e-04, 1.8369e-04, 9.6430e-06,\n",
              "            3.4062e-05, 4.1804e-04, 4.3960e-06, 2.3681e-04, 4.1945e-04, 6.0115e-05,\n",
              "            5.7906e-06, 5.6662e-05, 8.9227e-06, 1.5508e-07, 5.3604e-05, 2.0429e-05,\n",
              "            5.0393e-06, 2.4121e-05, 2.2147e-05, 5.6690e-06, 1.0007e-03, 9.2509e-04,\n",
              "            2.7737e-08, 8.9668e-06, 3.0475e-03, 7.0239e-06, 1.3461e-04, 4.6415e-06,\n",
              "            2.5048e-08, 1.8784e-08, 1.2829e-06, 7.2905e-07],\n",
              "           [9.6980e-01, 7.3591e-03, 5.0714e-03, 3.5182e-04, 2.5899e-02, 1.0458e-03,\n",
              "            2.1220e-02, 1.2901e-02, 2.0793e-03, 4.1231e-03, 1.1373e-02, 1.4884e-03,\n",
              "            2.3591e-05, 3.0039e-02, 1.3453e-04, 2.7518e-04, 4.1487e-03, 5.7978e-02,\n",
              "            2.4409e-03, 2.1436e-02, 2.9784e-04, 1.4241e-04, 5.5248e-03, 1.0775e-02,\n",
              "            2.9266e-04, 3.1134e-04, 1.3512e-03, 6.4459e-04, 1.8035e-04, 2.0099e-05,\n",
              "            1.8487e-04, 1.3227e-03, 4.8509e-04, 2.3273e-04, 3.3165e-04, 7.1714e-04,\n",
              "            2.1657e-04, 5.0315e-04, 1.7999e-04, 2.1545e-03, 5.0953e-04, 9.3259e-06,\n",
              "            7.8470e-05, 7.3151e-04, 4.4021e-05, 6.1647e-04, 3.1765e-04, 3.3293e-04,\n",
              "            1.6925e-05, 8.0045e-04, 1.0980e-05, 2.5268e-07, 3.2539e-04, 2.6808e-04,\n",
              "            5.9394e-05, 6.0885e-05, 2.1550e-05, 8.6607e-06, 2.8157e-04, 3.4705e-03,\n",
              "            3.1719e-08, 2.8039e-04, 5.5534e-05, 4.6821e-05, 2.3391e-05, 5.5682e-06,\n",
              "            2.9568e-07, 1.6819e-07, 6.8081e-06, 4.0544e-06],\n",
              "           [9.9499e-01, 1.5129e-03, 4.6684e-03, 1.4390e-05, 1.2884e-03, 5.3725e-05,\n",
              "            2.0380e-03, 3.8395e-03, 5.1612e-04, 8.7084e-04, 1.1502e-03, 8.9566e-04,\n",
              "            1.1443e-06, 2.3613e-04, 1.5771e-05, 1.0871e-05, 6.7178e-05, 5.1621e-03,\n",
              "            4.7117e-04, 2.9145e-02, 5.0234e-05, 1.2467e-06, 7.4300e-04, 2.0988e-03,\n",
              "            1.1895e-05, 1.9118e-05, 4.2424e-04, 2.6053e-05, 7.6936e-06, 1.1222e-06,\n",
              "            8.6335e-06, 1.2803e-04, 6.3508e-06, 1.7316e-05, 7.1030e-05, 7.3117e-06,\n",
              "            4.5800e-05, 8.8576e-05, 1.0442e-04, 1.1842e-04, 6.7051e-05, 7.8562e-07,\n",
              "            3.1115e-06, 3.1200e-05, 5.9345e-07, 5.2778e-05, 1.5293e-03, 1.0668e-05,\n",
              "            5.3933e-07, 1.3354e-05, 1.5986e-07, 1.6591e-08, 1.0153e-04, 2.7074e-05,\n",
              "            7.0787e-06, 1.0297e-06, 1.6299e-06, 7.6899e-08, 6.8635e-05, 2.0981e-03,\n",
              "            5.8081e-11, 1.7181e-07, 6.0104e-04, 1.3674e-06, 5.5262e-04, 1.7498e-07,\n",
              "            3.4863e-10, 2.2506e-09, 2.3341e-07, 3.8051e-07],\n",
              "           [9.8632e-01, 9.9877e-03, 4.1460e-03, 5.6357e-05, 5.0164e-03, 4.3204e-04,\n",
              "            9.3376e-03, 6.5038e-03, 1.6400e-03, 1.7265e-03, 8.2472e-03, 7.9396e-03,\n",
              "            1.8304e-05, 1.1960e-03, 9.0098e-05, 7.9688e-05, 6.9181e-04, 7.9132e-03,\n",
              "            3.9032e-03, 1.6359e-02, 2.2126e-04, 1.3388e-05, 3.7248e-03, 3.7489e-02,\n",
              "            6.5569e-05, 2.4476e-04, 1.0023e-03, 5.0164e-04, 4.8405e-05, 2.5397e-05,\n",
              "            6.1495e-05, 7.4199e-04, 2.5418e-05, 7.6345e-05, 2.4379e-04, 7.7066e-05,\n",
              "            3.7839e-04, 2.0228e-03, 7.3631e-04, 9.2070e-04, 1.0747e-04, 2.4364e-05,\n",
              "            2.6882e-05, 4.0778e-03, 2.1038e-06, 2.3489e-04, 1.6017e-03, 2.2867e-04,\n",
              "            2.7779e-05, 7.2280e-05, 1.5629e-06, 2.4379e-07, 1.7985e-03, 3.0055e-04,\n",
              "            3.4616e-05, 1.7379e-05, 2.9430e-05, 1.7216e-06, 1.8087e-04, 4.6090e-03,\n",
              "            1.4709e-09, 1.3350e-03, 6.1283e-03, 2.8958e-06, 4.3257e-06, 1.4645e-06,\n",
              "            8.9827e-08, 4.4932e-08, 8.3506e-07, 2.8038e-04],\n",
              "           [9.7990e-01, 1.1943e-02, 7.1060e-03, 2.1772e-04, 1.4237e-02, 5.0206e-04,\n",
              "            1.3128e-02, 7.0263e-03, 8.8643e-04, 6.1769e-04, 9.1054e-03, 2.1445e-03,\n",
              "            1.2813e-05, 5.5218e-03, 5.5117e-05, 2.0241e-04, 2.9821e-03, 3.6195e-02,\n",
              "            4.0644e-03, 1.8242e-02, 5.8384e-04, 7.3333e-05, 1.5921e-03, 1.6511e-02,\n",
              "            1.2617e-04, 1.6551e-04, 4.9520e-04, 2.8007e-04, 1.3413e-04, 2.8187e-05,\n",
              "            2.7280e-05, 5.4671e-04, 9.0779e-05, 1.1187e-04, 6.7912e-04, 2.8428e-04,\n",
              "            7.8830e-04, 2.4338e-04, 1.4503e-04, 6.1962e-04, 3.3010e-04, 5.9935e-05,\n",
              "            4.2936e-05, 7.8523e-04, 1.1889e-05, 6.0120e-04, 5.6846e-04, 3.4712e-04,\n",
              "            1.6084e-05, 3.6422e-05, 8.4081e-06, 8.0071e-07, 1.6606e-04, 6.7864e-05,\n",
              "            1.0811e-05, 5.2208e-05, 1.6081e-04, 1.8014e-05, 1.6220e-04, 1.7396e-03,\n",
              "            2.4324e-08, 5.5608e-05, 1.0606e-03, 7.5582e-06, 8.3062e-05, 9.7102e-06,\n",
              "            1.5828e-06, 4.3053e-08, 6.9687e-06, 3.5221e-06]], device='cuda:0',\n",
              "          grad_fn=<SigmoidBackward>),\n",
              "   tensor([[9.9927e-01, 3.9342e-04, 5.1272e-04, 6.0621e-06, 1.9052e-04, 8.5856e-05,\n",
              "            7.7070e-05, 2.2836e-03, 2.4763e-04, 3.6148e-04, 4.7066e-04, 1.4098e-02,\n",
              "            1.6050e-05, 9.2360e-05, 6.4537e-06, 5.7107e-08, 3.9585e-05, 4.7655e-04,\n",
              "            2.3891e-05, 1.9992e-03, 3.8568e-04, 6.5616e-06, 2.8272e-07, 2.0973e-04,\n",
              "            6.1903e-08, 3.6320e-07, 3.0733e-08, 1.5800e-06, 3.7899e-05, 1.1037e-05,\n",
              "            1.5975e-07, 3.0903e-06, 3.8679e-08, 8.7625e-07, 3.4586e-08, 1.4697e-09,\n",
              "            1.6993e-02, 2.2452e-07, 5.5663e-04, 2.3183e-07, 9.7144e-06, 4.6621e-07,\n",
              "            1.9907e-05, 5.5930e-04, 1.2136e-05, 8.0715e-04, 2.0941e-02, 2.6373e-08,\n",
              "            3.2737e-07, 1.3468e-06, 4.1287e-04, 4.6418e-05, 3.9994e-03, 2.3659e-05,\n",
              "            1.3458e-04, 6.6790e-07, 1.8043e-06, 1.0251e-06, 5.3895e-06, 3.2548e-02],\n",
              "           [1.0000e+00, 2.4568e-07, 2.3508e-08, 5.0008e-10, 5.8313e-06, 2.3017e-09,\n",
              "            3.1309e-07, 6.2484e-07, 1.0166e-09, 1.4806e-09, 3.9021e-10, 1.0566e-07,\n",
              "            1.4479e-12, 6.0515e-09, 7.4929e-08, 6.0368e-13, 1.6323e-10, 4.1160e-08,\n",
              "            2.5670e-07, 1.4316e-06, 7.2576e-10, 2.4744e-14, 1.1605e-10, 2.7780e-07,\n",
              "            1.3869e-11, 5.6553e-11, 2.5437e-14, 2.8244e-08, 3.7202e-06, 3.4590e-11,\n",
              "            8.5202e-14, 8.7611e-09, 3.8926e-13, 1.5309e-07, 3.3844e-13, 4.5740e-13,\n",
              "            1.2850e-10, 1.2401e-08, 1.2963e-09, 3.4680e-07, 3.4880e-06, 7.5731e-08,\n",
              "            1.0785e-10, 2.4861e-09, 1.8972e-09, 5.8170e-04, 5.9601e-06, 2.0605e-09,\n",
              "            5.9333e-08, 9.6217e-08, 3.0728e-08, 2.6211e-10, 5.5850e-06, 3.7796e-10,\n",
              "            2.5080e-10, 3.5179e-08, 3.7819e-09, 3.9189e-11, 3.9195e-04, 5.9063e-05],\n",
              "           [1.0000e+00, 2.2188e-07, 5.1856e-08, 4.9071e-10, 4.5231e-06, 8.4993e-09,\n",
              "            1.0801e-07, 1.5561e-07, 1.4929e-08, 1.0177e-07, 1.4252e-08, 1.7477e-07,\n",
              "            2.9990e-10, 3.0984e-07, 1.2297e-10, 1.3584e-13, 9.0181e-11, 1.6455e-06,\n",
              "            3.6240e-11, 1.4877e-05, 1.9605e-11, 8.8002e-14, 1.1026e-06, 8.1037e-08,\n",
              "            8.7774e-13, 1.7127e-10, 1.9573e-11, 7.6499e-07, 1.2154e-07, 4.8776e-13,\n",
              "            1.6440e-08, 1.2556e-10, 9.5125e-11, 7.3250e-12, 4.9555e-13, 2.1954e-10,\n",
              "            1.8605e-11, 6.1106e-06, 1.1142e-09, 2.5430e-07, 1.1374e-07, 1.9780e-09,\n",
              "            1.0531e-09, 1.3625e-08, 2.3967e-10, 4.8607e-05, 1.0578e-07, 1.4626e-10,\n",
              "            3.2430e-07, 1.1138e-07, 3.9993e-08, 4.2846e-11, 7.5756e-07, 9.3886e-09,\n",
              "            4.1427e-10, 7.2794e-10, 2.8817e-09, 1.2560e-10, 2.6553e-06, 2.9935e-04],\n",
              "           [1.0000e+00, 9.4856e-07, 4.8593e-06, 2.4670e-08, 1.6362e-04, 1.9260e-06,\n",
              "            2.5038e-06, 3.5077e-06, 1.5535e-06, 3.1797e-05, 2.6290e-07, 1.2698e-05,\n",
              "            1.0108e-08, 1.1146e-05, 8.5684e-09, 2.7340e-10, 2.9390e-07, 3.4924e-07,\n",
              "            2.9434e-09, 1.4173e-06, 5.6813e-09, 1.3439e-09, 1.1319e-06, 1.0499e-05,\n",
              "            1.0749e-09, 1.6395e-08, 4.9640e-11, 3.8749e-08, 2.7732e-06, 3.8154e-10,\n",
              "            8.1940e-07, 1.7845e-07, 1.9053e-09, 3.0656e-09, 3.9889e-10, 1.1588e-10,\n",
              "            9.0931e-06, 2.1598e-05, 2.8672e-08, 1.2468e-05, 9.0050e-08, 9.2936e-09,\n",
              "            2.7001e-08, 3.5867e-06, 1.2417e-08, 4.2308e-07, 9.5963e-07, 7.7659e-10,\n",
              "            8.8221e-07, 4.9517e-09, 6.6145e-05, 1.2895e-09, 2.1270e-06, 2.7276e-06,\n",
              "            1.4949e-08, 2.4949e-09, 1.2377e-05, 8.1774e-08, 8.7188e-05, 1.2380e-05],\n",
              "           [9.9995e-01, 2.9795e-05, 4.3348e-05, 1.3063e-06, 2.3048e-04, 2.6753e-05,\n",
              "            2.3030e-03, 3.3170e-04, 1.8667e-05, 1.5334e-05, 8.9883e-07, 4.8731e-07,\n",
              "            5.2188e-08, 5.0687e-04, 2.2942e-06, 1.1812e-08, 1.3397e-07, 2.6309e-04,\n",
              "            3.9791e-06, 1.1946e-04, 1.5777e-06, 5.1350e-09, 1.5403e-06, 7.1578e-05,\n",
              "            1.2034e-07, 5.8340e-07, 1.6320e-07, 3.9796e-06, 4.9034e-05, 8.4519e-10,\n",
              "            2.1278e-06, 2.8150e-06, 1.8854e-07, 3.4464e-07, 3.1656e-05, 7.9739e-07,\n",
              "            1.6056e-05, 9.1662e-06, 4.9538e-08, 2.2761e-05, 5.1749e-06, 1.2024e-06,\n",
              "            3.7049e-07, 2.0874e-05, 1.2906e-07, 2.7000e-05, 1.1796e-07, 1.7741e-07,\n",
              "            1.2002e-05, 5.7216e-06, 9.1958e-06, 1.3046e-08, 7.5193e-05, 2.8850e-06,\n",
              "            1.2738e-06, 2.6354e-04, 4.2958e-08, 6.1338e-07, 6.3707e-03, 2.7306e-05],\n",
              "           [1.0000e+00, 5.5493e-06, 4.9551e-07, 5.9953e-09, 4.2849e-06, 4.3735e-08,\n",
              "            3.7643e-06, 1.9775e-06, 1.0067e-07, 5.2575e-08, 2.5466e-08, 4.7122e-07,\n",
              "            9.5430e-09, 1.8563e-05, 1.0443e-07, 7.6725e-10, 2.2273e-08, 7.0830e-06,\n",
              "            6.9178e-08, 7.6307e-06, 2.0708e-10, 1.6494e-12, 3.9421e-10, 8.8338e-05,\n",
              "            1.5904e-10, 4.6854e-10, 5.7947e-10, 4.5516e-08, 1.0254e-08, 6.9279e-10,\n",
              "            2.0116e-08, 1.0055e-07, 2.2855e-10, 3.2538e-10, 5.6779e-11, 2.4144e-09,\n",
              "            1.1517e-08, 1.6899e-06, 4.5128e-07, 6.0438e-06, 1.5827e-06, 4.7799e-06,\n",
              "            1.1485e-07, 1.0315e-06, 1.0415e-06, 2.0087e-04, 9.7981e-07, 3.2849e-08,\n",
              "            2.4656e-06, 1.7197e-05, 1.8398e-06, 4.2589e-09, 1.1612e-06, 1.3952e-07,\n",
              "            1.8763e-08, 1.8611e-07, 7.3270e-09, 6.4341e-10, 7.1877e-04, 9.4681e-05],\n",
              "           [9.9998e-01, 5.1588e-05, 6.8390e-06, 3.1175e-07, 2.5913e-04, 3.8555e-06,\n",
              "            2.2259e-04, 1.6019e-05, 3.4131e-06, 2.2234e-05, 1.1949e-04, 8.6391e-06,\n",
              "            4.0334e-07, 3.5593e-04, 2.7853e-08, 1.1682e-08, 1.9077e-05, 2.3124e-04,\n",
              "            1.2511e-07, 2.9340e-06, 3.4189e-08, 5.5165e-09, 5.6383e-06, 1.1972e-04,\n",
              "            6.8795e-08, 1.3088e-06, 6.3472e-08, 4.3563e-05, 7.6014e-06, 1.3298e-08,\n",
              "            3.5824e-07, 5.1395e-08, 4.0049e-08, 3.7162e-05, 3.8187e-10, 8.9925e-07,\n",
              "            5.7292e-08, 1.5643e-06, 4.3761e-07, 3.1078e-04, 5.1781e-05, 2.1836e-07,\n",
              "            9.5932e-08, 1.2068e-06, 1.3922e-07, 1.7287e-04, 4.1145e-06, 8.8073e-08,\n",
              "            8.1573e-06, 1.5472e-06, 5.7900e-07, 2.1413e-09, 9.5199e-06, 3.1488e-07,\n",
              "            6.1521e-08, 4.4516e-08, 1.7784e-07, 2.7168e-06, 1.9678e-04, 6.7951e-05],\n",
              "           [1.0000e+00, 3.9109e-07, 1.8599e-07, 6.0853e-09, 4.3095e-07, 9.8276e-09,\n",
              "            3.8196e-08, 1.1119e-07, 4.1832e-08, 2.7726e-06, 5.4474e-09, 4.1669e-07,\n",
              "            1.9527e-09, 1.2930e-07, 3.2435e-09, 1.0544e-11, 1.6556e-09, 1.0695e-08,\n",
              "            4.6442e-10, 5.0739e-07, 1.1793e-11, 1.7209e-13, 1.8773e-09, 3.4233e-06,\n",
              "            1.3031e-11, 5.8925e-11, 4.0480e-11, 8.2943e-10, 9.3676e-09, 3.5306e-11,\n",
              "            2.0301e-10, 3.0517e-10, 1.7622e-12, 2.0587e-10, 3.2865e-17, 7.6890e-13,\n",
              "            2.2530e-10, 4.4744e-09, 3.9067e-07, 7.2888e-11, 5.5270e-06, 1.7215e-09,\n",
              "            2.3077e-12, 1.5699e-09, 6.7193e-10, 1.0045e-09, 2.9880e-06, 9.3406e-12,\n",
              "            1.2668e-08, 7.4357e-09, 1.8692e-09, 4.9025e-11, 3.5685e-06, 5.0941e-07,\n",
              "            3.9314e-10, 2.9345e-11, 7.4447e-10, 8.9303e-13, 4.3171e-05, 2.1655e-05],\n",
              "           [1.0000e+00, 6.5613e-08, 9.5917e-06, 2.1568e-09, 2.3789e-07, 1.4092e-07,\n",
              "            1.2733e-08, 4.7697e-06, 1.9745e-07, 4.4170e-07, 2.4013e-09, 1.3069e-05,\n",
              "            3.0765e-11, 4.6565e-11, 6.1062e-11, 1.5396e-13, 3.3597e-10, 1.4312e-07,\n",
              "            7.2696e-10, 2.0488e-07, 5.5595e-11, 1.4662e-13, 8.8376e-09, 4.1971e-05,\n",
              "            4.8519e-11, 1.8745e-10, 4.8979e-12, 5.3752e-09, 3.4772e-07, 6.6039e-09,\n",
              "            2.6271e-10, 4.1502e-10, 4.8637e-10, 2.3074e-09, 2.1424e-13, 8.0791e-11,\n",
              "            1.9439e-10, 6.2058e-05, 1.5254e-06, 1.1175e-06, 1.4883e-07, 5.5778e-06,\n",
              "            6.5616e-09, 2.1496e-06, 6.1604e-10, 1.0197e-06, 4.0868e-04, 7.1638e-08,\n",
              "            5.3466e-07, 3.4897e-09, 2.6962e-08, 2.1234e-09, 1.7170e-04, 1.8253e-06,\n",
              "            5.3423e-08, 2.7172e-09, 6.0674e-08, 4.6317e-10, 1.7139e-05, 4.4370e-04],\n",
              "           [9.9998e-01, 3.7573e-05, 5.5461e-05, 6.2451e-07, 2.1278e-04, 1.1761e-05,\n",
              "            1.5162e-05, 5.2794e-05, 1.1974e-05, 1.7163e-05, 1.4967e-05, 3.0585e-06,\n",
              "            8.1064e-08, 1.0978e-06, 4.2806e-08, 3.7034e-09, 1.7299e-06, 5.3450e-06,\n",
              "            1.2228e-07, 8.0584e-06, 7.0016e-09, 1.4730e-08, 5.1300e-07, 6.1863e-06,\n",
              "            4.4303e-09, 1.4334e-08, 1.6538e-10, 4.1551e-07, 4.5467e-05, 3.0982e-09,\n",
              "            5.5373e-08, 1.8149e-07, 3.4292e-09, 9.9317e-08, 1.1302e-10, 7.1736e-09,\n",
              "            7.5328e-07, 3.1819e-06, 6.8555e-08, 4.8033e-05, 1.4120e-05, 7.5598e-06,\n",
              "            3.3956e-07, 1.6536e-06, 8.7146e-07, 2.3346e-05, 5.9618e-06, 1.1699e-06,\n",
              "            1.4795e-06, 1.7455e-07, 1.2758e-05, 6.7129e-08, 3.6943e-05, 4.0345e-06,\n",
              "            1.1317e-06, 1.0772e-07, 1.5819e-05, 6.9153e-05, 1.1729e-03, 1.3393e-03]],\n",
              "          device='cuda:0', grad_fn=<CatBackward>)],\n",
              "  8: [tensor([[9.2063e-01, 6.6914e-02, 1.3863e-02, 8.7412e-04, 4.1343e-02, 1.1921e-03,\n",
              "            2.1934e-02, 1.5954e-02, 2.4651e-03, 5.1817e-03, 1.6006e-02, 1.2067e-01,\n",
              "            9.0780e-04, 2.4302e-03, 1.1055e-03, 2.1675e-04, 6.6171e-03, 1.8995e-02,\n",
              "            4.9220e-03, 3.6336e-02, 2.9821e-02, 9.4875e-04, 1.4603e-03, 2.6018e-01,\n",
              "            9.5330e-04, 7.5970e-04, 9.8422e-04, 1.1379e-03, 1.4913e-03, 6.3715e-04,\n",
              "            4.2457e-04, 3.6239e-03, 1.0038e-04, 2.3801e-04, 1.3030e-03, 1.1486e-04,\n",
              "            1.0719e-01, 1.8132e-03, 1.5868e-02, 2.9531e-03, 5.1489e-04, 3.1863e-04,\n",
              "            7.4333e-04, 2.1798e-02, 1.7136e-03, 7.1539e-03, 1.7848e-02, 5.5337e-05,\n",
              "            5.8083e-04, 2.1022e-04, 2.3543e-04, 1.0350e-03, 2.0184e-03, 4.5565e-04,\n",
              "            3.3456e-04, 3.7038e-05, 8.3337e-05, 3.9906e-04, 6.9956e-05, 3.9833e-03,\n",
              "            2.0338e-06, 3.3216e-05, 1.4050e-02, 3.2832e-04, 4.2203e-04, 1.0888e-03,\n",
              "            1.0887e-04, 2.2997e-05, 1.9815e-05, 1.6800e-02, 1.1687e-03, 1.6160e-04,\n",
              "            1.0066e-03, 9.1672e-06, 1.0063e-07, 7.7191e-06, 2.4545e-03, 1.5228e-06,\n",
              "            3.6136e-06, 2.2102e-07],\n",
              "           [9.6329e-01, 3.8270e-03, 4.5934e-03, 2.8797e-04, 1.2063e-02, 5.3015e-04,\n",
              "            4.3568e-02, 1.2422e-02, 1.1313e-03, 1.1389e-03, 7.9302e-03, 3.9034e-03,\n",
              "            9.8179e-06, 4.4604e-03, 6.1805e-04, 2.1031e-04, 1.6021e-03, 4.7175e-02,\n",
              "            2.1865e-03, 7.8213e-03, 6.4078e-04, 8.9026e-05, 1.2845e-03, 6.8757e-02,\n",
              "            1.4996e-04, 8.0221e-05, 4.3983e-04, 8.1735e-04, 6.2555e-04, 1.5582e-05,\n",
              "            5.5415e-05, 1.4782e-03, 8.4285e-05, 3.2028e-05, 6.7485e-04, 1.4408e-04,\n",
              "            6.5292e-04, 1.0056e-03, 2.2978e-04, 4.4343e-04, 1.9253e-04, 2.2187e-05,\n",
              "            6.0487e-05, 3.8609e-04, 1.5899e-05, 1.9671e-03, 1.7751e-03, 4.4586e-04,\n",
              "            2.3216e-05, 5.3312e-05, 5.5049e-06, 5.7442e-06, 3.9632e-04, 6.2481e-06,\n",
              "            3.1558e-05, 8.4038e-05, 1.3830e-04, 1.2923e-05, 1.1992e-03, 1.8269e-03,\n",
              "            1.6994e-05, 3.0413e-05, 1.7716e-03, 9.4329e-05, 4.7123e-05, 1.0413e-06,\n",
              "            8.8005e-06, 5.4709e-05, 2.2612e-05, 2.6441e-06, 5.2693e-06, 1.9623e-05,\n",
              "            1.2140e-05, 1.4497e-08, 1.3555e-06, 8.8108e-06, 1.9414e-07, 4.7174e-08,\n",
              "            9.6145e-08, 1.0471e-07],\n",
              "           [9.2099e-01, 4.1681e-02, 1.4407e-02, 1.0010e-03, 1.5601e-02, 2.4403e-03,\n",
              "            2.0597e-02, 1.3967e-02, 4.3292e-03, 4.5819e-03, 2.3369e-02, 2.2624e-02,\n",
              "            1.8711e-04, 7.6285e-03, 4.9673e-04, 7.1181e-04, 4.8593e-03, 6.3473e-02,\n",
              "            2.8950e-03, 3.1309e-02, 1.0826e-03, 6.3325e-04, 1.7144e-02, 3.5411e-02,\n",
              "            8.5072e-04, 7.9685e-04, 3.6550e-03, 2.9520e-03, 5.4520e-04, 1.6195e-04,\n",
              "            9.0438e-04, 2.6267e-03, 1.5197e-03, 1.1112e-03, 1.6413e-03, 1.2518e-03,\n",
              "            3.3344e-03, 2.8996e-03, 1.3499e-03, 8.1753e-03, 1.2144e-03, 2.7935e-04,\n",
              "            3.4395e-04, 5.2921e-03, 1.4513e-04, 6.6158e-03, 7.3058e-03, 2.3318e-03,\n",
              "            9.0466e-05, 2.2240e-03, 7.2644e-05, 1.3976e-05, 4.1933e-03, 2.0075e-03,\n",
              "            1.1949e-04, 5.3233e-04, 2.0406e-03, 4.4126e-04, 2.3218e-03, 1.6908e-02,\n",
              "            6.4812e-05, 1.1428e-03, 9.9666e-04, 9.9751e-04, 4.1258e-04, 7.4046e-05,\n",
              "            3.3807e-04, 2.8034e-04, 2.1189e-03, 1.6830e-03, 2.4427e-03, 6.1013e-04,\n",
              "            1.7398e-03, 1.6891e-03, 1.2708e-03, 4.1027e-05, 1.0324e-06, 1.4537e-06,\n",
              "            4.1499e-06, 1.9074e-07],\n",
              "           [9.6509e-01, 4.0645e-02, 2.5464e-02, 2.6104e-03, 1.2808e-02, 7.5398e-04,\n",
              "            6.1345e-03, 8.5401e-03, 1.0746e-03, 2.6794e-03, 8.6877e-03, 1.9791e-02,\n",
              "            1.7017e-04, 2.1610e-03, 1.9002e-04, 1.2076e-03, 1.3551e-03, 2.7451e-02,\n",
              "            2.3069e-03, 5.7185e-02, 1.4211e-03, 1.9170e-04, 3.2118e-03, 8.9296e-02,\n",
              "            1.6765e-03, 3.1601e-04, 9.6274e-04, 7.7431e-05, 3.3409e-04, 4.7079e-04,\n",
              "            4.9368e-04, 8.4968e-04, 3.3153e-04, 1.2246e-04, 1.5877e-04, 7.1102e-05,\n",
              "            1.1929e-01, 7.2599e-04, 1.7758e-03, 1.2092e-03, 1.7196e-03, 2.8049e-04,\n",
              "            2.1019e-04, 6.7553e-03, 5.1882e-05, 1.2623e-03, 5.4192e-03, 4.6384e-05,\n",
              "            1.0086e-04, 7.7770e-05, 3.4403e-05, 2.8720e-05, 3.1348e-03, 4.3114e-04,\n",
              "            2.5822e-05, 3.2549e-05, 3.1005e-04, 1.0023e-04, 1.8245e-03, 8.8897e-04,\n",
              "            5.3142e-06, 9.9276e-05, 4.8073e-03, 1.2366e-03, 1.1555e-02, 4.3459e-06,\n",
              "            2.5541e-05, 7.0208e-05, 2.2786e-05, 2.6505e-04, 3.0350e-04, 3.8295e-03,\n",
              "            7.4347e-03, 3.7044e-07, 9.0032e-06, 1.4956e-04, 1.0029e-06, 2.7254e-06,\n",
              "            2.3684e-05, 9.7104e-08],\n",
              "           [9.6969e-01, 7.7151e-03, 8.5717e-03, 7.5097e-04, 1.1506e-02, 2.5955e-04,\n",
              "            4.9589e-03, 5.5190e-03, 1.0891e-03, 1.3182e-03, 5.4904e-03, 5.4249e-04,\n",
              "            7.3880e-06, 1.5190e-02, 1.3112e-04, 2.1265e-04, 7.6516e-04, 4.6429e-02,\n",
              "            1.2221e-03, 1.1697e-02, 1.0956e-04, 6.6758e-05, 9.1528e-04, 5.7308e-03,\n",
              "            2.9351e-04, 1.1527e-04, 1.6668e-03, 1.1454e-04, 6.6291e-05, 4.5812e-06,\n",
              "            6.1612e-05, 5.4628e-04, 7.3782e-05, 1.9099e-05, 1.8907e-04, 4.0871e-04,\n",
              "            2.0502e-04, 4.5521e-04, 3.8770e-05, 7.0290e-04, 1.3005e-04, 9.8609e-06,\n",
              "            3.1209e-05, 4.7910e-04, 1.5915e-05, 1.3793e-04, 5.1975e-05, 1.7387e-04,\n",
              "            1.0505e-05, 1.5160e-04, 1.9871e-06, 2.3778e-07, 8.1604e-05, 4.0499e-05,\n",
              "            2.8103e-06, 9.7754e-05, 4.5938e-05, 1.5280e-05, 1.5034e-03, 6.2883e-04,\n",
              "            5.5939e-07, 6.4395e-04, 2.7175e-05, 6.7048e-05, 1.1371e-04, 8.7293e-06,\n",
              "            4.0108e-06, 9.2643e-07, 1.5968e-05, 1.4281e-06, 6.5683e-06, 2.3076e-06,\n",
              "            1.5445e-03, 3.5124e-07, 8.8307e-07, 4.2285e-06, 3.5930e-09, 3.3237e-09,\n",
              "            1.5345e-08, 3.3146e-09],\n",
              "           [9.5772e-01, 1.7834e-02, 7.1169e-03, 6.0577e-04, 1.1505e-02, 2.3842e-04,\n",
              "            8.0136e-03, 1.0679e-02, 2.5029e-03, 1.7569e-03, 6.6888e-03, 1.1125e-02,\n",
              "            3.1619e-05, 2.4199e-03, 8.0387e-05, 5.2496e-04, 1.2725e-03, 2.6258e-02,\n",
              "            1.4192e-03, 1.0798e-02, 2.9975e-04, 7.9334e-05, 1.9289e-03, 3.6931e-02,\n",
              "            1.5264e-04, 1.7043e-04, 9.9404e-04, 4.5868e-04, 2.2776e-04, 1.4928e-05,\n",
              "            9.3446e-05, 1.9515e-03, 9.2181e-05, 5.7318e-05, 4.4950e-04, 1.9025e-04,\n",
              "            7.6192e-04, 9.2334e-04, 7.7726e-04, 1.6790e-03, 7.6485e-04, 4.9810e-05,\n",
              "            7.6202e-05, 6.6744e-04, 1.9241e-05, 7.2248e-04, 3.5282e-03, 2.0724e-04,\n",
              "            2.7537e-05, 2.2649e-04, 8.3542e-06, 3.3590e-06, 3.7007e-04, 9.8740e-05,\n",
              "            1.3071e-05, 1.9186e-05, 4.3383e-05, 7.5308e-05, 3.4601e-03, 5.0185e-03,\n",
              "            1.6219e-05, 2.1456e-04, 1.4693e-03, 2.1543e-04, 1.0791e-04, 1.2261e-05,\n",
              "            8.6749e-06, 9.0811e-06, 7.5983e-06, 1.8520e-04, 2.3112e-03, 3.8638e-05,\n",
              "            5.3390e-05, 4.2908e-06, 2.3316e-07, 9.5069e-06, 6.1364e-07, 1.9418e-07,\n",
              "            1.2257e-08, 1.5815e-08],\n",
              "           [9.4308e-01, 1.9832e-02, 1.9149e-02, 1.4244e-03, 6.1465e-03, 6.0581e-04,\n",
              "            7.7156e-03, 9.1903e-03, 2.4901e-03, 2.4226e-03, 3.9778e-02, 2.6948e-03,\n",
              "            3.8203e-05, 3.7184e-03, 9.8287e-05, 2.1216e-04, 3.1261e-03, 1.5846e-01,\n",
              "            1.9175e-03, 1.1860e-02, 6.1697e-04, 5.0096e-04, 2.7316e-03, 1.3259e-02,\n",
              "            5.2764e-04, 2.2371e-04, 7.5539e-04, 4.2475e-04, 3.0269e-04, 2.5201e-05,\n",
              "            2.4342e-04, 6.0737e-04, 4.8865e-04, 2.0190e-04, 1.7349e-04, 1.6725e-03,\n",
              "            1.0698e-03, 2.6384e-04, 2.6397e-04, 3.6400e-03, 6.1146e-04, 3.3149e-05,\n",
              "            1.2248e-04, 1.0806e-03, 6.7634e-05, 2.4370e-03, 3.9021e-04, 2.7822e-04,\n",
              "            3.2609e-05, 8.2780e-04, 3.7607e-06, 1.6773e-06, 4.7531e-04, 1.2048e-04,\n",
              "            2.8155e-05, 1.3139e-04, 1.6925e-04, 1.8591e-04, 5.6701e-04, 1.9760e-03,\n",
              "            2.1011e-06, 1.2613e-03, 1.7561e-05, 1.5728e-04, 1.5188e-04, 9.2287e-06,\n",
              "            6.2110e-05, 8.8021e-06, 1.6010e-04, 6.8782e-05, 7.4316e-06, 5.7953e-04,\n",
              "            3.8817e-04, 2.5325e-05, 4.1805e-06, 1.0961e-06, 1.7014e-08, 4.9080e-08,\n",
              "            1.7243e-06, 3.6783e-08],\n",
              "           [9.6587e-01, 1.8390e-02, 1.1914e-02, 4.6663e-04, 9.6868e-03, 2.1528e-04,\n",
              "            3.4945e-03, 2.8673e-03, 1.7318e-03, 4.4489e-03, 6.0764e-03, 1.1155e-02,\n",
              "            3.0715e-05, 1.2451e-03, 6.4504e-05, 2.5790e-04, 4.3608e-04, 8.9571e-03,\n",
              "            7.7766e-04, 3.6298e-02, 2.9282e-04, 1.7031e-05, 2.4064e-03, 2.3420e-02,\n",
              "            1.2093e-04, 2.1124e-04, 6.9809e-04, 2.0464e-04, 1.2246e-04, 1.3006e-05,\n",
              "            1.6948e-04, 1.1296e-03, 3.9002e-05, 7.7093e-05, 1.5450e-04, 3.0608e-05,\n",
              "            1.3558e-03, 3.4331e-04, 7.1782e-04, 4.8568e-04, 4.4092e-04, 1.0765e-05,\n",
              "            2.8090e-05, 1.4300e-03, 1.8405e-05, 1.0851e-04, 3.2032e-03, 2.3579e-05,\n",
              "            3.1656e-05, 1.0506e-04, 1.9996e-06, 9.9367e-07, 2.7419e-04, 5.3270e-04,\n",
              "            7.4737e-06, 5.6137e-06, 2.5337e-05, 9.6225e-06, 3.0217e-04, 2.2139e-03,\n",
              "            8.0378e-07, 1.8311e-05, 4.6780e-04, 3.1801e-04, 3.4993e-04, 5.6198e-06,\n",
              "            4.2266e-06, 2.0823e-06, 3.7718e-06, 1.5974e-04, 2.1903e-05, 9.3872e-04,\n",
              "            4.1798e-04, 5.1748e-06, 1.5119e-08, 1.7442e-06, 2.2628e-08, 3.4451e-08,\n",
              "            3.2656e-08, 9.1066e-09],\n",
              "           [9.3582e-01, 3.1345e-02, 1.0958e-02, 3.0498e-04, 1.5668e-02, 8.8958e-04,\n",
              "            1.4816e-02, 9.6043e-03, 4.0247e-03, 2.4529e-03, 1.4100e-02, 8.1668e-02,\n",
              "            9.0688e-05, 2.5139e-03, 7.2453e-04, 1.3672e-04, 3.2818e-03, 2.0042e-02,\n",
              "            6.1209e-03, 9.9961e-03, 1.3164e-03, 1.4660e-04, 3.6571e-03, 1.2221e-01,\n",
              "            4.8121e-04, 5.0463e-04, 1.8680e-03, 3.5567e-03, 4.4327e-04, 6.0867e-05,\n",
              "            6.0264e-05, 6.2720e-03, 6.9933e-05, 9.2245e-05, 2.2734e-03, 1.2949e-04,\n",
              "            1.4774e-03, 3.1238e-03, 2.2403e-03, 4.9887e-03, 6.0930e-05, 1.1964e-04,\n",
              "            3.1673e-04, 7.3283e-03, 5.8436e-05, 1.5426e-03, 4.8019e-03, 1.6272e-04,\n",
              "            6.0782e-05, 1.4502e-04, 1.1234e-05, 2.8366e-05, 3.3027e-04, 5.9646e-05,\n",
              "            2.0381e-05, 4.6256e-05, 1.2423e-04, 2.1569e-04, 2.7501e-04, 1.5799e-03,\n",
              "            1.0415e-05, 1.7172e-04, 3.6756e-03, 3.1185e-05, 6.2570e-06, 2.9883e-05,\n",
              "            2.9456e-05, 3.4598e-06, 7.6650e-06, 3.3972e-03, 6.3969e-04, 3.1252e-06,\n",
              "            1.5905e-06, 6.2417e-07, 6.8975e-08, 1.9241e-06, 1.3010e-06, 6.0971e-07,\n",
              "            2.6773e-08, 2.9471e-07],\n",
              "           [9.8279e-01, 1.0286e-02, 9.0206e-03, 3.3758e-04, 8.7593e-03, 1.3648e-04,\n",
              "            3.5829e-03, 4.8569e-03, 8.1524e-04, 7.5225e-04, 1.3287e-02, 1.4877e-03,\n",
              "            6.7430e-06, 2.8535e-03, 3.8151e-05, 1.3107e-04, 8.2469e-04, 3.5864e-02,\n",
              "            1.6213e-03, 1.0303e-02, 2.6975e-04, 7.1495e-05, 7.0783e-04, 2.1523e-02,\n",
              "            8.2666e-05, 3.4731e-05, 5.3993e-04, 9.7609e-05, 1.6383e-04, 5.8355e-06,\n",
              "            1.2095e-05, 5.8473e-04, 3.2381e-05, 1.7908e-05, 3.6043e-04, 1.1221e-04,\n",
              "            3.8921e-04, 2.2278e-04, 1.3052e-04, 5.7715e-04, 8.4249e-05, 1.3969e-05,\n",
              "            2.9363e-05, 2.9584e-04, 1.6329e-05, 1.8425e-04, 3.5593e-04, 9.3731e-05,\n",
              "            2.0375e-05, 3.9462e-05, 5.4168e-07, 1.0927e-06, 4.2513e-05, 1.3903e-05,\n",
              "            3.9905e-06, 7.2045e-06, 6.6540e-05, 4.2205e-05, 1.6694e-04, 4.2029e-04,\n",
              "            7.2708e-07, 6.2858e-05, 8.4267e-05, 3.5410e-05, 2.7549e-05, 3.5952e-06,\n",
              "            2.2637e-05, 3.9175e-07, 2.0440e-06, 6.9071e-06, 2.1417e-06, 1.5742e-06,\n",
              "            1.2016e-04, 3.3701e-07, 1.0578e-07, 1.5978e-07, 3.7139e-08, 2.2594e-08,\n",
              "            4.9661e-09, 2.0311e-09]], device='cuda:0', grad_fn=<SigmoidBackward>),\n",
              "   tensor([[9.9908e-01, 6.9200e-04, 8.0072e-04, 6.9625e-06, 7.4145e-04, 1.4711e-04,\n",
              "            2.4716e-04, 3.2379e-03, 1.9919e-04, 6.0684e-05, 8.7689e-04, 1.4795e-03,\n",
              "            4.0972e-05, 1.3472e-03, 4.8064e-06, 1.4410e-07, 4.2784e-05, 7.0886e-04,\n",
              "            5.9732e-06, 3.4133e-03, 4.3562e-04, 4.6387e-06, 2.1214e-07, 5.8658e-04,\n",
              "            6.9392e-07, 3.9865e-07, 7.9708e-08, 1.3555e-06, 3.4763e-05, 1.3704e-05,\n",
              "            1.9209e-08, 1.9403e-06, 4.3153e-08, 4.2020e-07, 3.7238e-08, 1.5826e-10,\n",
              "            1.7362e-03, 7.0725e-07, 2.4322e-04, 6.2077e-07, 3.0596e-05, 2.0491e-07,\n",
              "            1.2148e-04, 7.7927e-05, 5.6224e-05, 1.6285e-03, 5.4466e-02, 2.9517e-08,\n",
              "            2.0784e-07, 3.2835e-06, 3.8881e-04, 4.2056e-05, 4.0017e-03, 2.5409e-04,\n",
              "            2.4236e-05, 8.2359e-07, 2.4384e-06, 1.9035e-07, 2.3073e-05, 1.1428e-02,\n",
              "            8.1056e-09, 2.9243e-06, 7.6995e-03, 7.2274e-05, 1.2191e-04, 2.2691e-05,\n",
              "            5.2998e-08, 1.2170e-06, 2.0950e-07, 1.9599e-02],\n",
              "           [1.0000e+00, 4.8492e-07, 8.1150e-07, 1.0362e-08, 4.0270e-05, 2.7533e-07,\n",
              "            3.3184e-05, 8.4204e-06, 8.8716e-08, 2.0187e-07, 4.2573e-07, 4.3933e-05,\n",
              "            2.5652e-09, 6.8812e-07, 1.7923e-07, 2.0900e-10, 2.3889e-07, 5.1605e-05,\n",
              "            1.2743e-07, 2.0778e-06, 2.9044e-08, 5.9167e-12, 5.4330e-09, 6.8410e-07,\n",
              "            3.7926e-10, 3.3011e-09, 5.6423e-12, 3.0810e-07, 6.7190e-05, 3.7466e-10,\n",
              "            1.3435e-12, 5.1881e-09, 1.8564e-11, 4.3423e-07, 1.6364e-11, 2.9239e-11,\n",
              "            4.3400e-10, 1.1583e-07, 1.0789e-07, 7.9823e-07, 4.2861e-06, 3.0959e-07,\n",
              "            1.2852e-09, 3.6185e-09, 1.9886e-08, 1.7517e-03, 1.6409e-05, 1.8498e-07,\n",
              "            1.0856e-06, 4.6288e-07, 6.8154e-08, 1.3247e-09, 9.9926e-06, 5.5676e-09,\n",
              "            1.2263e-08, 3.2483e-08, 2.2112e-08, 2.9702e-10, 4.8004e-04, 1.7813e-04,\n",
              "            1.1269e-07, 2.1631e-05, 1.2634e-03, 8.1985e-07, 4.1963e-06, 5.5841e-09,\n",
              "            9.4943e-09, 2.2211e-08, 3.6684e-06, 1.1148e-08],\n",
              "           [1.0000e+00, 4.4235e-05, 3.9204e-06, 2.1221e-07, 5.3139e-05, 1.9269e-06,\n",
              "            1.1930e-05, 1.4104e-05, 3.2766e-06, 5.0207e-06, 1.3716e-05, 2.2490e-05,\n",
              "            6.1373e-07, 7.1266e-05, 4.3726e-07, 9.0238e-09, 4.7590e-06, 1.4343e-04,\n",
              "            3.3249e-07, 3.3315e-04, 4.2677e-08, 9.9578e-10, 3.0770e-05, 1.5500e-05,\n",
              "            2.0124e-09, 1.0573e-07, 1.9891e-07, 3.5305e-05, 6.4607e-06, 1.0431e-09,\n",
              "            8.2108e-06, 2.0103e-06, 2.0106e-08, 7.7414e-07, 1.0650e-09, 1.4474e-06,\n",
              "            1.5022e-07, 1.0330e-04, 2.8796e-07, 3.0610e-04, 3.1960e-05, 9.1784e-07,\n",
              "            5.7860e-07, 2.5497e-05, 4.1775e-07, 2.3450e-04, 5.2293e-05, 2.1351e-07,\n",
              "            2.0445e-05, 8.8480e-06, 1.7400e-06, 1.1241e-08, 1.0254e-04, 7.4010e-06,\n",
              "            2.7599e-07, 9.2165e-07, 1.1783e-06, 8.7492e-08, 1.2582e-04, 3.2487e-03,\n",
              "            3.3307e-07, 1.7513e-03, 7.8850e-03, 3.7759e-04, 3.4265e-05, 6.5769e-05,\n",
              "            1.6974e-05, 6.5886e-06, 3.3915e-05, 2.0580e-04],\n",
              "           [9.9999e-01, 2.2478e-05, 4.0819e-05, 5.1062e-07, 4.5774e-04, 1.8481e-05,\n",
              "            2.8058e-05, 6.8651e-05, 1.6414e-05, 4.3917e-05, 1.0857e-05, 3.7650e-04,\n",
              "            7.4395e-07, 1.7993e-04, 1.3578e-06, 2.3530e-08, 4.4231e-06, 1.4510e-05,\n",
              "            1.0204e-06, 6.8003e-05, 3.4125e-07, 1.0105e-08, 3.5128e-06, 1.8945e-03,\n",
              "            9.3111e-08, 7.9602e-07, 2.6428e-08, 9.9818e-07, 5.1420e-06, 3.5291e-08,\n",
              "            7.3058e-06, 4.6001e-07, 1.1120e-08, 4.4645e-08, 4.8225e-09, 8.4143e-09,\n",
              "            4.3047e-04, 5.3224e-05, 2.4786e-07, 8.6821e-05, 9.8074e-07, 6.8903e-08,\n",
              "            8.5169e-08, 6.0948e-05, 1.0632e-07, 1.0041e-06, 1.4642e-05, 2.9089e-09,\n",
              "            5.3177e-06, 3.3957e-08, 1.1648e-04, 7.6467e-09, 6.6409e-06, 2.8094e-05,\n",
              "            4.4627e-08, 2.8971e-08, 2.9342e-05, 4.5039e-08, 2.8066e-04, 1.1379e-05,\n",
              "            4.6465e-09, 6.3909e-05, 1.6577e-04, 7.5948e-05, 8.7874e-03, 4.4715e-07,\n",
              "            2.1162e-08, 1.5308e-07, 8.5811e-06, 5.0737e-05],\n",
              "           [1.0000e+00, 3.2892e-06, 2.3595e-05, 1.3481e-07, 2.0522e-04, 7.1492e-06,\n",
              "            7.5380e-06, 4.7893e-05, 1.5782e-06, 8.2644e-07, 4.9282e-08, 3.7144e-08,\n",
              "            7.4850e-08, 4.1440e-05, 9.9630e-10, 2.0470e-10, 9.0763e-08, 1.3555e-04,\n",
              "            4.4645e-09, 1.1499e-05, 6.9140e-10, 2.4573e-12, 3.0633e-09, 2.2534e-06,\n",
              "            1.7030e-10, 3.4079e-09, 7.4912e-10, 1.8549e-06, 1.0884e-07, 2.4170e-12,\n",
              "            3.9477e-09, 1.0089e-08, 1.2726e-10, 8.1568e-09, 4.9966e-11, 3.2332e-09,\n",
              "            2.9195e-09, 2.3752e-07, 2.1880e-10, 2.9423e-06, 1.2972e-07, 1.4374e-08,\n",
              "            6.9272e-09, 5.3385e-07, 4.8447e-09, 9.4277e-07, 7.9305e-09, 5.9686e-09,\n",
              "            2.7876e-08, 3.3089e-07, 6.0583e-08, 6.6004e-11, 2.9463e-06, 2.9613e-07,\n",
              "            9.8864e-08, 2.3464e-07, 1.6869e-09, 6.1995e-09, 1.2356e-04, 8.7223e-06,\n",
              "            3.8794e-10, 2.8762e-04, 1.1962e-06, 4.4601e-06, 3.6969e-06, 3.7261e-06,\n",
              "            3.9959e-09, 5.4237e-10, 1.2262e-06, 2.1665e-07],\n",
              "           [1.0000e+00, 2.8102e-05, 3.3007e-06, 1.8039e-07, 1.7867e-05, 4.5562e-07,\n",
              "            2.3666e-05, 3.0321e-06, 7.7598e-07, 3.5545e-07, 2.1866e-06, 5.6248e-07,\n",
              "            7.2865e-08, 1.5414e-05, 2.1945e-09, 6.3591e-10, 7.9638e-08, 3.3080e-07,\n",
              "            1.7027e-09, 7.5247e-06, 3.4821e-10, 7.1898e-11, 5.3652e-09, 3.9638e-06,\n",
              "            1.1701e-10, 2.2745e-10, 1.1439e-07, 1.5616e-07, 1.8453e-07, 1.1493e-10,\n",
              "            3.5014e-09, 2.8371e-07, 4.5338e-11, 1.8242e-08, 2.6334e-12, 2.4513e-08,\n",
              "            3.6720e-08, 3.3587e-06, 2.2110e-07, 3.2221e-08, 3.8417e-06, 1.2377e-05,\n",
              "            2.9879e-08, 2.6192e-07, 7.6754e-08, 1.0275e-06, 4.4659e-05, 2.6043e-07,\n",
              "            1.2410e-06, 8.3409e-07, 3.6930e-07, 5.8822e-09, 1.0074e-05, 1.4728e-06,\n",
              "            3.6508e-08, 7.2212e-08, 5.0332e-09, 9.2354e-10, 4.0093e-03, 4.2112e-04,\n",
              "            7.9061e-08, 1.7951e-05, 5.0802e-03, 1.1939e-05, 1.2618e-04, 9.1541e-07,\n",
              "            1.8525e-08, 4.8036e-08, 5.8320e-07, 2.3856e-06],\n",
              "           [1.0000e+00, 1.1520e-04, 2.7779e-06, 4.1368e-07, 1.2517e-05, 9.8886e-07,\n",
              "            1.6817e-04, 1.4803e-05, 3.6708e-06, 8.3260e-06, 1.5695e-06, 4.7092e-07,\n",
              "            1.7338e-07, 4.7419e-05, 1.0294e-08, 7.8285e-10, 6.5684e-07, 5.2428e-05,\n",
              "            2.2145e-08, 2.7994e-06, 4.5749e-09, 1.1231e-10, 2.6104e-06, 1.2351e-05,\n",
              "            1.2798e-09, 8.2072e-08, 2.0546e-08, 1.3941e-05, 1.6354e-06, 8.2434e-11,\n",
              "            5.6648e-07, 5.3840e-09, 2.8903e-08, 1.0028e-06, 3.3167e-10, 6.2886e-07,\n",
              "            1.8063e-08, 1.2763e-07, 3.0293e-09, 1.1358e-03, 1.5005e-06, 7.3845e-09,\n",
              "            1.0343e-09, 5.7215e-08, 8.3859e-10, 6.8186e-05, 1.3064e-07, 2.4548e-10,\n",
              "            1.7721e-06, 1.0804e-08, 1.7062e-07, 3.5804e-10, 4.5781e-07, 5.7791e-09,\n",
              "            3.0184e-10, 6.8824e-09, 2.6051e-07, 3.1972e-07, 7.2086e-05, 3.0404e-06,\n",
              "            9.5294e-09, 1.4193e-04, 7.3911e-06, 7.0133e-05, 5.4532e-05, 4.1165e-06,\n",
              "            6.6870e-07, 9.0109e-08, 2.2419e-05, 2.4760e-06],\n",
              "           [9.9999e-01, 2.6787e-08, 1.7338e-06, 9.4711e-09, 5.5578e-05, 4.0109e-07,\n",
              "            2.7156e-07, 1.0116e-06, 3.9826e-07, 7.6756e-06, 6.6933e-08, 3.0601e-06,\n",
              "            3.3783e-08, 4.9536e-06, 5.0261e-09, 1.5874e-10, 2.3674e-08, 4.2293e-09,\n",
              "            1.4111e-11, 2.6479e-06, 4.5071e-09, 2.2931e-10, 1.7908e-07, 1.4718e-05,\n",
              "            1.2824e-09, 1.0668e-08, 3.5781e-08, 2.4240e-07, 2.5301e-07, 2.0920e-09,\n",
              "            1.4184e-08, 1.0575e-07, 1.0346e-10, 6.2776e-09, 4.5551e-15, 9.4344e-12,\n",
              "            1.0496e-08, 1.0608e-07, 8.2065e-06, 2.1395e-09, 6.4866e-05, 9.4885e-08,\n",
              "            6.5590e-10, 2.7408e-08, 6.7827e-09, 9.1735e-09, 7.7947e-05, 8.3855e-10,\n",
              "            2.0550e-07, 2.7558e-08, 1.5966e-08, 1.9500e-10, 1.9377e-06, 2.6023e-05,\n",
              "            2.6528e-09, 4.4533e-10, 1.3984e-08, 1.2303e-11, 1.7141e-04, 5.7072e-05,\n",
              "            2.5996e-09, 2.1057e-06, 3.7349e-04, 3.6164e-05, 3.6989e-04, 3.4500e-07,\n",
              "            3.4941e-09, 8.3525e-09, 2.2675e-07, 1.3285e-05],\n",
              "           [1.0000e+00, 5.1635e-07, 1.0300e-04, 9.9058e-09, 3.2265e-07, 6.1867e-07,\n",
              "            1.9642e-07, 2.4536e-06, 7.4995e-07, 8.6155e-07, 5.4114e-09, 3.4940e-05,\n",
              "            1.1758e-10, 1.1173e-10, 4.3528e-10, 5.7353e-13, 5.4245e-10, 5.1669e-07,\n",
              "            3.7378e-09, 1.3266e-06, 5.0680e-10, 3.2484e-12, 9.3181e-08, 3.3493e-04,\n",
              "            4.4336e-10, 6.1385e-10, 3.8011e-11, 8.1712e-09, 1.3309e-06, 4.2855e-08,\n",
              "            7.5056e-10, 3.2844e-10, 1.9126e-10, 8.1122e-09, 9.3865e-12, 1.0376e-09,\n",
              "            3.0539e-10, 3.3390e-05, 9.1770e-08, 6.9320e-06, 1.7867e-07, 1.3434e-05,\n",
              "            1.9522e-09, 1.5855e-06, 1.0299e-09, 2.3800e-06, 2.4416e-04, 3.2834e-08,\n",
              "            1.8295e-06, 4.2985e-09, 3.1876e-08, 1.5773e-09, 6.8505e-05, 3.1715e-07,\n",
              "            1.6754e-08, 1.8301e-09, 8.9405e-08, 4.6261e-10, 2.2130e-05, 4.7266e-05,\n",
              "            1.6206e-08, 1.1123e-03, 4.8956e-03, 6.0807e-06, 1.0776e-06, 1.5779e-06,\n",
              "            1.0567e-06, 1.2508e-08, 5.9781e-07, 5.4273e-04],\n",
              "           [1.0000e+00, 1.2937e-05, 2.3677e-05, 5.6655e-07, 2.8152e-05, 6.6959e-06,\n",
              "            5.3308e-06, 1.2006e-04, 1.2946e-05, 4.2006e-06, 3.3186e-05, 2.5173e-06,\n",
              "            5.2835e-09, 5.9312e-06, 5.0463e-09, 3.3154e-09, 9.2776e-07, 4.3737e-07,\n",
              "            3.9427e-08, 1.4702e-06, 4.7996e-11, 5.3613e-09, 2.3804e-08, 2.5086e-06,\n",
              "            7.5243e-11, 5.7315e-10, 6.5152e-11, 3.4224e-08, 3.4850e-06, 2.7782e-11,\n",
              "            5.9758e-11, 1.2988e-08, 2.1525e-11, 9.5504e-10, 4.3375e-13, 3.7756e-10,\n",
              "            4.2299e-08, 1.5204e-06, 2.8593e-10, 3.1248e-08, 3.1075e-07, 1.0578e-07,\n",
              "            4.8334e-09, 1.8225e-07, 2.5807e-08, 9.7184e-08, 9.8732e-08, 1.7799e-07,\n",
              "            3.5595e-07, 1.0382e-08, 1.1590e-07, 2.3672e-09, 7.0763e-07, 4.9935e-08,\n",
              "            1.8740e-07, 8.3083e-09, 5.0570e-09, 1.4904e-07, 1.0815e-04, 9.0862e-06,\n",
              "            1.2391e-09, 3.4619e-05, 1.8271e-05, 1.3404e-06, 3.2980e-06, 3.2864e-07,\n",
              "            1.0092e-07, 7.3097e-10, 2.3534e-07, 2.2890e-07]], device='cuda:0',\n",
              "          grad_fn=<CatBackward>)],\n",
              "  9: [tensor([[9.3244e-01, 8.0438e-02, 1.7978e-02, 1.2825e-03, 4.3520e-02, 2.4212e-03,\n",
              "            1.8792e-02, 1.1131e-02, 3.6004e-03, 1.1801e-02, 7.2559e-03, 1.6994e-01,\n",
              "            2.3011e-03, 2.2866e-03, 1.5450e-03, 4.3313e-04, 6.6715e-03, 6.5911e-02,\n",
              "            4.1955e-03, 3.3933e-02, 2.4877e-02, 1.5966e-03, 1.8695e-03, 3.4885e-01,\n",
              "            1.1903e-03, 6.8600e-04, 1.5033e-03, 1.4729e-03, 1.7423e-03, 1.1343e-03,\n",
              "            8.4370e-04, 2.2544e-03, 6.0807e-04, 6.4059e-04, 6.5322e-04, 1.4383e-04,\n",
              "            2.9058e-01, 1.8315e-03, 1.5853e-02, 2.3603e-03, 1.2780e-03, 1.7674e-04,\n",
              "            2.9480e-04, 2.4561e-02, 2.4741e-03, 1.7691e-02, 4.3905e-02, 1.4085e-04,\n",
              "            6.2409e-04, 4.0183e-04, 1.3235e-04, 1.5573e-03, 6.0027e-03, 2.2047e-04,\n",
              "            4.2496e-04, 1.0476e-04, 2.4690e-04, 1.0505e-03, 2.0984e-04, 1.6865e-03,\n",
              "            2.1677e-05, 3.6117e-05, 1.8185e-02, 3.4202e-04, 2.0219e-03, 1.8683e-04,\n",
              "            5.4200e-04, 1.0018e-04, 8.4957e-05, 1.0948e-02, 1.4891e-02, 2.7753e-03,\n",
              "            3.7107e-04, 1.0015e-04, 1.2850e-05, 4.0294e-05, 4.4675e-04, 8.3974e-05,\n",
              "            4.9371e-04, 1.0154e-06, 1.0783e-04, 6.9569e-09, 7.7065e-07, 1.8454e-05,\n",
              "            2.8709e-06, 3.3601e-03, 2.8257e-07, 1.9695e-05, 3.6996e-08, 5.2568e-06],\n",
              "           [9.3032e-01, 6.8645e-03, 7.8931e-03, 2.8308e-03, 1.8050e-02, 6.7103e-04,\n",
              "            5.8748e-02, 4.9866e-02, 6.0494e-03, 2.3433e-03, 6.5195e-03, 1.3176e-02,\n",
              "            4.6959e-05, 4.3449e-03, 3.1924e-03, 7.5755e-04, 3.1492e-03, 2.0223e-01,\n",
              "            2.4959e-03, 4.4070e-03, 1.6903e-03, 4.6819e-04, 1.6984e-03, 1.7355e-01,\n",
              "            3.4665e-04, 3.0862e-04, 1.5996e-03, 1.0223e-03, 3.7029e-03, 6.9560e-05,\n",
              "            5.1459e-04, 2.1655e-03, 2.1886e-04, 4.5491e-05, 8.7513e-04, 9.4813e-04,\n",
              "            2.9917e-03, 2.6170e-03, 1.1033e-03, 7.8529e-04, 7.9580e-04, 1.3701e-04,\n",
              "            9.4507e-05, 1.1319e-03, 1.0907e-04, 7.4774e-03, 6.5261e-03, 2.0542e-03,\n",
              "            1.5665e-04, 7.0180e-04, 1.4124e-05, 6.8016e-05, 1.1795e-03, 1.4613e-05,\n",
              "            1.0876e-03, 7.8803e-04, 3.0772e-04, 2.3339e-04, 1.1220e-03, 3.6564e-03,\n",
              "            4.7869e-05, 2.9496e-04, 6.4041e-03, 2.7609e-04, 1.5659e-04, 5.7716e-05,\n",
              "            2.0884e-04, 3.3371e-04, 2.0394e-04, 1.3297e-04, 3.7272e-04, 7.6629e-05,\n",
              "            1.4389e-04, 1.0577e-05, 2.2718e-06, 2.7142e-05, 5.2922e-05, 1.5303e-04,\n",
              "            1.1584e-04, 1.1534e-05, 6.1533e-04, 1.3008e-08, 1.9410e-08, 6.1056e-07,\n",
              "            1.4512e-08, 6.9283e-05, 4.9542e-07, 1.3963e-04, 3.6785e-07, 3.2630e-04],\n",
              "           [9.6410e-01, 1.5849e-02, 8.3041e-03, 2.0580e-04, 8.3709e-03, 5.9966e-04,\n",
              "            2.9065e-03, 1.2492e-02, 2.2495e-03, 6.5672e-04, 5.9422e-03, 5.1555e-03,\n",
              "            1.4520e-05, 2.2602e-03, 5.5664e-05, 8.9451e-05, 3.1717e-03, 7.6289e-02,\n",
              "            5.9824e-04, 1.4355e-02, 1.4136e-04, 2.1879e-04, 1.7259e-03, 8.0472e-03,\n",
              "            5.6628e-05, 5.5896e-05, 8.2786e-04, 1.1054e-03, 6.5280e-05, 4.3453e-06,\n",
              "            1.2158e-04, 1.3416e-03, 4.2005e-04, 1.6514e-05, 6.6651e-04, 3.4024e-04,\n",
              "            1.7973e-04, 1.0136e-04, 1.0361e-04, 8.6531e-04, 1.7146e-04, 4.9734e-06,\n",
              "            1.9533e-05, 1.2052e-04, 4.4662e-05, 2.2265e-03, 6.8223e-04, 1.1549e-03,\n",
              "            5.3255e-06, 2.0944e-03, 3.8053e-06, 6.7900e-07, 1.5323e-04, 2.8974e-05,\n",
              "            1.2378e-05, 2.3303e-05, 2.1708e-04, 5.2434e-05, 1.4720e-04, 7.6373e-03,\n",
              "            2.3822e-06, 2.0339e-04, 7.3582e-06, 3.6168e-05, 2.3316e-05, 7.2700e-06,\n",
              "            4.0441e-05, 1.0171e-04, 6.9732e-04, 1.1021e-04, 8.2465e-05, 1.2709e-04,\n",
              "            3.4797e-05, 8.2473e-05, 6.9906e-06, 1.2266e-06, 1.7265e-06, 6.8976e-06,\n",
              "            1.8808e-07, 1.3948e-08, 9.6990e-07, 1.2239e-08, 7.7302e-11, 3.6880e-06,\n",
              "            1.1324e-09, 6.2820e-09, 1.3344e-08, 8.1074e-09, 2.3544e-09, 1.7203e-03],\n",
              "           [9.8423e-01, 1.9530e-02, 1.3152e-02, 1.2624e-03, 1.5393e-02, 4.1074e-04,\n",
              "            2.3607e-03, 1.1465e-02, 1.7338e-03, 7.1125e-04, 7.0556e-03, 4.0425e-03,\n",
              "            2.1563e-05, 5.4140e-03, 9.5516e-05, 3.4767e-04, 1.4649e-03, 1.9927e-02,\n",
              "            1.2931e-03, 5.7071e-02, 2.3024e-04, 1.6530e-04, 1.0594e-03, 4.7153e-02,\n",
              "            4.8321e-04, 1.5277e-04, 2.3460e-03, 1.9825e-04, 1.6919e-04, 2.4027e-05,\n",
              "            1.6913e-04, 2.0003e-03, 3.4573e-04, 2.7417e-05, 3.5226e-04, 1.4561e-04,\n",
              "            9.9872e-03, 4.4125e-04, 4.3167e-04, 3.8642e-04, 4.3470e-04, 2.6438e-05,\n",
              "            1.1190e-04, 1.2822e-03, 3.2346e-05, 9.0108e-04, 6.0608e-04, 1.3279e-04,\n",
              "            4.5029e-05, 6.0684e-04, 8.0180e-06, 2.7864e-06, 2.7088e-04, 1.6559e-04,\n",
              "            1.1650e-04, 9.6356e-06, 1.4058e-04, 1.0330e-04, 2.0023e-04, 3.3673e-03,\n",
              "            2.4178e-06, 1.7928e-04, 9.9446e-05, 4.7380e-04, 1.0047e-03, 1.9098e-05,\n",
              "            1.0675e-04, 1.7713e-05, 8.4957e-05, 1.5299e-04, 3.7166e-04, 6.5652e-04,\n",
              "            2.8207e-03, 1.8610e-04, 8.9772e-07, 1.6744e-05, 8.1253e-06, 7.6791e-06,\n",
              "            1.4735e-05, 1.2607e-07, 9.8291e-09, 2.1045e-08, 1.1378e-09, 1.8577e-04,\n",
              "            8.3176e-06, 1.1085e-04, 4.1068e-09, 1.5166e-07, 1.5045e-09, 4.9642e-05],\n",
              "           [9.6699e-01, 5.3879e-03, 2.0219e-02, 1.5281e-03, 3.3274e-02, 8.8114e-04,\n",
              "            7.8306e-03, 1.7274e-02, 3.0681e-03, 1.6059e-03, 2.1109e-03, 2.7159e-03,\n",
              "            3.6074e-05, 1.3162e-02, 5.9139e-04, 3.0474e-04, 3.1365e-03, 1.8260e-01,\n",
              "            1.9695e-03, 2.4823e-02, 6.1541e-04, 4.0010e-04, 5.9885e-04, 1.4600e-02,\n",
              "            3.2946e-04, 3.4928e-04, 3.0588e-03, 7.7209e-04, 2.1707e-04, 2.3282e-05,\n",
              "            2.2498e-04, 1.1159e-03, 5.4441e-04, 5.9624e-05, 4.4081e-04, 1.5892e-03,\n",
              "            8.2352e-04, 5.9437e-04, 1.8300e-04, 2.6643e-04, 3.7011e-04, 3.8374e-05,\n",
              "            1.7053e-05, 8.3276e-04, 2.1888e-04, 9.5403e-04, 3.5491e-04, 1.3456e-03,\n",
              "            2.7192e-05, 2.0051e-03, 5.9136e-06, 4.1776e-06, 3.3822e-04, 6.2479e-05,\n",
              "            3.0947e-05, 7.1259e-04, 2.1575e-04, 5.6121e-05, 3.8857e-04, 3.7013e-03,\n",
              "            4.1335e-06, 2.9276e-04, 4.6872e-05, 1.5099e-04, 1.9869e-04, 4.9768e-05,\n",
              "            1.0039e-04, 5.2907e-05, 8.4045e-04, 3.4089e-05, 2.1133e-04, 1.5783e-04,\n",
              "            1.8705e-03, 6.1776e-04, 1.8951e-06, 3.3222e-06, 6.0935e-06, 1.3011e-05,\n",
              "            1.1266e-05, 8.0061e-08, 1.1408e-06, 1.1136e-06, 1.0034e-09, 2.4786e-06,\n",
              "            3.0881e-08, 5.9695e-06, 6.8997e-10, 1.3387e-06, 2.3720e-08, 8.3725e-06],\n",
              "           [9.8598e-01, 3.6963e-03, 5.6586e-03, 6.2305e-04, 8.5198e-03, 1.4766e-04,\n",
              "            5.2206e-03, 1.4932e-02, 1.5462e-03, 7.0245e-04, 1.3289e-03, 4.4176e-03,\n",
              "            7.1583e-06, 1.9251e-03, 5.0921e-05, 9.2474e-05, 1.3261e-03, 8.7419e-02,\n",
              "            4.4766e-04, 6.0020e-03, 8.3478e-05, 7.3486e-05, 2.3948e-04, 2.5541e-02,\n",
              "            3.7875e-05, 3.4430e-05, 6.4716e-04, 1.6136e-04, 4.7222e-05, 3.7139e-06,\n",
              "            4.2425e-05, 5.2191e-04, 8.6869e-05, 3.2921e-06, 7.0012e-05, 1.9657e-04,\n",
              "            3.4602e-04, 1.6294e-04, 3.1998e-04, 1.9628e-04, 1.4407e-04, 4.5677e-06,\n",
              "            9.5733e-06, 2.0415e-04, 1.6876e-05, 4.3998e-04, 8.7973e-04, 1.4869e-04,\n",
              "            3.0086e-06, 6.9990e-04, 2.8807e-06, 9.3176e-07, 1.5284e-04, 9.5297e-06,\n",
              "            6.3378e-06, 4.0115e-05, 9.1526e-06, 9.2230e-06, 3.2742e-04, 3.2499e-03,\n",
              "            1.0487e-06, 5.8278e-05, 7.0871e-05, 4.5794e-05, 5.1379e-05, 1.2944e-05,\n",
              "            1.9968e-06, 2.0584e-05, 4.6729e-05, 8.7316e-05, 2.5812e-04, 3.7704e-05,\n",
              "            9.1997e-05, 4.1599e-06, 4.4364e-07, 1.7032e-06, 4.4097e-07, 4.5084e-06,\n",
              "            6.4815e-07, 7.3309e-09, 3.1487e-08, 1.9152e-09, 2.8069e-12, 8.7355e-08,\n",
              "            7.3058e-10, 6.3019e-06, 1.1123e-09, 3.8013e-07, 2.2221e-10, 2.9787e-05],\n",
              "           [9.4669e-01, 1.5969e-02, 1.3717e-02, 9.3854e-04, 2.9763e-02, 1.1259e-03,\n",
              "            7.8245e-03, 1.8702e-02, 2.9702e-03, 2.3816e-03, 1.5943e-02, 2.8683e-03,\n",
              "            5.4046e-05, 1.8809e-02, 2.0942e-04, 2.4768e-04, 1.0313e-02, 1.6350e-01,\n",
              "            2.2486e-03, 1.8140e-02, 3.6275e-04, 1.6921e-03, 1.6247e-03, 1.8667e-02,\n",
              "            4.4128e-04, 4.2982e-04, 1.5103e-03, 1.7267e-03, 2.9398e-04, 1.7368e-05,\n",
              "            3.8838e-04, 1.7687e-03, 1.3589e-03, 6.6166e-05, 1.4134e-03, 3.4823e-03,\n",
              "            6.6051e-04, 2.1436e-04, 2.1989e-04, 2.3734e-03, 4.1401e-04, 1.8782e-05,\n",
              "            1.8460e-04, 6.2177e-04, 1.8380e-04, 3.4200e-03, 3.2379e-04, 4.5642e-03,\n",
              "            4.4852e-05, 3.5136e-03, 9.7835e-06, 2.5080e-06, 1.2481e-04, 7.5477e-05,\n",
              "            1.3312e-04, 1.1040e-04, 4.9188e-04, 1.9554e-03, 2.4881e-04, 7.8624e-03,\n",
              "            1.0139e-05, 9.6893e-04, 1.9062e-05, 1.2787e-04, 1.5320e-04, 4.0729e-05,\n",
              "            4.0834e-04, 1.9660e-04, 9.7734e-04, 3.1829e-04, 8.8333e-05, 3.5786e-04,\n",
              "            7.8255e-05, 2.4137e-03, 2.3758e-06, 8.1525e-06, 3.4081e-06, 1.0403e-04,\n",
              "            1.0914e-05, 2.3831e-07, 2.5977e-07, 1.7075e-08, 1.2008e-09, 6.8195e-05,\n",
              "            1.7521e-05, 4.0347e-08, 1.8639e-08, 5.0557e-08, 6.5490e-09, 4.8979e-03],\n",
              "           [9.8566e-01, 5.2592e-03, 1.1663e-02, 4.2809e-04, 8.1834e-03, 2.1638e-04,\n",
              "            3.8347e-03, 6.6723e-03, 1.9150e-03, 1.9844e-03, 3.9992e-03, 1.4844e-02,\n",
              "            8.2308e-06, 1.5718e-03, 5.6638e-05, 7.4718e-05, 6.3743e-04, 3.2922e-02,\n",
              "            7.0767e-04, 3.3718e-02, 2.5485e-04, 7.2841e-05, 6.5401e-04, 2.4803e-02,\n",
              "            6.6798e-05, 9.4472e-05, 7.6679e-04, 2.0707e-04, 8.5915e-05, 6.6945e-06,\n",
              "            1.3393e-04, 1.1385e-03, 1.1214e-04, 1.6279e-05, 1.2970e-04, 8.3153e-05,\n",
              "            2.0590e-03, 2.1339e-04, 4.2193e-04, 1.3439e-04, 2.4448e-04, 4.6033e-06,\n",
              "            1.2043e-05, 8.1352e-04, 2.9067e-05, 4.3606e-04, 3.3115e-03, 9.8422e-05,\n",
              "            6.6416e-06, 3.2543e-04, 1.8336e-06, 6.1130e-07, 5.6328e-04, 1.0534e-04,\n",
              "            6.3215e-06, 6.8739e-06, 5.5629e-05, 1.2270e-05, 6.0565e-05, 3.0538e-03,\n",
              "            6.9864e-07, 1.6010e-05, 6.2150e-05, 1.6775e-04, 2.1542e-04, 7.2062e-06,\n",
              "            1.5974e-05, 7.7388e-06, 1.1528e-04, 1.5186e-04, 1.4417e-04, 1.0833e-03,\n",
              "            7.2898e-04, 3.5720e-05, 3.1026e-07, 7.3415e-07, 5.9272e-07, 2.4826e-06,\n",
              "            2.7875e-06, 3.0702e-08, 2.4409e-07, 2.0546e-08, 5.0713e-12, 4.0821e-07,\n",
              "            1.3123e-07, 3.1717e-05, 3.6242e-10, 2.8738e-08, 1.7544e-09, 1.7337e-05],\n",
              "           [9.0465e-01, 5.2198e-02, 1.9440e-02, 1.6560e-03, 2.9360e-02, 2.2583e-03,\n",
              "            1.7080e-02, 6.0776e-03, 6.9196e-03, 6.3609e-03, 1.4683e-02, 7.5297e-02,\n",
              "            3.8913e-04, 2.3419e-03, 4.0856e-04, 1.1596e-03, 3.9206e-03, 2.3891e-02,\n",
              "            6.6942e-03, 2.7823e-02, 1.0498e-03, 4.7654e-04, 7.1675e-03, 9.3247e-02,\n",
              "            3.4518e-04, 5.9186e-04, 1.5644e-03, 1.8036e-03, 4.3881e-04, 4.8648e-04,\n",
              "            5.1345e-04, 1.0881e-03, 5.9874e-04, 2.2604e-04, 9.1103e-04, 3.8574e-04,\n",
              "            8.1492e-03, 1.5983e-03, 8.7726e-03, 2.5081e-03, 9.7682e-04, 3.4232e-04,\n",
              "            3.3894e-04, 1.1799e-02, 1.6564e-04, 8.2879e-04, 1.7003e-02, 9.3757e-04,\n",
              "            3.2239e-04, 3.8824e-04, 4.7283e-05, 6.1959e-05, 1.2831e-03, 1.1273e-03,\n",
              "            7.1482e-05, 1.1784e-04, 6.2650e-04, 1.4614e-04, 8.2562e-04, 2.0783e-03,\n",
              "            4.7264e-05, 6.2839e-04, 1.6831e-03, 1.6432e-04, 6.2594e-04, 6.3637e-05,\n",
              "            3.7202e-05, 3.8471e-05, 6.6085e-04, 1.3628e-02, 1.2272e-03, 3.1521e-04,\n",
              "            7.1920e-03, 2.6911e-04, 1.1955e-05, 1.0721e-04, 1.2813e-05, 2.4951e-05,\n",
              "            1.5260e-05, 4.1339e-06, 1.9896e-04, 1.3062e-06, 8.8286e-10, 6.3489e-07,\n",
              "            6.5136e-08, 4.7242e-04, 2.3174e-08, 1.3460e-04, 7.7047e-07, 7.1415e-06],\n",
              "           [9.7157e-01, 1.4559e-02, 1.3301e-02, 1.6095e-03, 2.6458e-02, 7.0683e-04,\n",
              "            1.4899e-02, 3.1804e-02, 2.9666e-03, 1.2287e-03, 1.6909e-02, 8.0889e-03,\n",
              "            7.5353e-05, 8.6553e-03, 4.2494e-04, 3.0119e-04, 5.1992e-03, 1.0943e-01,\n",
              "            6.7168e-03, 1.2426e-02, 1.2368e-03, 1.3626e-03, 7.6887e-04, 1.2717e-01,\n",
              "            4.2596e-04, 3.5373e-04, 3.4445e-03, 7.4356e-04, 5.5620e-04, 6.6020e-05,\n",
              "            1.3829e-04, 2.2389e-03, 3.5262e-04, 6.6041e-05, 3.8085e-03, 1.8228e-03,\n",
              "            6.8779e-03, 8.6109e-04, 7.6106e-04, 1.6828e-03, 8.1977e-04, 1.2998e-04,\n",
              "            2.6488e-04, 2.5762e-03, 1.3669e-04, 2.6402e-03, 2.1932e-03, 1.4727e-03,\n",
              "            1.5087e-04, 8.9510e-04, 1.0426e-05, 2.4319e-05, 2.5650e-04, 2.6112e-05,\n",
              "            2.3736e-04, 1.1665e-04, 8.4462e-04, 1.5341e-03, 7.9611e-04, 3.3479e-03,\n",
              "            1.4132e-05, 2.8185e-04, 6.6610e-04, 1.9117e-04, 2.7230e-04, 1.5030e-04,\n",
              "            8.0376e-04, 3.7865e-05, 2.5404e-04, 2.7322e-04, 6.7235e-04, 3.7713e-05,\n",
              "            1.4713e-03, 2.8991e-04, 2.5387e-06, 2.9492e-05, 7.6138e-05, 7.7035e-05,\n",
              "            1.2879e-05, 1.0991e-06, 7.1672e-08, 1.3618e-07, 8.3295e-09, 2.4436e-05,\n",
              "            1.9391e-06, 8.1152e-05, 3.8273e-08, 3.8523e-05, 3.9162e-08, 8.1332e-05]],\n",
              "          device='cuda:0', grad_fn=<SigmoidBackward>),\n",
              "   tensor([[9.9588e-01, 2.3390e-03, 2.2199e-03, 3.7238e-05, 6.3291e-03, 9.8143e-04,\n",
              "            1.8453e-03, 5.1647e-03, 5.8960e-04, 2.4653e-04, 2.3658e-03, 1.0801e-02,\n",
              "            1.2801e-05, 5.6695e-03, 2.2348e-05, 1.1380e-06, 3.2061e-04, 1.6561e-04,\n",
              "            7.2345e-05, 3.7950e-03, 1.9761e-04, 1.0559e-06, 1.0919e-06, 3.4084e-03,\n",
              "            9.2692e-07, 2.5322e-06, 2.3525e-07, 8.0215e-06, 2.6101e-05, 1.8874e-05,\n",
              "            2.2272e-07, 1.7287e-06, 9.1725e-08, 8.9510e-08, 5.5087e-08, 1.9176e-09,\n",
              "            2.2664e-03, 6.3557e-07, 1.6434e-05, 5.1960e-07, 1.5684e-05, 1.3739e-07,\n",
              "            7.7095e-06, 1.2741e-04, 7.7055e-05, 4.2096e-04, 2.0622e-02, 2.2073e-08,\n",
              "            7.1547e-07, 3.2050e-06, 1.9807e-04, 1.1096e-04, 1.1728e-03, 9.6705e-05,\n",
              "            2.1716e-04, 1.1105e-06, 8.6633e-07, 4.3099e-08, 8.0480e-06, 1.4380e-02,\n",
              "            6.0298e-09, 2.7838e-06, 1.0482e-02, 1.2181e-04, 4.4168e-04, 5.0553e-05,\n",
              "            1.3737e-07, 1.0775e-06, 5.7808e-07, 2.8296e-02, 2.0488e-03, 2.0671e-04,\n",
              "            9.5544e-04, 8.2062e-06, 4.7637e-07, 1.6726e-05, 2.4198e-03, 4.9513e-07,\n",
              "            1.7526e-05, 4.1272e-07],\n",
              "           [1.0000e+00, 1.5790e-06, 1.0343e-06, 3.3592e-08, 1.1915e-04, 3.1194e-07,\n",
              "            6.1787e-05, 4.9264e-05, 6.8516e-08, 4.2586e-08, 1.8073e-07, 7.3177e-05,\n",
              "            2.3955e-09, 6.3154e-06, 7.2798e-07, 2.0381e-09, 2.8211e-07, 7.3340e-06,\n",
              "            4.0362e-06, 1.3023e-06, 2.1524e-07, 2.4518e-10, 2.6250e-07, 9.5452e-06,\n",
              "            3.4235e-09, 1.2552e-08, 1.3603e-10, 4.6024e-07, 9.9055e-05, 2.4018e-09,\n",
              "            1.1834e-10, 2.5395e-06, 5.3649e-10, 1.2280e-05, 7.8908e-09, 1.8357e-10,\n",
              "            2.6017e-08, 5.1994e-08, 3.2749e-09, 4.4411e-04, 2.9745e-05, 7.2476e-07,\n",
              "            6.5132e-10, 4.1345e-08, 1.4918e-08, 4.7502e-03, 2.9501e-05, 7.2420e-09,\n",
              "            2.0497e-06, 5.4684e-07, 1.8447e-06, 3.8423e-08, 8.2077e-05, 4.7367e-08,\n",
              "            1.2912e-07, 4.9301e-07, 4.9047e-08, 3.3877e-09, 8.1491e-04, 8.7336e-04,\n",
              "            2.4615e-05, 3.6916e-05, 2.2374e-02, 5.2254e-06, 3.2485e-05, 1.2703e-07,\n",
              "            2.5641e-07, 2.6493e-06, 3.0835e-05, 2.0359e-07, 1.0997e-05, 4.0785e-05,\n",
              "            3.0943e-05, 6.0856e-08, 3.0227e-05, 3.7559e-05, 1.6184e-06, 2.2626e-07,\n",
              "            1.7525e-06, 3.6540e-06],\n",
              "           [1.0000e+00, 4.2556e-07, 4.6050e-07, 5.1574e-09, 4.6189e-05, 1.7922e-07,\n",
              "            2.4283e-06, 1.3648e-06, 1.3391e-07, 3.1818e-07, 1.5268e-07, 7.1951e-07,\n",
              "            1.7179e-08, 1.2489e-05, 1.8463e-09, 7.3837e-12, 7.9665e-09, 1.0529e-05,\n",
              "            1.3605e-10, 2.6523e-05, 3.5432e-11, 1.1684e-13, 1.4428e-07, 5.5376e-07,\n",
              "            3.4624e-12, 3.3754e-10, 1.5038e-11, 3.8027e-07, 4.3051e-08, 1.4756e-12,\n",
              "            4.4288e-09, 6.2904e-10, 1.5751e-10, 1.2598e-09, 5.5469e-13, 1.0022e-09,\n",
              "            1.8858e-10, 2.0268e-06, 4.0189e-09, 1.9199e-07, 7.0115e-08, 4.8351e-10,\n",
              "            6.5989e-10, 8.2777e-10, 8.1299e-11, 1.2793e-04, 1.3538e-08, 4.8475e-11,\n",
              "            6.9962e-08, 1.4866e-08, 1.1261e-08, 5.4147e-12, 1.3615e-07, 1.0140e-09,\n",
              "            3.8502e-11, 1.9754e-11, 2.5644e-09, 1.1931e-10, 1.4152e-06, 1.4706e-05,\n",
              "            5.8410e-10, 2.6341e-04, 4.1391e-06, 6.0933e-06, 8.9961e-07, 5.2628e-07,\n",
              "            1.4639e-08, 4.6956e-08, 7.2416e-06, 8.3190e-07, 2.1020e-04, 1.1892e-04,\n",
              "            1.0342e-05, 9.9328e-06, 1.8637e-05, 3.9227e-06, 2.6172e-08, 5.3768e-09,\n",
              "            9.7627e-09, 2.3188e-09],\n",
              "           [1.0000e+00, 3.3746e-07, 4.2053e-06, 1.7141e-08, 1.4401e-04, 1.1512e-06,\n",
              "            8.1250e-07, 2.7447e-06, 7.0187e-07, 8.7920e-06, 2.9803e-08, 9.6664e-06,\n",
              "            1.2860e-09, 1.0632e-06, 9.9578e-09, 1.7387e-11, 8.1297e-09, 5.8390e-08,\n",
              "            5.5432e-10, 3.6173e-06, 7.9785e-10, 1.1908e-10, 1.1160e-06, 4.3782e-06,\n",
              "            1.7298e-10, 3.7847e-09, 2.5745e-11, 2.4709e-08, 3.3741e-06, 1.6492e-10,\n",
              "            2.9150e-07, 3.9220e-08, 6.9260e-10, 2.8664e-10, 2.5997e-11, 1.5436e-11,\n",
              "            3.7267e-06, 1.7174e-06, 4.1739e-09, 9.2223e-07, 3.0226e-08, 7.4661e-10,\n",
              "            6.3543e-10, 3.3990e-07, 3.2651e-09, 1.7232e-07, 2.0447e-07, 1.2310e-10,\n",
              "            1.5328e-07, 6.3746e-10, 1.0002e-05, 7.6673e-11, 3.5194e-07, 1.8699e-07,\n",
              "            5.2315e-10, 1.2339e-10, 2.8807e-06, 7.0202e-10, 1.3076e-05, 1.4312e-06,\n",
              "            2.1189e-10, 2.2365e-05, 2.2081e-05, 2.5274e-05, 1.7043e-03, 2.8199e-08,\n",
              "            6.9348e-10, 1.2698e-08, 2.1263e-06, 2.7413e-06, 1.3112e-04, 1.2110e-03,\n",
              "            9.6432e-04, 1.2563e-08, 8.0824e-07, 2.2054e-05, 8.8213e-08, 9.2619e-08,\n",
              "            5.7640e-07, 6.3655e-09],\n",
              "           [1.0000e+00, 1.1420e-06, 2.2119e-05, 1.0107e-07, 6.3365e-05, 4.2046e-06,\n",
              "            7.4724e-05, 1.0581e-04, 2.7766e-06, 6.4663e-07, 9.6705e-07, 1.6672e-08,\n",
              "            1.0297e-08, 1.6618e-06, 2.2108e-08, 2.4181e-10, 1.6769e-08, 1.1526e-05,\n",
              "            3.1006e-08, 5.6049e-05, 2.1548e-08, 6.5086e-11, 7.2454e-08, 1.6885e-06,\n",
              "            5.7630e-10, 3.6295e-09, 1.1662e-09, 4.6836e-07, 2.8146e-05, 1.5371e-11,\n",
              "            3.6148e-08, 3.9928e-07, 2.9793e-09, 2.9493e-08, 5.6337e-07, 4.7364e-08,\n",
              "            9.6681e-07, 4.5739e-07, 4.6346e-09, 1.1216e-06, 1.9842e-06, 4.4128e-07,\n",
              "            3.1141e-08, 2.3461e-06, 2.7500e-08, 8.9916e-06, 9.3410e-08, 1.5924e-08,\n",
              "            2.6245e-06, 1.6182e-06, 2.5298e-08, 3.0047e-10, 6.0900e-06, 5.2467e-07,\n",
              "            7.8472e-08, 1.7994e-05, 4.4129e-10, 3.1054e-09, 2.9578e-04, 4.0481e-06,\n",
              "            6.1538e-08, 8.0008e-05, 2.4193e-05, 1.2507e-05, 1.7919e-05, 4.5072e-05,\n",
              "            8.6750e-07, 4.4945e-08, 1.6894e-05, 6.5167e-07, 2.6490e-05, 2.5445e-05,\n",
              "            7.7331e-03, 2.4881e-04, 5.1734e-06, 1.4517e-06, 1.5910e-06, 1.6005e-07,\n",
              "            3.1835e-07, 1.5074e-08],\n",
              "           [1.0000e+00, 2.6018e-06, 1.4774e-06, 2.0996e-08, 9.7799e-07, 2.3837e-07,\n",
              "            6.7930e-07, 8.3132e-06, 8.9151e-07, 4.4883e-07, 9.1584e-09, 4.5765e-07,\n",
              "            7.7409e-08, 4.1808e-06, 4.2837e-08, 2.0405e-10, 6.5086e-08, 8.5110e-05,\n",
              "            1.0626e-08, 8.0593e-06, 1.8694e-10, 1.6572e-13, 3.2545e-10, 6.2562e-06,\n",
              "            5.6829e-11, 4.3702e-10, 6.3919e-10, 3.8822e-08, 8.2933e-09, 1.2296e-10,\n",
              "            1.1702e-08, 1.6157e-08, 2.3383e-10, 8.1281e-11, 5.2455e-13, 6.9098e-10,\n",
              "            1.8402e-09, 5.6387e-07, 2.8242e-05, 3.0506e-08, 1.6458e-06, 7.7414e-07,\n",
              "            1.6144e-09, 1.9215e-07, 6.3592e-08, 5.1262e-06, 1.9849e-06, 5.6545e-09,\n",
              "            4.6426e-08, 2.0279e-06, 1.0733e-07, 6.4934e-10, 7.6699e-06, 1.5700e-07,\n",
              "            7.3539e-10, 3.4185e-08, 1.1789e-10, 8.1187e-11, 7.5938e-04, 1.0696e-04,\n",
              "            6.0916e-10, 3.1725e-06, 8.5104e-05, 1.3628e-06, 3.0997e-05, 1.6310e-06,\n",
              "            3.2725e-10, 2.3277e-09, 2.3063e-07, 1.8812e-06, 9.1048e-04, 6.6911e-06,\n",
              "            4.1260e-05, 2.2835e-07, 1.0177e-08, 3.2675e-06, 8.4826e-09, 9.2159e-08,\n",
              "            4.8613e-09, 1.3939e-09],\n",
              "           [1.0000e+00, 5.9124e-05, 1.2201e-06, 4.6669e-08, 1.7909e-04, 3.0240e-07,\n",
              "            3.3339e-05, 1.5705e-06, 3.7828e-07, 1.2375e-05, 2.5564e-05, 3.6742e-06,\n",
              "            1.4585e-07, 1.8926e-05, 3.6501e-09, 9.0818e-10, 5.4474e-06, 1.8664e-05,\n",
              "            4.8867e-09, 2.4893e-06, 2.2676e-09, 2.0188e-10, 1.4179e-06, 2.7424e-05,\n",
              "            6.0779e-09, 1.0853e-07, 4.4220e-09, 1.1840e-05, 1.7391e-06, 7.7223e-10,\n",
              "            8.5637e-08, 3.5662e-09, 1.0632e-08, 2.9766e-06, 1.9224e-10, 8.8833e-08,\n",
              "            6.6804e-09, 1.8734e-07, 1.4250e-08, 1.7073e-04, 7.5390e-06, 1.2706e-08,\n",
              "            3.7459e-09, 1.0592e-07, 8.1055e-09, 5.2721e-05, 1.3812e-07, 1.5672e-09,\n",
              "            1.6761e-06, 5.5332e-07, 1.4876e-07, 2.2930e-10, 7.7118e-07, 2.3047e-08,\n",
              "            1.1675e-08, 2.8615e-08, 5.6049e-08, 8.1943e-07, 4.9237e-05, 1.5074e-05,\n",
              "            9.5022e-09, 2.6753e-04, 1.1968e-05, 2.7166e-05, 4.1639e-05, 2.5793e-06,\n",
              "            1.3116e-07, 1.3323e-07, 9.8397e-06, 1.7221e-06, 4.5397e-05, 5.9755e-04,\n",
              "            7.3872e-05, 1.3383e-04, 7.9239e-06, 4.1756e-06, 2.1117e-08, 4.6008e-08,\n",
              "            8.2303e-07, 1.1696e-08],\n",
              "           [1.0000e+00, 2.8388e-08, 2.1861e-07, 1.3620e-09, 3.4180e-05, 2.5489e-08,\n",
              "            8.7798e-09, 3.8969e-07, 9.3255e-08, 1.6967e-06, 3.8718e-08, 1.4816e-07,\n",
              "            8.2539e-10, 7.8882e-07, 3.2433e-10, 4.8749e-12, 5.2194e-10, 5.0821e-10,\n",
              "            9.4965e-12, 8.1547e-07, 1.8700e-11, 2.0879e-13, 6.5520e-09, 2.3216e-06,\n",
              "            1.2558e-12, 4.2806e-11, 1.1186e-11, 2.4991e-09, 9.5531e-09, 4.2284e-12,\n",
              "            1.8261e-08, 4.1892e-09, 1.4273e-11, 9.6973e-09, 3.1219e-14, 6.6913e-12,\n",
              "            8.4735e-10, 7.9987e-10, 6.0318e-08, 3.2332e-09, 8.2372e-05, 5.1866e-09,\n",
              "            2.3439e-11, 3.3587e-09, 3.5282e-09, 3.4389e-08, 3.9837e-06, 7.7442e-12,\n",
              "            2.3888e-08, 2.6841e-08, 3.1544e-09, 2.3036e-11, 2.3200e-06, 3.2891e-07,\n",
              "            2.1902e-10, 4.8172e-11, 5.8608e-09, 3.9186e-13, 3.4354e-05, 7.5397e-06,\n",
              "            7.2161e-11, 1.2118e-07, 7.5793e-05, 1.0185e-05, 3.7251e-04, 3.1170e-07,\n",
              "            2.3006e-09, 1.8277e-09, 1.7386e-07, 1.1026e-06, 4.6410e-06, 8.2880e-04,\n",
              "            7.9356e-04, 8.0709e-07, 8.4713e-09, 1.5928e-07, 2.4214e-09, 3.3737e-09,\n",
              "            7.5731e-09, 2.1023e-09],\n",
              "           [9.9996e-01, 2.8709e-06, 1.4179e-04, 4.4837e-07, 9.9528e-05, 1.6856e-05,\n",
              "            3.6115e-06, 6.2199e-05, 1.9178e-05, 2.0411e-06, 8.9425e-07, 7.2160e-05,\n",
              "            8.4731e-09, 1.1158e-06, 2.3761e-07, 2.1212e-09, 1.0621e-07, 1.1290e-07,\n",
              "            3.1852e-07, 5.8168e-05, 8.6807e-08, 4.4254e-09, 5.9383e-06, 1.2614e-04,\n",
              "            2.6027e-09, 1.1898e-07, 6.7629e-09, 9.8572e-07, 1.2356e-05, 4.5312e-08,\n",
              "            2.3920e-08, 7.3084e-08, 1.1626e-08, 1.8726e-06, 6.3578e-09, 3.6031e-07,\n",
              "            4.3588e-07, 3.3693e-04, 1.9769e-05, 1.2855e-04, 7.9590e-05, 3.2010e-05,\n",
              "            7.2860e-07, 7.1314e-06, 9.3757e-06, 9.7731e-06, 5.5818e-03, 2.0180e-06,\n",
              "            1.1682e-05, 9.7893e-06, 2.3887e-06, 8.7477e-08, 9.8487e-05, 1.2847e-05,\n",
              "            9.8425e-07, 5.0124e-07, 2.3308e-06, 1.9017e-08, 1.1507e-04, 5.7715e-04,\n",
              "            4.2202e-07, 8.4777e-04, 9.2448e-02, 6.5968e-05, 1.2528e-04, 6.3759e-06,\n",
              "            4.2197e-06, 1.9836e-07, 2.3886e-06, 1.4890e-03, 2.8430e-04, 6.9013e-05,\n",
              "            8.6944e-04, 2.9493e-05, 9.8954e-07, 9.7847e-05, 7.1304e-07, 2.3879e-07,\n",
              "            9.5480e-07, 2.7202e-07],\n",
              "           [1.0000e+00, 2.5933e-06, 2.4950e-06, 3.9233e-08, 1.2527e-04, 1.1281e-06,\n",
              "            3.1023e-06, 9.2178e-06, 1.6403e-06, 1.3988e-05, 2.2142e-05, 2.5020e-06,\n",
              "            2.3343e-08, 1.1300e-05, 1.7355e-08, 2.5440e-09, 1.4530e-06, 5.4018e-06,\n",
              "            6.2615e-07, 1.9303e-06, 5.7033e-09, 8.9038e-09, 1.3261e-06, 4.1390e-05,\n",
              "            3.1321e-09, 4.3912e-08, 1.3351e-10, 3.6484e-07, 1.7988e-05, 8.2675e-10,\n",
              "            9.3956e-10, 1.3733e-08, 5.0931e-09, 8.0614e-09, 2.1652e-09, 2.0816e-08,\n",
              "            1.1780e-06, 1.3840e-06, 1.4100e-08, 8.1499e-06, 1.1463e-05, 1.4225e-05,\n",
              "            4.6074e-07, 2.7818e-06, 6.8231e-07, 4.3677e-05, 1.9350e-06, 8.8037e-06,\n",
              "            7.3260e-06, 2.5244e-07, 1.8243e-06, 3.3143e-08, 1.8635e-05, 3.2163e-07,\n",
              "            1.4100e-07, 1.1287e-07, 1.5528e-05, 7.3741e-06, 8.5410e-04, 1.0908e-04,\n",
              "            2.9984e-09, 1.7318e-04, 5.7468e-05, 2.0781e-06, 6.5529e-04, 1.4003e-06,\n",
              "            2.7435e-07, 4.3167e-09, 2.0205e-06, 1.2966e-06, 2.9839e-04, 3.0314e-06,\n",
              "            3.0545e-03, 6.8545e-06, 1.3950e-06, 8.3435e-06, 1.4881e-06, 1.9786e-06,\n",
              "            2.6845e-07, 4.7670e-08]], device='cuda:0', grad_fn=<CatBackward>)]},\n",
              " {}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEn9P6usbwYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loss = [[logs_icarl[run_i][i]['train_loss'] for i in range(10)] for run_i in range(NUM_RUNS)]\n",
        "train_accuracy = [[logs_icarl[run_i][i]['train_accuracy'] for i in range(10)] for run_i in range(NUM_RUNS)]\n",
        "val_loss = [[logs_icarl[run_i][i]['val_loss'] for i in range(10)] for run_i in range(NUM_RUNS)]\n",
        "val_accuracy = [[logs_icarl[run_i][i]['val_accuracy'] for i in range(10)] for run_i in range(NUM_RUNS)]\n",
        "test_accuracy = [[logs_icarl[run_i][i]['accuracy'] for i in range(10)] for run_i in range(NUM_RUNS)]\n",
        "\n",
        "train_loss = np.array(train_loss)\n",
        "train_accuracy = np.array(train_accuracy)\n",
        "val_loss = np.array(val_loss)\n",
        "val_accuracy = np.array(val_accuracy)\n",
        "test_accuracy = np.array(test_accuracy)\n",
        "\n",
        "train_loss_stats = np.array([train_loss.mean(0), train_loss.std(0)]).transpose()\n",
        "train_accuracy_stats = np.array([train_accuracy.mean(0), train_accuracy.std(0)]).transpose()\n",
        "val_loss_stats = np.array([val_loss.mean(0), val_loss.std(0)]).transpose()\n",
        "val_accuracy_stats = np.array([val_accuracy.mean(0), val_accuracy.std(0)]).transpose()\n",
        "test_accuracy_stats = np.array([test_accuracy.mean(0), test_accuracy.std(0)]).transpose()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GmiU4BfhVht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot.train_val_scores(train_loss_stats, train_accuracy_stats, val_loss_stats, val_accuracy_stats)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAWPfif3j7pK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot.test_scores(test_accuracy_stats)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Kiw-q4AChB6",
        "colab_type": "text"
      },
      "source": [
        "### Analisys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvD4EPGJLNZn",
        "colab_type": "text"
      },
      "source": [
        "#### Raw Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07e3f7xqCnGy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Alla versione degli scores mancano sempre gli ultimi 10 scores, ultimi 10 nodi:\n",
        "ma si tratta di scores identici in quanto prodotti dalla stessa rete\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "logs_analisys = [{1: [[[1.0000e+00, 1.5512e-07, 2.7733e-09, 9.1395e-06, 5.4964e-08, 4.7753e-09,\n",
        "            5.9064e-09, 4.2234e-09, 4.2606e-07, 3.8278e-06],\n",
        "           [1.0000e+00, 4.7220e-09, 1.7920e-10, 7.7666e-08, 1.7943e-09, 5.6214e-12,\n",
        "            6.7881e-10, 2.7197e-12, 4.2738e-08, 3.3349e-08],\n",
        "           [1.0000e+00, 1.9654e-11, 3.7885e-14, 2.2945e-07, 5.6073e-10, 5.4636e-13,\n",
        "            4.6445e-11, 4.8380e-11, 2.7386e-08, 5.7785e-09],\n",
        "           [1.0000e+00, 1.5525e-08, 1.0396e-08, 1.9264e-07, 2.1828e-09, 1.2135e-09,\n",
        "            3.1585e-08, 5.8995e-10, 9.9534e-09, 3.5256e-08],\n",
        "           [1.0000e+00, 1.2908e-08, 3.4542e-07, 6.1864e-07, 1.2921e-08, 3.1958e-09,\n",
        "            9.4153e-08, 3.6375e-09, 3.7195e-08, 9.2690e-09],\n",
        "           [1.0000e+00, 2.9726e-09, 7.0455e-11, 1.8400e-07, 2.3927e-09, 3.2849e-11,\n",
        "            2.6100e-10, 7.3590e-12, 4.3375e-09, 6.4679e-08],\n",
        "           [1.0000e+00, 4.0591e-10, 6.5797e-08, 4.2255e-09, 1.5108e-09, 1.3463e-12,\n",
        "            2.2160e-10, 1.0328e-14, 2.1021e-10, 2.1925e-08],\n",
        "           [1.0000e+00, 1.2241e-08, 8.1332e-12, 8.7271e-08, 1.8324e-09, 4.0020e-12,\n",
        "            2.0444e-09, 1.9574e-11, 2.4395e-08, 6.1851e-08],\n",
        "           [9.9966e-01, 1.5357e-06, 2.1753e-07, 2.3316e-04, 2.5847e-04, 2.5666e-07,\n",
        "            2.7809e-07, 2.5095e-08, 1.7301e-05, 1.5338e-04],\n",
        "           [1.0000e+00, 4.6669e-08, 5.4749e-09, 1.4178e-06, 4.1075e-08, 8.7116e-11,\n",
        "            1.5250e-09, 1.8640e-12, 2.8481e-07, 1.2294e-07]],\n",
        "   [[1.0000e+00, 1.5512e-07, 2.7733e-09, 9.1395e-06, 5.4964e-08, 4.7753e-09,\n",
        "            5.9064e-09, 4.2234e-09, 4.2606e-07, 3.8278e-06],\n",
        "           [1.0000e+00, 4.7220e-09, 1.7920e-10, 7.7666e-08, 1.7943e-09, 5.6214e-12,\n",
        "            6.7881e-10, 2.7197e-12, 4.2738e-08, 3.3349e-08],\n",
        "           [1.0000e+00, 1.9654e-11, 3.7885e-14, 2.2945e-07, 5.6073e-10, 5.4636e-13,\n",
        "            4.6445e-11, 4.8380e-11, 2.7386e-08, 5.7785e-09],\n",
        "           [1.0000e+00, 1.5525e-08, 1.0396e-08, 1.9264e-07, 2.1828e-09, 1.2135e-09,\n",
        "            3.1585e-08, 5.8995e-10, 9.9534e-09, 3.5256e-08],\n",
        "           [1.0000e+00, 1.2908e-08, 3.4542e-07, 6.1864e-07, 1.2921e-08, 3.1958e-09,\n",
        "            9.4153e-08, 3.6375e-09, 3.7195e-08, 9.2690e-09],\n",
        "           [1.0000e+00, 2.9726e-09, 7.0455e-11, 1.8400e-07, 2.3927e-09, 3.2849e-11,\n",
        "            2.6100e-10, 7.3590e-12, 4.3375e-09, 6.4679e-08],\n",
        "           [1.0000e+00, 4.0591e-10, 6.5797e-08, 4.2255e-09, 1.5108e-09, 1.3463e-12,\n",
        "            2.2160e-10, 1.0328e-14, 2.1021e-10, 2.1925e-08],\n",
        "           [1.0000e+00, 1.2241e-08, 8.1332e-12, 8.7271e-08, 1.8324e-09, 4.0020e-12,\n",
        "            2.0444e-09, 1.9574e-11, 2.4395e-08, 6.1851e-08],\n",
        "           [9.9966e-01, 1.5357e-06, 2.1753e-07, 2.3316e-04, 2.5847e-04, 2.5666e-07,\n",
        "            2.7809e-07, 2.5095e-08, 1.7301e-05, 1.5338e-04],\n",
        "           [1.0000e+00, 4.6669e-08, 5.4749e-09, 1.4178e-06, 4.1075e-08, 8.7116e-11,\n",
        "            1.5250e-09, 1.8640e-12, 2.8481e-07, 1.2294e-07]]],\n",
        "  2: [[[9.9904e-01, 6.1108e-06, 7.6811e-07, 2.6569e-05, 1.1443e-06, 2.8027e-07,\n",
        "            4.8393e-06, 1.3142e-05, 1.1733e-04, 8.9212e-03, 3.6623e-06, 7.4250e-08,\n",
        "            1.1871e-07, 1.9095e-04, 1.2327e-08, 1.9918e-08, 4.5079e-09, 4.7653e-10,\n",
        "            1.1713e-07, 1.6491e-05],\n",
        "           [9.9999e-01, 1.8378e-07, 7.4163e-07, 1.6811e-06, 1.6994e-07, 4.5483e-09,\n",
        "            3.4043e-07, 1.5851e-07, 1.9727e-05, 9.2757e-06, 6.6584e-07, 2.2817e-08,\n",
        "            2.6848e-09, 1.3572e-07, 1.5413e-09, 6.3152e-09, 2.3346e-09, 7.8178e-13,\n",
        "            2.7959e-08, 7.2424e-08],\n",
        "           [9.9898e-01, 4.3246e-06, 1.3550e-06, 1.1471e-04, 8.7652e-05, 1.4895e-07,\n",
        "            5.0754e-05, 1.2141e-05, 8.1777e-05, 7.4493e-04, 1.1550e-06, 9.8130e-08,\n",
        "            2.3800e-05, 5.2410e-05, 9.3319e-07, 1.1695e-06, 1.6644e-08, 2.6441e-09,\n",
        "            2.6572e-07, 8.8477e-07],\n",
        "           [9.9961e-01, 1.0428e-05, 8.3710e-05, 3.3551e-05, 3.0381e-05, 1.2643e-06,\n",
        "            9.1982e-05, 9.8438e-05, 4.0849e-04, 3.7268e-04, 5.6644e-04, 1.6377e-06,\n",
        "            5.8960e-07, 1.1287e-03, 9.4880e-07, 1.4330e-07, 3.2545e-07, 8.1160e-09,\n",
        "            4.1411e-04, 3.4461e-04],\n",
        "           [9.9996e-01, 2.2000e-06, 1.7469e-04, 2.3958e-06, 2.0135e-06, 1.6926e-07,\n",
        "            5.6029e-06, 1.3688e-05, 3.3362e-05, 2.5196e-05, 6.1075e-06, 2.9075e-08,\n",
        "            4.8573e-08, 1.7029e-09, 1.2466e-08, 3.0845e-08, 9.7068e-07, 4.9751e-08,\n",
        "            8.6962e-05, 3.1717e-06],\n",
        "           [9.9990e-01, 2.8315e-06, 8.2047e-06, 2.3720e-05, 8.9772e-06, 7.9908e-07,\n",
        "            3.9742e-06, 1.0073e-05, 1.5856e-05, 7.9337e-05, 3.4752e-06, 1.2206e-07,\n",
        "            1.1070e-07, 8.8884e-06, 3.8883e-07, 9.4539e-07, 4.7949e-07, 6.8461e-08,\n",
        "            2.9232e-07, 3.8337e-05],\n",
        "           [9.9971e-01, 1.1861e-05, 7.3742e-05, 2.3601e-04, 6.9816e-05, 2.4166e-06,\n",
        "            4.2156e-05, 2.7891e-06, 1.2529e-04, 1.3164e-04, 2.6155e-04, 5.5860e-06,\n",
        "            8.3533e-08, 1.0086e-05, 8.8398e-08, 3.6213e-08, 9.8903e-07, 1.4704e-07,\n",
        "            1.2090e-05, 2.8844e-06],\n",
        "           [9.9902e-01, 1.7233e-05, 5.6348e-05, 5.5970e-05, 2.8565e-04, 2.8437e-06,\n",
        "            1.5302e-05, 4.2305e-06, 2.2740e-04, 1.1709e-03, 1.3844e-05, 2.6668e-07,\n",
        "            7.4909e-06, 8.8376e-05, 2.5774e-05, 4.3247e-08, 1.6700e-08, 2.9542e-07,\n",
        "            3.0934e-06, 4.1988e-08],\n",
        "           [9.9983e-01, 8.1740e-06, 1.3645e-04, 2.3626e-05, 1.1034e-04, 4.2919e-07,\n",
        "            2.1350e-05, 2.0771e-06, 3.5675e-05, 1.4272e-04, 8.2387e-05, 5.9825e-06,\n",
        "            1.1562e-07, 6.9221e-06, 3.8257e-08, 5.4804e-07, 5.5636e-07, 1.4444e-10,\n",
        "            1.4953e-05, 1.2633e-06],\n",
        "           [9.9985e-01, 9.5231e-07, 1.1093e-06, 4.7206e-05, 1.4982e-05, 5.3036e-09,\n",
        "            1.4137e-05, 3.0088e-08, 2.5937e-06, 1.4501e-04, 1.0794e-08, 4.3337e-07,\n",
        "            7.9758e-10, 2.4959e-06, 6.6511e-11, 5.9032e-11, 4.0701e-09, 3.4270e-11,\n",
        "            8.0493e-07, 1.0403e-05]],\n",
        "   [[1.0000e+00, 4.0539e-07, 5.3036e-09, 2.3897e-06, 5.6445e-08, 5.8158e-09,\n",
        "            1.3008e-08, 7.9494e-09, 5.2112e-07, 8.4610e-06],\n",
        "           [1.0000e+00, 1.8461e-10, 2.1985e-12, 2.0374e-09, 7.6756e-11, 3.1285e-14,\n",
        "            1.8355e-11, 2.2137e-14, 1.4756e-09, 3.7414e-09],\n",
        "           [1.0000e+00, 3.1312e-09, 2.0415e-11, 2.1626e-06, 3.8640e-08, 1.1514e-10,\n",
        "            4.6784e-09, 2.8972e-09, 4.2748e-07, 2.7371e-07],\n",
        "           [1.0000e+00, 1.0963e-09, 7.6110e-10, 1.4282e-07, 4.7674e-10, 4.6220e-11,\n",
        "            2.1577e-09, 4.2405e-11, 1.1324e-07, 1.1012e-08],\n",
        "           [1.0000e+00, 5.6656e-10, 1.0182e-08, 2.3817e-08, 1.1296e-09, 6.0204e-11,\n",
        "            5.0308e-09, 1.1462e-10, 1.1088e-08, 4.8738e-09],\n",
        "           [1.0000e+00, 1.5873e-08, 2.0167e-09, 3.2493e-07, 2.1377e-09, 9.5178e-10,\n",
        "            2.7259e-09, 5.7873e-10, 9.1451e-09, 1.4482e-07],\n",
        "           [9.9995e-01, 9.2030e-07, 7.6245e-06, 1.2260e-06, 3.4697e-06, 1.0736e-08,\n",
        "            1.4169e-05, 2.7383e-09, 1.3860e-06, 6.8341e-06],\n",
        "           [1.0000e+00, 2.2978e-08, 1.5485e-10, 2.2725e-07, 7.4805e-10, 1.0605e-09,\n",
        "            2.3003e-09, 6.3426e-10, 5.8909e-07, 5.3563e-06],\n",
        "           [9.9998e-01, 1.5130e-06, 1.5883e-05, 8.6189e-07, 1.3249e-05, 1.8953e-08,\n",
        "            1.0330e-06, 9.7505e-10, 4.9172e-07, 3.2706e-06],\n",
        "           [1.0000e+00, 1.6511e-08, 9.0421e-10, 2.2618e-06, 4.1464e-08, 9.3147e-11,\n",
        "            4.8591e-10, 1.7294e-12, 3.3435e-08, 1.3159e-06]]],\n",
        "  3: [[[9.9497e-01, 1.3670e-04, 6.2672e-05, 7.8652e-04, 8.8190e-05, 8.6947e-05,\n",
        "            1.3595e-04, 5.7186e-04, 3.1095e-03, 8.1867e-03, 1.2887e-02, 6.8811e-07,\n",
        "            1.8423e-04, 4.8562e-03, 2.5540e-05, 1.8609e-05, 3.3238e-05, 4.3052e-05,\n",
        "            1.1514e-05, 3.1777e-04, 2.4182e-06, 5.1525e-05, 3.5149e-07, 1.5444e-04,\n",
        "            1.8624e-03, 4.0914e-06, 1.2528e-04, 5.8105e-07, 8.3717e-07, 3.5384e-06],\n",
        "           [9.9926e-01, 1.9702e-05, 2.5127e-05, 9.2505e-05, 1.2716e-05, 2.4741e-06,\n",
        "            9.4557e-05, 2.4500e-05, 8.4409e-04, 6.4998e-04, 2.4969e-04, 2.4986e-06,\n",
        "            2.8274e-05, 9.7097e-05, 9.1761e-06, 2.8689e-04, 5.0013e-06, 1.6412e-07,\n",
        "            4.7498e-06, 1.4030e-04, 8.0608e-06, 2.1785e-05, 3.1336e-07, 1.0161e-06,\n",
        "            4.9465e-05, 1.9331e-07, 2.8468e-07, 1.1440e-07, 6.5992e-07, 6.3921e-07],\n",
        "           [9.9732e-01, 3.8367e-05, 1.5710e-05, 5.2855e-04, 2.7407e-04, 1.4189e-05,\n",
        "            3.4510e-04, 7.1055e-05, 6.2532e-04, 1.4013e-03, 9.6550e-05, 1.9125e-06,\n",
        "            9.0568e-05, 2.5789e-04, 2.8191e-04, 2.2703e-04, 1.1072e-05, 1.2632e-06,\n",
        "            4.7813e-05, 1.2004e-04, 5.0406e-05, 2.6994e-04, 2.1034e-07, 3.4974e-07,\n",
        "            6.2481e-06, 1.1822e-06, 8.0045e-07, 1.5527e-06, 8.4397e-07, 7.8099e-04],\n",
        "           [9.9991e-01, 9.4056e-06, 1.0654e-04, 1.6004e-05, 2.0681e-05, 3.1005e-06,\n",
        "            1.1372e-04, 2.9922e-05, 7.4122e-05, 1.3311e-04, 3.9588e-04, 1.8885e-07,\n",
        "            4.5795e-06, 5.9266e-05, 5.3764e-06, 3.8286e-06, 1.4571e-07, 8.0020e-07,\n",
        "            9.0456e-04, 3.4095e-04, 1.2139e-08, 4.8333e-05, 9.6611e-09, 7.9337e-06,\n",
        "            6.4256e-07, 1.8233e-07, 1.9338e-07, 2.3928e-08, 8.1668e-08, 1.6064e-10],\n",
        "           [9.9692e-01, 1.5815e-04, 2.5399e-03, 3.3636e-04, 6.9519e-05, 1.3867e-04,\n",
        "            1.0205e-03, 5.2695e-04, 9.6117e-04, 2.5466e-03, 7.4275e-04, 7.1466e-06,\n",
        "            6.9022e-05, 2.3228e-04, 2.5895e-05, 9.9411e-05, 1.9898e-04, 3.5482e-04,\n",
        "            4.5961e-04, 5.6532e-03, 4.4535e-05, 1.5114e-05, 4.2548e-06, 7.1443e-05,\n",
        "            6.5261e-05, 7.4741e-07, 2.5288e-05, 7.0361e-05, 5.9697e-07, 1.1101e-06],\n",
        "           [9.9972e-01, 2.3293e-05, 2.6264e-04, 5.0283e-05, 1.7808e-04, 4.4024e-05,\n",
        "            1.2901e-05, 7.1257e-05, 3.9415e-04, 7.6657e-04, 4.5464e-05, 1.5366e-06,\n",
        "            1.7035e-05, 3.8906e-05, 7.0340e-04, 1.0755e-03, 2.8262e-06, 1.3301e-05,\n",
        "            1.3366e-05, 3.8523e-04, 2.3048e-07, 2.6555e-03, 5.6095e-09, 1.3740e-08,\n",
        "            9.4972e-04, 1.4793e-06, 1.1411e-05, 6.2993e-07, 3.4391e-05, 6.9141e-09],\n",
        "           [9.9955e-01, 3.7735e-05, 6.2206e-04, 2.2252e-04, 4.2827e-05, 1.8215e-05,\n",
        "            1.9561e-04, 7.5382e-06, 1.2090e-04, 5.8907e-04, 1.6830e-04, 1.5263e-05,\n",
        "            2.7702e-05, 9.6200e-05, 1.3708e-06, 2.8780e-05, 5.4921e-06, 6.8853e-07,\n",
        "            5.8054e-05, 1.9539e-04, 1.8952e-08, 1.0535e-06, 6.7485e-07, 7.9980e-08,\n",
        "            1.2567e-06, 1.6740e-06, 5.9675e-07, 1.7051e-07, 3.8934e-05, 3.8763e-08],\n",
        "           [9.9865e-01, 2.2290e-04, 2.5009e-04, 3.2739e-04, 1.3660e-03, 7.6049e-05,\n",
        "            6.2460e-04, 6.8481e-05, 9.4228e-04, 4.6150e-03, 8.9465e-03, 3.4566e-06,\n",
        "            5.1222e-04, 1.4141e-04, 1.2064e-04, 1.5942e-04, 1.3034e-05, 9.7301e-04,\n",
        "            8.0239e-04, 2.7224e-06, 6.2506e-05, 3.8117e-05, 8.9434e-08, 1.2114e-06,\n",
        "            3.4772e-06, 2.2164e-05, 5.2218e-05, 1.0493e-04, 1.6241e-07, 1.3735e-06],\n",
        "           [9.9903e-01, 1.5231e-04, 1.6216e-04, 1.1899e-04, 5.9836e-04, 3.4135e-05,\n",
        "            8.2819e-05, 4.9766e-06, 9.4933e-05, 1.0512e-03, 1.1538e-04, 1.3711e-06,\n",
        "            8.0326e-06, 1.4810e-05, 8.9577e-06, 5.3398e-05, 6.6580e-05, 1.7708e-06,\n",
        "            1.8322e-04, 1.7642e-05, 6.8387e-07, 9.8164e-06, 1.3419e-08, 1.8031e-09,\n",
        "            3.8905e-06, 6.0016e-07, 3.9403e-07, 6.3632e-07, 1.1190e-08, 6.4758e-04],\n",
        "           [9.9679e-01, 7.2829e-05, 4.8762e-05, 2.7307e-04, 5.5423e-05, 2.6464e-05,\n",
        "            6.9354e-05, 8.6936e-06, 4.7876e-05, 3.4233e-03, 2.3324e-05, 6.4399e-06,\n",
        "            1.7130e-05, 6.6205e-05, 3.2829e-06, 4.7439e-06, 3.9406e-06, 1.2660e-07,\n",
        "            2.0765e-05, 1.7318e-03, 6.1373e-08, 3.4050e-05, 2.2953e-08, 4.4887e-07,\n",
        "            1.6524e-05, 2.4105e-07, 4.5070e-08, 2.5709e-08, 1.6703e-05, 8.0363e-05]],\n",
        "   [[9.9987e-01, 2.4680e-05, 1.8700e-07, 1.2716e-04, 2.4063e-05, 3.0993e-07,\n",
        "            1.0672e-06, 8.0062e-07, 1.0360e-04, 7.8824e-05, 4.4446e-04, 2.9240e-07,\n",
        "            2.8301e-06, 1.7289e-03, 2.7222e-07, 3.2630e-07, 5.7026e-07, 3.3757e-07,\n",
        "            6.0039e-06, 4.7954e-05],\n",
        "           [1.0000e+00, 1.7523e-09, 4.3527e-11, 2.9970e-08, 2.8811e-10, 7.4064e-13,\n",
        "            1.4748e-10, 2.9498e-13, 2.6416e-08, 3.9409e-09, 4.7417e-07, 6.3283e-08,\n",
        "            1.9351e-08, 1.3180e-06, 3.0784e-09, 2.3058e-08, 1.4804e-09, 4.8282e-12,\n",
        "            5.5130e-08, 3.8734e-07],\n",
        "           [1.0000e+00, 4.6700e-10, 5.9283e-12, 3.3245e-06, 1.5430e-08, 4.7375e-11,\n",
        "            2.3706e-09, 6.9842e-10, 2.1725e-07, 3.0642e-08, 1.3325e-07, 1.5980e-08,\n",
        "            2.4591e-06, 5.2045e-06, 1.4639e-06, 2.6079e-07, 4.3705e-09, 1.5232e-10,\n",
        "            1.6661e-07, 3.7063e-08],\n",
        "           [1.0000e+00, 1.2636e-09, 2.1382e-10, 1.2505e-07, 8.5986e-10, 5.0049e-11,\n",
        "            6.4731e-10, 6.6049e-12, 1.6817e-09, 9.6507e-10, 1.3608e-04, 3.0652e-07,\n",
        "            9.7352e-08, 1.0914e-05, 1.6591e-06, 1.2558e-08, 2.0924e-08, 1.0739e-08,\n",
        "            7.5602e-04, 2.9525e-06],\n",
        "           [1.0000e+00, 1.6401e-09, 3.8214e-08, 2.3238e-08, 3.3990e-10, 4.3282e-11,\n",
        "            7.6048e-09, 1.6215e-10, 6.4609e-08, 1.0747e-08, 6.9916e-05, 1.7930e-06,\n",
        "            9.6979e-07, 5.5376e-07, 1.4907e-06, 1.6927e-06, 2.1360e-06, 2.4554e-06,\n",
        "            2.4849e-04, 4.3064e-03],\n",
        "           [1.0000e+00, 4.5650e-10, 8.5759e-11, 1.1311e-07, 4.0049e-09, 1.6196e-11,\n",
        "            2.2601e-10, 2.5111e-12, 2.3588e-09, 4.9547e-09, 3.4757e-08, 1.0179e-08,\n",
        "            5.0768e-09, 2.7156e-08, 7.0065e-06, 4.9165e-09, 1.1584e-09, 2.0520e-09,\n",
        "            4.0622e-09, 4.1126e-07],\n",
        "           [9.9998e-01, 1.0615e-07, 1.0389e-06, 1.5352e-06, 2.7051e-07, 4.7834e-09,\n",
        "            3.9737e-07, 3.8776e-10, 1.1340e-07, 6.7827e-06, 4.7191e-06, 2.4034e-06,\n",
        "            1.2632e-08, 1.0240e-05, 2.3031e-09, 4.6428e-09, 1.1530e-07, 5.4102e-10,\n",
        "            2.8358e-06, 1.3331e-06],\n",
        "           [1.0000e+00, 8.1287e-09, 1.2897e-11, 5.9185e-08, 1.4771e-09, 3.4110e-12,\n",
        "            1.5214e-09, 5.8082e-12, 1.7846e-08, 1.2081e-08, 2.8583e-05, 1.6558e-08,\n",
        "            7.2524e-06, 6.1947e-06, 3.2974e-08, 1.9900e-08, 7.3111e-09, 1.3744e-06,\n",
        "            1.7257e-06, 1.2238e-08],\n",
        "           [9.9987e-01, 9.4912e-08, 5.3217e-09, 5.2093e-06, 2.0340e-05, 5.8806e-09,\n",
        "            2.2925e-08, 1.2471e-09, 8.2344e-07, 1.3634e-04, 1.6633e-07, 8.2097e-09,\n",
        "            5.1092e-10, 9.2388e-07, 4.1078e-09, 1.3430e-08, 6.1960e-08, 2.9340e-11,\n",
        "            2.2553e-06, 5.4524e-07],\n",
        "           [9.9994e-01, 4.2031e-07, 2.5006e-08, 4.2994e-06, 7.2355e-07, 1.2443e-09,\n",
        "            1.1733e-07, 3.6851e-10, 9.0084e-07, 4.4407e-05, 1.6455e-07, 1.8854e-06,\n",
        "            1.6645e-08, 1.6419e-05, 2.2738e-09, 3.7601e-09, 2.1062e-08, 2.7692e-10,\n",
        "            3.3552e-06, 1.0201e-05]]],\n",
        "  4: [[[9.7691e-01, 1.4708e-04, 4.7844e-04, 2.8038e-03, 4.5718e-04, 1.9647e-03,\n",
        "            1.0082e-03, 1.4207e-03, 2.2999e-03, 2.1587e-02, 2.0280e-02, 1.1083e-05,\n",
        "            6.1546e-03, 2.6712e-03, 3.0335e-05, 3.2448e-04, 6.3143e-04, 3.2993e-05,\n",
        "            3.7900e-05, 5.8161e-04, 3.2715e-05, 2.9348e-04, 1.1942e-05, 9.6408e-04,\n",
        "            2.6015e-03, 1.2103e-05, 1.4322e-04, 1.5728e-05, 5.7640e-06, 2.1039e-04,\n",
        "            8.2887e-08, 1.3949e-03, 1.7249e-09, 2.6718e-09, 3.8979e-06, 1.2251e-08,\n",
        "            2.3329e-07, 5.6653e-07, 1.0003e-02, 2.8273e-08],\n",
        "           [9.9941e-01, 3.2515e-05, 1.0898e-03, 4.0120e-04, 1.5220e-04, 7.8571e-05,\n",
        "            4.6232e-04, 8.2248e-05, 2.4346e-03, 9.3341e-04, 2.9846e-04, 1.1499e-04,\n",
        "            1.6542e-04, 2.5813e-04, 1.3948e-04, 8.5149e-04, 2.0161e-05, 2.0307e-05,\n",
        "            1.8085e-04, 3.8683e-04, 1.8636e-05, 2.4377e-05, 9.8580e-05, 2.7593e-05,\n",
        "            2.2343e-03, 5.0732e-05, 6.9431e-06, 3.4352e-06, 3.2180e-05, 1.9513e-06,\n",
        "            1.4551e-08, 1.8068e-05, 1.2592e-10, 8.9021e-10, 6.1303e-08, 8.3844e-09,\n",
        "            4.3853e-07, 1.0865e-05, 2.4779e-05, 3.2192e-06],\n",
        "           [9.9336e-01, 1.6664e-04, 1.1315e-03, 4.1938e-04, 1.5843e-03, 2.4920e-04,\n",
        "            1.9865e-03, 1.9230e-03, 4.2043e-03, 5.8243e-03, 1.2787e-03, 1.0164e-04,\n",
        "            7.2291e-03, 3.4117e-04, 4.4599e-04, 1.4795e-02, 2.5073e-04, 4.5961e-05,\n",
        "            1.2937e-04, 1.2266e-03, 1.6173e-03, 6.6866e-04, 1.7317e-04, 6.2953e-05,\n",
        "            2.1501e-03, 1.7499e-04, 6.1385e-05, 4.5397e-04, 1.6133e-04, 7.0917e-05,\n",
        "            1.7552e-05, 1.4930e-03, 2.4483e-09, 5.3960e-09, 4.6697e-06, 2.7052e-07,\n",
        "            4.8098e-06, 1.4384e-03, 8.4151e-03, 9.5712e-07],\n",
        "           [9.9894e-01, 6.9062e-05, 1.9329e-03, 5.2304e-04, 1.3921e-04, 1.7751e-04,\n",
        "            2.5363e-03, 4.6113e-04, 7.1088e-04, 2.1927e-03, 2.8335e-03, 6.7619e-05,\n",
        "            3.3661e-04, 1.5671e-03, 6.8507e-05, 1.1497e-04, 2.8356e-06, 1.3089e-04,\n",
        "            7.4816e-03, 2.3854e-03, 2.0346e-05, 1.0145e-03, 2.4882e-05, 3.3182e-03,\n",
        "            2.1772e-04, 4.5713e-06, 2.1817e-05, 1.1833e-05, 9.7620e-06, 1.0292e-06,\n",
        "            6.0327e-09, 5.1043e-07, 1.8336e-10, 1.8131e-09, 4.0356e-06, 5.2559e-08,\n",
        "            1.9099e-06, 8.7277e-07, 1.7378e-03, 1.2166e-06],\n",
        "           [9.9361e-01, 3.3689e-04, 2.8253e-03, 7.6572e-04, 3.0162e-04, 4.2129e-04,\n",
        "            1.7565e-03, 2.4402e-03, 8.3579e-03, 4.8822e-03, 9.3997e-03, 8.0528e-05,\n",
        "            4.2455e-04, 2.4641e-04, 6.4972e-05, 1.2291e-03, 2.5784e-04, 9.2451e-04,\n",
        "            1.1746e-03, 5.3570e-03, 6.6608e-04, 5.1273e-05, 3.6691e-04, 1.3497e-03,\n",
        "            5.8225e-04, 1.0353e-05, 8.0235e-04, 5.5745e-04, 2.3993e-06, 4.0560e-06,\n",
        "            7.1123e-05, 2.4614e-06, 6.3053e-09, 6.4534e-10, 4.8015e-06, 8.0572e-08,\n",
        "            3.5163e-07, 1.7527e-06, 1.0345e-03, 7.1951e-05],\n",
        "           [9.9708e-01, 5.3553e-04, 4.6028e-03, 4.0834e-04, 3.0074e-03, 1.0745e-03,\n",
        "            4.9136e-04, 1.5309e-03, 2.9569e-03, 5.9007e-03, 9.4669e-04, 1.7102e-04,\n",
        "            2.4217e-03, 6.9735e-04, 2.0822e-03, 1.8290e-03, 6.6120e-05, 6.9437e-04,\n",
        "            1.1984e-03, 1.9620e-03, 2.9104e-04, 3.9732e-03, 6.6100e-05, 1.3089e-04,\n",
        "            6.4165e-03, 4.2787e-05, 8.2833e-04, 1.1061e-04, 4.6951e-05, 6.5818e-05,\n",
        "            5.1693e-06, 4.5311e-05, 3.9764e-09, 5.0618e-09, 3.1990e-03, 2.0915e-08,\n",
        "            4.6575e-07, 9.0827e-06, 6.1502e-04, 3.2784e-07],\n",
        "           [9.9863e-01, 9.4833e-05, 2.0799e-03, 2.0133e-03, 4.1358e-04, 1.3242e-04,\n",
        "            2.6939e-03, 5.9353e-05, 1.3154e-03, 1.8865e-03, 3.7327e-04, 3.9800e-04,\n",
        "            7.0560e-04, 2.1839e-03, 1.4001e-05, 1.0479e-04, 2.4410e-05, 2.2700e-05,\n",
        "            7.5576e-04, 9.3660e-04, 6.7073e-06, 1.6954e-04, 4.0545e-05, 2.8844e-05,\n",
        "            3.0445e-04, 1.9457e-05, 1.4366e-05, 2.7028e-05, 8.9899e-05, 3.9096e-05,\n",
        "            9.7293e-10, 1.5828e-05, 1.2253e-10, 1.7786e-09, 7.0902e-06, 1.9011e-06,\n",
        "            2.9243e-05, 1.5332e-08, 1.2452e-04, 5.1426e-07],\n",
        "           [9.9807e-01, 3.3541e-04, 6.5154e-04, 7.8196e-04, 2.1611e-03, 2.4309e-04,\n",
        "            9.6032e-04, 4.4961e-04, 1.7884e-03, 2.8664e-03, 1.7875e-02, 1.0500e-05,\n",
        "            1.0430e-03, 6.7101e-04, 3.7754e-05, 5.4442e-04, 4.1418e-05, 1.0791e-03,\n",
        "            6.9423e-04, 9.1352e-05, 5.1099e-05, 1.0865e-04, 1.3864e-05, 1.7260e-04,\n",
        "            2.3099e-04, 7.9722e-05, 4.6435e-04, 1.5711e-03, 3.4303e-06, 1.0876e-05,\n",
        "            3.2234e-07, 1.4337e-06, 7.4365e-09, 3.7361e-10, 2.2813e-05, 1.6622e-10,\n",
        "            3.2374e-07, 9.1015e-07, 8.7211e-01, 6.1890e-07],\n",
        "           [9.9250e-01, 2.8877e-04, 3.8188e-03, 1.2403e-03, 6.5572e-03, 3.6633e-03,\n",
        "            5.2551e-04, 1.5810e-04, 1.4610e-03, 4.8822e-03, 1.6009e-03, 5.0023e-04,\n",
        "            5.5941e-04, 8.7524e-04, 5.3133e-04, 6.9835e-04, 3.9461e-04, 1.7114e-04,\n",
        "            7.7599e-04, 9.2931e-05, 1.6476e-04, 3.3837e-03, 7.9322e-05, 6.1120e-06,\n",
        "            1.1150e-03, 7.9710e-05, 5.3115e-05, 1.0544e-04, 1.2782e-05, 1.0660e-02,\n",
        "            6.8643e-08, 6.9406e-06, 8.4672e-09, 6.6181e-08, 1.0911e-04, 7.1068e-07,\n",
        "            1.7796e-05, 1.4838e-05, 3.5799e-03, 6.1294e-07],\n",
        "           [9.9849e-01, 2.6325e-05, 9.2676e-04, 1.7828e-03, 2.1110e-04, 3.2023e-04,\n",
        "            3.2471e-04, 9.6808e-06, 7.4102e-04, 9.2448e-04, 2.2285e-05, 9.7824e-05,\n",
        "            1.5740e-04, 8.0065e-04, 3.6693e-06, 1.8092e-04, 2.7119e-05, 4.3486e-06,\n",
        "            1.1122e-04, 7.3391e-04, 8.4874e-07, 4.1992e-05, 1.2266e-05, 7.5185e-06,\n",
        "            1.3150e-04, 2.3698e-05, 1.9802e-06, 2.8446e-06, 5.8505e-06, 1.3382e-04,\n",
        "            1.2479e-10, 1.1718e-05, 8.4009e-12, 4.2854e-10, 1.2017e-06, 2.1740e-09,\n",
        "            7.3533e-07, 2.1082e-08, 4.3835e-07, 8.5802e-07]],\n",
        "   [[9.9987e-01, 6.7159e-06, 1.5844e-07, 2.3563e-04, 7.1418e-05, 7.5361e-08,\n",
        "            7.0188e-07, 6.6285e-08, 5.6897e-05, 3.5947e-05, 4.7790e-03, 1.0675e-06,\n",
        "            1.0006e-06, 4.3781e-03, 1.5212e-06, 4.1284e-06, 1.8449e-06, 6.1799e-07,\n",
        "            3.5275e-05, 9.9769e-05, 2.4968e-06, 7.5498e-05, 8.9476e-07, 1.9447e-03,\n",
        "            1.0859e-03, 1.5178e-06, 9.7048e-05, 3.0003e-07, 7.1291e-07, 7.2794e-07],\n",
        "           [1.0000e+00, 1.1807e-07, 2.9886e-07, 2.7769e-08, 1.0997e-07, 2.4552e-10,\n",
        "            2.1881e-07, 6.1704e-11, 2.7008e-07, 1.7047e-07, 2.3885e-06, 4.5382e-06,\n",
        "            1.0490e-07, 1.6664e-06, 1.5743e-07, 8.1369e-07, 8.0432e-07, 9.6372e-10,\n",
        "            9.6244e-06, 3.3131e-05, 7.2828e-06, 2.8669e-06, 1.4604e-07, 7.7093e-09,\n",
        "            7.0538e-05, 5.3454e-07, 2.1764e-07, 1.1455e-07, 1.5141e-06, 2.6136e-07],\n",
        "           [1.0000e+00, 5.0164e-10, 2.0191e-11, 6.0766e-07, 5.2080e-09, 3.8754e-11,\n",
        "            8.2597e-10, 9.0102e-11, 6.9640e-09, 4.1604e-08, 7.0534e-07, 5.9183e-08,\n",
        "            1.1033e-05, 2.2550e-08, 2.4415e-06, 8.2153e-06, 3.1781e-09, 2.8391e-10,\n",
        "            8.2264e-10, 6.8072e-10, 3.2225e-03, 1.1683e-03, 3.2649e-05, 1.0207e-06,\n",
        "            1.7260e-04, 4.4697e-05, 3.4249e-06, 3.7568e-05, 1.8890e-05, 4.7580e-06],\n",
        "           [1.0000e+00, 3.6516e-08, 2.0179e-08, 1.8168e-07, 4.1485e-08, 5.6788e-10,\n",
        "            5.2025e-08, 1.4914e-10, 2.5363e-08, 1.0129e-08, 3.5849e-03, 1.4716e-06,\n",
        "            3.1772e-06, 1.7145e-04, 1.2911e-05, 7.1784e-07, 6.0757e-07, 5.5441e-07,\n",
        "            2.4329e-03, 9.6962e-05, 2.3205e-07, 3.8542e-04, 5.3733e-08, 9.8563e-05,\n",
        "            1.1279e-05, 2.0679e-06, 7.9739e-08, 5.9056e-07, 1.3294e-06, 2.0209e-08],\n",
        "           [9.9999e-01, 2.2385e-07, 1.3772e-05, 3.6688e-06, 8.7289e-07, 2.3523e-08,\n",
        "            3.4613e-06, 2.5454e-07, 6.2658e-06, 2.9207e-07, 5.7150e-04, 3.1207e-07,\n",
        "            1.0811e-06, 1.9178e-07, 1.3907e-06, 1.0981e-06, 1.0239e-05, 6.6514e-05,\n",
        "            5.2404e-03, 6.5375e-04, 1.6572e-02, 1.1477e-06, 1.6525e-06, 1.2310e-04,\n",
        "            6.0133e-05, 3.1376e-07, 4.4168e-05, 4.6179e-05, 3.6010e-07, 3.7847e-08],\n",
        "           [1.0000e+00, 4.9273e-09, 7.0017e-10, 7.1248e-07, 6.5853e-09, 6.2969e-10,\n",
        "            1.1883e-09, 1.9957e-10, 1.4328e-08, 6.8209e-08, 1.6170e-07, 7.1714e-08,\n",
        "            1.7291e-08, 2.6293e-07, 1.3290e-06, 3.1879e-08, 9.8781e-09, 5.6548e-09,\n",
        "            1.8234e-08, 3.7201e-06, 7.1477e-07, 2.3142e-03, 2.2940e-08, 2.1182e-07,\n",
        "            3.0488e-04, 5.2921e-06, 3.5915e-05, 2.4225e-06, 4.2975e-05, 2.3039e-07],\n",
        "           [1.0000e+00, 3.2858e-10, 4.6788e-10, 9.9061e-08, 2.1664e-10, 1.0558e-12,\n",
        "            4.5664e-09, 1.5862e-14, 2.6154e-10, 8.1627e-09, 1.8155e-07, 5.3357e-06,\n",
        "            1.9354e-08, 1.7374e-06, 9.5368e-10, 5.6616e-11, 1.0426e-08, 1.0029e-10,\n",
        "            3.1686e-06, 9.5612e-06, 1.4570e-08, 3.7090e-06, 2.4661e-05, 4.4784e-07,\n",
        "            1.5292e-05, 5.5943e-07, 3.5794e-08, 2.4288e-08, 2.7045e-06, 1.5066e-08],\n",
        "           [1.0000e+00, 1.3563e-09, 3.7369e-12, 2.8677e-08, 1.0548e-09, 1.8642e-13,\n",
        "            6.7658e-10, 2.0810e-13, 6.5628e-09, 5.4553e-10, 7.1902e-05, 1.1116e-08,\n",
        "            5.8666e-07, 5.2920e-07, 1.0673e-09, 2.0710e-09, 7.1731e-09, 3.7589e-06,\n",
        "            1.3931e-06, 6.7785e-09, 3.0142e-06, 8.8025e-06, 7.6731e-08, 2.8095e-07,\n",
        "            1.0521e-06, 1.4587e-05, 4.8487e-07, 1.4011e-04, 1.0220e-07, 2.3506e-07],\n",
        "           [9.9993e-01, 3.7276e-07, 5.8291e-08, 1.5813e-05, 4.4158e-05, 2.8018e-08,\n",
        "            2.0783e-07, 6.3076e-09, 2.4923e-06, 5.2088e-05, 5.9594e-06, 4.6699e-07,\n",
        "            2.1365e-08, 1.9074e-05, 8.8786e-07, 6.5738e-08, 1.2630e-07, 6.3257e-08,\n",
        "            1.2444e-04, 7.0189e-06, 8.2656e-06, 7.7038e-05, 1.6444e-07, 5.9382e-08,\n",
        "            9.5577e-06, 5.2083e-06, 2.2234e-06, 2.2665e-06, 2.1714e-07, 1.1337e-02],\n",
        "           [9.9997e-01, 1.4419e-07, 4.8525e-08, 1.5151e-05, 5.0104e-07, 3.0108e-09,\n",
        "            3.8155e-09, 1.9726e-11, 1.4384e-07, 2.2587e-06, 1.1912e-07, 3.9706e-06,\n",
        "            3.3555e-09, 7.1716e-06, 2.2191e-09, 1.8646e-09, 3.7483e-08, 4.8747e-10,\n",
        "            6.3055e-07, 2.5798e-05, 1.0014e-08, 2.1708e-06, 7.5820e-08, 1.1204e-07,\n",
        "            4.5720e-06, 2.5173e-06, 9.4937e-09, 2.0395e-08, 8.0086e-07, 1.7020e-05]]],\n",
        "  5: [[[9.1109e-01, 1.1706e-03, 3.1035e-03, 7.6748e-03, 3.2692e-03, 3.6345e-03,\n",
        "            5.7706e-03, 3.0696e-03, 5.7163e-03, 4.6223e-02, 1.5713e-02, 4.6612e-04,\n",
        "            6.4481e-03, 2.3743e-02, 6.9806e-04, 6.1178e-03, 4.2951e-04, 4.3952e-04,\n",
        "            4.1621e-03, 6.9975e-03, 2.1408e-03, 2.9255e-03, 8.1034e-04, 8.0679e-03,\n",
        "            4.6842e-03, 1.3496e-04, 9.4564e-04, 5.8643e-04, 6.0001e-04, 2.7310e-03,\n",
        "            3.8864e-05, 1.3062e-02, 2.1040e-04, 7.5377e-06, 2.3408e-04, 8.0858e-05,\n",
        "            6.4179e-05, 3.8047e-03, 3.2392e-02, 1.4735e-04, 6.6889e-08, 2.5277e-06,\n",
        "            2.3315e-05, 5.9174e-03, 5.0249e-05, 1.3230e-05, 9.4544e-06, 6.1643e-07,\n",
        "            9.9686e-06, 5.4625e-05],\n",
        "           [9.9770e-01, 1.1408e-04, 2.8428e-03, 2.0750e-03, 7.7548e-04, 5.5324e-04,\n",
        "            5.2772e-04, 3.1546e-04, 2.5263e-03, 5.7583e-03, 2.2811e-03, 3.4412e-04,\n",
        "            4.5658e-04, 1.9311e-03, 6.4028e-04, 2.1599e-03, 4.5385e-05, 1.6675e-04,\n",
        "            1.5840e-03, 3.5883e-04, 1.3477e-03, 4.6349e-05, 4.4962e-04, 7.6390e-04,\n",
        "            6.7278e-04, 6.1616e-06, 1.9031e-04, 2.3723e-04, 2.7236e-04, 1.2866e-04,\n",
        "            6.1811e-06, 7.8669e-04, 8.1425e-06, 4.8721e-07, 1.4054e-05, 2.1505e-05,\n",
        "            2.6832e-05, 3.9863e-04, 3.5050e-03, 1.1251e-05, 1.6952e-08, 1.2359e-07,\n",
        "            1.4670e-06, 1.1051e-03, 2.5651e-07, 4.5663e-08, 8.3925e-07, 8.7665e-08,\n",
        "            1.5492e-08, 3.6169e-07],\n",
        "           [9.9711e-01, 1.1831e-05, 5.9661e-04, 3.3436e-04, 7.3352e-04, 1.0505e-04,\n",
        "            6.1798e-04, 5.3418e-04, 1.4043e-03, 5.0456e-03, 1.1951e-03, 6.8789e-05,\n",
        "            2.1934e-03, 3.3871e-04, 1.3341e-04, 5.7418e-03, 2.6844e-05, 2.1504e-05,\n",
        "            4.2955e-05, 7.1165e-05, 5.8294e-04, 3.1983e-05, 2.4205e-05, 1.2242e-04,\n",
        "            1.9217e-03, 2.3301e-06, 6.5802e-06, 3.4843e-05, 9.4101e-05, 1.6275e-05,\n",
        "            2.6861e-06, 1.8147e-04, 4.6204e-08, 2.0671e-07, 6.5120e-06, 7.7981e-07,\n",
        "            7.5335e-07, 3.5363e-04, 8.2875e-03, 2.6722e-06, 4.7083e-10, 4.0198e-09,\n",
        "            5.6578e-05, 4.4230e-07, 1.0198e-08, 1.5229e-08, 7.1202e-08, 1.0081e-08,\n",
        "            1.3206e-10, 1.9393e-07],\n",
        "           [9.9866e-01, 8.5314e-05, 3.5297e-03, 5.8935e-04, 3.1888e-04, 9.5796e-04,\n",
        "            1.4368e-03, 6.9577e-04, 5.7425e-04, 2.7255e-03, 1.0918e-03, 1.9210e-04,\n",
        "            4.9212e-04, 1.1067e-03, 9.8474e-05, 1.8471e-03, 1.1546e-05, 4.0858e-04,\n",
        "            5.2084e-03, 1.3688e-03, 3.5741e-05, 2.4305e-04, 1.2435e-04, 1.3180e-03,\n",
        "            2.4241e-04, 1.5620e-06, 1.1403e-04, 2.5675e-04, 1.6463e-04, 4.3505e-06,\n",
        "            9.4639e-07, 5.2333e-05, 1.4691e-07, 2.8712e-07, 7.7227e-05, 1.5143e-06,\n",
        "            1.3766e-05, 5.2088e-05, 7.3718e-04, 8.4571e-06, 2.5062e-12, 7.4790e-09,\n",
        "            3.4730e-07, 9.4406e-08, 2.7800e-07, 3.0731e-09, 1.9130e-07, 3.9629e-07,\n",
        "            6.2497e-10, 6.5868e-09],\n",
        "           [9.9336e-01, 1.6342e-04, 1.2179e-02, 3.7915e-03, 5.2278e-04, 1.9378e-03,\n",
        "            8.8090e-04, 3.0151e-03, 4.4122e-03, 5.6653e-03, 3.1570e-03, 8.6794e-04,\n",
        "            9.3131e-04, 5.5301e-04, 3.0783e-04, 6.3102e-03, 1.7370e-04, 2.2948e-03,\n",
        "            5.9791e-04, 4.5837e-03, 4.9790e-04, 1.6652e-04, 7.4848e-04, 1.0093e-03,\n",
        "            5.2491e-04, 2.1114e-06, 3.5963e-03, 3.7236e-03, 1.4728e-04, 1.5014e-05,\n",
        "            2.1376e-04, 1.9723e-03, 4.1734e-07, 2.0390e-06, 4.0853e-04, 1.2726e-05,\n",
        "            3.5479e-05, 4.5196e-06, 4.4749e-04, 4.5998e-05, 1.1919e-08, 4.9841e-07,\n",
        "            2.8638e-06, 1.7145e-06, 1.8970e-06, 3.7374e-06, 1.9680e-08, 9.1521e-08,\n",
        "            7.7655e-09, 2.6093e-05],\n",
        "           [9.9818e-01, 9.4042e-05, 6.4968e-04, 7.5201e-04, 1.5588e-03, 8.6139e-04,\n",
        "            2.3566e-04, 1.6262e-03, 1.4133e-03, 4.8433e-03, 1.5086e-04, 6.7744e-05,\n",
        "            5.0263e-04, 1.3391e-03, 8.6690e-04, 1.5842e-03, 1.3636e-05, 4.4261e-04,\n",
        "            2.0985e-04, 2.4919e-03, 9.8081e-05, 3.9636e-03, 1.0696e-04, 8.3307e-05,\n",
        "            1.2098e-03, 1.2940e-06, 4.2210e-04, 9.3828e-05, 2.0774e-04, 8.3882e-05,\n",
        "            5.2184e-05, 4.1829e-04, 1.7527e-07, 1.0171e-07, 7.1358e-04, 1.4425e-06,\n",
        "            7.6149e-06, 1.6018e-05, 1.1912e-03, 2.4176e-07, 2.1230e-12, 2.0678e-06,\n",
        "            2.5681e-06, 1.4611e-05, 3.1994e-07, 4.2690e-10, 7.2574e-09, 2.7926e-08,\n",
        "            1.6961e-10, 3.7349e-06],\n",
        "           [9.8906e-01, 2.5780e-04, 2.9833e-02, 3.3814e-03, 1.6007e-03, 2.0973e-03,\n",
        "            4.4741e-03, 5.2821e-04, 9.1631e-04, 3.9548e-03, 3.3629e-03, 4.6067e-03,\n",
        "            1.5561e-03, 7.4788e-04, 1.5795e-04, 5.1808e-03, 1.1527e-04, 6.0824e-04,\n",
        "            1.1353e-02, 1.4096e-03, 1.9919e-04, 2.7724e-04, 3.4652e-03, 5.4958e-04,\n",
        "            3.9645e-04, 2.0137e-05, 3.4977e-04, 7.6293e-04, 7.7959e-04, 1.0378e-04,\n",
        "            4.8227e-06, 7.1350e-04, 1.9608e-06, 7.3075e-06, 2.8143e-04, 3.8274e-04,\n",
        "            2.4311e-04, 3.7361e-05, 1.0880e-03, 2.2798e-04, 8.4487e-10, 4.9479e-07,\n",
        "            8.9190e-07, 4.3196e-05, 1.6293e-05, 7.2021e-07, 1.0655e-05, 8.3578e-06,\n",
        "            1.7462e-08, 1.5005e-07],\n",
        "           [9.9676e-01, 1.7346e-04, 6.5098e-04, 1.7136e-03, 2.5357e-03, 4.7441e-04,\n",
        "            1.1422e-03, 7.7404e-04, 1.8754e-03, 6.0482e-03, 1.4291e-02, 3.8306e-05,\n",
        "            3.4797e-03, 1.0426e-03, 1.5021e-04, 8.6603e-04, 1.7262e-05, 3.4517e-03,\n",
        "            1.0560e-03, 4.9413e-05, 4.7529e-05, 6.5781e-05, 3.6834e-05, 1.4333e-03,\n",
        "            2.6053e-04, 2.7667e-05, 1.9886e-03, 3.2055e-04, 1.6771e-05, 4.0044e-05,\n",
        "            5.4538e-05, 5.8570e-05, 1.4917e-06, 3.3420e-07, 3.1084e-04, 5.0991e-08,\n",
        "            1.1438e-06, 2.9020e-05, 1.0466e-01, 7.6396e-06, 1.9687e-11, 2.0161e-09,\n",
        "            1.3330e-05, 1.0516e-05, 5.8214e-08, 8.0324e-06, 2.0573e-06, 7.3155e-07,\n",
        "            3.7752e-10, 6.1115e-07],\n",
        "           [9.9061e-01, 1.1963e-04, 3.3359e-03, 1.4511e-03, 1.6289e-03, 6.5654e-03,\n",
        "            9.8716e-04, 3.6388e-04, 4.1336e-04, 8.3278e-03, 3.8778e-03, 3.4136e-04,\n",
        "            1.0041e-03, 2.3836e-04, 1.0838e-04, 2.0663e-03, 3.4011e-04, 2.1448e-04,\n",
        "            1.4956e-03, 5.7133e-04, 2.4325e-04, 3.2837e-04, 1.0350e-03, 6.7181e-05,\n",
        "            2.3354e-04, 5.9587e-06, 2.1957e-04, 3.5476e-04, 2.5686e-05, 7.3265e-04,\n",
        "            2.3963e-06, 1.0722e-03, 9.1289e-07, 1.3102e-06, 1.3576e-04, 2.0704e-05,\n",
        "            5.1079e-05, 8.2226e-05, 8.7657e-04, 1.7450e-06, 1.1659e-09, 1.1604e-08,\n",
        "            1.2126e-06, 2.3205e-04, 1.5953e-06, 1.4046e-07, 1.1191e-09, 1.3002e-08,\n",
        "            2.7600e-08, 3.9515e-06],\n",
        "           [9.8997e-01, 1.0882e-04, 3.0366e-03, 1.1568e-03, 7.6263e-04, 4.6278e-03,\n",
        "            5.1943e-04, 8.6943e-05, 4.7494e-05, 3.5008e-03, 2.8495e-04, 2.6404e-04,\n",
        "            3.3786e-04, 3.5620e-04, 1.5173e-05, 3.1582e-04, 2.1960e-05, 3.7292e-05,\n",
        "            3.6060e-03, 4.4290e-04, 2.6473e-05, 3.4788e-05, 4.8751e-05, 6.7035e-05,\n",
        "            7.4560e-05, 8.0812e-07, 1.2806e-05, 6.8790e-05, 6.7662e-05, 1.1484e-04,\n",
        "            3.0401e-08, 1.0625e-04, 2.0196e-07, 9.2441e-07, 2.6467e-05, 8.8225e-06,\n",
        "            2.7305e-05, 3.7853e-06, 1.3133e-04, 1.5254e-07, 9.2978e-13, 2.6040e-09,\n",
        "            9.6712e-11, 4.6403e-06, 3.4450e-07, 9.5785e-10, 2.1591e-10, 9.8636e-09,\n",
        "            2.2300e-10, 1.0893e-08]],\n",
        "   [[9.9948e-01, 2.1611e-05, 6.6664e-07, 1.9065e-04, 5.1596e-06, 8.8803e-07,\n",
        "            2.5331e-06, 1.5160e-06, 2.7261e-05, 4.3884e-04, 2.2886e-04, 2.5145e-06,\n",
        "            3.0209e-06, 1.0647e-02, 1.4485e-05, 2.3764e-06, 8.9595e-07, 5.6571e-07,\n",
        "            1.6875e-05, 1.1432e-03, 1.5548e-05, 4.9307e-03, 7.4413e-05, 2.0912e-04,\n",
        "            1.1818e-02, 3.1406e-05, 4.9858e-05, 1.5456e-05, 6.6409e-05, 3.7935e-05,\n",
        "            2.0905e-07, 4.7484e-03, 1.6120e-07, 2.5867e-08, 2.3967e-05, 5.7685e-07,\n",
        "            3.2598e-06, 1.0993e-04, 4.4240e-04, 3.0864e-06],\n",
        "           [1.0000e+00, 1.0545e-09, 3.1139e-11, 3.4034e-09, 2.6900e-10, 1.1532e-13,\n",
        "            1.1725e-10, 2.8712e-14, 9.2055e-10, 1.0312e-09, 6.5216e-07, 9.2392e-09,\n",
        "            2.9984e-09, 4.5219e-08, 2.5594e-09, 8.5159e-09, 2.6790e-10, 8.2623e-14,\n",
        "            3.6353e-09, 2.1939e-08, 8.3651e-06, 1.7327e-06, 1.3345e-07, 5.9547e-06,\n",
        "            6.8423e-05, 2.1526e-08, 1.5055e-08, 7.8625e-08, 8.4952e-08, 3.8430e-08,\n",
        "            1.1671e-09, 5.0764e-06, 6.1035e-10, 3.3154e-10, 5.5747e-07, 9.1468e-10,\n",
        "            2.3003e-08, 5.9079e-06, 5.6538e-05, 6.6267e-08],\n",
        "           [1.0000e+00, 4.7700e-11, 1.4589e-12, 2.2735e-07, 2.7753e-09, 1.6718e-12,\n",
        "            2.8915e-10, 5.4675e-12, 2.2424e-09, 1.5231e-09, 7.0566e-08, 2.0385e-08,\n",
        "            5.5006e-07, 1.4243e-09, 2.2307e-06, 2.8538e-05, 5.6227e-10, 9.9238e-12,\n",
        "            7.2155e-10, 3.4875e-10, 3.7064e-05, 1.3357e-03, 4.8674e-07, 2.2116e-07,\n",
        "            1.3135e-04, 2.3160e-06, 1.1461e-06, 3.5536e-06, 4.9310e-07, 8.2796e-07,\n",
        "            3.5874e-07, 7.5423e-05, 7.0929e-11, 6.7563e-10, 4.9812e-07, 2.3541e-08,\n",
        "            8.2188e-08, 8.7535e-04, 1.1483e-03, 7.9793e-07],\n",
        "           [1.0000e+00, 4.5102e-09, 9.2171e-09, 1.5386e-08, 1.3560e-09, 8.7343e-11,\n",
        "            1.3473e-08, 2.6632e-11, 9.5508e-09, 8.1420e-09, 8.0417e-06, 2.7104e-06,\n",
        "            2.5582e-06, 1.7289e-06, 6.6412e-07, 2.7477e-08, 4.8623e-08, 1.4436e-09,\n",
        "            1.3932e-04, 1.9639e-06, 8.3630e-08, 1.1879e-04, 4.6372e-07, 4.7580e-06,\n",
        "            5.9315e-05, 5.0971e-06, 7.7718e-08, 3.1003e-07, 7.1468e-06, 2.0892e-07,\n",
        "            1.8279e-08, 1.6572e-06, 8.7861e-10, 1.7657e-09, 2.0499e-05, 1.7783e-08,\n",
        "            9.0077e-07, 3.5742e-06, 4.1779e-04, 3.2397e-06],\n",
        "           [1.0000e+00, 4.2889e-08, 1.8820e-07, 1.1470e-06, 1.2124e-08, 5.4738e-09,\n",
        "            5.6681e-08, 1.5625e-08, 1.3269e-06, 5.7840e-07, 7.9370e-04, 4.1719e-06,\n",
        "            2.1857e-06, 1.3179e-06, 6.8647e-06, 5.8087e-06, 5.0853e-06, 3.5645e-06,\n",
        "            1.5565e-03, 4.5606e-03, 2.4521e-04, 2.6597e-04, 1.6534e-05, 1.1269e-03,\n",
        "            6.5432e-04, 4.9374e-06, 9.4299e-05, 6.5518e-05, 6.9635e-07, 6.6520e-06,\n",
        "            2.3285e-06, 6.1214e-06, 7.4687e-09, 6.8773e-09, 8.7651e-05, 3.2725e-07,\n",
        "            1.0001e-06, 1.3447e-07, 2.1267e-03, 8.8947e-06],\n",
        "           [1.0000e+00, 6.7422e-10, 1.1289e-10, 6.4406e-07, 5.8586e-10, 8.5270e-11,\n",
        "            5.0566e-11, 5.0937e-12, 1.7348e-08, 1.3837e-08, 1.0549e-07, 1.4012e-08,\n",
        "            3.5850e-09, 1.2802e-08, 2.9198e-06, 1.9689e-08, 1.3685e-08, 2.3599e-07,\n",
        "            1.0611e-08, 1.1821e-05, 3.3744e-07, 2.8592e-04, 5.0024e-09, 2.3187e-08,\n",
        "            2.2863e-04, 5.1288e-07, 3.1099e-05, 4.9227e-07, 5.4073e-05, 1.9974e-08,\n",
        "            6.0726e-07, 5.5955e-06, 3.3323e-10, 1.2071e-10, 6.1116e-04, 8.0324e-10,\n",
        "            1.2380e-08, 3.3898e-06, 4.3688e-03, 5.9761e-09],\n",
        "           [1.0000e+00, 4.4812e-09, 1.5821e-07, 2.9381e-08, 1.3313e-08, 2.7872e-11,\n",
        "            2.7671e-09, 3.1399e-13, 4.9416e-09, 4.1317e-08, 1.0864e-06, 9.1715e-07,\n",
        "            5.6857e-09, 1.3548e-07, 6.0657e-10, 3.1229e-10, 2.2574e-08, 9.4643e-12,\n",
        "            3.9283e-07, 8.3117e-08, 5.0317e-08, 6.1939e-07, 2.8982e-07, 9.9798e-09,\n",
        "            3.3780e-06, 5.6461e-06, 1.5571e-08, 1.1007e-07, 3.9543e-06, 3.4719e-08,\n",
        "            1.4150e-09, 2.0596e-06, 4.8676e-11, 2.5428e-09, 1.1763e-06, 1.3419e-08,\n",
        "            1.1857e-06, 1.2653e-07, 5.6949e-05, 2.3271e-06],\n",
        "           [1.0000e+00, 3.3548e-08, 5.1610e-12, 6.9990e-07, 1.1073e-09, 1.3539e-11,\n",
        "            9.1148e-10, 3.9717e-11, 1.6513e-07, 1.3312e-07, 9.2876e-04, 9.5120e-09,\n",
        "            1.0697e-06, 7.8164e-05, 7.8076e-09, 2.4249e-08, 1.6308e-09, 9.7036e-08,\n",
        "            4.0583e-07, 5.7388e-09, 1.7569e-06, 7.4800e-06, 6.9111e-08, 2.3307e-08,\n",
        "            1.8923e-06, 8.0656e-07, 1.8600e-04, 4.7166e-06, 2.9984e-08, 1.6386e-08,\n",
        "            1.1533e-06, 9.5359e-05, 6.0237e-09, 1.0336e-09, 4.6788e-05, 3.5446e-09,\n",
        "            5.2606e-07, 2.2921e-07, 1.5549e-01, 3.9765e-08],\n",
        "           [9.9985e-01, 1.7422e-07, 2.7862e-08, 1.1637e-05, 4.5956e-05, 1.5953e-08,\n",
        "            5.6475e-08, 2.0992e-09, 1.5115e-06, 2.1113e-04, 5.7729e-06, 1.5027e-07,\n",
        "            1.2189e-08, 1.9204e-05, 4.5803e-08, 8.2064e-08, 2.5866e-07, 1.6170e-08,\n",
        "            3.1012e-05, 2.2001e-05, 2.0932e-05, 1.0307e-04, 2.4625e-07, 3.2256e-08,\n",
        "            1.5707e-05, 4.1425e-06, 6.5683e-06, 4.5559e-06, 1.7549e-07, 2.3880e-03,\n",
        "            6.9581e-07, 1.4475e-05, 2.7318e-08, 3.9685e-08, 1.3837e-04, 1.0521e-06,\n",
        "            1.5322e-05, 1.0245e-04, 4.6690e-02, 2.2940e-06],\n",
        "           [1.0000e+00, 6.7895e-10, 5.8545e-11, 5.2954e-09, 4.6222e-11, 1.3670e-12,\n",
        "            3.0486e-11, 1.0365e-14, 9.6298e-11, 2.7916e-08, 1.2138e-09, 2.0379e-07,\n",
        "            3.1403e-10, 1.9182e-08, 6.5372e-11, 3.1074e-11, 1.1852e-09, 4.8830e-13,\n",
        "            4.1339e-08, 5.2703e-08, 1.1039e-09, 1.7342e-07, 5.1006e-09, 4.5145e-08,\n",
        "            1.5468e-06, 3.1462e-07, 9.7341e-10, 5.7212e-09, 4.2525e-07, 4.3093e-06,\n",
        "            3.3175e-11, 1.2992e-06, 1.6784e-11, 9.7534e-10, 5.3692e-07, 5.1677e-09,\n",
        "            2.9907e-07, 1.4928e-08, 5.5152e-06, 5.7938e-08]]],\n",
        "  6: [[[8.8289e-01, 1.0784e-03, 3.3760e-03, 8.3431e-03, 4.3805e-03, 5.3576e-03,\n",
        "            4.1142e-03, 2.9339e-03, 1.3245e-02, 9.3742e-02, 7.4423e-02, 5.7284e-04,\n",
        "            9.1368e-03, 1.7792e-02, 7.8364e-04, 5.1170e-03, 6.1124e-04, 7.5646e-04,\n",
        "            1.5315e-03, 7.5653e-03, 4.3931e-03, 5.5333e-03, 8.1136e-04, 8.9894e-03,\n",
        "            3.0225e-03, 2.3723e-04, 4.0780e-03, 4.6627e-04, 8.8912e-04, 1.9971e-03,\n",
        "            1.4415e-03, 1.3451e-02, 4.8969e-04, 1.2928e-05, 1.2454e-04, 3.7168e-04,\n",
        "            2.0911e-04, 4.4293e-03, 4.3227e-02, 6.9765e-05, 3.9644e-05, 6.7464e-05,\n",
        "            7.3460e-03, 1.3950e-02, 1.4673e-04, 6.8295e-04, 2.3229e-05, 7.0519e-06,\n",
        "            3.4949e-04, 1.0879e-03, 1.5523e-05, 6.9798e-04, 2.3816e-07, 3.0045e-08,\n",
        "            1.0719e-06, 1.7400e-04, 9.2563e-09, 1.8052e-05, 4.1100e-04, 3.3733e-04],\n",
        "           [9.9125e-01, 2.5103e-04, 2.0088e-02, 2.5707e-03, 9.0987e-04, 4.9717e-04,\n",
        "            1.7698e-03, 9.0353e-04, 2.6562e-03, 8.3991e-03, 3.0456e-03, 3.1881e-04,\n",
        "            3.3957e-03, 5.6789e-04, 3.2283e-04, 2.7875e-03, 9.7053e-04, 1.8748e-03,\n",
        "            1.8799e-03, 4.6848e-04, 3.1384e-03, 1.6861e-04, 2.6369e-03, 3.2458e-05,\n",
        "            2.6211e-04, 1.7803e-05, 7.0493e-04, 8.8793e-05, 5.3855e-04, 1.0271e-03,\n",
        "            4.7968e-05, 9.0308e-05, 4.5804e-05, 3.6758e-06, 3.9195e-05, 2.7767e-04,\n",
        "            4.4023e-04, 4.4425e-05, 5.7228e-03, 1.3461e-04, 6.4695e-05, 2.0470e-07,\n",
        "            8.1001e-06, 9.0938e-04, 1.9937e-06, 7.7715e-06, 1.0639e-05, 1.1964e-04,\n",
        "            6.7812e-07, 2.1234e-05, 5.1733e-08, 3.5191e-06, 3.7552e-05, 9.0523e-08,\n",
        "            1.3501e-06, 8.3187e-08, 2.0857e-09, 1.8461e-07, 3.6611e-06, 6.6288e-10],\n",
        "           [9.9343e-01, 1.6077e-04, 8.6359e-03, 1.9510e-03, 1.4529e-03, 5.3493e-04,\n",
        "            5.0283e-03, 5.8959e-03, 7.3181e-03, 1.6714e-02, 4.3852e-03, 6.3551e-04,\n",
        "            9.6524e-03, 9.1922e-04, 2.1174e-03, 5.6796e-02, 2.2387e-03, 4.3551e-04,\n",
        "            5.7121e-04, 1.1242e-03, 1.4260e-02, 5.9938e-04, 5.5111e-04, 2.3057e-04,\n",
        "            1.4655e-02, 2.4468e-05, 5.6672e-04, 3.0265e-04, 1.4231e-03, 1.9461e-04,\n",
        "            1.1049e-03, 9.1958e-04, 3.3082e-05, 2.6936e-06, 1.3587e-04, 3.7294e-04,\n",
        "            1.1949e-04, 1.5175e-03, 2.2380e-02, 3.3911e-04, 3.1860e-04, 2.1182e-06,\n",
        "            1.4769e-02, 8.6937e-04, 2.8704e-06, 3.7815e-05, 4.6772e-05, 2.6584e-04,\n",
        "            9.9061e-07, 1.3387e-04, 4.7124e-08, 1.1495e-04, 3.0679e-06, 1.8652e-06,\n",
        "            1.2073e-06, 2.2318e-05, 1.3370e-06, 2.1946e-04, 8.4984e-08, 1.9615e-07],\n",
        "           [9.8493e-01, 6.9873e-04, 9.2812e-03, 4.5382e-03, 1.8526e-03, 1.5435e-03,\n",
        "            1.0719e-02, 2.8651e-03, 1.1366e-03, 5.2260e-03, 7.0698e-03, 3.3735e-04,\n",
        "            2.4179e-03, 3.5577e-03, 3.3671e-04, 2.5640e-03, 3.0404e-04, 8.8171e-03,\n",
        "            1.3028e-02, 2.2954e-03, 5.3686e-04, 2.4446e-03, 2.2696e-03, 1.2150e-03,\n",
        "            7.9538e-04, 6.9947e-05, 8.9248e-04, 4.2807e-04, 4.2346e-04, 4.2525e-04,\n",
        "            7.9007e-05, 2.7408e-04, 1.6120e-05, 1.8253e-05, 3.9859e-04, 4.3091e-04,\n",
        "            6.0337e-04, 4.5424e-04, 1.1817e-02, 2.7291e-04, 1.1936e-06, 4.6508e-06,\n",
        "            3.1077e-05, 3.6628e-05, 1.4383e-04, 1.1055e-04, 7.0772e-05, 2.0279e-04,\n",
        "            2.9295e-06, 1.1758e-05, 3.2664e-08, 7.0387e-06, 1.9522e-08, 3.5064e-05,\n",
        "            1.3115e-06, 1.9746e-06, 1.0576e-08, 6.8245e-05, 2.2750e-05, 1.8442e-08],\n",
        "           [9.9189e-01, 6.5473e-05, 1.2142e-02, 1.3053e-03, 6.8569e-04, 4.6183e-03,\n",
        "            9.2158e-04, 1.4556e-03, 1.6080e-03, 7.2949e-03, 3.5579e-02, 8.7769e-04,\n",
        "            1.4713e-03, 6.8955e-05, 2.0460e-04, 6.9113e-03, 7.0595e-04, 3.6675e-03,\n",
        "            6.1428e-04, 1.9493e-04, 1.2458e-03, 9.0334e-05, 9.1044e-04, 1.1380e-04,\n",
        "            4.1120e-04, 5.3091e-06, 1.4669e-03, 1.1539e-03, 5.2579e-05, 2.1256e-04,\n",
        "            1.0954e-04, 2.2445e-04, 4.2736e-06, 5.1060e-06, 7.2227e-05, 1.4453e-04,\n",
        "            4.4008e-05, 4.5647e-05, 9.7708e-04, 2.0089e-04, 7.2833e-06, 7.7640e-07,\n",
        "            3.9096e-05, 1.2142e-04, 1.7492e-05, 3.8021e-05, 7.5902e-07, 3.4112e-06,\n",
        "            2.1663e-06, 4.3855e-05, 3.2821e-09, 2.3539e-06, 3.4609e-07, 2.0105e-06,\n",
        "            1.3176e-09, 8.2791e-07, 6.6333e-10, 1.2577e-04, 6.0876e-08, 4.0770e-07],\n",
        "           [9.9196e-01, 1.2590e-03, 4.0610e-03, 4.8451e-03, 6.2819e-03, 1.3666e-03,\n",
        "            1.9397e-03, 5.6066e-03, 2.7882e-03, 1.1200e-02, 6.3328e-03, 1.1841e-04,\n",
        "            2.7590e-03, 7.3089e-03, 5.1373e-03, 1.6074e-03, 1.9765e-04, 2.5406e-03,\n",
        "            1.9502e-03, 3.9143e-03, 1.1995e-03, 1.3815e-02, 1.6126e-03, 3.0850e-04,\n",
        "            2.6296e-03, 5.6989e-05, 4.1774e-03, 2.6331e-04, 4.9691e-04, 1.2128e-03,\n",
        "            1.4830e-03, 2.1957e-03, 4.1373e-05, 3.8936e-06, 1.4128e-03, 1.4085e-04,\n",
        "            3.2229e-04, 6.9040e-04, 3.0999e-02, 4.9003e-06, 4.7749e-06, 1.2482e-04,\n",
        "            2.0132e-04, 9.6364e-04, 5.1904e-05, 1.9148e-05, 1.0278e-05, 2.7517e-05,\n",
        "            8.6121e-07, 1.4775e-04, 7.3692e-08, 5.6103e-05, 1.5297e-09, 6.3849e-06,\n",
        "            8.5590e-08, 1.2167e-07, 4.2749e-08, 8.2181e-05, 3.8431e-06, 6.6433e-06],\n",
        "           [9.7722e-01, 6.2141e-04, 3.2720e-02, 3.5114e-03, 2.3512e-03, 2.0753e-03,\n",
        "            1.0863e-02, 1.7136e-03, 9.4635e-04, 9.4922e-03, 4.1080e-03, 1.1251e-03,\n",
        "            6.4388e-03, 1.4290e-03, 2.9430e-04, 6.8969e-03, 1.6594e-03, 7.8472e-04,\n",
        "            6.6862e-03, 2.3221e-03, 1.0710e-03, 2.7421e-03, 3.4294e-03, 1.4642e-04,\n",
        "            6.2764e-04, 7.1096e-05, 4.9192e-04, 3.5021e-04, 1.3377e-03, 1.2211e-03,\n",
        "            1.2007e-04, 6.7715e-04, 2.1830e-05, 2.4138e-05, 1.6656e-04, 9.0206e-04,\n",
        "            2.2305e-03, 2.1682e-04, 4.4112e-03, 2.1303e-04, 4.7715e-05, 4.4008e-06,\n",
        "            5.5056e-05, 2.4293e-04, 1.2411e-04, 8.6477e-05, 1.2352e-05, 1.8739e-04,\n",
        "            1.8065e-06, 2.7141e-05, 1.6500e-08, 4.6155e-05, 1.6053e-06, 6.4080e-07,\n",
        "            5.2607e-06, 7.4452e-07, 4.1982e-08, 3.4238e-06, 6.5515e-06, 2.1083e-07],\n",
        "           [9.7779e-01, 1.1427e-03, 3.3370e-03, 3.2348e-03, 7.6386e-03, 1.2150e-03,\n",
        "            2.6283e-03, 2.1613e-03, 2.9393e-03, 2.0721e-02, 3.0906e-02, 3.4035e-04,\n",
        "            1.7410e-02, 4.4843e-03, 4.8541e-04, 9.0069e-04, 2.5868e-04, 5.0464e-03,\n",
        "            3.0321e-03, 1.1076e-04, 1.0456e-03, 4.2127e-04, 2.1447e-04, 1.3432e-03,\n",
        "            9.9618e-04, 6.3480e-05, 7.0492e-03, 1.5291e-03, 3.4097e-05, 6.6842e-04,\n",
        "            5.1951e-04, 2.3747e-03, 1.5420e-04, 4.3918e-06, 6.9483e-04, 3.2952e-05,\n",
        "            1.8904e-04, 5.3737e-04, 7.5863e-02, 1.3907e-05, 1.9926e-06, 7.2277e-06,\n",
        "            1.7667e-04, 4.7971e-03, 5.1918e-05, 6.3742e-04, 2.2820e-05, 9.1188e-05,\n",
        "            3.4833e-06, 1.4692e-04, 3.9964e-07, 1.3970e-02, 4.0455e-09, 7.9343e-09,\n",
        "            4.2283e-08, 8.7046e-05, 6.2129e-09, 3.3370e-03, 8.0077e-06, 2.9524e-07],\n",
        "           [9.6365e-01, 2.3566e-04, 9.6230e-03, 2.5117e-03, 3.6011e-03, 1.6720e-03,\n",
        "            2.1688e-03, 4.9224e-04, 9.2940e-05, 1.1755e-02, 3.2313e-03, 2.7649e-04,\n",
        "            2.8171e-03, 6.0109e-04, 1.6514e-04, 1.8710e-03, 5.3913e-04, 1.6433e-04,\n",
        "            1.7928e-03, 6.1599e-04, 6.1639e-04, 5.5918e-03, 1.4245e-03, 3.0079e-05,\n",
        "            5.2486e-04, 1.1164e-05, 3.6111e-04, 1.8255e-04, 1.2914e-04, 1.5244e-03,\n",
        "            1.0355e-04, 7.4020e-04, 1.1808e-05, 2.3322e-05, 1.9942e-04, 6.4005e-04,\n",
        "            7.2726e-04, 1.8203e-04, 2.4940e-02, 6.3671e-06, 4.3760e-06, 8.7526e-07,\n",
        "            1.0975e-04, 2.2616e-04, 3.1839e-05, 1.9118e-04, 9.0752e-07, 5.7023e-05,\n",
        "            1.9744e-06, 6.0913e-04, 5.1999e-09, 5.7918e-06, 1.0929e-07, 1.8913e-05,\n",
        "            1.2031e-07, 3.1165e-06, 7.3223e-08, 1.3715e-05, 1.8077e-07, 6.7896e-06],\n",
        "           [9.8452e-01, 1.2162e-04, 3.9667e-03, 3.6115e-03, 6.4047e-04, 3.1040e-03,\n",
        "            6.5689e-04, 6.7632e-05, 8.1545e-05, 4.7472e-03, 3.2963e-04, 9.6614e-05,\n",
        "            1.1126e-03, 1.3425e-04, 2.2130e-05, 2.7852e-04, 2.7861e-04, 1.5312e-04,\n",
        "            1.5685e-03, 1.2468e-04, 6.3945e-05, 1.4043e-04, 1.8007e-04, 9.1219e-06,\n",
        "            3.4866e-05, 1.4558e-06, 8.5300e-05, 5.6187e-06, 4.0004e-05, 1.5137e-03,\n",
        "            1.3927e-06, 8.8667e-05, 1.4485e-06, 4.0469e-06, 1.7134e-05, 3.2940e-05,\n",
        "            9.5230e-05, 1.3661e-06, 7.1144e-04, 1.9338e-06, 4.2463e-07, 9.6636e-09,\n",
        "            1.5013e-07, 4.8733e-05, 1.9894e-06, 8.2239e-07, 9.0065e-09, 8.0101e-06,\n",
        "            2.8424e-08, 1.3661e-06, 8.6930e-11, 5.1253e-07, 4.7679e-08, 5.1365e-09,\n",
        "            5.9453e-11, 5.6972e-09, 7.0064e-10, 2.3160e-07, 7.9023e-11, 5.9598e-10]],\n",
        "   [[9.9691e-01, 1.4129e-04, 8.7632e-07, 1.4948e-03, 9.7212e-05, 6.6318e-06,\n",
        "            1.5184e-06, 2.9562e-06, 8.4292e-04, 5.6795e-04, 1.3256e-04, 8.1973e-08,\n",
        "            1.7976e-06, 2.5594e-02, 2.5607e-07, 2.6801e-07, 5.5726e-08, 5.6738e-07,\n",
        "            3.7876e-07, 6.4406e-06, 1.2899e-06, 6.9697e-04, 1.0919e-06, 7.9554e-04,\n",
        "            9.6891e-04, 1.9067e-05, 3.2315e-05, 9.7277e-07, 8.9470e-07, 3.0937e-06,\n",
        "            1.8967e-07, 2.4899e-03, 2.4699e-08, 4.6224e-09, 2.4250e-05, 2.6433e-08,\n",
        "            2.0853e-07, 1.1007e-04, 2.4591e-03, 6.6079e-08, 9.4112e-09, 1.5396e-06,\n",
        "            6.4836e-04, 5.7018e-04, 2.0221e-05, 3.7175e-06, 7.3041e-07, 2.7645e-08,\n",
        "            1.7590e-06, 5.6159e-05],\n",
        "           [1.0000e+00, 3.4104e-10, 6.5802e-11, 1.7143e-08, 1.2880e-10, 1.5455e-12,\n",
        "            1.2944e-10, 1.5664e-13, 1.3595e-09, 9.7594e-10, 1.5152e-07, 9.8074e-08,\n",
        "            1.8084e-08, 2.1177e-08, 3.7285e-08, 6.5756e-09, 1.9984e-09, 8.6011e-12,\n",
        "            1.1800e-07, 1.5027e-08, 6.4474e-06, 9.4635e-06, 6.4130e-07, 6.0994e-07,\n",
        "            2.8181e-05, 6.2896e-07, 1.6566e-08, 3.6371e-08, 8.0576e-08, 3.6942e-07,\n",
        "            1.4459e-09, 2.2643e-06, 1.5965e-10, 1.7000e-10, 3.4103e-07, 4.8663e-10,\n",
        "            7.3751e-08, 5.5147e-06, 7.0913e-06, 8.1133e-07, 8.9529e-10, 2.9783e-08,\n",
        "            6.2327e-07, 1.5283e-04, 9.7491e-08, 6.0946e-09, 4.0586e-07, 1.1399e-07,\n",
        "            3.0366e-09, 1.5612e-07],\n",
        "           [1.0000e+00, 1.2656e-09, 1.6256e-10, 4.2417e-06, 5.5116e-08, 3.7469e-10,\n",
        "            1.9573e-09, 1.9391e-10, 1.9899e-08, 3.7388e-08, 4.8529e-06, 3.0818e-07,\n",
        "            2.1055e-06, 1.3725e-07, 3.6050e-06, 5.0507e-06, 1.3885e-08, 1.3959e-09,\n",
        "            2.3015e-08, 6.4472e-09, 3.4947e-04, 6.3475e-04, 2.5003e-06, 4.3780e-07,\n",
        "            1.0187e-04, 1.1063e-05, 4.3197e-06, 1.1476e-05, 8.4391e-06, 8.1657e-07,\n",
        "            3.9218e-06, 1.9322e-04, 7.5702e-10, 1.8967e-09, 2.3429e-06, 2.9334e-08,\n",
        "            5.4342e-07, 8.5785e-04, 8.2697e-03, 3.0677e-06, 1.1930e-09, 5.1905e-08,\n",
        "            4.9679e-04, 2.4123e-06, 2.1300e-08, 9.6184e-08, 4.4036e-07, 5.5913e-08,\n",
        "            5.4639e-10, 1.2439e-06],\n",
        "           [1.0000e+00, 2.3602e-08, 2.1184e-08, 4.3339e-07, 2.8265e-08, 1.0893e-09,\n",
        "            1.0095e-07, 2.2091e-10, 2.9173e-08, 1.4672e-08, 9.6672e-06, 1.4434e-07,\n",
        "            1.8417e-07, 1.4203e-06, 5.8105e-07, 4.1531e-09, 5.7484e-08, 1.5883e-08,\n",
        "            3.7110e-03, 2.0505e-06, 7.6117e-07, 1.1536e-04, 1.3902e-06, 8.1849e-06,\n",
        "            1.1994e-05, 8.9669e-06, 1.9422e-07, 1.8955e-06, 2.1501e-06, 7.2865e-08,\n",
        "            7.1603e-09, 1.1574e-06, 3.8387e-10, 3.1546e-09, 2.5290e-05, 4.7145e-08,\n",
        "            1.1427e-06, 1.1308e-06, 1.2547e-03, 6.3432e-06, 5.5045e-11, 3.0753e-07,\n",
        "            2.3859e-06, 1.7387e-06, 2.0678e-05, 2.7796e-07, 4.5629e-05, 3.3699e-05,\n",
        "            1.0221e-07, 5.1846e-06],\n",
        "           [1.0000e+00, 2.8705e-09, 8.5043e-09, 1.1471e-08, 1.6648e-10, 3.5209e-11,\n",
        "            4.9881e-09, 1.2321e-10, 1.2016e-07, 1.0952e-08, 2.5595e-05, 8.8518e-07,\n",
        "            2.4845e-07, 2.1144e-08, 5.4367e-07, 7.5038e-07, 2.1098e-07, 3.5715e-07,\n",
        "            2.3628e-05, 9.3108e-04, 1.3445e-04, 3.3091e-06, 2.0621e-05, 7.8247e-05,\n",
        "            4.5922e-05, 9.5354e-08, 4.8234e-06, 1.2038e-05, 8.0630e-08, 1.6071e-08,\n",
        "            1.2389e-06, 3.1185e-06, 7.9797e-10, 2.6104e-10, 4.9073e-05, 2.0732e-07,\n",
        "            3.6972e-07, 5.0600e-08, 4.9351e-04, 3.5539e-06, 1.2046e-08, 4.1603e-08,\n",
        "            1.6475e-07, 2.4413e-05, 5.2927e-08, 2.1290e-07, 3.1255e-10, 7.8512e-09,\n",
        "            2.4762e-09, 8.9177e-07],\n",
        "           [1.0000e+00, 3.1176e-08, 5.8800e-09, 5.6653e-06, 2.1864e-08, 8.8540e-09,\n",
        "            8.5804e-10, 1.9542e-10, 2.6470e-08, 8.0813e-08, 5.9169e-08, 3.4047e-08,\n",
        "            6.4141e-09, 2.6899e-08, 7.4719e-07, 2.1466e-08, 5.0271e-08, 4.9740e-09,\n",
        "            1.2121e-08, 8.9858e-06, 3.4673e-06, 1.5369e-03, 9.5532e-08, 3.5796e-06,\n",
        "            1.8494e-04, 1.3023e-05, 2.1591e-04, 2.1864e-06, 2.3394e-05, 5.2245e-06,\n",
        "            1.0693e-06, 5.8324e-06, 3.6652e-10, 8.4999e-10, 1.3212e-03, 1.5021e-09,\n",
        "            3.1960e-08, 1.6924e-06, 1.5670e-04, 4.1285e-07, 4.2787e-12, 1.0162e-05,\n",
        "            1.4109e-06, 1.1233e-04, 7.3040e-07, 9.7569e-10, 1.2223e-07, 1.2928e-07,\n",
        "            2.4511e-09, 9.5957e-07],\n",
        "           [1.0000e+00, 5.2894e-09, 4.7019e-08, 1.2972e-08, 3.9302e-09, 2.5784e-11,\n",
        "            1.5916e-08, 3.7626e-13, 1.1588e-09, 8.1475e-09, 8.9667e-07, 3.2393e-05,\n",
        "            3.3658e-08, 4.2970e-08, 5.1351e-09, 3.2800e-10, 1.0392e-07, 3.1968e-10,\n",
        "            1.9560e-05, 1.5057e-06, 4.1436e-07, 9.0949e-06, 1.9256e-05, 1.8574e-07,\n",
        "            3.7993e-05, 5.9320e-06, 1.4295e-08, 1.9591e-07, 1.7793e-06, 1.5533e-06,\n",
        "            7.1547e-10, 8.1707e-06, 1.1714e-10, 1.2892e-08, 1.6073e-05, 2.7676e-07,\n",
        "            2.2095e-05, 3.7205e-07, 4.7250e-06, 8.8194e-07, 2.0192e-09, 4.7803e-07,\n",
        "            3.7204e-07, 1.0261e-04, 1.1068e-05, 8.1715e-07, 1.0798e-06, 6.8213e-06,\n",
        "            2.8565e-08, 6.8513e-07],\n",
        "           [1.0000e+00, 3.5256e-07, 5.7005e-10, 5.2089e-06, 3.7594e-07, 8.1015e-10,\n",
        "            4.8905e-08, 1.4668e-09, 6.7533e-07, 1.3644e-06, 4.2790e-05, 4.5824e-07,\n",
        "            7.2854e-05, 1.2162e-05, 3.8070e-07, 2.0436e-07, 2.2027e-07, 1.5002e-04,\n",
        "            1.0234e-05, 5.2358e-07, 4.6150e-05, 2.3364e-05, 1.6147e-06, 2.9246e-07,\n",
        "            1.8833e-06, 1.0197e-05, 1.3523e-03, 3.3143e-05, 3.2310e-07, 1.8251e-07,\n",
        "            1.4023e-05, 4.9683e-04, 2.9925e-07, 2.2326e-08, 4.8635e-05, 4.6629e-07,\n",
        "            2.0223e-06, 6.4472e-06, 7.4074e-02, 5.1168e-07, 3.1866e-11, 1.0891e-08,\n",
        "            8.7509e-07, 5.0348e-05, 1.1027e-07, 1.3484e-05, 3.0058e-06, 1.7844e-05,\n",
        "            2.5166e-09, 2.1638e-07],\n",
        "           [1.0000e+00, 1.4056e-09, 3.0522e-09, 2.1485e-08, 4.8683e-08, 2.6269e-12,\n",
        "            2.7285e-10, 2.7026e-14, 3.4810e-10, 3.8021e-09, 9.8293e-07, 1.0249e-06,\n",
        "            1.4698e-09, 1.0008e-06, 4.3928e-10, 1.9569e-09, 1.1695e-10, 4.1760e-13,\n",
        "            3.0049e-08, 8.0134e-09, 6.1933e-06, 4.1460e-05, 2.6346e-08, 1.6655e-08,\n",
        "            1.1041e-05, 2.8839e-08, 4.7489e-07, 2.5428e-06, 3.7030e-08, 2.0200e-03,\n",
        "            4.3389e-09, 2.5152e-06, 1.0794e-09, 1.3180e-09, 2.7027e-04, 2.3029e-09,\n",
        "            7.8901e-07, 8.6194e-08, 4.1837e-03, 5.4308e-08, 2.7193e-12, 3.5312e-09,\n",
        "            3.4686e-09, 6.8745e-05, 3.2359e-07, 1.4459e-07, 3.3484e-09, 3.9314e-09,\n",
        "            1.1291e-09, 4.4069e-05],\n",
        "           [9.9995e-01, 1.6036e-07, 2.6521e-09, 3.0359e-06, 6.0814e-07, 1.1189e-10,\n",
        "            1.2414e-08, 1.8314e-11, 1.9433e-07, 3.5336e-05, 2.1436e-07, 1.9489e-06,\n",
        "            1.4876e-08, 8.1911e-06, 1.4327e-09, 2.6813e-09, 6.5472e-08, 6.9205e-10,\n",
        "            1.9582e-05, 2.8429e-05, 4.3902e-08, 2.6484e-05, 2.7483e-08, 8.4729e-07,\n",
        "            2.4917e-05, 4.0470e-07, 3.9544e-08, 2.1863e-08, 2.2771e-05, 4.2784e-05,\n",
        "            6.7004e-11, 1.9020e-05, 1.1714e-11, 1.3845e-10, 2.0696e-06, 4.3964e-09,\n",
        "            5.2569e-07, 3.6211e-09, 3.0165e-07, 2.6087e-08, 2.9208e-12, 3.0816e-09,\n",
        "            4.1911e-10, 1.2977e-03, 1.5631e-06, 6.1408e-09, 3.0134e-10, 1.7059e-08,\n",
        "            1.4667e-08, 5.2817e-08]]],\n",
        "  7: [[[8.5760e-01, 1.9248e-03, 1.7344e-03, 1.3639e-02, 5.0408e-03, 4.4330e-03,\n",
        "            5.3192e-03, 4.5892e-03, 1.1188e-02, 1.5671e-01, 4.2374e-02, 4.5401e-04,\n",
        "            1.2050e-02, 3.5256e-02, 1.2727e-03, 9.1030e-03, 4.0230e-04, 1.8815e-03,\n",
        "            3.6585e-03, 1.6254e-02, 3.7635e-03, 2.1353e-02, 1.0105e-03, 1.9524e-02,\n",
        "            5.1913e-03, 1.2795e-04, 9.0202e-03, 4.3555e-04, 8.7874e-04, 3.5810e-03,\n",
        "            3.2787e-03, 2.1100e-02, 5.1584e-04, 3.2044e-05, 4.6765e-04, 1.1751e-03,\n",
        "            1.7682e-04, 6.6708e-03, 1.0755e-01, 1.5381e-04, 8.3686e-05, 3.0753e-04,\n",
        "            1.1905e-02, 1.3844e-02, 8.8655e-04, 9.2013e-04, 1.8891e-04, 9.9015e-05,\n",
        "            2.0830e-03, 4.0536e-03, 1.2056e-04, 1.1473e-02, 2.7865e-05, 3.2020e-06,\n",
        "            4.7346e-05, 6.7149e-03, 1.7053e-05, 1.4681e-03, 1.1710e-03, 5.8252e-03,\n",
        "            1.2907e-05, 3.2088e-07, 3.0842e-05, 3.8017e-07, 4.1295e-04, 1.3378e-07,\n",
        "            2.4366e-05, 6.8855e-06, 4.9339e-03, 1.1752e-04],\n",
        "           [9.9196e-01, 7.5620e-04, 1.0928e-02, 2.5095e-03, 3.1531e-03, 1.1345e-03,\n",
        "            5.0975e-03, 6.0698e-04, 2.9537e-03, 9.2010e-03, 1.1917e-02, 5.0654e-04,\n",
        "            3.1778e-03, 1.2694e-03, 3.2910e-04, 3.3381e-03, 2.0979e-03, 2.3080e-03,\n",
        "            2.9680e-03, 6.0879e-04, 4.7353e-03, 2.4771e-04, 4.3335e-03, 1.8098e-04,\n",
        "            3.2428e-04, 1.2089e-05, 7.0763e-04, 7.8874e-04, 1.0622e-04, 2.4916e-04,\n",
        "            1.4875e-04, 2.1752e-04, 9.6084e-05, 2.1288e-05, 5.0321e-05, 1.9548e-04,\n",
        "            1.5176e-04, 2.7719e-04, 8.6102e-03, 2.8327e-04, 1.1106e-04, 3.3338e-06,\n",
        "            1.6502e-04, 8.0039e-04, 6.1670e-05, 8.9011e-05, 5.1853e-05, 2.7351e-05,\n",
        "            1.2829e-05, 6.5630e-05, 1.6897e-05, 3.1218e-05, 4.3217e-05, 1.9598e-06,\n",
        "            3.3680e-05, 2.8326e-05, 6.4276e-07, 2.3700e-05, 7.9437e-05, 3.2295e-06,\n",
        "            2.7235e-10, 1.3017e-12, 4.2544e-06, 2.8805e-07, 1.0254e-06, 1.1045e-07,\n",
        "            1.4271e-05, 4.6409e-09, 2.3543e-07, 9.5317e-06],\n",
        "           [9.7987e-01, 7.8994e-04, 6.6462e-03, 1.4080e-03, 5.5530e-03, 8.9248e-04,\n",
        "            1.6441e-02, 1.1104e-02, 6.5453e-03, 2.1828e-02, 1.2196e-02, 3.9546e-04,\n",
        "            2.7967e-02, 1.9972e-03, 2.7939e-03, 1.9343e-02, 4.4704e-03, 3.2636e-03,\n",
        "            1.5653e-03, 2.4107e-03, 1.3616e-02, 2.5608e-03, 3.5256e-03, 2.4466e-04,\n",
        "            4.3659e-03, 1.8571e-04, 1.1748e-03, 1.1705e-03, 1.6976e-03, 3.7191e-04,\n",
        "            2.2363e-03, 6.8852e-04, 2.0554e-04, 9.4437e-06, 9.6111e-05, 1.1875e-03,\n",
        "            1.0833e-03, 3.7315e-03, 1.0577e-01, 3.9400e-04, 1.4948e-03, 1.7676e-05,\n",
        "            1.9132e-02, 1.2201e-03, 5.4047e-05, 6.4156e-04, 1.1380e-03, 6.5088e-04,\n",
        "            1.2250e-05, 6.9512e-05, 9.0150e-06, 3.3984e-04, 1.7454e-04, 2.3358e-05,\n",
        "            1.8349e-03, 2.3101e-05, 5.3181e-05, 3.2365e-04, 1.0494e-03, 1.0769e-04,\n",
        "            8.3343e-08, 1.9814e-09, 1.3861e-04, 1.0134e-06, 1.1889e-05, 1.5044e-06,\n",
        "            1.1040e-05, 2.2032e-07, 2.4341e-06, 2.7393e-04],\n",
        "           [9.9230e-01, 4.7193e-04, 1.9076e-03, 4.2292e-03, 8.5849e-04, 1.8196e-03,\n",
        "            4.9086e-03, 3.0133e-03, 8.9093e-04, 1.8487e-02, 1.0243e-02, 2.8531e-04,\n",
        "            2.0719e-03, 3.3124e-03, 7.7414e-04, 1.6918e-03, 1.0916e-04, 4.7244e-03,\n",
        "            5.3392e-03, 5.7113e-03, 3.0259e-04, 5.8216e-03, 3.7759e-03, 3.4619e-03,\n",
        "            1.0404e-03, 8.0286e-06, 1.0099e-03, 2.1403e-04, 3.6702e-04, 1.2176e-04,\n",
        "            2.3793e-04, 2.7118e-04, 9.8258e-06, 4.3389e-05, 9.8251e-05, 3.5039e-04,\n",
        "            8.9767e-05, 9.8752e-04, 3.9440e-02, 6.1598e-05, 1.4125e-06, 2.8926e-05,\n",
        "            6.3514e-04, 2.9644e-05, 6.8913e-04, 2.5166e-04, 1.0258e-04, 5.5264e-05,\n",
        "            6.3620e-05, 4.6685e-05, 4.5784e-06, 2.9004e-04, 1.6681e-06, 5.5535e-05,\n",
        "            1.5027e-06, 2.7555e-04, 2.0109e-06, 9.5571e-05, 8.1740e-04, 2.5507e-05,\n",
        "            1.2645e-06, 3.2956e-10, 6.5477e-08, 3.4329e-05, 2.4663e-08, 1.2731e-07,\n",
        "            3.3983e-05, 6.4390e-10, 5.4519e-06, 4.4500e-05],\n",
        "           [9.0832e-01, 1.8994e-03, 1.0931e-02, 5.4762e-03, 4.2715e-03, 5.2758e-03,\n",
        "            2.7717e-02, 2.8136e-02, 1.4077e-02, 1.3756e-02, 3.5753e-02, 2.1862e-03,\n",
        "            6.3139e-03, 4.7063e-03, 2.3476e-03, 2.3206e-02, 2.0785e-03, 2.6589e-02,\n",
        "            9.0646e-03, 2.6196e-02, 8.1270e-03, 5.8861e-03, 5.8227e-03, 4.9764e-03,\n",
        "            6.4401e-03, 1.0649e-04, 3.0478e-02, 7.5844e-03, 9.8604e-04, 7.0881e-04,\n",
        "            7.3741e-03, 3.8665e-03, 3.8985e-04, 3.6041e-04, 8.1023e-04, 3.3049e-03,\n",
        "            7.9509e-04, 1.1444e-03, 4.3053e-02, 3.9433e-03, 2.2413e-04, 2.1553e-04,\n",
        "            1.5240e-03, 1.6055e-03, 1.9894e-03, 1.1781e-02, 1.4410e-03, 1.2348e-03,\n",
        "            1.5292e-03, 2.5591e-03, 4.8912e-04, 8.5357e-04, 3.4488e-04, 1.9332e-04,\n",
        "            2.2633e-04, 3.7053e-04, 1.0955e-04, 1.1939e-02, 3.0029e-03, 1.8780e-03,\n",
        "            1.3637e-04, 1.1832e-06, 3.8453e-05, 2.7663e-06, 5.3933e-05, 3.5091e-06,\n",
        "            5.0493e-04, 4.4092e-06, 5.1354e-05, 1.8272e-04],\n",
        "           [9.8885e-01, 1.3727e-03, 5.7090e-03, 3.1567e-03, 8.5499e-03, 8.2825e-04,\n",
        "            6.0071e-03, 3.9102e-03, 3.4022e-03, 7.8828e-03, 7.0500e-03, 1.1436e-04,\n",
        "            5.3575e-03, 5.7856e-03, 1.2795e-03, 3.8792e-03, 8.1005e-04, 4.5316e-03,\n",
        "            1.5914e-03, 4.9084e-03, 5.8578e-04, 7.9189e-03, 1.3265e-03, 2.2464e-04,\n",
        "            1.8746e-03, 3.4102e-05, 5.5989e-03, 4.1477e-04, 2.3085e-04, 3.5364e-04,\n",
        "            4.0737e-03, 5.2335e-04, 2.8245e-05, 9.5003e-06, 7.7207e-04, 1.3983e-04,\n",
        "            1.9178e-04, 3.0193e-04, 3.5936e-02, 8.0959e-05, 1.0354e-05, 3.6650e-05,\n",
        "            8.6268e-04, 6.4094e-04, 1.9247e-04, 9.8966e-05, 1.3706e-04, 6.4578e-05,\n",
        "            6.9230e-06, 8.1063e-05, 5.7618e-05, 5.5531e-04, 5.0996e-07, 2.6463e-06,\n",
        "            1.4112e-05, 3.4213e-06, 2.3674e-06, 1.3967e-04, 1.0805e-04, 2.3425e-05,\n",
        "            4.1485e-09, 9.7776e-11, 3.5177e-07, 3.8704e-07, 1.1017e-07, 4.2630e-08,\n",
        "            8.0340e-06, 2.1118e-08, 1.5624e-06, 6.3853e-06],\n",
        "           [9.8954e-01, 2.8939e-04, 1.0741e-02, 8.2862e-03, 1.1452e-03, 7.7632e-04,\n",
        "            1.8467e-02, 1.6264e-03, 1.3643e-03, 4.3277e-03, 1.4423e-02, 6.5372e-04,\n",
        "            2.3691e-03, 6.1440e-03, 2.0752e-04, 7.1565e-03, 8.4495e-04, 1.2026e-03,\n",
        "            3.7936e-03, 6.9908e-03, 3.9402e-04, 2.3372e-03, 2.0401e-03, 6.5189e-04,\n",
        "            4.2087e-04, 6.3318e-06, 9.5149e-04, 7.5711e-04, 1.3145e-03, 9.7235e-05,\n",
        "            1.4780e-04, 3.3642e-04, 1.9338e-05, 5.8517e-05, 9.2715e-05, 2.5904e-04,\n",
        "            5.1729e-04, 2.5753e-04, 1.9693e-02, 8.1326e-04, 1.0256e-05, 3.5912e-06,\n",
        "            2.3619e-04, 7.4012e-05, 1.1063e-03, 3.8132e-04, 3.0462e-04, 4.8362e-05,\n",
        "            1.1147e-05, 1.0587e-04, 8.9062e-07, 2.2201e-04, 1.7328e-05, 3.3133e-06,\n",
        "            1.5594e-05, 2.9086e-05, 3.2999e-06, 6.4217e-05, 7.4911e-04, 4.4373e-05,\n",
        "            5.2756e-09, 3.7834e-10, 4.7264e-07, 3.8912e-07, 1.7068e-07, 9.2233e-09,\n",
        "            2.9917e-03, 1.0651e-08, 5.8602e-07, 3.6079e-06],\n",
        "           [9.8424e-01, 9.0365e-04, 2.4445e-03, 1.8136e-03, 8.7461e-03, 1.0679e-03,\n",
        "            6.1520e-03, 2.3689e-03, 4.0395e-03, 2.2588e-02, 5.8938e-02, 4.3099e-04,\n",
        "            3.9421e-02, 5.0958e-03, 5.6382e-04, 1.9265e-03, 3.3991e-04, 2.3553e-03,\n",
        "            2.9025e-03, 2.7316e-04, 1.4999e-03, 6.6856e-04, 5.7405e-04, 2.5880e-03,\n",
        "            8.2976e-04, 5.3446e-05, 5.0178e-03, 5.0660e-04, 1.1517e-04, 9.6849e-04,\n",
        "            1.0235e-03, 9.2272e-04, 2.1818e-04, 2.4500e-05, 7.4945e-04, 9.9555e-05,\n",
        "            1.1687e-04, 1.3989e-03, 2.0628e-01, 3.2720e-05, 6.5805e-06, 3.4260e-05,\n",
        "            4.2007e-03, 4.7242e-03, 2.3898e-04, 1.3284e-03, 3.1585e-04, 1.2887e-04,\n",
        "            1.7730e-05, 3.7262e-04, 8.2502e-05, 3.7296e-03, 1.7709e-06, 1.7870e-06,\n",
        "            1.0872e-05, 3.7882e-04, 4.2823e-06, 8.2043e-04, 2.2338e-04, 7.7749e-04,\n",
        "            3.2136e-08, 2.5192e-09, 6.4936e-05, 8.7478e-07, 2.0086e-05, 5.7712e-07,\n",
        "            4.6454e-06, 2.9930e-08, 7.0172e-03, 1.5706e-05],\n",
        "           [9.8548e-01, 1.9650e-04, 3.6023e-03, 5.2566e-03, 1.5636e-03, 2.3546e-03,\n",
        "            2.1571e-03, 5.7070e-04, 4.1221e-04, 1.8941e-02, 1.0663e-02, 3.7399e-04,\n",
        "            2.3593e-03, 2.1519e-03, 1.4320e-04, 2.7124e-03, 7.0651e-04, 5.9558e-04,\n",
        "            8.0140e-04, 1.2325e-03, 3.5172e-04, 2.1321e-03, 1.5162e-03, 3.3066e-04,\n",
        "            5.2167e-04, 5.1263e-06, 8.0268e-04, 2.7849e-04, 7.5599e-05, 3.6317e-04,\n",
        "            1.5916e-04, 4.3022e-04, 1.1486e-05, 5.5644e-05, 9.2545e-05, 2.6607e-04,\n",
        "            9.4423e-05, 2.8327e-04, 1.7717e-02, 4.2204e-05, 3.7862e-06, 4.4863e-06,\n",
        "            3.4057e-04, 2.1663e-04, 2.4661e-04, 4.8961e-04, 8.3549e-06, 5.6354e-06,\n",
        "            1.6292e-05, 3.4031e-04, 1.1413e-06, 1.7213e-04, 3.0257e-06, 2.2644e-05,\n",
        "            6.4829e-06, 2.0097e-05, 4.8991e-07, 4.9899e-05, 5.1483e-05, 9.4590e-05,\n",
        "            3.5636e-10, 1.8385e-10, 1.7914e-07, 9.5554e-07, 8.5140e-08, 7.4000e-09,\n",
        "            1.4123e-04, 6.7958e-09, 8.0634e-06, 5.8017e-05],\n",
        "           [9.9192e-01, 5.6493e-04, 4.9520e-03, 1.4429e-03, 2.6767e-03, 1.4205e-03,\n",
        "            7.8564e-03, 5.4979e-04, 3.1560e-04, 9.1379e-03, 2.7823e-03, 3.8627e-04,\n",
        "            3.7398e-03, 1.5782e-03, 1.3546e-04, 1.5748e-03, 1.2137e-03, 6.5007e-04,\n",
        "            3.3074e-03, 9.6911e-04, 5.8533e-04, 1.1540e-03, 4.0835e-03, 9.9595e-05,\n",
        "            4.9455e-04, 4.7793e-06, 9.1118e-05, 1.1288e-04, 3.1804e-04, 3.3429e-04,\n",
        "            3.4498e-05, 8.3799e-05, 1.7857e-05, 5.6389e-05, 5.7649e-05, 5.1703e-04,\n",
        "            2.9302e-04, 8.6357e-05, 2.2601e-02, 6.2423e-05, 9.0900e-06, 1.2600e-06,\n",
        "            9.1165e-05, 7.0348e-05, 3.5854e-04, 2.5992e-05, 2.8807e-05, 5.9679e-05,\n",
        "            5.6441e-06, 3.0570e-05, 7.9625e-07, 1.0975e-04, 1.6818e-05, 2.5030e-06,\n",
        "            6.5377e-07, 3.9032e-06, 2.8541e-06, 2.3156e-05, 3.1662e-05, 6.4762e-06,\n",
        "            1.4215e-08, 1.1911e-11, 1.8001e-06, 4.6508e-08, 1.8522e-08, 1.2346e-09,\n",
        "            4.3514e-05, 1.0627e-08, 1.5725e-07, 1.8695e-06]],\n",
        "   [[9.9968e-01, 1.7206e-05, 1.4568e-07, 8.4414e-05, 1.2062e-05, 3.6473e-07,\n",
        "            1.6839e-06, 3.1264e-07, 2.4113e-04, 1.3128e-04, 2.6141e-03, 2.4215e-07,\n",
        "            1.4479e-06, 9.8740e-02, 6.1901e-06, 1.2801e-06, 1.6783e-07, 5.4892e-06,\n",
        "            1.9132e-06, 1.2049e-04, 1.4893e-05, 4.3437e-03, 1.6282e-05, 4.9748e-03,\n",
        "            1.3588e-03, 1.9623e-05, 5.8514e-05, 4.5638e-06, 3.4070e-06, 2.5184e-05,\n",
        "            5.5928e-08, 5.2856e-03, 4.8725e-08, 5.2468e-09, 2.4018e-05, 1.0373e-08,\n",
        "            2.3106e-07, 2.3386e-04, 2.7388e-03, 4.0262e-07, 3.0641e-09, 1.3008e-06,\n",
        "            8.4487e-05, 3.8236e-04, 6.9968e-06, 1.8346e-06, 2.4850e-07, 2.3220e-07,\n",
        "            1.6114e-06, 1.9207e-04, 4.0428e-05, 2.4794e-03, 2.3022e-07, 3.2831e-08,\n",
        "            2.5402e-06, 2.1909e-03, 4.7453e-08, 3.1543e-05, 1.7843e-04, 6.0016e-04],\n",
        "           [1.0000e+00, 4.9232e-08, 1.8345e-08, 8.4629e-08, 5.1455e-08, 7.2885e-11,\n",
        "            1.8108e-08, 1.9561e-11, 7.5899e-07, 4.4762e-07, 2.1964e-04, 1.7669e-06,\n",
        "            6.5824e-07, 9.2186e-05, 2.7546e-07, 2.7400e-06, 3.2523e-07, 5.2348e-09,\n",
        "            1.6319e-05, 9.0610e-05, 6.7801e-05, 3.1289e-06, 2.6579e-07, 3.0629e-07,\n",
        "            3.3797e-04, 1.3052e-06, 3.7455e-07, 4.4167e-07, 3.8998e-07, 7.2200e-07,\n",
        "            6.2504e-08, 2.1888e-05, 1.1396e-08, 3.7373e-09, 1.1853e-06, 2.0932e-08,\n",
        "            7.0879e-07, 1.2781e-05, 6.0520e-04, 1.8080e-05, 6.8710e-10, 1.5846e-07,\n",
        "            5.2232e-08, 1.1324e-02, 2.8142e-08, 4.4746e-09, 1.1562e-08, 2.8121e-07,\n",
        "            7.8335e-10, 2.4104e-08, 3.1458e-07, 4.0459e-05, 8.3169e-06, 1.1347e-07,\n",
        "            2.6894e-06, 1.5514e-06, 1.0831e-09, 3.2044e-06, 2.1133e-07, 2.0980e-09],\n",
        "           [1.0000e+00, 1.4694e-08, 1.0133e-09, 1.2285e-05, 1.8761e-06, 1.5885e-09,\n",
        "            2.7029e-08, 5.5520e-09, 3.9986e-07, 1.0920e-06, 2.1007e-07, 1.6859e-08,\n",
        "            2.5917e-05, 1.7853e-08, 1.4163e-06, 9.4081e-05, 4.5084e-09, 2.9886e-10,\n",
        "            6.8294e-10, 2.2616e-10, 1.1561e-03, 7.0847e-04, 9.1924e-06, 4.5267e-07,\n",
        "            6.9889e-05, 2.5238e-05, 7.5730e-06, 9.2215e-05, 8.0055e-06, 2.1653e-06,\n",
        "            6.5114e-05, 9.5950e-04, 7.4653e-09, 1.4009e-08, 8.6728e-06, 4.5994e-07,\n",
        "            8.1604e-06, 3.5153e-03, 3.6552e-03, 4.5380e-06, 1.1563e-07, 1.2597e-07,\n",
        "            3.4687e-04, 1.5343e-05, 3.0789e-07, 8.7786e-06, 7.4151e-06, 1.0214e-05,\n",
        "            3.4308e-08, 8.5246e-06, 1.1075e-06, 1.2720e-04, 3.1545e-06, 2.3391e-06,\n",
        "            1.1398e-04, 1.0813e-04, 2.5281e-06, 8.3600e-05, 4.2243e-06, 2.2473e-07],\n",
        "           [1.0000e+00, 2.2976e-09, 9.5791e-10, 1.6321e-08, 2.7984e-10, 1.2582e-11,\n",
        "            3.5014e-09, 4.6045e-12, 3.4037e-08, 4.0854e-09, 1.5339e-04, 1.5164e-07,\n",
        "            3.6675e-07, 3.4443e-05, 1.7264e-07, 9.0294e-09, 1.0631e-08, 7.7198e-10,\n",
        "            1.6304e-04, 2.9996e-06, 1.6512e-09, 1.5236e-05, 3.3539e-08, 4.3087e-05,\n",
        "            6.3458e-06, 5.5138e-07, 5.6833e-08, 2.0346e-08, 4.8090e-07, 1.5130e-10,\n",
        "            2.9775e-08, 2.1385e-06, 3.0356e-10, 8.8338e-10, 2.9066e-06, 6.1674e-09,\n",
        "            9.7521e-07, 7.2482e-07, 3.1162e-03, 8.5989e-07, 3.9652e-12, 1.3471e-07,\n",
        "            6.8470e-07, 1.4679e-07, 2.3124e-06, 9.7684e-09, 2.0764e-07, 1.5219e-07,\n",
        "            1.7096e-09, 7.2666e-09, 1.4197e-09, 4.4462e-06, 3.4561e-10, 5.6571e-06,\n",
        "            5.2054e-08, 2.6149e-07, 8.4463e-10, 1.5666e-05, 8.4116e-05, 3.8859e-08],\n",
        "           [9.9995e-01, 7.0282e-07, 6.4608e-05, 1.7178e-05, 5.8516e-06, 1.1210e-07,\n",
        "            2.0330e-06, 1.6241e-07, 3.1625e-06, 1.1837e-06, 7.8761e-04, 4.8970e-07,\n",
        "            6.7472e-06, 9.6940e-07, 1.0227e-06, 2.2291e-06, 2.8287e-05, 5.6318e-05,\n",
        "            8.4620e-04, 3.2112e-04, 1.5857e-02, 1.8949e-06, 2.4766e-06, 1.1186e-03,\n",
        "            2.0443e-04, 6.0270e-07, 8.7567e-05, 7.7783e-05, 8.2623e-07, 6.1146e-08,\n",
        "            2.3263e-03, 2.9905e-06, 5.4144e-09, 3.2838e-09, 5.8866e-06, 1.1277e-07,\n",
        "            1.2968e-06, 1.2475e-05, 9.4444e-04, 3.7956e-05, 1.4509e-07, 2.4816e-07,\n",
        "            5.3636e-06, 3.6281e-05, 2.5063e-06, 5.6124e-03, 7.1182e-06, 4.5980e-06,\n",
        "            2.6416e-06, 4.2101e-04, 1.3581e-06, 8.8518e-06, 6.0118e-05, 9.7585e-06,\n",
        "            5.3817e-07, 5.7680e-06, 3.4097e-08, 1.6159e-03, 1.6987e-04, 7.6961e-05],\n",
        "           [1.0000e+00, 1.6764e-08, 2.0333e-09, 5.0270e-06, 6.3536e-09, 7.3294e-09,\n",
        "            5.6408e-10, 2.6849e-10, 2.1498e-08, 8.7252e-08, 3.4000e-07, 1.3743e-07,\n",
        "            1.8756e-08, 1.5674e-07, 4.3994e-06, 3.8385e-08, 1.1679e-07, 1.3176e-08,\n",
        "            4.7601e-08, 5.9795e-06, 8.2634e-07, 3.3670e-03, 1.1737e-07, 7.4426e-06,\n",
        "            1.0279e-03, 1.6013e-05, 7.4593e-05, 7.5997e-07, 2.9784e-05, 1.7308e-06,\n",
        "            1.6536e-06, 2.1980e-05, 2.5333e-09, 6.7790e-09, 9.6094e-04, 2.6920e-08,\n",
        "            1.0421e-07, 1.2366e-05, 3.5937e-04, 1.3101e-06, 5.9223e-12, 1.0582e-06,\n",
        "            5.0207e-07, 3.1304e-04, 7.4096e-07, 1.2826e-09, 3.7476e-07, 1.6902e-07,\n",
        "            7.6546e-09, 5.0803e-07, 8.8897e-08, 5.6808e-05, 1.0511e-09, 1.8759e-06,\n",
        "            1.1518e-07, 7.2294e-08, 1.3147e-08, 1.0474e-05, 4.3657e-06, 7.3055e-07],\n",
        "           [1.0000e+00, 7.1896e-10, 1.1613e-09, 1.3308e-08, 2.8522e-10, 8.8830e-13,\n",
        "            1.7202e-08, 3.8996e-14, 2.5088e-10, 4.6892e-09, 1.1360e-07, 1.6509e-06,\n",
        "            1.0352e-08, 3.4656e-07, 3.0760e-10, 1.4912e-11, 2.1520e-09, 6.1863e-12,\n",
        "            9.1983e-07, 6.0009e-07, 1.8064e-08, 6.6521e-07, 1.5204e-05, 4.6068e-08,\n",
        "            3.0187e-05, 4.2122e-07, 1.5096e-08, 3.0433e-08, 9.8407e-07, 1.2572e-08,\n",
        "            1.4075e-09, 2.5259e-05, 1.2667e-10, 3.3238e-09, 4.4602e-06, 3.2124e-06,\n",
        "            4.1917e-05, 4.9502e-08, 1.2138e-04, 6.2943e-07, 2.9188e-10, 4.0393e-07,\n",
        "            9.1621e-08, 4.0542e-05, 4.0177e-05, 9.7128e-07, 4.6288e-07, 2.4331e-06,\n",
        "            9.8961e-08, 7.0153e-07, 1.5918e-09, 1.0881e-05, 1.6008e-06, 7.7525e-07,\n",
        "            3.8078e-07, 1.2301e-07, 9.0307e-09, 2.7103e-06, 1.9539e-05, 7.9116e-08],\n",
        "           [1.0000e+00, 5.5563e-07, 1.3321e-09, 1.7945e-06, 1.0319e-07, 6.2541e-10,\n",
        "            9.0350e-08, 1.1229e-09, 3.7719e-07, 6.4339e-07, 9.0582e-05, 8.6594e-07,\n",
        "            6.6746e-04, 3.4156e-05, 2.0909e-07, 1.6511e-07, 4.1650e-08, 3.8062e-06,\n",
        "            1.7425e-05, 3.2503e-07, 3.3499e-06, 1.6568e-05, 1.0242e-06, 3.5275e-07,\n",
        "            3.1746e-06, 2.2717e-05, 3.0823e-03, 7.4670e-06, 1.1792e-06, 1.9805e-07,\n",
        "            2.7259e-06, 2.2173e-04, 2.0983e-08, 6.1300e-09, 1.9711e-05, 4.8493e-08,\n",
        "            1.4497e-06, 8.6237e-07, 3.8299e-02, 9.2404e-08, 1.4208e-10, 2.2442e-09,\n",
        "            7.2001e-05, 2.9413e-05, 1.4165e-06, 2.0306e-06, 2.0595e-05, 3.6205e-06,\n",
        "            3.0029e-09, 2.3811e-06, 3.1844e-07, 5.7643e-02, 1.0473e-08, 3.6804e-08,\n",
        "            3.0536e-08, 3.3364e-05, 3.9072e-08, 2.0740e-04, 7.0394e-05, 1.1587e-06],\n",
        "           [9.9999e-01, 2.2219e-08, 1.9896e-09, 2.8420e-06, 2.3417e-06, 1.0594e-09,\n",
        "            7.0712e-10, 2.5895e-11, 6.9810e-08, 1.4510e-05, 2.0317e-07, 2.3722e-08,\n",
        "            1.3871e-09, 1.2557e-06, 9.0635e-09, 1.8267e-08, 4.9185e-08, 1.3438e-10,\n",
        "            4.0021e-07, 7.5835e-06, 4.2334e-07, 9.2314e-06, 3.3440e-08, 8.6371e-10,\n",
        "            3.5014e-06, 1.2824e-07, 1.2819e-07, 4.2122e-07, 3.6333e-09, 8.9731e-05,\n",
        "            1.5174e-08, 5.3283e-07, 1.1248e-11, 3.1840e-10, 5.1602e-06, 3.3125e-09,\n",
        "            5.7798e-07, 9.8888e-07, 2.7515e-04, 1.5437e-08, 3.4590e-11, 1.4438e-09,\n",
        "            1.4081e-07, 4.6058e-05, 4.0230e-07, 1.0568e-08, 9.8126e-11, 3.8158e-10,\n",
        "            2.2561e-09, 7.5536e-07, 1.5315e-08, 1.5854e-04, 1.6941e-07, 4.7005e-07,\n",
        "            3.8005e-08, 4.1600e-06, 3.5966e-10, 6.2817e-07, 6.3055e-09, 4.8681e-07],\n",
        "           [1.0000e+00, 3.6234e-08, 8.3495e-08, 8.7862e-08, 2.9489e-08, 2.6652e-10,\n",
        "            4.8580e-09, 2.1569e-12, 5.9351e-09, 2.0739e-07, 3.1349e-08, 1.4274e-06,\n",
        "            4.2774e-09, 5.7307e-07, 3.0923e-09, 6.1393e-08, 8.1212e-08, 9.6838e-11,\n",
        "            1.4631e-06, 3.4028e-07, 2.7367e-08, 2.1152e-06, 5.8077e-09, 1.2873e-07,\n",
        "            4.9948e-06, 6.9965e-07, 1.1300e-09, 3.6716e-08, 1.8298e-06, 2.1394e-06,\n",
        "            1.0814e-10, 2.9016e-07, 2.4071e-11, 5.9327e-09, 1.2582e-06, 8.3965e-09,\n",
        "            3.8752e-07, 1.4718e-07, 7.4282e-06, 3.7510e-07, 3.3430e-11, 1.1491e-08,\n",
        "            2.2171e-09, 5.2087e-05, 2.1325e-06, 4.1989e-09, 7.8486e-09, 8.6940e-08,\n",
        "            1.1132e-09, 6.8157e-08, 8.8158e-10, 8.7358e-07, 5.1818e-08, 6.1939e-08,\n",
        "            2.7854e-09, 3.6010e-08, 7.9968e-09, 1.6058e-06, 4.2558e-08, 4.5688e-09]]],\n",
        "  8: [[[9.4308e-01, 1.6969e-03, 5.9912e-03, 7.7871e-03, 7.6981e-03, 4.0134e-03,\n",
        "            5.3719e-03, 9.4514e-03, 5.6826e-03, 8.1009e-02, 9.9040e-02, 1.0702e-03,\n",
        "            9.7548e-03, 1.4392e-02, 4.4638e-03, 7.5678e-03, 8.5898e-04, 2.4414e-03,\n",
        "            3.7499e-03, 7.4997e-03, 3.0166e-03, 1.1859e-02, 3.1481e-03, 5.3400e-03,\n",
        "            6.0824e-03, 3.1031e-04, 5.7328e-03, 4.7787e-04, 1.4566e-03, 1.9095e-03,\n",
        "            1.7848e-03, 3.4384e-03, 4.2011e-04, 2.9418e-04, 4.5399e-04, 1.2405e-03,\n",
        "            5.8337e-04, 7.6111e-03, 2.5756e-01, 1.3418e-04, 9.7953e-05, 3.5410e-04,\n",
        "            2.0313e-02, 3.7419e-03, 8.7271e-04, 2.8698e-03, 4.9797e-04, 1.5055e-04,\n",
        "            9.4158e-04, 1.0160e-03, 2.8769e-04, 2.3280e-03, 2.7061e-04, 3.2206e-04,\n",
        "            1.5732e-04, 2.1350e-03, 2.1308e-05, 5.3195e-04, 1.9381e-03, 8.0356e-03,\n",
        "            2.3347e-04, 1.1151e-05, 1.3145e-04, 2.7028e-05, 3.1019e-04, 3.1652e-05,\n",
        "            8.9817e-05, 1.0662e-04, 7.3734e-03, 4.7453e-04, 7.4809e-07, 1.3428e-07,\n",
        "            1.3304e-02, 2.6540e-07, 1.6141e-03, 3.6877e-09, 2.3556e-06, 1.8352e-05,\n",
        "            1.3258e-07, 1.4701e-04],\n",
        "           [9.8614e-01, 1.3109e-03, 2.3581e-02, 2.8633e-03, 3.4635e-03, 5.4196e-04,\n",
        "            1.1078e-02, 2.6177e-03, 8.0909e-03, 1.7301e-02, 2.3387e-02, 7.5468e-04,\n",
        "            1.3108e-02, 2.3864e-03, 1.0746e-03, 9.3913e-03, 2.5175e-03, 5.1850e-03,\n",
        "            3.3855e-03, 1.8511e-03, 7.6959e-03, 4.6336e-04, 2.0646e-02, 3.1522e-04,\n",
        "            7.1016e-04, 1.7143e-04, 4.0537e-03, 2.6275e-03, 4.9364e-04, 4.5354e-04,\n",
        "            1.7128e-03, 5.4326e-04, 6.8678e-04, 1.1202e-04, 2.1386e-04, 2.7407e-04,\n",
        "            1.2437e-03, 1.0241e-03, 3.0655e-02, 1.2360e-03, 2.2197e-03, 5.1814e-05,\n",
        "            4.6510e-04, 1.4973e-03, 1.1095e-04, 1.3456e-03, 1.5145e-03, 2.9357e-04,\n",
        "            2.3912e-05, 2.1774e-04, 4.7227e-04, 8.9019e-05, 3.2083e-04, 1.0866e-04,\n",
        "            3.2388e-03, 2.4704e-05, 2.4539e-05, 3.5199e-04, 1.0930e-03, 6.0589e-05,\n",
        "            5.1857e-07, 4.1612e-07, 1.8316e-04, 1.5397e-06, 1.0723e-04, 9.3734e-05,\n",
        "            4.7403e-04, 8.1533e-06, 1.2129e-05, 8.1942e-05, 2.6935e-06, 2.1854e-07,\n",
        "            1.1101e-05, 5.8804e-06, 8.2557e-09, 1.4009e-08, 5.9229e-07, 7.0805e-05,\n",
        "            1.2628e-09, 1.6259e-04],\n",
        "           [9.7506e-01, 3.4857e-04, 4.9763e-03, 6.8546e-04, 1.9751e-03, 6.6709e-04,\n",
        "            8.9399e-03, 1.9615e-02, 1.3287e-03, 5.2062e-02, 5.4385e-03, 2.8854e-04,\n",
        "            4.2968e-02, 5.8006e-04, 2.5112e-03, 8.0352e-03, 4.5674e-03, 1.6635e-03,\n",
        "            5.8377e-04, 1.9902e-03, 7.0493e-03, 3.8869e-03, 1.1303e-02, 7.0578e-05,\n",
        "            1.7068e-03, 1.4674e-04, 5.8585e-04, 1.9257e-04, 5.6884e-04, 5.6808e-04,\n",
        "            1.2225e-03, 3.4660e-04, 1.4171e-04, 1.3538e-05, 1.0156e-04, 1.0623e-03,\n",
        "            3.9055e-04, 6.8619e-03, 4.5121e-02, 1.0391e-04, 1.5231e-03, 8.3916e-05,\n",
        "            1.4735e-02, 6.1479e-04, 5.3245e-05, 1.1123e-04, 2.9211e-04, 3.1605e-04,\n",
        "            1.9758e-05, 1.2004e-04, 5.9385e-05, 2.7985e-04, 1.7485e-04, 1.1516e-04,\n",
        "            7.7251e-04, 9.1372e-05, 1.0154e-04, 2.5761e-05, 3.4242e-04, 1.2907e-04,\n",
        "            2.1913e-06, 2.6451e-07, 2.3497e-05, 3.4841e-06, 3.9611e-05, 1.9381e-04,\n",
        "            4.2797e-05, 8.6658e-05, 2.7293e-06, 4.9324e-04, 1.5405e-08, 9.5821e-08,\n",
        "            2.4224e-07, 8.7743e-07, 2.2753e-06, 5.3442e-10, 3.8053e-07, 1.9672e-06,\n",
        "            1.2582e-09, 2.7128e-05],\n",
        "           [9.9640e-01, 2.6567e-04, 1.8002e-03, 2.0001e-03, 8.4633e-04, 3.0770e-04,\n",
        "            2.8799e-03, 4.2715e-03, 1.8848e-04, 6.0365e-03, 1.5689e-02, 5.2775e-05,\n",
        "            8.0091e-04, 1.5645e-03, 2.7999e-04, 1.6630e-03, 7.1387e-05, 2.3579e-03,\n",
        "            1.9265e-03, 3.4511e-03, 6.9285e-05, 2.4253e-03, 2.7793e-03, 3.6616e-04,\n",
        "            2.9953e-04, 8.0784e-06, 1.1869e-03, 4.4884e-04, 1.2092e-04, 4.0874e-05,\n",
        "            2.5802e-04, 3.6141e-05, 1.8409e-05, 1.6313e-05, 5.3640e-05, 5.5259e-05,\n",
        "            1.5037e-04, 4.1542e-04, 3.5054e-02, 2.0558e-05, 2.4229e-06, 2.0095e-05,\n",
        "            9.3623e-05, 1.1257e-05, 1.4662e-04, 8.2610e-04, 1.0124e-04, 7.6018e-06,\n",
        "            9.7077e-06, 1.0598e-05, 8.3791e-06, 1.7474e-05, 1.9134e-06, 9.8064e-05,\n",
        "            2.1462e-05, 9.4141e-06, 3.7127e-07, 4.2563e-05, 4.1562e-04, 1.2305e-05,\n",
        "            4.8750e-07, 3.6269e-07, 9.8981e-07, 5.4176e-07, 6.5592e-08, 1.2070e-06,\n",
        "            8.4304e-05, 2.1658e-08, 9.5094e-06, 8.5164e-06, 1.9862e-08, 1.0607e-09,\n",
        "            2.0617e-05, 2.3985e-13, 3.6201e-10, 3.2427e-10, 6.0987e-10, 1.2066e-06,\n",
        "            2.9872e-10, 4.5776e-07],\n",
        "           [9.3289e-01, 1.0347e-03, 1.3682e-02, 4.8397e-03, 1.8752e-03, 7.3559e-03,\n",
        "            1.5574e-02, 2.3430e-02, 2.9477e-03, 2.4397e-02, 4.1962e-02, 7.7097e-03,\n",
        "            1.4922e-02, 3.1829e-03, 1.0936e-03, 5.8982e-03, 1.6160e-03, 1.8386e-02,\n",
        "            6.6610e-03, 7.0568e-03, 3.7405e-03, 2.3052e-03, 2.1268e-02, 5.1727e-03,\n",
        "            2.8095e-03, 1.0398e-04, 3.1916e-02, 3.9524e-03, 3.7544e-04, 4.5887e-04,\n",
        "            4.6738e-03, 1.1746e-03, 4.1528e-04, 1.1257e-03, 6.2506e-04, 7.8318e-03,\n",
        "            2.6489e-04, 9.6526e-04, 2.9644e-02, 3.1875e-03, 3.6397e-04, 4.0686e-04,\n",
        "            2.6843e-03, 7.0045e-04, 5.3003e-03, 2.9844e-03, 5.4218e-04, 1.2781e-03,\n",
        "            9.9652e-04, 9.4193e-04, 1.1848e-03, 1.7557e-03, 1.0044e-03, 6.5308e-04,\n",
        "            1.6863e-04, 9.5998e-04, 5.7496e-05, 1.0624e-03, 5.1361e-04, 2.8266e-03,\n",
        "            8.8471e-04, 2.5800e-05, 4.3461e-04, 2.0876e-05, 2.1553e-04, 1.1055e-05,\n",
        "            1.4866e-03, 2.5562e-04, 1.5243e-04, 1.1961e-04, 3.4258e-05, 1.8247e-06,\n",
        "            2.1950e-02, 1.4494e-06, 1.3393e-05, 4.5445e-08, 1.0348e-06, 7.5068e-04,\n",
        "            5.5829e-05, 1.8235e-04],\n",
        "           [9.9697e-01, 3.5543e-04, 2.1695e-03, 1.4785e-03, 3.5847e-03, 1.9473e-04,\n",
        "            1.2015e-03, 1.0719e-02, 6.9820e-04, 1.2981e-02, 3.4615e-03, 5.8750e-05,\n",
        "            2.8948e-03, 1.6494e-03, 4.6231e-03, 2.5263e-03, 1.4800e-04, 1.8093e-03,\n",
        "            3.4402e-04, 3.4637e-03, 1.1184e-04, 1.1756e-02, 1.2407e-03, 6.3130e-05,\n",
        "            2.7526e-03, 1.5619e-05, 9.1998e-03, 1.2146e-04, 2.1486e-04, 5.5411e-05,\n",
        "            9.8402e-03, 1.0103e-04, 1.4937e-05, 6.1835e-06, 3.4123e-04, 6.3220e-05,\n",
        "            4.0809e-05, 4.0106e-04, 8.6366e-02, 9.3403e-06, 4.7638e-06, 3.8060e-05,\n",
        "            1.8342e-03, 1.5472e-04, 7.0752e-05, 1.2220e-04, 7.5213e-05, 2.8026e-05,\n",
        "            6.0273e-06, 1.7682e-05, 8.4249e-05, 1.8579e-04, 8.7102e-07, 7.1981e-05,\n",
        "            1.8223e-05, 1.3055e-05, 2.1570e-06, 5.5885e-05, 6.2582e-05, 5.2499e-05,\n",
        "            6.2635e-07, 2.2007e-08, 6.0380e-07, 1.5160e-06, 6.5129e-07, 2.5839e-06,\n",
        "            2.7779e-05, 1.7704e-06, 4.6159e-06, 2.0202e-04, 3.1799e-09, 5.8062e-08,\n",
        "            4.3848e-07, 2.2538e-12, 5.3948e-07, 1.2322e-11, 1.1078e-09, 1.6958e-06,\n",
        "            6.1675e-12, 5.2219e-08],\n",
        "           [9.7552e-01, 5.5669e-04, 9.4657e-03, 1.3676e-02, 2.8971e-03, 7.0937e-04,\n",
        "            4.1131e-02, 2.8965e-03, 3.0524e-03, 1.3358e-02, 1.5802e-02, 6.5910e-04,\n",
        "            8.3502e-03, 7.4768e-03, 4.7061e-04, 2.4831e-02, 1.2145e-03, 2.1089e-03,\n",
        "            4.7546e-03, 8.6874e-03, 9.2459e-04, 2.2042e-03, 4.5602e-03, 1.3997e-03,\n",
        "            9.9126e-04, 4.3680e-05, 2.5652e-03, 1.0091e-03, 2.1285e-03, 3.6776e-04,\n",
        "            1.1618e-03, 1.2505e-03, 1.2874e-04, 8.4205e-05, 3.6129e-04, 2.1783e-04,\n",
        "            8.3247e-04, 1.2992e-03, 2.5521e-02, 1.1555e-03, 2.3192e-04, 4.8420e-05,\n",
        "            8.1090e-04, 2.7718e-04, 6.8667e-04, 7.7522e-04, 1.8561e-03, 1.7379e-04,\n",
        "            3.1222e-05, 5.2692e-04, 1.5029e-04, 1.9915e-04, 3.4502e-05, 1.7612e-05,\n",
        "            9.7630e-04, 1.7281e-04, 3.1181e-05, 3.7020e-05, 5.5331e-03, 8.6949e-05,\n",
        "            1.6553e-06, 2.0765e-06, 1.9343e-05, 1.0492e-06, 8.6678e-06, 5.3782e-05,\n",
        "            1.4433e-03, 1.7002e-05, 1.0023e-05, 7.5087e-05, 1.1457e-07, 4.0293e-09,\n",
        "            2.9606e-05, 3.2416e-08, 9.0236e-08, 1.4502e-09, 2.9475e-06, 1.3442e-06,\n",
        "            3.9773e-07, 2.6272e-04],\n",
        "           [9.8623e-01, 1.5408e-03, 4.0136e-03, 4.0613e-03, 1.1700e-02, 6.5664e-04,\n",
        "            1.0600e-02, 1.5150e-03, 2.6056e-03, 1.0542e-02, 9.7740e-02, 3.3390e-04,\n",
        "            1.8806e-02, 6.6977e-03, 4.8392e-04, 1.0928e-03, 4.8447e-04, 4.5067e-03,\n",
        "            7.9382e-03, 1.2399e-04, 1.7015e-03, 2.7596e-04, 5.9472e-04, 1.5292e-03,\n",
        "            4.5262e-04, 1.1377e-04, 6.3861e-03, 1.2976e-03, 8.1816e-05, 5.5422e-04,\n",
        "            7.1714e-04, 5.8742e-04, 5.6105e-04, 6.1204e-05, 5.9289e-04, 4.0549e-05,\n",
        "            5.4340e-04, 1.0452e-03, 2.1746e-01, 6.5626e-05, 3.4902e-05, 2.7803e-05,\n",
        "            9.1804e-04, 1.8542e-03, 2.2960e-04, 3.4032e-03, 4.0867e-04, 1.6612e-04,\n",
        "            1.1744e-05, 3.4709e-04, 3.9256e-04, 8.8260e-04, 2.3130e-05, 9.0323e-06,\n",
        "            8.4167e-05, 6.6294e-05, 4.0767e-06, 7.8251e-04, 4.0892e-04, 2.8875e-04,\n",
        "            3.1360e-06, 3.7472e-07, 3.4380e-04, 1.1417e-06, 5.2409e-05, 2.6125e-05,\n",
        "            1.4929e-05, 1.1255e-06, 8.7731e-03, 3.0006e-05, 1.0613e-07, 6.9378e-08,\n",
        "            5.2592e-03, 1.2557e-08, 7.8866e-06, 1.4724e-09, 3.1680e-09, 7.4911e-06,\n",
        "            8.9183e-09, 3.7546e-04],\n",
        "           [9.5387e-01, 3.3404e-04, 8.9344e-03, 2.6458e-03, 3.6143e-03, 4.5346e-03,\n",
        "            8.3959e-03, 2.1969e-03, 2.9310e-04, 2.7054e-02, 7.8259e-03, 8.0912e-04,\n",
        "            1.3685e-02, 1.5001e-03, 3.8254e-04, 2.8098e-03, 3.7324e-03, 9.2694e-04,\n",
        "            2.0364e-03, 1.4548e-03, 4.5294e-04, 3.1652e-03, 3.2496e-03, 2.2252e-04,\n",
        "            3.3608e-04, 4.6761e-05, 1.0825e-03, 3.5805e-04, 1.1403e-04, 4.8048e-04,\n",
        "            3.5857e-04, 1.5948e-04, 4.6703e-05, 4.6151e-04, 1.9173e-04, 3.3050e-04,\n",
        "            3.5905e-04, 2.1847e-03, 2.4816e-02, 1.1189e-04, 4.2059e-05, 1.7205e-05,\n",
        "            1.0523e-03, 2.7015e-04, 9.1240e-04, 4.5941e-04, 5.8846e-05, 1.1348e-04,\n",
        "            8.1502e-05, 4.1294e-04, 6.2991e-05, 4.4064e-04, 9.0456e-05, 8.1902e-05,\n",
        "            4.0000e-05, 4.2559e-04, 7.0318e-06, 2.7837e-05, 5.5091e-05, 3.3218e-04,\n",
        "            1.5775e-05, 3.3992e-07, 3.3222e-05, 3.1758e-06, 7.7171e-06, 3.6471e-05,\n",
        "            2.6756e-04, 3.0801e-05, 6.1091e-05, 9.0575e-05, 4.5713e-07, 1.9000e-09,\n",
        "            2.0763e-04, 2.2204e-08, 5.4442e-06, 2.2117e-10, 4.1531e-07, 1.0570e-05,\n",
        "            6.7734e-08, 7.0005e-05],\n",
        "           [9.8495e-01, 3.6151e-04, 1.4496e-03, 4.9361e-03, 1.3440e-03, 1.1974e-03,\n",
        "            5.4756e-03, 7.0155e-04, 4.3430e-04, 1.4952e-02, 2.2941e-03, 3.6386e-04,\n",
        "            5.1396e-03, 2.9121e-03, 8.5587e-05, 5.0929e-03, 2.6420e-04, 6.8767e-04,\n",
        "            1.4737e-03, 2.4386e-03, 9.8128e-05, 1.1433e-03, 9.1509e-04, 3.9278e-04,\n",
        "            3.2023e-04, 8.2986e-06, 6.6888e-04, 2.3251e-04, 3.3236e-04, 2.8164e-04,\n",
        "            2.1553e-04, 3.6256e-04, 2.6539e-05, 1.7148e-04, 8.2073e-05, 5.3300e-05,\n",
        "            1.0865e-04, 1.1269e-04, 2.5624e-02, 7.6121e-05, 1.7117e-05, 2.9619e-06,\n",
        "            8.5169e-05, 1.1078e-04, 3.1709e-04, 4.1681e-04, 4.7920e-05, 3.5512e-05,\n",
        "            1.5193e-05, 1.3317e-04, 1.1340e-05, 5.1034e-05, 1.3419e-05, 2.0641e-06,\n",
        "            1.1496e-05, 1.0110e-04, 5.6679e-06, 6.5519e-05, 3.9253e-05, 8.3295e-05,\n",
        "            1.5831e-06, 1.0931e-07, 3.2359e-06, 2.7279e-08, 4.9753e-06, 1.1016e-06,\n",
        "            1.3243e-04, 6.2487e-06, 1.8121e-06, 2.6639e-05, 4.5007e-08, 1.1243e-09,\n",
        "            4.3933e-05, 8.1461e-09, 2.4160e-08, 4.9452e-14, 1.3088e-07, 2.0312e-06,\n",
        "            2.3976e-09, 2.6576e-06]],\n",
        "   [[9.9995e-01, 3.8543e-06, 3.7210e-08, 2.7998e-04, 2.0512e-05, 6.6691e-08,\n",
        "            3.5782e-07, 8.4758e-08, 1.8237e-04, 1.7706e-05, 3.5138e-03, 1.1317e-06,\n",
        "            6.4768e-07, 6.8161e-03, 1.3220e-06, 2.9803e-06, 1.1470e-06, 5.4372e-07,\n",
        "            1.6254e-04, 1.8312e-04, 2.4752e-06, 4.6606e-05, 1.0194e-06, 5.2570e-03,\n",
        "            3.8288e-04, 2.5457e-06, 6.6563e-05, 2.6142e-07, 3.9403e-07, 7.3129e-07,\n",
        "            5.4256e-08, 1.3752e-03, 1.5161e-09, 2.3655e-09, 2.7402e-06, 2.7329e-08,\n",
        "            2.0449e-07, 2.7902e-07, 1.0307e-02, 3.8085e-08, 5.7589e-08, 3.7922e-06,\n",
        "            1.1800e-02, 1.9976e-03, 8.7775e-05, 4.2548e-06, 9.1367e-07, 1.3800e-07,\n",
        "            1.7369e-06, 2.7150e-05, 6.6856e-06, 2.0612e-03, 6.0428e-07, 2.0019e-07,\n",
        "            5.8310e-07, 1.4128e-04, 1.2140e-08, 6.9428e-05, 2.4681e-04, 1.0948e-03,\n",
        "            1.5926e-05, 7.1464e-09, 3.7409e-05, 2.0083e-05, 2.4351e-05, 6.5669e-08,\n",
        "            6.1810e-06, 3.6520e-06, 1.5456e-02, 2.2171e-04],\n",
        "           [1.0000e+00, 9.4053e-08, 8.7937e-09, 3.3226e-07, 8.8741e-08, 1.6719e-10,\n",
        "            1.2202e-08, 3.7142e-11, 1.1252e-06, 1.1779e-06, 3.8629e-05, 1.6952e-06,\n",
        "            3.9410e-07, 1.5253e-05, 1.8168e-07, 4.4161e-06, 1.1267e-06, 1.9442e-08,\n",
        "            1.9486e-05, 4.9739e-05, 1.5945e-04, 1.8670e-06, 2.4054e-06, 3.1782e-07,\n",
        "            1.8329e-04, 1.5559e-06, 1.4960e-05, 3.6864e-06, 2.8109e-06, 2.4413e-07,\n",
        "            2.6449e-07, 1.4501e-04, 9.3507e-09, 7.9092e-09, 1.2600e-06, 4.5784e-07,\n",
        "            9.3620e-06, 5.4682e-06, 2.5186e-04, 5.1157e-06, 6.8258e-09, 1.5502e-06,\n",
        "            4.6586e-07, 2.5774e-03, 5.1058e-07, 3.6559e-08, 1.9862e-07, 2.0569e-05,\n",
        "            2.3135e-08, 1.9949e-07, 1.4035e-06, 2.3318e-05, 1.3736e-04, 7.6934e-07,\n",
        "            1.5796e-05, 1.9655e-06, 2.1943e-08, 6.3629e-05, 1.9014e-05, 1.7694e-08,\n",
        "            3.2820e-09, 4.0654e-11, 1.8739e-05, 7.9312e-07, 1.5837e-06, 5.1070e-07,\n",
        "            4.4607e-05, 8.1075e-09, 4.2889e-07, 1.0146e-04],\n",
        "           [1.0000e+00, 4.1324e-09, 4.6021e-11, 6.4898e-06, 6.7102e-08, 1.6974e-10,\n",
        "            1.0111e-08, 1.1083e-09, 6.5034e-07, 2.0823e-07, 5.2708e-07, 2.4779e-07,\n",
        "            1.5499e-05, 1.5098e-05, 3.4266e-06, 1.9469e-06, 3.1823e-08, 1.4074e-09,\n",
        "            7.3219e-07, 3.4088e-07, 1.6819e-04, 3.7555e-04, 3.5587e-06, 1.4610e-06,\n",
        "            7.8943e-06, 2.4406e-05, 1.1695e-06, 4.0176e-06, 2.6596e-06, 1.5892e-03,\n",
        "            1.1230e-06, 1.8050e-04, 5.1300e-10, 2.4645e-09, 5.5102e-06, 1.3999e-08,\n",
        "            1.5458e-06, 3.7816e-05, 2.3327e-03, 3.9391e-07, 1.8454e-07, 8.1406e-07,\n",
        "            4.9291e-03, 1.6592e-05, 9.0325e-08, 3.9959e-07, 7.5091e-07, 4.1585e-06,\n",
        "            3.1299e-09, 1.0515e-05, 3.7392e-07, 1.1333e-03, 1.9652e-07, 8.5562e-08,\n",
        "            1.3862e-05, 2.3126e-05, 4.8181e-07, 7.1410e-05, 1.3861e-05, 2.7714e-07,\n",
        "            1.2093e-07, 8.5101e-09, 4.4683e-06, 9.0759e-06, 2.4726e-05, 7.6242e-06,\n",
        "            8.2390e-05, 4.5917e-06, 3.3653e-06, 1.4313e-04],\n",
        "           [1.0000e+00, 2.7745e-11, 9.8638e-12, 2.4537e-09, 3.8815e-12, 1.8392e-13,\n",
        "            3.4138e-11, 2.9719e-14, 2.9800e-10, 9.1221e-11, 7.7670e-07, 9.7454e-09,\n",
        "            1.2173e-08, 2.3472e-07, 1.3941e-08, 5.4388e-11, 5.2331e-10, 1.8892e-12,\n",
        "            2.0858e-05, 5.5174e-08, 2.7792e-10, 2.9494e-05, 1.7825e-08, 2.3028e-07,\n",
        "            8.4857e-07, 7.3048e-08, 2.8085e-09, 1.0003e-09, 1.8335e-07, 2.4063e-10,\n",
        "            1.0323e-09, 1.2631e-08, 2.5633e-12, 8.3800e-12, 1.6211e-07, 4.4563e-11,\n",
        "            1.9924e-08, 2.0965e-07, 3.6427e-04, 3.3363e-08, 1.6123e-14, 3.4795e-09,\n",
        "            2.0800e-09, 6.1225e-09, 2.2207e-08, 2.2135e-11, 1.7486e-09, 1.1053e-09,\n",
        "            2.2195e-12, 1.5090e-11, 7.9016e-13, 3.9505e-08, 9.3215e-12, 2.0233e-06,\n",
        "            3.1592e-09, 1.9993e-09, 6.1461e-12, 9.8232e-08, 4.3120e-07, 1.2162e-09,\n",
        "            1.3740e-08, 2.4971e-12, 2.8822e-09, 1.6846e-06, 8.4470e-10, 1.1118e-09,\n",
        "            2.2080e-06, 5.7458e-12, 6.4188e-08, 1.1100e-05],\n",
        "           [1.0000e+00, 2.4863e-09, 3.7890e-08, 8.0342e-08, 8.3442e-10, 9.8994e-11,\n",
        "            1.5079e-08, 1.2872e-10, 4.4617e-08, 5.8832e-09, 3.1726e-05, 3.1899e-06,\n",
        "            6.5969e-07, 1.3381e-06, 1.4833e-06, 1.0500e-06, 1.5252e-06, 3.3054e-07,\n",
        "            3.6328e-05, 1.3609e-02, 9.4915e-06, 4.1983e-04, 5.6737e-05, 1.0342e-04,\n",
        "            1.0421e-03, 1.6235e-06, 1.8496e-05, 1.4115e-05, 3.8417e-06, 1.9843e-07,\n",
        "            1.2454e-06, 8.9823e-07, 6.0152e-10, 5.1822e-10, 2.5458e-05, 1.3340e-08,\n",
        "            9.5067e-08, 1.5573e-07, 1.0621e-03, 3.1862e-05, 2.3527e-08, 3.6698e-07,\n",
        "            1.6169e-06, 1.8412e-05, 3.5400e-06, 1.2458e-05, 1.0373e-08, 1.0364e-07,\n",
        "            3.3977e-08, 1.0704e-05, 4.4034e-07, 3.3191e-05, 4.3635e-06, 4.8373e-05,\n",
        "            1.1449e-07, 3.6128e-05, 3.7043e-09, 2.8206e-03, 4.5422e-06, 3.2203e-06,\n",
        "            1.2668e-05, 1.7600e-07, 1.5664e-05, 1.2759e-05, 5.2632e-05, 1.4981e-06,\n",
        "            5.6935e-04, 6.6006e-07, 3.1444e-05, 1.2259e-04],\n",
        "           [1.0000e+00, 6.8802e-09, 7.1275e-10, 3.1137e-08, 7.5194e-10, 6.7332e-11,\n",
        "            1.5096e-09, 1.5674e-10, 3.3520e-09, 2.6925e-07, 5.5019e-06, 1.0293e-06,\n",
        "            5.1581e-07, 5.8058e-07, 9.1341e-06, 7.8345e-07, 1.7354e-07, 1.7715e-08,\n",
        "            7.7206e-07, 7.8664e-06, 1.3478e-07, 7.7339e-04, 2.2758e-08, 1.4848e-08,\n",
        "            1.3141e-04, 1.3243e-07, 5.6310e-07, 3.9980e-08, 2.9415e-05, 1.0517e-08,\n",
        "            1.9477e-07, 1.4443e-07, 1.2175e-11, 6.3647e-11, 3.3682e-06, 3.9417e-10,\n",
        "            7.7372e-08, 5.7733e-07, 2.4135e-04, 3.1303e-09, 4.3839e-12, 1.5552e-06,\n",
        "            1.6645e-05, 2.2935e-07, 7.6556e-08, 3.3937e-10, 6.0390e-08, 1.2848e-07,\n",
        "            1.8859e-10, 9.5263e-07, 2.0263e-08, 2.6432e-05, 1.2238e-11, 3.7486e-07,\n",
        "            1.9897e-09, 1.1568e-08, 2.1288e-10, 6.5519e-06, 5.1534e-08, 8.0389e-07,\n",
        "            1.2662e-08, 1.2089e-11, 2.3239e-09, 4.4050e-08, 1.5604e-08, 2.4015e-09,\n",
        "            1.5003e-06, 6.7564e-08, 3.0632e-07, 3.9776e-05],\n",
        "           [1.0000e+00, 6.0125e-10, 6.8573e-10, 8.1634e-08, 6.2866e-10, 1.9734e-12,\n",
        "            3.3121e-09, 7.4570e-14, 6.6286e-10, 1.7406e-08, 2.8339e-07, 2.4181e-06,\n",
        "            6.3475e-09, 2.0524e-08, 3.9015e-10, 3.2800e-11, 4.4937e-09, 8.4642e-12,\n",
        "            1.9651e-07, 8.0757e-07, 1.5446e-08, 2.3092e-06, 1.3749e-05, 6.6194e-08,\n",
        "            8.9313e-06, 9.7710e-07, 2.5053e-08, 3.0326e-08, 8.1466e-07, 8.4019e-08,\n",
        "            8.5187e-10, 5.3332e-06, 7.3629e-11, 2.8234e-09, 1.1210e-06, 1.5172e-07,\n",
        "            7.2702e-06, 2.8553e-07, 2.2074e-05, 4.0705e-06, 7.2810e-11, 1.1767e-07,\n",
        "            4.2065e-07, 8.1750e-05, 8.5374e-06, 4.0424e-07, 2.8395e-07, 4.4990e-06,\n",
        "            1.1985e-07, 4.1031e-07, 4.5236e-08, 1.7433e-05, 3.5602e-07, 1.3286e-06,\n",
        "            4.3971e-06, 3.1805e-06, 3.8787e-08, 1.3698e-06, 6.1680e-05, 7.6375e-07,\n",
        "            4.6592e-09, 2.2510e-10, 5.4034e-07, 1.7093e-06, 3.0087e-08, 1.2928e-08,\n",
        "            6.8055e-05, 5.0068e-10, 4.6618e-07, 8.3417e-06],\n",
        "           [1.0000e+00, 3.1227e-08, 4.9655e-11, 6.8075e-07, 1.1669e-08, 2.4256e-11,\n",
        "            3.2623e-09, 1.9238e-11, 6.2050e-08, 2.1280e-08, 2.6576e-05, 8.2531e-08,\n",
        "            2.2252e-05, 8.1314e-06, 4.7125e-08, 3.7391e-08, 2.9591e-08, 1.3458e-06,\n",
        "            4.8169e-06, 3.8172e-08, 2.7021e-05, 2.1078e-05, 1.0296e-07, 1.0411e-06,\n",
        "            1.0569e-06, 1.1004e-05, 8.3961e-05, 1.6329e-04, 3.1522e-07, 3.5020e-07,\n",
        "            1.0574e-06, 1.2782e-04, 4.2530e-08, 6.3662e-09, 5.6604e-05, 3.2895e-09,\n",
        "            1.3321e-06, 1.2995e-06, 3.4792e-02, 7.0495e-07, 9.8077e-12, 4.0289e-10,\n",
        "            8.5246e-06, 6.0714e-07, 5.5201e-08, 4.9221e-06, 3.2612e-06, 3.6876e-06,\n",
        "            6.2048e-11, 3.1803e-07, 2.1119e-08, 5.4231e-03, 1.4845e-09, 1.0536e-09,\n",
        "            1.0426e-09, 1.3409e-06, 3.9176e-09, 2.1262e-03, 5.7657e-07, 4.1086e-08,\n",
        "            1.0684e-08, 3.6794e-09, 4.2090e-05, 7.8979e-08, 2.7173e-05, 8.5113e-08,\n",
        "            1.1470e-05, 5.3237e-09, 3.8519e-03, 7.4863e-06],\n",
        "           [1.0000e+00, 6.9932e-08, 6.1757e-09, 2.5633e-07, 1.9209e-07, 1.7097e-10,\n",
        "            3.2071e-09, 7.3026e-12, 1.4059e-08, 3.7106e-07, 3.7448e-07, 2.4895e-07,\n",
        "            2.2723e-09, 3.8688e-07, 1.5765e-11, 5.4212e-08, 2.0857e-09, 1.2918e-13,\n",
        "            3.4852e-08, 2.2144e-08, 6.0391e-05, 3.0228e-06, 1.6541e-08, 1.1326e-07,\n",
        "            4.7086e-05, 8.8018e-09, 6.0401e-07, 3.8812e-06, 3.2836e-08, 1.2349e-04,\n",
        "            1.3158e-09, 2.5984e-07, 3.8397e-11, 5.7657e-11, 2.0069e-05, 5.9866e-11,\n",
        "            6.7844e-08, 2.8017e-09, 1.1067e-04, 5.3349e-08, 5.0622e-11, 1.3011e-09,\n",
        "            4.1192e-08, 1.2763e-04, 5.6285e-07, 2.8728e-07, 2.3875e-09, 7.0943e-09,\n",
        "            2.4701e-08, 7.4663e-05, 2.6212e-08, 5.2553e-05, 1.4163e-06, 2.0694e-05,\n",
        "            2.9007e-08, 3.7918e-06, 3.6722e-08, 2.6142e-05, 1.6043e-07, 1.7868e-05,\n",
        "            1.5131e-08, 8.7845e-10, 7.9473e-06, 1.3870e-06, 4.5001e-07, 6.2283e-09,\n",
        "            3.0737e-04, 4.1916e-07, 1.5818e-05, 5.6301e-06],\n",
        "           [9.9908e-01, 2.4686e-06, 1.0012e-07, 9.7268e-06, 1.5495e-05, 2.0025e-09,\n",
        "            3.1259e-07, 1.1191e-09, 2.3730e-06, 5.6846e-04, 9.4779e-07, 5.6614e-06,\n",
        "            2.6592e-08, 2.8935e-05, 8.4761e-09, 1.7907e-08, 1.9392e-07, 9.2735e-09,\n",
        "            6.9976e-05, 4.6603e-05, 3.0517e-08, 7.9450e-06, 3.1874e-09, 2.7599e-07,\n",
        "            6.9577e-06, 9.8038e-08, 2.4853e-08, 1.4453e-08, 4.6981e-06, 9.8826e-05,\n",
        "            7.3242e-11, 1.0158e-05, 2.0952e-11, 2.8253e-10, 3.0429e-06, 8.4373e-09,\n",
        "            3.8399e-07, 2.7019e-09, 8.8411e-07, 3.7349e-08, 1.5131e-12, 2.7576e-09,\n",
        "            1.4064e-10, 1.1535e-03, 1.7190e-06, 1.4252e-08, 2.0807e-10, 1.5373e-08,\n",
        "            3.2981e-08, 7.7455e-08, 1.3849e-10, 5.2133e-07, 1.6189e-07, 3.9482e-09,\n",
        "            1.0246e-10, 2.1076e-09, 1.3844e-09, 4.7442e-07, 2.4197e-10, 2.7533e-09,\n",
        "            7.9573e-10, 3.5811e-12, 2.2580e-07, 1.5613e-08, 3.0426e-08, 2.1594e-10,\n",
        "            2.7919e-05, 1.0155e-08, 7.9849e-08, 1.5416e-06]]],\n",
        "  9: [[[9.1711e-01, 1.0010e-03, 2.9850e-03, 4.3067e-03, 9.6675e-03, 4.2705e-03,\n",
        "            4.3700e-03, 4.4590e-03, 3.3410e-03, 9.2555e-02, 6.7271e-02, 1.4341e-03,\n",
        "            1.3616e-02, 2.2734e-02, 1.5304e-03, 5.3759e-03, 3.8469e-04, 3.8317e-03,\n",
        "            2.5059e-03, 3.5212e-03, 3.2598e-03, 3.4173e-03, 4.0834e-03, 7.0849e-03,\n",
        "            2.9551e-03, 3.2065e-04, 1.4053e-03, 7.5724e-04, 1.0811e-03, 5.7240e-03,\n",
        "            8.4250e-04, 5.2245e-03, 5.8078e-04, 2.7282e-04, 2.6425e-04, 1.3326e-03,\n",
        "            1.7501e-04, 1.9365e-02, 1.0328e-01, 3.6375e-04, 4.1844e-04, 2.8159e-04,\n",
        "            1.0474e-02, 4.8729e-03, 1.2269e-03, 1.2828e-03, 4.6640e-04, 9.8948e-05,\n",
        "            9.7559e-04, 7.7003e-04, 3.4308e-04, 4.1613e-03, 1.0883e-03, 1.8371e-04,\n",
        "            2.6144e-04, 1.2900e-03, 4.6879e-05, 3.4565e-04, 1.2521e-03, 1.1276e-02,\n",
        "            1.2117e-04, 2.1633e-05, 3.7097e-04, 4.4541e-05, 2.5575e-03, 1.0392e-04,\n",
        "            2.3488e-04, 8.1360e-04, 1.9419e-03, 4.1325e-04, 6.3988e-06, 6.0376e-05,\n",
        "            4.5467e-03, 2.1710e-05, 2.3453e-03, 4.5627e-06, 1.1446e-05, 2.6601e-04,\n",
        "            6.7132e-05, 2.1671e-03, 2.1455e-07, 4.7834e-05, 1.2080e-08, 6.7917e-04,\n",
        "            1.4877e-05, 4.3658e-07, 1.4592e-05, 4.6550e-04, 2.6897e-09, 2.0758e-04],\n",
        "           [9.8823e-01, 1.0003e-03, 1.5907e-02, 1.3114e-03, 7.7452e-03, 2.0122e-04,\n",
        "            1.3319e-02, 4.0391e-03, 7.6404e-03, 1.8415e-02, 2.7052e-02, 9.7337e-04,\n",
        "            2.2777e-02, 3.5109e-03, 1.6707e-03, 5.3010e-03, 8.1128e-04, 5.9936e-03,\n",
        "            3.9368e-03, 1.2546e-03, 2.7505e-02, 2.4494e-03, 4.9367e-03, 6.0558e-04,\n",
        "            1.5756e-03, 2.0179e-04, 2.5337e-03, 1.5572e-03, 7.1438e-04, 1.0764e-03,\n",
        "            4.4489e-03, 1.2303e-03, 1.6154e-03, 5.5858e-05, 1.3489e-04, 1.0720e-03,\n",
        "            8.1980e-04, 5.4979e-03, 2.2018e-01, 1.3588e-03, 7.7695e-03, 2.5131e-04,\n",
        "            4.4171e-03, 2.1587e-03, 1.3432e-04, 8.7588e-04, 1.4394e-03, 1.4181e-03,\n",
        "            6.4061e-05, 2.5139e-04, 1.5558e-03, 5.1485e-04, 1.5736e-03, 5.4944e-04,\n",
        "            1.7462e-03, 7.7466e-05, 2.6704e-04, 5.6325e-04, 7.0358e-04, 9.8463e-04,\n",
        "            2.6989e-05, 2.9362e-06, 9.6763e-04, 2.8930e-05, 1.9670e-03, 9.7301e-05,\n",
        "            4.6234e-04, 2.7209e-04, 1.9450e-04, 2.7940e-04, 1.9293e-05, 3.1882e-04,\n",
        "            3.0777e-04, 3.1422e-04, 7.6355e-06, 2.8728e-05, 5.3991e-06, 4.6953e-03,\n",
        "            5.8800e-06, 3.7991e-03, 3.5583e-04, 8.7017e-07, 1.7790e-06, 3.2651e-05,\n",
        "            3.6296e-06, 4.9355e-05, 7.8275e-06, 3.0410e-04, 2.1874e-07, 2.2250e-05],\n",
        "           [9.6161e-01, 4.5023e-04, 7.7009e-03, 1.2093e-03, 5.4437e-03, 3.4461e-04,\n",
        "            1.6401e-02, 2.3887e-02, 4.6167e-03, 2.2577e-02, 1.4909e-02, 6.3082e-04,\n",
        "            6.2737e-02, 1.7520e-03, 4.7185e-03, 1.0174e-02, 1.9194e-03, 2.9479e-03,\n",
        "            7.8251e-04, 1.0709e-03, 5.6524e-03, 3.4388e-03, 6.2081e-03, 2.6702e-04,\n",
        "            2.8832e-03, 1.0215e-03, 1.2481e-03, 7.1039e-04, 5.9581e-04, 8.4564e-04,\n",
        "            3.3089e-03, 9.9975e-04, 2.7830e-04, 2.3013e-05, 4.7074e-04, 1.0505e-03,\n",
        "            3.8093e-04, 1.6833e-02, 6.7556e-02, 5.7785e-04, 1.2843e-03, 2.7320e-04,\n",
        "            2.7280e-02, 1.6838e-03, 9.7255e-05, 4.9843e-04, 1.4503e-03, 9.9595e-04,\n",
        "            3.6133e-05, 1.0402e-04, 4.8291e-04, 1.0505e-03, 8.8653e-05, 6.8041e-04,\n",
        "            6.9025e-03, 1.5297e-04, 2.2175e-04, 2.2346e-04, 3.0184e-03, 4.7027e-04,\n",
        "            2.1300e-05, 1.2560e-05, 8.4706e-04, 2.8062e-05, 1.2594e-04, 6.3286e-04,\n",
        "            6.6629e-05, 5.0504e-05, 7.5053e-05, 5.9458e-04, 3.3466e-06, 3.4235e-05,\n",
        "            4.6686e-05, 6.3546e-06, 1.5481e-05, 5.2941e-05, 3.4310e-06, 3.0208e-04,\n",
        "            7.4664e-06, 1.8537e-04, 7.6302e-07, 1.6768e-07, 9.5593e-08, 1.1992e-04,\n",
        "            5.1803e-07, 4.9380e-06, 5.1964e-07, 1.2657e-06, 2.9567e-07, 1.4457e-05],\n",
        "           [9.6688e-01, 2.1980e-03, 1.3638e-02, 7.0172e-03, 4.9016e-03, 1.9688e-03,\n",
        "            3.1275e-02, 1.7625e-02, 1.2726e-03, 1.0381e-02, 1.8133e-02, 1.2214e-03,\n",
        "            1.0495e-02, 1.0325e-02, 2.0561e-03, 3.0607e-03, 7.1460e-04, 1.3293e-02,\n",
        "            2.4309e-02, 8.2316e-03, 1.1448e-03, 1.3915e-02, 1.1981e-02, 2.9346e-03,\n",
        "            1.7882e-03, 1.2340e-04, 7.5622e-03, 1.7124e-03, 8.3816e-04, 1.0656e-03,\n",
        "            2.5933e-03, 8.8672e-04, 2.5513e-04, 2.5811e-04, 2.3032e-03, 2.0878e-03,\n",
        "            1.1153e-03, 2.8094e-03, 8.1746e-02, 5.2358e-04, 1.4668e-04, 7.3809e-04,\n",
        "            2.3325e-03, 3.1953e-04, 2.3527e-03, 1.1273e-03, 1.0329e-03, 1.3155e-03,\n",
        "            1.7280e-04, 2.0725e-04, 5.2099e-04, 3.0421e-03, 1.0325e-04, 1.4445e-03,\n",
        "            1.5060e-04, 1.5897e-04, 1.3892e-04, 4.8615e-04, 2.2367e-03, 4.4547e-04,\n",
        "            2.1831e-04, 6.1462e-05, 1.0088e-04, 7.8136e-05, 3.6164e-05, 1.5768e-04,\n",
        "            3.3599e-03, 2.6820e-05, 6.6461e-04, 1.9939e-04, 2.2300e-05, 7.8091e-05,\n",
        "            8.0393e-04, 4.4948e-07, 9.7120e-05, 1.8674e-05, 4.3931e-06, 4.3405e-04,\n",
        "            2.0675e-05, 9.1487e-05, 2.3799e-06, 4.5463e-07, 1.0070e-06, 7.5293e-06,\n",
        "            6.6177e-07, 7.0287e-06, 1.8625e-06, 6.8329e-05, 3.4067e-06, 1.5572e-06],\n",
        "           [9.3015e-01, 2.1857e-03, 2.0865e-02, 7.8275e-03, 6.6724e-03, 5.3074e-03,\n",
        "            1.2594e-02, 5.7089e-02, 8.6756e-03, 1.5385e-02, 8.1017e-02, 6.3789e-03,\n",
        "            1.3207e-02, 6.9315e-03, 7.9827e-03, 1.0227e-02, 1.2117e-03, 4.6871e-02,\n",
        "            6.7880e-03, 6.2191e-03, 7.0073e-03, 6.2950e-03, 1.7086e-02, 9.4933e-03,\n",
        "            5.0171e-03, 5.8494e-04, 5.3913e-02, 1.1178e-02, 8.8974e-04, 1.2896e-03,\n",
        "            1.7022e-02, 3.0007e-03, 1.0717e-03, 8.2749e-04, 1.8435e-03, 1.1413e-02,\n",
        "            5.4737e-04, 5.4242e-03, 6.1530e-02, 3.3063e-03, 1.3618e-03, 1.6114e-03,\n",
        "            1.6030e-02, 1.9762e-03, 5.0185e-03, 9.1918e-03, 1.7148e-03, 1.9985e-03,\n",
        "            1.6088e-03, 1.1683e-03, 6.6904e-03, 3.2227e-03, 2.1280e-03, 7.5081e-03,\n",
        "            9.0095e-04, 2.4619e-03, 4.5818e-04, 4.5602e-03, 2.6267e-03, 3.0602e-03,\n",
        "            2.2776e-03, 8.5371e-05, 2.0115e-03, 4.5407e-04, 1.4996e-03, 4.8977e-04,\n",
        "            4.1680e-03, 6.0431e-04, 1.1565e-03, 6.2601e-04, 2.0180e-04, 8.3425e-04,\n",
        "            8.5401e-03, 6.7228e-05, 9.2041e-04, 6.8828e-04, 4.6154e-05, 1.2259e-03,\n",
        "            6.5790e-04, 5.7310e-03, 5.2390e-04, 4.0174e-06, 9.5671e-07, 5.2296e-04,\n",
        "            2.9926e-05, 2.9043e-04, 1.3694e-04, 1.6519e-04, 4.5518e-04, 7.7946e-04],\n",
        "           [9.9154e-01, 4.8844e-04, 5.1979e-03, 2.0213e-03, 8.0798e-03, 2.0518e-04,\n",
        "            3.1996e-03, 2.0363e-02, 1.7466e-03, 1.4460e-02, 1.1441e-02, 1.7134e-04,\n",
        "            1.2768e-02, 7.3745e-03, 3.5262e-03, 2.1754e-03, 2.7967e-04, 1.1812e-02,\n",
        "            9.8841e-04, 4.0629e-03, 1.0166e-03, 2.1418e-02, 1.4499e-03, 4.0895e-04,\n",
        "            6.2662e-03, 9.5776e-05, 1.5170e-02, 9.3584e-04, 3.0259e-04, 3.6403e-04,\n",
        "            1.9603e-02, 9.0770e-04, 1.7815e-04, 1.8056e-05, 7.8759e-04, 4.2453e-04,\n",
        "            9.9721e-05, 2.0361e-03, 2.4384e-01, 1.8885e-04, 1.8781e-04, 4.3375e-04,\n",
        "            5.4198e-03, 6.8650e-04, 3.9648e-04, 7.5535e-04, 3.9223e-04, 3.4189e-04,\n",
        "            3.5732e-05, 1.4437e-04, 8.6084e-04, 1.3369e-03, 4.3833e-05, 3.5373e-04,\n",
        "            1.1076e-04, 7.6251e-05, 7.1608e-05, 5.7108e-04, 2.4657e-04, 2.0879e-03,\n",
        "            1.8814e-05, 2.8161e-06, 3.6558e-05, 3.8405e-05, 1.5460e-04, 2.0478e-05,\n",
        "            7.4715e-04, 1.0026e-04, 1.7387e-04, 1.8291e-04, 6.9562e-06, 1.1339e-04,\n",
        "            6.3611e-04, 1.1480e-06, 3.5075e-04, 1.0432e-05, 3.1910e-07, 4.9007e-04,\n",
        "            1.4031e-06, 5.1939e-05, 7.4980e-04, 3.9148e-08, 1.3370e-08, 1.4394e-06,\n",
        "            1.5273e-06, 1.3286e-07, 1.5073e-06, 7.1971e-05, 8.9996e-07, 2.2124e-06],\n",
        "           [9.7489e-01, 5.0468e-04, 9.1569e-03, 9.2901e-03, 6.6405e-03, 4.0770e-04,\n",
        "            3.8753e-02, 4.2500e-03, 8.6792e-04, 5.4301e-03, 1.1541e-02, 1.0807e-03,\n",
        "            7.4427e-03, 8.4811e-03, 3.9979e-04, 4.1591e-03, 3.9630e-04, 1.0153e-02,\n",
        "            7.1530e-03, 2.5960e-03, 6.2576e-04, 2.0869e-03, 4.7744e-03, 1.0506e-03,\n",
        "            9.9518e-04, 3.6497e-05, 3.0112e-03, 1.1544e-03, 5.9165e-04, 1.1223e-03,\n",
        "            1.6535e-03, 1.7131e-03, 1.5425e-04, 1.1321e-04, 5.5596e-04, 3.7894e-04,\n",
        "            7.0241e-04, 1.1762e-03, 2.4723e-02, 9.1865e-04, 2.6063e-04, 6.6612e-05,\n",
        "            5.8708e-04, 3.4879e-04, 1.2017e-03, 3.9968e-04, 7.7914e-04, 4.4285e-04,\n",
        "            3.7430e-05, 2.3852e-04, 5.6067e-04, 1.5306e-03, 1.5035e-04, 7.0854e-05,\n",
        "            2.2522e-04, 2.5200e-05, 7.4763e-05, 4.8351e-05, 2.3296e-03, 9.8424e-05,\n",
        "            3.0215e-05, 4.5637e-06, 1.5523e-04, 1.2504e-05, 1.7878e-05, 8.4747e-05,\n",
        "            3.0142e-03, 1.1744e-04, 5.8863e-05, 3.2607e-05, 1.0191e-05, 3.5890e-06,\n",
        "            1.2741e-03, 9.6195e-07, 2.7706e-06, 6.3097e-06, 9.8562e-06, 4.4204e-05,\n",
        "            3.0057e-05, 2.4578e-04, 9.5493e-06, 7.3681e-07, 9.0218e-07, 2.9223e-04,\n",
        "            4.3100e-09, 1.1821e-07, 2.3263e-08, 4.7509e-05, 1.3145e-07, 1.4226e-07],\n",
        "           [9.6882e-01, 9.8827e-04, 4.6446e-03, 5.0450e-03, 8.0317e-03, 1.0137e-03,\n",
        "            1.3395e-02, 3.8505e-03, 2.3825e-03, 2.7827e-02, 1.3194e-01, 6.5746e-04,\n",
        "            4.3756e-02, 1.4028e-02, 1.0366e-03, 1.4748e-03, 3.2026e-04, 2.7197e-03,\n",
        "            8.8438e-03, 5.4699e-04, 1.4652e-03, 1.0447e-03, 1.5880e-03, 4.3574e-03,\n",
        "            5.1273e-04, 3.6991e-04, 5.7032e-03, 1.1487e-03, 2.9706e-04, 1.1603e-03,\n",
        "            1.7154e-03, 1.3446e-03, 3.6110e-04, 2.1099e-04, 1.1211e-03, 1.8495e-04,\n",
        "            1.5722e-04, 6.4819e-03, 2.5838e-01, 2.2066e-04, 1.5489e-04, 3.7068e-04,\n",
        "            5.2041e-03, 2.7529e-03, 4.7270e-04, 2.0425e-03, 6.9287e-04, 3.7818e-04,\n",
        "            5.5204e-05, 1.1074e-03, 7.2996e-04, 7.0162e-04, 5.6425e-05, 3.4223e-04,\n",
        "            1.1373e-04, 3.7295e-04, 3.3031e-05, 9.1048e-04, 1.4205e-03, 6.4006e-03,\n",
        "            2.3067e-05, 1.2772e-05, 4.4753e-04, 8.0976e-05, 6.2572e-04, 7.3427e-05,\n",
        "            8.7490e-05, 4.4185e-05, 2.1092e-02, 9.9245e-05, 7.8117e-06, 4.0309e-05,\n",
        "            9.5159e-03, 1.6777e-05, 2.0896e-04, 8.4745e-06, 3.5957e-06, 5.9918e-03,\n",
        "            4.8502e-06, 8.8648e-04, 2.0483e-05, 7.1405e-07, 2.6265e-07, 4.0342e-07,\n",
        "            2.0433e-02, 8.7856e-06, 1.8866e-03, 2.5797e-04, 6.2815e-08, 3.9771e-06],\n",
        "           [9.0755e-01, 9.0974e-04, 4.1858e-02, 1.0816e-02, 9.1266e-03, 9.1146e-03,\n",
        "            1.2061e-02, 3.5740e-02, 3.5240e-03, 4.0801e-02, 3.7978e-02, 1.5316e-02,\n",
        "            1.0678e-02, 1.3756e-02, 7.7507e-03, 9.1767e-03, 2.5517e-03, 2.0397e-02,\n",
        "            5.5274e-03, 1.4609e-02, 5.3045e-03, 2.4224e-02, 1.4905e-02, 6.3370e-03,\n",
        "            7.7243e-03, 4.7850e-04, 2.5453e-02, 1.7608e-03, 2.6367e-03, 3.7058e-03,\n",
        "            5.2457e-03, 2.4568e-03, 5.4998e-04, 5.9156e-03, 1.2417e-03, 1.5712e-02,\n",
        "            9.6542e-04, 6.3795e-03, 1.4326e-01, 4.5866e-03, 8.1429e-04, 9.4325e-04,\n",
        "            1.1113e-02, 2.0783e-03, 1.8990e-02, 3.9697e-03, 1.0535e-03, 2.0466e-03,\n",
        "            5.1831e-03, 3.2465e-03, 4.4922e-03, 6.2555e-03, 4.8855e-03, 9.9823e-03,\n",
        "            5.0969e-04, 4.5807e-03, 4.8476e-04, 4.8764e-04, 1.4968e-03, 1.0912e-02,\n",
        "            2.1983e-03, 1.0154e-04, 5.3146e-04, 7.2580e-04, 3.1422e-03, 7.9724e-04,\n",
        "            2.4083e-02, 4.3651e-03, 2.8891e-03, 2.5372e-03, 2.3270e-04, 5.6523e-04,\n",
        "            5.0415e-02, 1.1188e-04, 5.0022e-03, 4.7912e-04, 1.0221e-03, 1.7698e-03,\n",
        "            6.0669e-04, 2.3459e-03, 2.1274e-03, 1.7852e-06, 8.3191e-05, 1.2768e-03,\n",
        "            5.5910e-03, 4.2627e-05, 1.3283e-04, 1.8549e-03, 1.2477e-04, 8.2422e-04],\n",
        "           [9.9659e-01, 9.9988e-05, 2.7562e-03, 1.6506e-03, 1.1031e-03, 6.6678e-05,\n",
        "            3.7632e-03, 4.8857e-04, 1.3065e-04, 2.9146e-03, 1.4494e-03, 1.2309e-04,\n",
        "            2.0133e-03, 3.0173e-03, 3.7704e-05, 7.1642e-04, 6.2242e-05, 2.3234e-03,\n",
        "            6.8653e-04, 5.8913e-04, 1.7560e-04, 9.0725e-04, 8.5801e-04, 1.1064e-04,\n",
        "            2.2841e-04, 2.2579e-06, 2.4474e-04, 8.4441e-05, 1.2125e-04, 2.6566e-04,\n",
        "            1.3444e-04, 2.7682e-04, 1.3624e-05, 8.3291e-06, 3.7412e-05, 7.3785e-05,\n",
        "            7.6289e-05, 1.2956e-04, 5.9243e-02, 9.3485e-05, 4.0475e-05, 2.7217e-06,\n",
        "            1.9663e-04, 4.0591e-05, 1.3290e-04, 4.5788e-05, 6.7731e-05, 3.9036e-05,\n",
        "            1.3160e-06, 1.3462e-05, 1.9565e-05, 2.6119e-04, 1.6297e-05, 4.5729e-06,\n",
        "            1.9220e-05, 2.2146e-06, 8.3672e-06, 5.7262e-06, 9.9817e-05, 2.4808e-05,\n",
        "            1.5341e-06, 6.3370e-08, 1.1457e-05, 1.7743e-07, 2.2563e-06, 1.9828e-06,\n",
        "            4.5867e-04, 6.6181e-06, 5.0997e-06, 4.0477e-06, 4.1308e-07, 1.1524e-06,\n",
        "            4.7731e-05, 2.0896e-08, 6.3924e-07, 3.8762e-08, 7.5432e-08, 1.5409e-05,\n",
        "            1.6040e-07, 7.4333e-06, 8.2627e-07, 2.0538e-10, 1.6219e-09, 3.8425e-06,\n",
        "            3.2495e-10, 1.6146e-08, 5.5142e-11, 1.1678e-06, 7.4937e-11, 1.2263e-05]],\n",
        "   [[1.0000e+00, 1.7307e-07, 3.0456e-09, 1.7270e-05, 6.4998e-08, 6.8176e-09,\n",
        "            5.9874e-09, 2.5287e-09, 6.5237e-07, 3.3236e-06, 1.2421e-05, 1.7091e-07,\n",
        "            3.2444e-07, 2.6255e-04, 3.1532e-08, 7.4034e-08, 5.6564e-09, 3.1431e-09,\n",
        "            3.1382e-07, 1.0633e-05, 7.6830e-08, 9.3520e-05, 2.8754e-07, 2.3557e-05,\n",
        "            2.4110e-03, 2.6864e-07, 1.0244e-06, 1.0995e-07, 5.5776e-06, 1.2585e-06,\n",
        "            1.7406e-08, 3.3394e-04, 1.0670e-09, 6.8570e-10, 1.1969e-06, 8.4320e-08,\n",
        "            1.2980e-07, 2.7753e-06, 2.6379e-04, 8.0851e-09, 2.2960e-09, 8.8976e-08,\n",
        "            3.5998e-05, 1.0492e-03, 7.6911e-06, 6.3475e-07, 7.2589e-08, 1.3666e-09,\n",
        "            1.1965e-07, 1.1938e-06, 5.8216e-06, 3.0701e-04, 1.1415e-07, 3.9282e-08,\n",
        "            1.5075e-06, 4.5404e-04, 1.6990e-09, 8.5154e-06, 1.6629e-05, 1.8363e-04,\n",
        "            1.0162e-07, 1.7673e-09, 2.0774e-05, 1.1290e-06, 1.5822e-05, 3.2373e-09,\n",
        "            3.4438e-06, 6.7343e-07, 6.8490e-04, 2.7392e-04, 1.5062e-07, 3.7817e-08,\n",
        "            1.1136e-03, 3.3599e-08, 7.5391e-04, 1.1709e-10, 1.8294e-07, 4.4786e-06,\n",
        "            9.7231e-07, 9.3916e-05],\n",
        "           [1.0000e+00, 5.6687e-08, 2.3314e-07, 1.5637e-07, 2.3377e-07, 6.9954e-10,\n",
        "            4.6306e-08, 1.1150e-10, 8.5839e-08, 8.5228e-07, 1.4683e-06, 3.7546e-06,\n",
        "            2.4960e-08, 1.2130e-06, 1.4796e-07, 3.5193e-07, 2.3644e-07, 7.1231e-10,\n",
        "            2.8312e-06, 6.6866e-06, 1.0420e-06, 8.8771e-07, 5.5844e-08, 8.4978e-09,\n",
        "            4.4987e-05, 1.7308e-07, 7.2787e-08, 2.7608e-08, 1.5770e-06, 1.8874e-07,\n",
        "            5.6410e-08, 8.1004e-05, 4.0612e-10, 7.8802e-10, 7.7220e-08, 7.2264e-09,\n",
        "            6.0349e-07, 3.5373e-06, 2.8170e-04, 3.4480e-06, 3.2356e-09, 2.8729e-07,\n",
        "            1.1758e-06, 2.8772e-03, 9.5136e-07, 1.0006e-07, 6.9579e-07, 5.2979e-06,\n",
        "            2.7203e-08, 1.4938e-07, 1.0109e-06, 3.2599e-05, 1.8210e-05, 1.0756e-07,\n",
        "            1.2285e-04, 2.1479e-06, 1.7775e-08, 4.5502e-06, 6.2349e-06, 6.4277e-08,\n",
        "            1.2531e-09, 1.8897e-11, 3.1836e-06, 3.7870e-07, 2.9255e-06, 1.8184e-08,\n",
        "            1.2046e-05, 1.1944e-08, 2.7154e-07, 3.0862e-05, 5.2705e-07, 2.3448e-07,\n",
        "            9.0712e-06, 6.2016e-06, 1.2243e-08, 1.6188e-10, 2.5973e-07, 3.3591e-05,\n",
        "            1.4162e-10, 2.6119e-04],\n",
        "           [1.0000e+00, 6.4335e-10, 2.7529e-11, 4.3847e-06, 4.7453e-08, 1.4095e-10,\n",
        "            4.2653e-10, 1.2966e-10, 2.3893e-08, 3.6964e-08, 4.4640e-07, 5.7526e-08,\n",
        "            1.6388e-06, 1.0420e-08, 2.6548e-07, 3.0569e-06, 3.3613e-09, 1.6369e-10,\n",
        "            9.2545e-10, 3.5170e-10, 3.1025e-04, 2.8433e-04, 1.6784e-06, 1.6670e-07,\n",
        "            3.7840e-05, 4.4432e-06, 1.6802e-06, 1.1756e-05, 1.1824e-05, 4.7410e-07,\n",
        "            7.3567e-06, 7.0479e-04, 5.1607e-10, 5.2940e-10, 1.3141e-06, 8.8372e-09,\n",
        "            3.0710e-07, 9.4764e-05, 1.8930e-02, 7.3451e-07, 4.0842e-09, 8.9730e-08,\n",
        "            3.9214e-04, 1.8301e-05, 1.0239e-07, 8.0049e-07, 8.3292e-07, 3.0837e-07,\n",
        "            8.3475e-10, 2.0211e-06, 3.4765e-07, 2.3004e-05, 2.0317e-06, 2.3916e-06,\n",
        "            1.0807e-05, 2.4795e-05, 8.6539e-07, 3.6952e-04, 2.4683e-07, 2.3177e-07,\n",
        "            1.4795e-08, 3.6690e-09, 1.9022e-05, 2.0668e-06, 8.8783e-06, 7.0601e-07,\n",
        "            4.2024e-06, 7.5339e-07, 1.5651e-06, 8.2154e-05, 3.7737e-09, 1.7097e-09,\n",
        "            2.7161e-08, 1.4632e-08, 3.4014e-09, 4.3994e-09, 2.7264e-08, 1.1827e-04,\n",
        "            7.5123e-10, 1.9875e-04],\n",
        "           [1.0000e+00, 3.9725e-08, 4.9600e-08, 2.6120e-07, 6.6990e-08, 1.0657e-09,\n",
        "            8.6575e-08, 2.9005e-10, 2.7567e-08, 1.9628e-08, 1.7095e-04, 1.3893e-06,\n",
        "            1.0397e-06, 1.6851e-04, 1.7863e-06, 6.2991e-08, 2.1574e-07, 2.2576e-08,\n",
        "            1.7012e-03, 1.0927e-05, 1.6072e-07, 9.5923e-04, 8.1717e-08, 9.3692e-05,\n",
        "            9.4765e-06, 3.0300e-06, 2.0920e-07, 5.0306e-07, 7.5311e-07, 8.5763e-09,\n",
        "            4.8808e-09, 2.6626e-06, 9.2247e-10, 1.2025e-08, 1.6568e-05, 9.2505e-08,\n",
        "            3.0814e-06, 7.5476e-07, 5.8927e-04, 3.8798e-06, 5.5796e-11, 1.0214e-06,\n",
        "            4.7684e-06, 4.2325e-07, 6.8270e-05, 1.4968e-07, 9.3778e-06, 3.0007e-06,\n",
        "            2.2971e-08, 6.8301e-07, 1.4727e-08, 5.8688e-05, 4.2510e-08, 1.4188e-05,\n",
        "            5.6649e-07, 1.3345e-06, 7.9929e-09, 3.2916e-04, 1.0531e-04, 6.0229e-07,\n",
        "            1.2984e-05, 2.6460e-09, 3.9050e-07, 3.6180e-05, 3.5561e-08, 1.0975e-06,\n",
        "            4.1348e-04, 1.3616e-09, 9.7608e-06, 3.9015e-05, 2.4561e-06, 1.3719e-07,\n",
        "            1.1077e-04, 8.3714e-10, 4.2956e-06, 1.7147e-08, 6.9571e-07, 1.8011e-05,\n",
        "            9.3387e-07, 2.5527e-06],\n",
        "           [1.0000e+00, 1.4767e-08, 6.7556e-07, 4.4814e-07, 7.5479e-09, 3.6617e-09,\n",
        "            7.3103e-08, 7.7175e-09, 3.5223e-08, 2.8515e-08, 1.9228e-04, 1.5999e-07,\n",
        "            2.5528e-07, 8.4291e-08, 1.1806e-08, 5.4516e-08, 3.8836e-06, 1.8132e-08,\n",
        "            3.7518e-05, 5.5312e-06, 1.6626e-04, 3.4101e-07, 2.0920e-07, 2.8025e-04,\n",
        "            5.8000e-05, 3.6045e-08, 7.8781e-07, 6.7230e-05, 1.6985e-07, 5.5669e-09,\n",
        "            4.7942e-05, 6.9447e-07, 8.3861e-10, 2.7245e-10, 1.7964e-06, 1.8531e-09,\n",
        "            8.4360e-08, 1.6672e-06, 2.0970e-04, 1.9887e-05, 1.6205e-09, 4.6460e-08,\n",
        "            6.8882e-07, 9.4000e-07, 1.1670e-07, 3.1426e-04, 3.0751e-08, 2.6966e-08,\n",
        "            1.7633e-08, 3.7940e-06, 8.6738e-08, 9.0060e-05, 2.3147e-06, 7.5384e-07,\n",
        "            1.7377e-08, 1.1620e-06, 1.5013e-08, 4.9261e-03, 1.9880e-06, 8.3627e-05,\n",
        "            5.9090e-05, 1.3653e-07, 7.0305e-06, 1.2458e-06, 1.6171e-05, 7.1519e-08,\n",
        "            9.4323e-05, 4.1079e-07, 2.4327e-05, 2.7158e-05, 1.4356e-05, 1.8153e-05,\n",
        "            4.7081e-02, 3.1397e-07, 2.7707e-05, 2.9734e-06, 5.9111e-07, 1.0352e-04,\n",
        "            1.3676e-05, 8.5559e-04],\n",
        "           [1.0000e+00, 9.0956e-09, 9.7896e-10, 6.6439e-08, 1.5122e-09, 1.7823e-10,\n",
        "            1.7454e-09, 1.8147e-10, 5.5038e-09, 1.2356e-07, 1.6634e-05, 5.7499e-08,\n",
        "            4.1851e-08, 5.2381e-08, 2.4565e-06, 1.3896e-07, 1.1365e-07, 2.8163e-09,\n",
        "            1.1337e-07, 1.0946e-06, 3.1336e-07, 5.4544e-04, 2.5713e-08, 3.5534e-08,\n",
        "            1.0678e-04, 8.3572e-07, 4.5677e-07, 1.5959e-07, 9.4330e-05, 3.5386e-08,\n",
        "            6.7805e-08, 3.6187e-07, 9.8466e-12, 1.1427e-10, 4.9841e-06, 2.4054e-09,\n",
        "            1.5039e-07, 3.8527e-07, 2.6960e-04, 1.1514e-08, 1.9833e-11, 8.4971e-06,\n",
        "            1.7111e-05, 1.3014e-06, 1.8390e-07, 8.3416e-10, 2.2187e-07, 3.6878e-07,\n",
        "            3.1466e-10, 8.8528e-07, 1.4549e-08, 3.4590e-05, 2.9277e-11, 6.3737e-07,\n",
        "            7.7764e-09, 2.9943e-08, 3.0751e-10, 2.4657e-06, 2.3067e-07, 2.3045e-06,\n",
        "            1.2675e-08, 7.5351e-12, 5.8213e-09, 2.7340e-08, 2.0862e-08, 3.2558e-09,\n",
        "            1.7092e-06, 1.0314e-07, 2.9484e-07, 9.5541e-06, 7.1577e-09, 1.0756e-07,\n",
        "            1.8580e-06, 8.4028e-12, 4.3610e-07, 8.8655e-11, 2.6282e-09, 2.8209e-06,\n",
        "            1.0743e-10, 1.9785e-07],\n",
        "           [1.0000e+00, 2.7283e-10, 2.1313e-09, 6.7566e-09, 2.0766e-10, 1.2308e-12,\n",
        "            5.8248e-10, 8.8433e-15, 3.8932e-11, 1.1601e-09, 2.7192e-07, 1.8540e-06,\n",
        "            7.8588e-09, 6.6913e-09, 5.8648e-10, 1.7773e-11, 4.6060e-09, 1.0733e-11,\n",
        "            1.1018e-06, 4.0837e-07, 7.7928e-08, 4.9772e-06, 3.2773e-06, 4.8775e-08,\n",
        "            1.9293e-05, 1.8773e-06, 5.7542e-09, 6.9951e-08, 1.6006e-06, 2.6771e-07,\n",
        "            3.4254e-10, 2.8117e-06, 1.9554e-11, 4.8368e-09, 2.3087e-06, 1.2121e-07,\n",
        "            9.2126e-06, 1.9328e-07, 6.5704e-06, 4.5515e-07, 1.2453e-10, 2.0510e-07,\n",
        "            2.8454e-07, 5.8800e-05, 1.1326e-05, 3.2217e-07, 8.7400e-07, 5.6583e-06,\n",
        "            5.0955e-08, 3.1779e-07, 2.5654e-09, 7.3172e-06, 2.1878e-07, 3.2130e-07,\n",
        "            1.5988e-06, 1.3720e-07, 8.5341e-09, 1.9395e-06, 3.9823e-06, 8.0884e-08,\n",
        "            8.4239e-10, 7.7942e-10, 4.7964e-07, 1.4320e-07, 4.0046e-08, 4.0946e-09,\n",
        "            7.9764e-05, 1.3059e-09, 1.0849e-07, 3.1876e-06, 1.1187e-07, 2.6021e-09,\n",
        "            1.1719e-05, 2.4522e-08, 9.8504e-09, 2.4103e-09, 5.9507e-06, 2.6456e-06,\n",
        "            3.2082e-07, 5.0343e-04],\n",
        "           [1.0000e+00, 1.7962e-07, 8.8030e-11, 1.1026e-06, 2.5077e-08, 1.0602e-10,\n",
        "            1.0758e-08, 2.8609e-10, 1.8399e-07, 1.2039e-06, 3.1150e-04, 1.0810e-07,\n",
        "            4.4190e-05, 6.8193e-05, 1.9839e-07, 2.1294e-07, 1.7606e-08, 1.3437e-06,\n",
        "            2.6668e-06, 9.9541e-08, 1.1876e-05, 5.7434e-05, 8.7175e-07, 2.0406e-06,\n",
        "            9.7133e-06, 1.2217e-04, 4.5253e-04, 8.2315e-06, 8.4298e-07, 3.3284e-06,\n",
        "            1.0142e-05, 2.9931e-04, 5.6493e-08, 1.3644e-08, 2.2370e-04, 5.5547e-08,\n",
        "            1.0751e-06, 3.7103e-05, 1.2171e-02, 6.1725e-08, 1.0488e-10, 1.0067e-09,\n",
        "            6.9537e-05, 1.2847e-04, 9.5372e-07, 3.0062e-06, 5.2161e-06, 1.9735e-06,\n",
        "            5.1099e-09, 3.6177e-06, 1.5957e-06, 5.6662e-02, 1.2434e-08, 5.8738e-08,\n",
        "            6.1450e-08, 6.1140e-05, 3.2020e-08, 1.0629e-04, 1.0831e-04, 4.4367e-06,\n",
        "            1.1762e-07, 1.0309e-08, 9.0983e-05, 1.3766e-06, 9.8791e-05, 2.5262e-06,\n",
        "            2.6297e-06, 1.3671e-07, 4.1500e-02, 7.4607e-06, 3.3381e-07, 1.0551e-07,\n",
        "            3.8679e-02, 1.0229e-07, 1.4107e-04, 1.9483e-08, 2.2838e-08, 4.1105e-05,\n",
        "            2.7559e-08, 2.6325e-04],\n",
        "           [9.9996e-01, 4.2634e-06, 7.2434e-07, 1.3512e-04, 1.4998e-05, 8.8217e-07,\n",
        "            5.9380e-07, 8.6147e-08, 4.9744e-05, 5.4125e-05, 6.2127e-05, 3.0378e-06,\n",
        "            1.3535e-06, 4.2090e-05, 2.8623e-06, 2.4983e-06, 3.2392e-07, 9.2404e-08,\n",
        "            2.1696e-05, 1.1615e-04, 1.9161e-05, 9.4272e-05, 2.0137e-06, 5.4964e-06,\n",
        "            1.6900e-04, 6.9894e-06, 1.0904e-04, 8.0016e-06, 1.3445e-06, 8.4311e-04,\n",
        "            3.2648e-07, 1.4232e-05, 7.6939e-08, 4.4996e-08, 1.0528e-04, 1.6220e-06,\n",
        "            1.2671e-05, 1.5220e-05, 2.1231e-03, 1.1919e-05, 5.3373e-08, 1.0245e-06,\n",
        "            1.9980e-06, 2.7413e-03, 6.0731e-06, 6.1659e-08, 6.1440e-09, 2.3521e-07,\n",
        "            2.2897e-07, 2.0849e-05, 8.9530e-07, 6.6472e-05, 6.8041e-06, 3.0007e-05,\n",
        "            4.1650e-06, 4.0209e-04, 3.2761e-09, 1.9308e-06, 3.7434e-07, 1.0432e-05,\n",
        "            1.5129e-07, 9.1802e-09, 4.8426e-06, 5.1530e-05, 4.3672e-06, 2.8591e-06,\n",
        "            2.3537e-03, 1.4590e-07, 9.8066e-05, 1.0384e-03, 3.5929e-05, 1.3567e-06,\n",
        "            5.7470e-03, 1.2769e-06, 9.9665e-04, 2.8710e-07, 5.3789e-04, 2.9985e-04,\n",
        "            4.2118e-06, 5.5037e-03],\n",
        "           [1.0000e+00, 3.3967e-09, 2.4267e-10, 2.6190e-07, 4.2031e-09, 5.8121e-12,\n",
        "            1.1151e-10, 9.0963e-14, 6.7375e-09, 1.9273e-07, 7.9171e-09, 1.4996e-07,\n",
        "            6.2101e-10, 2.3231e-06, 7.8317e-11, 7.8098e-11, 4.4621e-09, 2.2019e-11,\n",
        "            3.4116e-07, 3.1688e-05, 1.7586e-09, 1.5653e-06, 2.6506e-09, 1.9544e-08,\n",
        "            3.4458e-06, 3.9300e-08, 8.3244e-09, 4.6746e-09, 3.5842e-06, 8.6202e-07,\n",
        "            3.4535e-11, 1.8573e-05, 1.1374e-12, 8.8303e-11, 3.6727e-07, 1.5608e-09,\n",
        "            2.1732e-07, 3.1533e-10, 2.4016e-06, 1.3866e-08, 8.3776e-13, 3.2381e-10,\n",
        "            1.9440e-09, 2.0879e-04, 7.6539e-07, 3.4337e-09, 7.0637e-10, 1.2778e-08,\n",
        "            1.5219e-09, 2.0740e-08, 1.6004e-12, 1.7432e-07, 7.4693e-08, 1.0938e-09,\n",
        "            9.4434e-12, 3.4348e-10, 7.3909e-11, 1.5652e-07, 1.1365e-10, 3.0410e-10,\n",
        "            1.3168e-10, 1.8963e-12, 1.7055e-07, 6.9168e-09, 3.4384e-08, 1.9791e-10,\n",
        "            1.8407e-05, 7.2473e-09, 3.5226e-08, 5.4828e-07, 2.3177e-08, 3.8219e-10,\n",
        "            1.6682e-05, 3.5542e-09, 5.9894e-09, 5.2165e-14, 1.2231e-08, 4.2818e-07,\n",
        "            1.0237e-09, 3.1627e-05]]]},\n",
        " {1: [[[9.9675e-01, 1.9405e-03, 2.9267e-03, 2.2958e-05, 7.6831e-04, 3.9533e-04,\n",
        "            3.6149e-04, 7.9860e-03, 5.9478e-04, 1.0889e-04],\n",
        "           [1.0000e+00, 3.9136e-08, 7.2778e-09, 3.1283e-10, 1.8783e-05, 2.5041e-09,\n",
        "            2.1833e-05, 5.4088e-07, 1.0370e-09, 1.8149e-08],\n",
        "           [1.0000e+00, 3.7585e-05, 1.1283e-06, 3.6188e-08, 2.0992e-05, 2.4672e-07,\n",
        "            1.3998e-06, 6.5545e-06, 5.2690e-07, 7.9246e-07],\n",
        "           [1.0000e+00, 1.1913e-06, 1.8508e-06, 9.6649e-09, 5.0319e-06, 1.8961e-07,\n",
        "            3.8241e-07, 1.1612e-06, 2.2529e-07, 2.0893e-06],\n",
        "           [1.0000e+00, 5.5362e-08, 5.3834e-07, 2.4824e-09, 3.5232e-06, 1.3453e-07,\n",
        "            5.7396e-07, 1.5680e-06, 4.6706e-08, 3.5064e-08],\n",
        "           [1.0000e+00, 3.3735e-06, 3.2294e-06, 3.3591e-08, 2.5237e-06, 6.6707e-07,\n",
        "            2.7052e-06, 1.7723e-05, 1.7670e-06, 8.0426e-07],\n",
        "           [1.0000e+00, 3.9221e-05, 6.3970e-08, 9.5927e-09, 8.8523e-06, 1.5219e-08,\n",
        "            1.8456e-05, 1.2740e-07, 3.9835e-08, 2.9568e-06],\n",
        "           [1.0000e+00, 3.1334e-08, 1.8194e-07, 5.3577e-10, 3.4858e-06, 8.8925e-09,\n",
        "            4.8822e-09, 8.5618e-08, 3.2582e-08, 1.2637e-06],\n",
        "           [9.9999e-01, 1.3771e-06, 4.0884e-05, 2.3278e-08, 1.8647e-06, 1.1383e-06,\n",
        "            1.5389e-06, 2.8489e-06, 1.0478e-06, 2.5620e-06],\n",
        "           [9.9997e-01, 9.6893e-06, 1.7038e-05, 2.3080e-07, 1.3176e-03, 7.5329e-06,\n",
        "            1.0037e-05, 5.8992e-05, 6.3828e-06, 2.7492e-05]],\n",
        "   [[9.9675e-01, 1.9405e-03, 2.9267e-03, 2.2958e-05, 7.6831e-04, 3.9533e-04,\n",
        "            3.6149e-04, 7.9860e-03, 5.9478e-04, 1.0889e-04],\n",
        "           [1.0000e+00, 3.9136e-08, 7.2778e-09, 3.1283e-10, 1.8783e-05, 2.5041e-09,\n",
        "            2.1833e-05, 5.4088e-07, 1.0370e-09, 1.8149e-08],\n",
        "           [1.0000e+00, 3.7585e-05, 1.1283e-06, 3.6188e-08, 2.0992e-05, 2.4672e-07,\n",
        "            1.3998e-06, 6.5545e-06, 5.2690e-07, 7.9246e-07],\n",
        "           [1.0000e+00, 1.1913e-06, 1.8508e-06, 9.6649e-09, 5.0319e-06, 1.8961e-07,\n",
        "            3.8241e-07, 1.1612e-06, 2.2529e-07, 2.0893e-06],\n",
        "           [1.0000e+00, 5.5362e-08, 5.3834e-07, 2.4824e-09, 3.5232e-06, 1.3453e-07,\n",
        "            5.7396e-07, 1.5680e-06, 4.6706e-08, 3.5064e-08],\n",
        "           [1.0000e+00, 3.3735e-06, 3.2294e-06, 3.3591e-08, 2.5237e-06, 6.6707e-07,\n",
        "            2.7052e-06, 1.7723e-05, 1.7670e-06, 8.0426e-07],\n",
        "           [1.0000e+00, 3.9221e-05, 6.3970e-08, 9.5927e-09, 8.8523e-06, 1.5219e-08,\n",
        "            1.8456e-05, 1.2740e-07, 3.9835e-08, 2.9568e-06],\n",
        "           [1.0000e+00, 3.1334e-08, 1.8194e-07, 5.3577e-10, 3.4858e-06, 8.8925e-09,\n",
        "            4.8822e-09, 8.5618e-08, 3.2582e-08, 1.2637e-06],\n",
        "           [9.9999e-01, 1.3771e-06, 4.0884e-05, 2.3278e-08, 1.8647e-06, 1.1383e-06,\n",
        "            1.5389e-06, 2.8489e-06, 1.0478e-06, 2.5620e-06],\n",
        "           [9.9997e-01, 9.6893e-06, 1.7038e-05, 2.3080e-07, 1.3176e-03, 7.5329e-06,\n",
        "            1.0037e-05, 5.8992e-05, 6.3828e-06, 2.7492e-05]]],\n",
        "  2: [[[9.9576e-01, 5.6356e-03, 5.1784e-03, 2.7833e-05, 1.3690e-03, 4.1772e-04,\n",
        "            2.6829e-03, 6.6040e-03, 7.3081e-04, 3.3454e-04, 3.9820e-05, 1.2683e-02,\n",
        "            1.4226e-05, 2.2656e-04, 1.7503e-04, 5.3236e-07, 2.2348e-05, 9.4289e-04,\n",
        "            8.2729e-05, 1.4333e-03],\n",
        "           [9.9984e-01, 8.8776e-06, 8.9419e-06, 5.4175e-07, 2.5605e-03, 3.5509e-06,\n",
        "            1.0875e-04, 6.2581e-05, 5.2045e-07, 4.1386e-06, 4.0294e-08, 7.7502e-07,\n",
        "            1.1723e-09, 3.8523e-08, 2.7014e-08, 1.6345e-11, 2.1542e-07, 3.7851e-06,\n",
        "            7.5020e-07, 1.1481e-06],\n",
        "           [9.9984e-01, 1.4393e-04, 1.2851e-05, 2.1621e-06, 1.8695e-03, 1.3385e-05,\n",
        "            1.5781e-04, 4.0013e-05, 4.3783e-06, 4.4051e-06, 4.5503e-08, 7.3673e-07,\n",
        "            3.2650e-07, 3.4725e-05, 3.7635e-09, 1.7517e-10, 9.7944e-08, 1.9125e-04,\n",
        "            3.4698e-09, 3.7376e-06],\n",
        "           [9.9992e-01, 3.2906e-05, 3.2963e-05, 1.5644e-06, 4.2078e-04, 3.5267e-06,\n",
        "            6.8188e-05, 1.0116e-05, 1.6289e-06, 3.3045e-05, 8.8960e-07, 5.8938e-07,\n",
        "            5.5091e-09, 2.8425e-04, 2.9692e-10, 2.3806e-09, 2.9855e-07, 1.7486e-08,\n",
        "            2.5218e-10, 1.9756e-07],\n",
        "           [9.9986e-01, 1.6137e-05, 2.7790e-05, 6.4894e-07, 2.9610e-04, 3.4952e-06,\n",
        "            8.6011e-05, 2.9024e-05, 2.6463e-06, 1.6302e-06, 1.0745e-07, 1.1834e-09,\n",
        "            1.1576e-09, 1.4385e-07, 1.2554e-09, 6.3223e-12, 8.5600e-10, 3.3882e-06,\n",
        "            1.2006e-09, 2.2862e-05],\n",
        "           [9.9999e-01, 8.5245e-06, 1.3647e-05, 6.1132e-07, 1.0319e-04, 1.4375e-06,\n",
        "            1.4362e-05, 1.0928e-05, 5.1880e-07, 1.6788e-06, 3.6971e-06, 2.7502e-08,\n",
        "            1.1650e-08, 1.3757e-07, 7.4059e-11, 5.9853e-12, 1.0773e-07, 5.3514e-08,\n",
        "            6.8858e-11, 7.9017e-07],\n",
        "           [9.9988e-01, 1.5405e-04, 3.8556e-05, 7.4754e-06, 1.9045e-03, 2.0296e-05,\n",
        "            2.4065e-04, 9.3337e-05, 5.2035e-06, 3.1621e-06, 2.6194e-07, 1.2176e-07,\n",
        "            4.0942e-07, 2.5713e-04, 4.7038e-09, 4.7090e-10, 1.0648e-07, 7.0159e-04,\n",
        "            7.4982e-09, 1.0849e-05],\n",
        "           [9.9994e-01, 5.3046e-06, 1.6588e-05, 6.5041e-07, 3.1737e-04, 1.0656e-06,\n",
        "            1.4958e-05, 3.4092e-06, 4.5773e-07, 9.9720e-06, 3.3355e-08, 1.1425e-07,\n",
        "            2.3886e-09, 6.5693e-07, 3.9801e-10, 5.3662e-11, 1.5949e-09, 4.0150e-09,\n",
        "            1.4452e-11, 8.2960e-07],\n",
        "           [9.9997e-01, 3.2125e-05, 5.7967e-05, 3.6462e-07, 2.9532e-05, 8.1232e-06,\n",
        "            6.3658e-06, 2.3678e-05, 8.4487e-06, 3.1693e-06, 4.0102e-07, 1.2584e-06,\n",
        "            3.7116e-10, 5.4485e-09, 2.8310e-09, 5.8144e-11, 7.2360e-09, 7.7373e-08,\n",
        "            3.9706e-08, 1.0055e-05],\n",
        "           [9.9865e-01, 7.1700e-04, 1.7421e-04, 1.0446e-05, 1.1263e-03, 3.9279e-05,\n",
        "            8.6711e-04, 1.1585e-04, 2.1755e-05, 6.3026e-05, 1.2658e-04, 1.0026e-05,\n",
        "            1.4193e-07, 1.0592e-04, 1.8455e-08, 1.7444e-07, 7.8008e-06, 1.3432e-06,\n",
        "            3.1778e-08, 5.8806e-06]],\n",
        "   [[9.9827e-01, 2.9183e-03, 1.8905e-03, 2.5136e-05, 6.7528e-04, 2.3172e-04,\n",
        "            2.9385e-04, 4.2130e-03, 4.8867e-04, 6.6612e-05],\n",
        "           [9.9999e-01, 5.4751e-07, 1.1815e-08, 2.3711e-09, 4.1564e-04, 1.2911e-08,\n",
        "            6.2294e-07, 2.4553e-05, 1.6831e-08, 5.0345e-08],\n",
        "           [9.9999e-01, 1.1651e-04, 4.1824e-06, 1.8877e-07, 2.1016e-03, 1.6216e-06,\n",
        "            9.8692e-05, 1.1898e-05, 1.1013e-06, 9.3140e-06],\n",
        "           [1.0000e+00, 5.8748e-06, 6.8655e-06, 7.3922e-08, 1.4613e-04, 1.9687e-06,\n",
        "            1.2051e-05, 2.7613e-06, 7.9749e-07, 1.3474e-05],\n",
        "           [1.0000e+00, 2.3167e-07, 8.5377e-06, 2.4754e-08, 1.3561e-05, 9.1074e-07,\n",
        "            2.3662e-05, 3.1505e-05, 6.2991e-07, 9.7880e-08],\n",
        "           [1.0000e+00, 3.1046e-05, 1.2751e-07, 3.7446e-09, 3.0354e-07, 4.1198e-09,\n",
        "            7.4486e-07, 1.0333e-07, 1.1081e-08, 5.9495e-08],\n",
        "           [1.0000e+00, 2.6165e-06, 1.6633e-06, 3.6293e-08, 1.9558e-04, 3.3095e-07,\n",
        "            3.1514e-06, 3.4841e-06, 1.6232e-07, 5.1189e-07],\n",
        "           [1.0000e+00, 1.7186e-08, 3.1150e-07, 1.8521e-09, 3.1228e-05, 7.0362e-08,\n",
        "            9.7707e-08, 1.1864e-07, 5.9518e-08, 5.8582e-06],\n",
        "           [1.0000e+00, 1.3397e-06, 4.0085e-06, 7.8311e-09, 7.8508e-06, 2.7688e-07,\n",
        "            4.2477e-07, 3.3033e-06, 3.6790e-07, 3.9823e-07],\n",
        "           [9.9998e-01, 7.1278e-05, 1.8846e-05, 1.6921e-06, 2.0342e-04, 1.6118e-05,\n",
        "            1.2092e-04, 2.2558e-04, 2.8075e-05, 1.5930e-05]]],\n",
        "  3: [[[9.9503e-01, 8.4993e-03, 2.8418e-03, 1.3949e-05, 2.0869e-03, 4.8083e-04,\n",
        "            7.2865e-03, 2.0297e-03, 5.1354e-04, 3.7172e-04, 5.2104e-04, 2.1280e-02,\n",
        "            3.1946e-05, 1.6704e-04, 1.4777e-04, 2.2933e-05, 9.3523e-04, 3.8875e-04,\n",
        "            8.2627e-05, 4.3269e-03, 3.1947e-04, 1.2741e-06, 3.6073e-07, 5.1585e-04,\n",
        "            2.6785e-08, 1.2847e-07, 1.9966e-08, 1.3543e-07, 1.0941e-04, 6.6827e-07],\n",
        "           [9.9931e-01, 2.8303e-04, 1.1631e-04, 1.0430e-05, 7.0295e-04, 6.9354e-05,\n",
        "            1.1650e-03, 1.8328e-03, 6.8371e-05, 1.4154e-05, 5.7736e-06, 2.2837e-05,\n",
        "            9.1936e-08, 6.0962e-05, 3.3669e-07, 1.2953e-07, 3.1803e-05, 3.9351e-04,\n",
        "            2.6157e-05, 5.2331e-05, 2.1512e-08, 1.6242e-11, 1.2055e-09, 9.3072e-07,\n",
        "            9.0996e-10, 9.3384e-10, 1.2027e-11, 5.9412e-07, 7.0583e-06, 4.6345e-10],\n",
        "           [9.9228e-01, 6.7129e-03, 1.1457e-03, 3.7621e-05, 5.9777e-03, 1.1287e-03,\n",
        "            9.1497e-03, 1.9463e-03, 1.0652e-03, 1.1428e-04, 2.8567e-04, 1.5897e-03,\n",
        "            1.3597e-05, 2.7525e-03, 1.3696e-04, 1.4273e-06, 2.6253e-04, 7.2817e-04,\n",
        "            4.0369e-05, 2.2704e-03, 1.6133e-06, 1.9558e-08, 5.0992e-05, 1.4185e-03,\n",
        "            4.7836e-08, 2.1410e-06, 2.6764e-06, 1.3003e-04, 1.3130e-05, 2.7437e-08],\n",
        "           [9.9953e-01, 1.0698e-03, 7.2732e-04, 5.8218e-06, 6.0847e-04, 1.7425e-04,\n",
        "            2.3769e-04, 8.1146e-05, 2.9773e-04, 6.6919e-05, 2.5941e-04, 1.0977e-04,\n",
        "            1.0553e-07, 1.9915e-04, 3.2977e-06, 5.9093e-08, 2.9342e-05, 2.7776e-05,\n",
        "            9.2280e-06, 2.5439e-03, 2.3394e-08, 2.8444e-10, 3.4991e-07, 2.3408e-04,\n",
        "            6.5249e-09, 3.2697e-08, 2.7506e-10, 6.8546e-08, 9.9629e-07, 5.2957e-09],\n",
        "           [9.9833e-01, 3.2175e-04, 9.7046e-04, 3.2129e-05, 9.6789e-04, 2.7227e-04,\n",
        "            5.1882e-04, 1.6085e-03, 1.6680e-04, 3.9645e-05, 2.0164e-04, 1.4210e-05,\n",
        "            2.0438e-07, 1.3859e-04, 1.2309e-06, 7.5924e-08, 8.8493e-06, 1.2451e-03,\n",
        "            1.1119e-04, 8.8993e-05, 2.9417e-08, 1.8468e-10, 9.6302e-08, 2.4429e-07,\n",
        "            1.4767e-09, 2.1477e-08, 9.7230e-10, 4.7270e-06, 5.6098e-05, 4.4138e-10],\n",
        "           [9.9995e-01, 9.7342e-05, 2.8991e-05, 1.1838e-06, 2.2432e-04, 2.8845e-05,\n",
        "            1.6373e-05, 1.4316e-04, 1.1820e-05, 5.4785e-07, 9.3627e-07, 7.7587e-07,\n",
        "            1.1408e-09, 5.7174e-05, 5.0176e-09, 7.0010e-11, 9.8490e-08, 4.9134e-06,\n",
        "            5.1615e-08, 6.0093e-06, 1.5534e-13, 1.3353e-15, 1.4721e-12, 9.7821e-09,\n",
        "            2.4624e-14, 4.0016e-14, 1.0587e-12, 2.6132e-09, 4.7635e-10, 2.0690e-14],\n",
        "           [9.9850e-01, 1.0332e-03, 2.1986e-03, 1.3698e-05, 4.6563e-03, 6.4156e-04,\n",
        "            8.2740e-04, 1.8798e-03, 2.4848e-04, 2.7543e-05, 4.4739e-04, 1.3259e-05,\n",
        "            4.3685e-07, 3.1989e-03, 1.0785e-06, 7.4960e-08, 9.7972e-05, 2.8470e-03,\n",
        "            1.7670e-05, 1.8176e-03, 2.9934e-07, 4.7599e-10, 1.2395e-06, 9.6842e-05,\n",
        "            3.4658e-08, 4.6134e-07, 1.3975e-08, 1.1047e-05, 7.9402e-06, 1.6338e-10],\n",
        "           [9.9813e-01, 2.4486e-04, 3.0849e-04, 1.0803e-05, 1.4498e-03, 9.2054e-05,\n",
        "            5.3037e-04, 2.4014e-04, 1.6976e-04, 3.3828e-05, 1.2613e-05, 9.3269e-05,\n",
        "            1.2375e-06, 4.4656e-05, 1.2270e-06, 4.7148e-08, 4.9571e-06, 1.1231e-05,\n",
        "            4.1914e-07, 5.8704e-04, 7.2166e-10, 7.0118e-12, 1.1869e-07, 1.3125e-04,\n",
        "            1.0555e-09, 4.3480e-09, 2.8742e-10, 2.9181e-08, 7.5798e-08, 1.7984e-09],\n",
        "           [9.9901e-01, 8.0005e-04, 6.7738e-04, 6.9876e-06, 1.0963e-03, 2.2719e-04,\n",
        "            6.2372e-05, 4.1850e-04, 2.1361e-04, 4.1456e-05, 1.0130e-06, 5.0184e-04,\n",
        "            1.2799e-07, 1.2192e-05, 2.5164e-07, 1.9537e-07, 3.4819e-06, 7.5815e-05,\n",
        "            1.8209e-04, 5.2066e-05, 6.5873e-10, 7.0504e-11, 1.8832e-08, 4.6080e-05,\n",
        "            1.5310e-11, 3.5106e-10, 7.9916e-12, 1.7896e-08, 3.3186e-06, 2.1786e-10],\n",
        "           [9.9983e-01, 1.7374e-04, 3.2194e-04, 5.4866e-06, 8.1546e-04, 1.0699e-04,\n",
        "            7.4595e-05, 2.5189e-04, 7.2103e-05, 6.9897e-06, 3.3545e-05, 1.3324e-06,\n",
        "            2.5127e-08, 6.5214e-05, 1.1111e-07, 1.0391e-08, 2.2142e-06, 9.5226e-06,\n",
        "            1.4172e-05, 6.3561e-05, 1.1197e-11, 1.5489e-10, 8.0193e-10, 1.0038e-06,\n",
        "            1.3602e-11, 4.3504e-11, 2.6325e-12, 2.3741e-09, 1.2195e-06, 2.8637e-12]],\n",
        "   [[9.9975e-01, 5.1315e-04, 1.7071e-04, 1.2916e-06, 1.7883e-04, 1.0117e-05,\n",
        "            2.2378e-05, 1.9019e-04, 2.4197e-05, 1.9729e-05, 7.7432e-07, 2.0611e-03,\n",
        "            9.9372e-08, 5.9699e-05, 3.0192e-06, 3.8196e-09, 1.3525e-06, 7.0448e-05,\n",
        "            1.9804e-07, 2.1485e-04],\n",
        "           [1.0000e+00, 5.1324e-07, 3.0047e-07, 1.9429e-08, 1.0331e-04, 3.6185e-07,\n",
        "            1.2612e-05, 2.8056e-05, 2.7405e-07, 5.4235e-07, 3.5129e-07, 9.7815e-07,\n",
        "            1.1971e-07, 3.3625e-07, 3.1900e-08, 3.8222e-10, 4.0482e-07, 4.4078e-06,\n",
        "            4.2083e-07, 7.9146e-06],\n",
        "           [9.9999e-01, 4.6443e-05, 2.0310e-05, 1.5277e-06, 2.6935e-04, 1.9346e-05,\n",
        "            9.9036e-05, 7.5857e-05, 2.0895e-05, 2.1258e-05, 4.5642e-05, 1.7690e-04,\n",
        "            1.9497e-06, 1.2515e-03, 1.3614e-05, 1.0484e-07, 1.7067e-05, 2.2162e-04,\n",
        "            1.9527e-06, 6.1075e-04],\n",
        "           [1.0000e+00, 4.8159e-06, 8.1106e-06, 5.5551e-08, 4.0566e-05, 1.6605e-06,\n",
        "            4.1070e-06, 1.1172e-05, 1.5542e-06, 7.8217e-06, 8.6537e-06, 4.1749e-04,\n",
        "            4.3665e-08, 6.3561e-05, 7.3827e-07, 6.5287e-09, 1.8306e-06, 9.6678e-07,\n",
        "            2.9811e-07, 1.6225e-05],\n",
        "           [9.9997e-01, 5.2654e-06, 1.2425e-04, 1.4041e-06, 1.3760e-04, 7.8537e-05,\n",
        "            3.2814e-05, 9.6733e-04, 6.8258e-05, 4.8839e-05, 7.4629e-06, 8.1491e-07,\n",
        "            5.9801e-07, 2.0407e-05, 6.6087e-07, 1.1304e-08, 2.6843e-06, 1.0994e-02,\n",
        "            2.4617e-07, 1.6353e-04],\n",
        "           [1.0000e+00, 4.5976e-06, 2.8846e-08, 1.6925e-09, 1.6193e-06, 4.5994e-09,\n",
        "            7.3610e-07, 7.3348e-08, 4.4083e-09, 5.0489e-08, 2.4480e-08, 1.7592e-08,\n",
        "            4.9662e-10, 4.9390e-07, 8.3069e-11, 1.2682e-12, 1.7818e-08, 3.6706e-07,\n",
        "            8.2752e-11, 2.0072e-07],\n",
        "           [1.0000e+00, 4.0728e-06, 2.8490e-06, 8.8488e-08, 6.8586e-05, 6.9147e-07,\n",
        "            4.8332e-05, 3.3041e-06, 5.9325e-07, 3.5570e-06, 3.4698e-06, 2.7940e-08,\n",
        "            9.3258e-08, 1.1164e-04, 1.3682e-09, 6.0882e-10, 5.4214e-07, 3.3565e-05,\n",
        "            2.1526e-09, 1.2690e-05],\n",
        "           [9.9991e-01, 1.0231e-06, 2.3174e-06, 1.2266e-07, 2.8928e-04, 9.2582e-07,\n",
        "            1.0064e-06, 5.2345e-06, 1.1800e-06, 3.8728e-04, 1.4835e-07, 7.7331e-06,\n",
        "            6.4413e-08, 2.1638e-06, 1.5097e-08, 4.0719e-10, 3.6983e-08, 8.6296e-08,\n",
        "            4.8588e-09, 3.1188e-05],\n",
        "           [1.0000e+00, 6.3628e-06, 1.7057e-05, 1.0489e-08, 3.6562e-06, 2.5651e-07,\n",
        "            3.7365e-07, 1.0441e-06, 3.1573e-07, 5.8169e-07, 6.5544e-07, 4.0966e-06,\n",
        "            5.2929e-10, 3.6034e-08, 1.0295e-08, 1.3253e-10, 6.0610e-09, 9.3168e-08,\n",
        "            1.2113e-07, 1.5345e-05],\n",
        "           [1.0000e+00, 2.1522e-06, 7.1459e-07, 1.6334e-08, 2.8384e-06, 7.0501e-08,\n",
        "            5.6469e-07, 1.5554e-06, 1.5645e-07, 1.7409e-07, 9.0906e-06, 3.0557e-08,\n",
        "            3.2501e-10, 1.4586e-07, 1.8648e-09, 1.1328e-10, 8.9617e-08, 4.0888e-08,\n",
        "            9.6390e-09, 1.0606e-06]]],\n",
        "  4: [[[9.7729e-01, 4.1358e-02, 5.9934e-03, 3.8451e-05, 7.4464e-03, 1.5540e-03,\n",
        "            9.4944e-03, 4.3170e-03, 6.6100e-04, 2.5680e-03, 1.0830e-02, 2.4720e-02,\n",
        "            7.9576e-05, 5.6113e-04, 6.7674e-04, 3.6942e-05, 8.3344e-04, 1.4701e-03,\n",
        "            6.9450e-04, 1.8492e-02, 1.0188e-02, 2.7228e-05, 3.0767e-04, 5.7422e-03,\n",
        "            4.5415e-06, 7.8245e-06, 5.4848e-06, 8.3199e-05, 9.7906e-04, 5.8553e-05,\n",
        "            4.1034e-08, 3.4510e-06, 1.0485e-07, 4.3902e-07, 7.3744e-08, 3.6245e-10,\n",
        "            1.5575e-03, 1.3520e-06, 1.0893e-03, 1.5539e-06],\n",
        "           [9.9731e-01, 2.1486e-04, 4.9209e-04, 7.8332e-06, 1.1318e-03, 1.4855e-04,\n",
        "            7.2813e-03, 8.2162e-04, 1.8599e-05, 2.8585e-05, 3.8336e-05, 7.3996e-05,\n",
        "            6.1298e-08, 8.8483e-05, 5.4609e-06, 2.2726e-06, 1.0963e-04, 5.1165e-03,\n",
        "            3.8746e-05, 1.0748e-04, 7.7850e-06, 3.1281e-08, 5.5739e-05, 5.4466e-05,\n",
        "            5.5671e-08, 2.3372e-08, 5.2119e-08, 5.3451e-06, 7.8698e-05, 1.0754e-08,\n",
        "            2.8913e-13, 5.9628e-09, 1.5150e-11, 6.8567e-07, 2.2849e-11, 2.7943e-11,\n",
        "            5.3393e-10, 1.3971e-08, 4.5320e-09, 1.0189e-06],\n",
        "           [9.9552e-01, 2.2545e-03, 1.3943e-03, 1.2455e-05, 2.8243e-03, 7.3786e-04,\n",
        "            1.2005e-03, 5.9869e-04, 3.4605e-04, 1.6008e-04, 3.1328e-04, 1.1262e-03,\n",
        "            3.7898e-06, 1.7685e-04, 6.4193e-06, 1.1745e-05, 1.4792e-04, 3.0122e-03,\n",
        "            1.7863e-04, 6.7229e-04, 4.9537e-06, 9.8107e-07, 3.8180e-04, 2.1441e-03,\n",
        "            4.6421e-07, 1.2716e-06, 8.0712e-07, 2.3278e-04, 4.5080e-05, 1.9245e-07,\n",
        "            5.1284e-08, 1.3827e-08, 1.2276e-09, 1.3859e-07, 1.7933e-11, 1.3518e-08,\n",
        "            4.7049e-09, 2.7541e-05, 2.4249e-07, 1.4917e-05],\n",
        "           [9.9945e-01, 3.0222e-03, 4.1069e-04, 4.7861e-06, 1.3710e-03, 8.8137e-04,\n",
        "            2.0135e-04, 1.6422e-04, 6.5591e-05, 5.9231e-05, 4.6333e-04, 1.3976e-04,\n",
        "            6.3152e-07, 1.1122e-03, 1.7859e-06, 2.3419e-06, 1.1740e-05, 3.1908e-04,\n",
        "            2.7295e-05, 5.6427e-04, 2.9370e-07, 7.8366e-07, 6.0658e-05, 5.1399e-04,\n",
        "            6.0887e-08, 9.0224e-08, 3.4104e-07, 1.6791e-06, 8.7124e-06, 2.4569e-08,\n",
        "            3.7769e-08, 4.6322e-08, 8.5970e-11, 4.2865e-10, 1.5993e-12, 3.8961e-12,\n",
        "            5.8745e-07, 4.9287e-07, 1.2467e-09, 1.6952e-06],\n",
        "           [9.9933e-01, 4.1686e-04, 6.2118e-04, 8.4446e-06, 1.6214e-03, 6.0224e-04,\n",
        "            3.3388e-04, 5.8383e-04, 5.8334e-05, 5.0665e-05, 6.5414e-04, 1.3695e-05,\n",
        "            1.8696e-07, 1.6291e-03, 6.7536e-07, 5.7294e-07, 1.2802e-05, 1.1154e-03,\n",
        "            2.0363e-04, 2.2570e-04, 3.9765e-07, 1.7507e-07, 4.7663e-06, 1.0337e-04,\n",
        "            3.0739e-08, 2.2652e-08, 7.8004e-07, 4.5640e-06, 9.8494e-06, 1.0841e-08,\n",
        "            1.4216e-10, 2.4124e-10, 1.7866e-11, 1.4899e-09, 1.2508e-12, 3.4960e-10,\n",
        "            4.7851e-10, 3.4244e-07, 8.2674e-11, 8.5580e-07],\n",
        "           [9.9975e-01, 3.0494e-04, 1.8278e-04, 5.6341e-06, 5.8597e-04, 1.5693e-04,\n",
        "            2.4201e-04, 8.5013e-04, 2.6623e-05, 7.2694e-06, 4.8095e-05, 4.5725e-05,\n",
        "            1.3718e-07, 9.9958e-05, 1.9611e-07, 2.4462e-07, 1.3049e-05, 3.0867e-04,\n",
        "            3.1735e-05, 1.0075e-04, 1.2234e-07, 9.6179e-09, 5.7289e-07, 3.9184e-04,\n",
        "            1.2436e-08, 9.7028e-09, 4.6270e-07, 1.5944e-06, 1.8816e-06, 4.1686e-09,\n",
        "            6.6637e-11, 1.6493e-10, 2.2817e-11, 2.3550e-12, 4.0281e-14, 4.4441e-11,\n",
        "            6.0455e-11, 4.9354e-07, 6.0115e-07, 3.6466e-08],\n",
        "           [9.9649e-01, 3.4186e-03, 1.6506e-03, 1.2641e-05, 1.5234e-03, 6.2932e-04,\n",
        "            2.7040e-03, 7.3766e-04, 1.8486e-04, 1.4118e-04, 1.6752e-03, 1.6372e-04,\n",
        "            2.5193e-06, 3.7316e-04, 5.7218e-06, 5.3567e-06, 8.3636e-05, 1.3376e-02,\n",
        "            1.4150e-04, 1.2198e-03, 3.2688e-06, 7.4681e-06, 3.0616e-04, 7.5841e-04,\n",
        "            1.3584e-06, 9.4178e-07, 1.2049e-06, 8.4190e-05, 5.5579e-05, 2.4413e-07,\n",
        "            8.6154e-07, 5.2764e-09, 1.5527e-08, 2.7888e-07, 6.6174e-10, 2.2611e-07,\n",
        "            5.2546e-08, 1.4465e-07, 7.4548e-09, 8.6475e-05],\n",
        "           [9.9822e-01, 9.3057e-04, 1.6653e-03, 1.2460e-06, 5.9194e-04, 3.0653e-04,\n",
        "            1.3156e-04, 1.7165e-04, 5.5576e-05, 1.1301e-04, 1.0928e-04, 1.7681e-04,\n",
        "            1.3696e-07, 2.0484e-05, 8.8538e-07, 9.2863e-07, 2.8136e-06, 7.1707e-05,\n",
        "            3.3375e-06, 5.5485e-03, 3.3924e-07, 6.4187e-09, 1.0896e-04, 7.5755e-05,\n",
        "            1.0820e-08, 3.3856e-08, 3.6739e-08, 2.0693e-06, 9.9172e-07, 4.4499e-09,\n",
        "            1.7230e-08, 6.7578e-08, 3.1859e-11, 2.3359e-10, 3.5502e-13, 5.0145e-13,\n",
        "            3.4985e-09, 2.4281e-09, 1.1983e-07, 2.4369e-10],\n",
        "           [9.9319e-01, 7.4407e-03, 1.6501e-03, 2.6199e-05, 2.7478e-03, 1.1248e-03,\n",
        "            2.0257e-03, 6.5484e-04, 4.5499e-04, 5.0490e-04, 7.6048e-04, 2.3016e-03,\n",
        "            5.3688e-06, 3.6434e-04, 2.8416e-05, 2.7125e-05, 8.5093e-05, 2.1589e-03,\n",
        "            1.5274e-03, 5.3793e-04, 2.9985e-06, 1.1829e-06, 4.5475e-04, 5.4606e-03,\n",
        "            1.5027e-07, 3.5950e-07, 1.6755e-05, 2.4509e-04, 7.5605e-05, 9.7103e-07,\n",
        "            2.1528e-09, 1.4581e-09, 6.0916e-10, 6.8084e-08, 2.9966e-11, 2.0679e-08,\n",
        "            2.4650e-08, 1.0027e-04, 2.8678e-06, 4.0156e-06],\n",
        "           [9.9816e-01, 2.8903e-03, 1.1572e-03, 1.7467e-05, 2.7955e-03, 8.9984e-04,\n",
        "            5.6126e-04, 1.7253e-03, 1.7576e-04, 1.1295e-04, 9.4125e-04, 5.7194e-05,\n",
        "            1.8767e-06, 1.7087e-03, 7.4741e-06, 9.8153e-06, 4.3283e-05, 6.5028e-04,\n",
        "            1.5772e-04, 8.7344e-04, 8.0007e-07, 7.2594e-07, 4.5188e-05, 3.0800e-04,\n",
        "            1.9294e-07, 2.4977e-07, 3.3951e-06, 7.5919e-06, 1.7997e-05, 1.1903e-07,\n",
        "            3.1491e-09, 6.6047e-07, 5.3946e-11, 1.7905e-08, 3.9008e-12, 9.9466e-10,\n",
        "            1.3732e-07, 6.4043e-07, 5.6584e-09, 2.6020e-07]],\n",
        "   [[9.9675e-01, 1.9405e-03, 2.9267e-03, 2.2958e-05, 7.6831e-04, 3.9533e-04,\n",
        "            3.6149e-04, 7.9860e-03, 5.9478e-04, 1.0889e-04, 4.7229e-04, 1.9576e-03,\n",
        "            1.0670e-04, 1.1273e-03, 1.1077e-05, 8.1197e-07, 1.0775e-04, 6.5548e-04,\n",
        "            1.8181e-05, 2.4716e-03, 3.0095e-04, 3.0275e-06, 1.1399e-07, 5.6137e-04,\n",
        "            4.2913e-07, 3.8367e-07, 3.5724e-08, 1.2737e-06, 1.8378e-05, 4.8027e-06],\n",
        "           [1.0000e+00, 3.7998e-07, 4.3262e-08, 9.9352e-10, 2.8273e-06, 7.3927e-09,\n",
        "            1.5353e-06, 6.1452e-07, 6.5618e-09, 2.2082e-08, 1.2664e-08, 4.8213e-06,\n",
        "            5.0238e-10, 9.9615e-08, 3.1846e-07, 2.1113e-11, 8.7905e-09, 1.2943e-06,\n",
        "            4.4205e-09, 1.2963e-06, 7.5218e-09, 2.2162e-12, 3.8212e-09, 5.6382e-07,\n",
        "            4.4898e-10, 9.3348e-10, 8.3981e-13, 1.7742e-07, 1.6781e-05, 2.4430e-10],\n",
        "           [1.0000e+00, 1.0841e-06, 4.3666e-06, 2.3677e-08, 5.3873e-05, 8.3908e-07,\n",
        "            3.0427e-06, 5.6047e-06, 6.1908e-07, 8.7366e-07, 1.6861e-07, 3.2178e-06,\n",
        "            1.8905e-08, 3.9509e-05, 1.3450e-08, 7.3527e-11, 1.9878e-08, 3.0896e-05,\n",
        "            4.8660e-09, 1.2600e-05, 1.5844e-09, 3.2405e-11, 5.4293e-06, 4.7892e-06,\n",
        "            1.9524e-10, 2.1426e-08, 4.6254e-09, 1.2256e-05, 1.7968e-06, 2.5308e-10],\n",
        "           [1.0000e+00, 7.7094e-08, 1.4917e-06, 3.5804e-09, 1.2766e-04, 2.9342e-07,\n",
        "            1.9051e-07, 1.1386e-06, 1.7690e-07, 2.3016e-06, 6.2241e-09, 3.4120e-06,\n",
        "            7.1443e-10, 4.5323e-07, 2.9176e-09, 1.2879e-11, 1.7194e-09, 3.1457e-08,\n",
        "            2.0008e-10, 5.4015e-07, 3.8158e-10, 6.8013e-12, 1.9826e-07, 4.5536e-06,\n",
        "            1.1184e-10, 1.8851e-09, 1.4891e-11, 1.5446e-08, 1.3878e-06, 1.1798e-10],\n",
        "           [1.0000e+00, 3.6720e-07, 1.0637e-05, 3.0444e-08, 1.8279e-05, 1.0387e-06,\n",
        "            1.5158e-06, 6.5379e-06, 3.6878e-07, 1.2611e-07, 6.4186e-08, 2.9194e-09,\n",
        "            3.7437e-09, 5.1739e-07, 3.9134e-11, 6.4861e-12, 9.3017e-09, 7.6671e-06,\n",
        "            4.7543e-10, 5.3478e-06, 8.8714e-11, 1.5113e-13, 6.7334e-10, 7.1619e-08,\n",
        "            6.9523e-12, 6.9923e-10, 7.7202e-11, 3.9892e-07, 1.5392e-07, 1.1532e-12],\n",
        "           [1.0000e+00, 7.1625e-07, 6.5400e-07, 1.6662e-09, 6.7108e-07, 2.0835e-08,\n",
        "            3.3150e-07, 3.2268e-07, 7.5809e-08, 1.0026e-07, 4.9565e-10, 3.2335e-09,\n",
        "            3.4885e-10, 5.1344e-08, 2.8151e-10, 1.0361e-12, 2.2043e-10, 6.0717e-07,\n",
        "            2.6509e-10, 1.2502e-06, 2.0971e-12, 2.3520e-14, 8.9682e-12, 2.9962e-07,\n",
        "            8.7709e-13, 1.2289e-11, 2.0295e-11, 4.0653e-09, 1.7805e-09, 3.8931e-12],\n",
        "           [1.0000e+00, 2.5234e-04, 1.0141e-06, 1.3677e-07, 2.0420e-05, 2.2664e-07,\n",
        "            1.0308e-04, 3.4210e-06, 5.3894e-07, 5.4590e-06, 2.4490e-06, 5.7135e-07,\n",
        "            3.5165e-08, 2.8242e-06, 2.0807e-09, 1.3512e-10, 4.1164e-07, 4.4318e-05,\n",
        "            9.4875e-09, 2.0377e-06, 7.8802e-10, 1.2806e-10, 1.2628e-06, 2.6845e-06,\n",
        "            1.0472e-09, 1.5630e-08, 7.2660e-09, 5.3122e-06, 2.2561e-06, 7.2112e-11],\n",
        "           [1.0000e+00, 3.2420e-08, 6.4797e-07, 9.5303e-10, 1.4385e-05, 2.6152e-08,\n",
        "            6.0016e-08, 2.2277e-07, 3.9362e-08, 5.6378e-07, 2.7354e-08, 3.8381e-07,\n",
        "            3.5030e-08, 8.1118e-07, 2.9356e-09, 7.0476e-11, 2.3461e-09, 1.3150e-06,\n",
        "            2.4049e-10, 4.8116e-06, 3.3782e-10, 1.7720e-11, 2.9966e-08, 3.2430e-05,\n",
        "            1.4607e-10, 8.0186e-10, 6.2635e-11, 1.3992e-08, 1.3471e-07, 1.0069e-10],\n",
        "           [9.9995e-01, 5.4302e-06, 4.7076e-05, 5.5716e-08, 2.4280e-05, 1.8178e-06,\n",
        "            2.8050e-06, 6.2149e-06, 2.5192e-06, 1.5529e-06, 8.8824e-07, 1.3995e-05,\n",
        "            3.2853e-09, 2.1982e-07, 3.5518e-08, 2.7318e-09, 1.8335e-08, 7.1371e-08,\n",
        "            2.5822e-06, 1.2769e-05, 5.9641e-09, 8.7913e-09, 4.3610e-07, 1.6578e-04,\n",
        "            2.4007e-10, 9.2807e-09, 1.5053e-09, 1.8628e-07, 4.4919e-06, 2.4081e-09],\n",
        "           [1.0000e+00, 1.5304e-05, 1.9115e-06, 9.1234e-08, 9.7628e-06, 5.1401e-07,\n",
        "            4.5374e-06, 5.6598e-06, 1.2179e-06, 5.6253e-06, 9.2211e-06, 5.6363e-08,\n",
        "            2.9524e-09, 2.4728e-07, 1.8444e-09, 3.1184e-10, 1.0226e-07, 6.6529e-07,\n",
        "            3.3009e-09, 3.0251e-06, 5.9326e-10, 2.9708e-09, 3.0257e-08, 3.1521e-05,\n",
        "            8.8196e-10, 1.8862e-09, 2.4048e-10, 3.1238e-08, 5.4142e-06, 6.9621e-11]]],\n",
        "  5: [[[9.7427e-01, 3.0776e-02, 7.0236e-03, 3.5646e-05, 5.3765e-03, 7.2342e-04,\n",
        "            8.0844e-03, 8.6134e-03, 1.0386e-03, 1.0995e-03, 8.0710e-03, 9.8909e-03,\n",
        "            2.1445e-04, 5.3387e-04, 2.6659e-04, 3.9863e-05, 9.7419e-04, 3.9525e-03,\n",
        "            1.8314e-03, 4.4058e-02, 9.6799e-03, 5.3028e-05, 1.8372e-03, 4.4518e-02,\n",
        "            4.7671e-05, 3.5197e-05, 4.2662e-05, 2.7761e-04, 6.1002e-04, 7.7841e-05,\n",
        "            1.5200e-05, 1.8990e-04, 3.8564e-06, 3.2046e-05, 1.2048e-05, 1.0820e-06,\n",
        "            1.5212e-02, 8.2539e-05, 2.3523e-03, 7.8170e-04, 9.1295e-06, 8.5012e-07,\n",
        "            4.4814e-07, 7.1689e-05, 1.9464e-04, 2.9712e-04, 1.6519e-02, 2.2220e-09,\n",
        "            1.3704e-06, 7.6322e-07],\n",
        "           [9.8047e-01, 1.0116e-03, 1.3827e-03, 1.0962e-05, 3.1044e-03, 3.2904e-04,\n",
        "            7.4766e-02, 6.6022e-03, 2.3236e-04, 2.5314e-04, 5.7985e-04, 3.8391e-04,\n",
        "            2.4582e-06, 1.0661e-03, 8.0700e-05, 2.2731e-05, 1.5098e-03, 9.5198e-03,\n",
        "            3.5104e-04, 2.4521e-03, 7.0741e-05, 6.5015e-06, 1.2863e-03, 6.2154e-04,\n",
        "            4.7540e-06, 1.0765e-05, 7.8909e-05, 4.0390e-04, 2.7516e-04, 8.4343e-07,\n",
        "            8.0025e-08, 1.1486e-04, 7.5119e-06, 3.4075e-04, 7.3357e-06, 5.8929e-06,\n",
        "            1.5015e-05, 2.4813e-05, 1.1964e-05, 6.6534e-05, 4.2757e-04, 4.0046e-07,\n",
        "            3.3056e-09, 7.4960e-09, 2.9999e-08, 9.1933e-04, 4.8156e-06, 4.6560e-08,\n",
        "            1.6903e-06, 6.6629e-07],\n",
        "           [9.8667e-01, 4.4180e-03, 1.6255e-03, 3.5491e-05, 2.9416e-02, 1.1417e-03,\n",
        "            4.7438e-03, 3.3079e-03, 9.5721e-05, 5.5254e-04, 1.2983e-03, 5.0247e-04,\n",
        "            6.9176e-06, 3.5990e-02, 1.7484e-05, 2.2020e-05, 1.2195e-03, 1.2592e-02,\n",
        "            4.7516e-04, 6.8679e-03, 2.7559e-05, 1.7406e-05, 4.5730e-04, 5.9616e-03,\n",
        "            2.2940e-05, 4.0800e-06, 6.1670e-05, 3.9694e-04, 2.3974e-04, 2.0545e-06,\n",
        "            8.8773e-07, 8.7051e-05, 1.1536e-05, 6.0760e-07, 7.6686e-06, 1.6588e-06,\n",
        "            2.1659e-05, 9.4796e-05, 1.2733e-06, 1.1948e-03, 3.4780e-07, 9.0219e-08,\n",
        "            2.5965e-08, 4.3246e-07, 3.3075e-08, 2.8555e-04, 8.5335e-07, 9.6700e-08,\n",
        "            6.5534e-06, 1.5472e-06],\n",
        "           [9.9887e-01, 1.9625e-03, 1.0324e-03, 2.4073e-06, 2.7510e-03, 3.8416e-04,\n",
        "            4.8301e-04, 1.5673e-03, 2.9597e-05, 1.7613e-04, 1.3592e-03, 2.1381e-04,\n",
        "            1.3918e-06, 5.8288e-03, 2.4209e-06, 4.5551e-06, 8.4799e-05, 1.5202e-03,\n",
        "            3.4539e-04, 1.0263e-02, 6.4754e-06, 2.4590e-06, 3.5882e-05, 2.7042e-03,\n",
        "            6.8641e-06, 3.8417e-07, 4.0343e-05, 1.2712e-05, 1.1471e-04, 2.0038e-06,\n",
        "            1.3623e-07, 4.7015e-05, 4.9722e-07, 1.5112e-07, 6.1201e-08, 4.7672e-08,\n",
        "            4.1246e-04, 4.4998e-05, 3.9027e-07, 6.6273e-05, 2.7022e-08, 1.6004e-08,\n",
        "            1.6777e-08, 5.4611e-06, 1.0109e-09, 3.6221e-07, 9.5163e-07, 1.6948e-09,\n",
        "            8.4265e-07, 4.0055e-09],\n",
        "           [9.9805e-01, 2.5899e-04, 2.6496e-03, 6.3194e-06, 3.3980e-03, 3.0473e-04,\n",
        "            4.8717e-04, 2.4405e-03, 4.4710e-05, 1.4312e-04, 2.7609e-04, 1.5120e-05,\n",
        "            4.3333e-07, 7.1339e-03, 2.6615e-06, 1.1106e-06, 2.0470e-04, 1.1462e-02,\n",
        "            6.4113e-04, 3.2908e-03, 6.8279e-06, 8.2659e-07, 2.1873e-05, 1.7782e-04,\n",
        "            2.8333e-06, 2.9107e-07, 1.1464e-04, 1.9974e-05, 2.4312e-05, 9.1035e-08,\n",
        "            2.2369e-09, 5.4859e-05, 3.7039e-07, 1.6628e-07, 8.1310e-08, 7.0495e-07,\n",
        "            2.0328e-06, 3.5834e-06, 2.6188e-08, 6.4921e-05, 3.8875e-08, 1.2010e-08,\n",
        "            4.9505e-11, 1.8100e-08, 1.6469e-10, 4.1260e-07, 1.8124e-10, 2.5807e-11,\n",
        "            7.2122e-08, 1.7154e-08],\n",
        "           [9.9866e-01, 7.7404e-04, 7.5264e-04, 3.2347e-06, 3.1223e-03, 1.8531e-04,\n",
        "            2.4961e-03, 4.5260e-03, 5.2135e-05, 6.7846e-05, 7.7655e-05, 4.9980e-04,\n",
        "            5.0404e-07, 1.6001e-03, 6.4850e-06, 1.9174e-06, 1.0493e-03, 1.2063e-02,\n",
        "            1.3144e-04, 1.9986e-03, 2.1640e-05, 7.4791e-07, 2.7173e-05, 4.3530e-03,\n",
        "            2.5983e-06, 1.1837e-06, 6.3898e-05, 8.2497e-05, 5.0616e-05, 5.5897e-07,\n",
        "            2.8251e-08, 3.8659e-05, 5.8369e-07, 2.4815e-06, 4.7415e-07, 5.2436e-07,\n",
        "            6.5067e-06, 7.5160e-05, 1.5049e-06, 3.4978e-04, 1.8759e-07, 1.2487e-06,\n",
        "            1.2612e-09, 4.2602e-07, 2.9396e-08, 2.5525e-06, 1.5468e-06, 6.0744e-09,\n",
        "            4.4164e-07, 6.2397e-07],\n",
        "           [9.8067e-01, 3.9320e-03, 5.5441e-03, 3.7928e-05, 1.1694e-02, 4.1678e-04,\n",
        "            2.9617e-03, 2.4609e-03, 1.3529e-04, 1.3763e-03, 5.4846e-03, 2.8077e-04,\n",
        "            7.5701e-06, 1.1130e-02, 8.3052e-06, 2.9967e-05, 5.8038e-04, 5.2058e-03,\n",
        "            4.5779e-04, 1.4474e-02, 5.5267e-05, 1.2408e-05, 1.8452e-03, 2.2126e-03,\n",
        "            1.5503e-05, 1.4423e-05, 2.7933e-05, 1.4353e-04, 1.1819e-04, 3.0155e-06,\n",
        "            3.2229e-06, 1.7110e-04, 4.5228e-06, 3.7270e-06, 3.2476e-06, 2.3062e-06,\n",
        "            5.2864e-05, 1.0270e-05, 2.9832e-06, 9.1799e-04, 5.5253e-06, 6.6766e-08,\n",
        "            3.8085e-08, 1.1452e-06, 5.1491e-09, 3.5954e-05, 2.7291e-06, 1.0334e-08,\n",
        "            1.2333e-05, 1.7548e-06],\n",
        "           [9.9539e-01, 1.3962e-03, 2.6764e-03, 2.4272e-06, 1.0290e-03, 2.0007e-04,\n",
        "            3.6801e-04, 8.0751e-04, 7.2013e-05, 3.3203e-04, 3.2059e-04, 5.2902e-04,\n",
        "            6.7683e-07, 2.2409e-04, 1.7272e-06, 3.8193e-06, 4.3456e-05, 7.2463e-04,\n",
        "            6.2658e-05, 5.1689e-03, 5.0929e-06, 5.2542e-07, 6.1036e-04, 1.9572e-04,\n",
        "            4.6719e-07, 1.0208e-06, 7.7140e-06, 4.7055e-05, 1.6017e-05, 1.1382e-07,\n",
        "            9.0405e-08, 3.2302e-05, 3.5748e-07, 1.3952e-06, 1.3039e-08, 4.3979e-08,\n",
        "            2.2613e-06, 7.2308e-06, 6.0926e-07, 1.0921e-04, 2.0608e-05, 2.0277e-08,\n",
        "            1.0195e-10, 5.6932e-09, 7.1085e-09, 2.7190e-08, 8.9348e-06, 2.5550e-10,\n",
        "            4.9443e-08, 2.2113e-08],\n",
        "           [9.9543e-01, 4.1715e-03, 3.9521e-03, 8.4711e-05, 2.6786e-03, 7.6149e-04,\n",
        "            3.7331e-03, 1.0469e-02, 1.0267e-03, 1.0760e-03, 3.6054e-03, 3.2299e-03,\n",
        "            2.4792e-05, 1.0517e-03, 4.6656e-05, 5.3500e-05, 3.3977e-04, 1.0090e-02,\n",
        "            5.6219e-03, 8.0685e-03, 3.3813e-04, 1.3588e-05, 1.6540e-03, 1.2335e-02,\n",
        "            1.3387e-05, 1.5806e-05, 2.8738e-04, 5.5375e-04, 1.6890e-04, 2.5373e-05,\n",
        "            1.5204e-06, 1.2933e-04, 8.2829e-06, 1.3759e-05, 2.2608e-06, 1.1317e-05,\n",
        "            1.8129e-04, 4.1412e-04, 6.6509e-04, 2.4634e-03, 3.7217e-05, 2.5528e-05,\n",
        "            3.1567e-07, 1.7912e-05, 8.6489e-07, 9.6095e-07, 2.1971e-03, 1.3147e-07,\n",
        "            6.0852e-06, 1.1183e-05],\n",
        "           [9.9523e-01, 6.3780e-03, 1.9487e-03, 3.6397e-05, 4.1828e-03, 1.1065e-03,\n",
        "            3.7233e-03, 5.0076e-03, 2.5382e-04, 3.4411e-04, 2.6525e-03, 3.9908e-04,\n",
        "            7.4534e-06, 1.1256e-02, 2.5580e-05, 4.1376e-05, 1.1283e-03, 2.1366e-02,\n",
        "            1.8465e-03, 3.1439e-03, 5.7436e-05, 4.6339e-05, 3.7718e-04, 3.4121e-03,\n",
        "            2.7003e-05, 6.3926e-06, 3.2500e-04, 2.5395e-04, 5.4979e-04, 5.8004e-06,\n",
        "            7.1882e-07, 1.4939e-04, 2.0523e-05, 1.1867e-05, 2.1670e-06, 1.5705e-05,\n",
        "            2.5601e-04, 2.5186e-04, 1.9378e-06, 1.9341e-03, 8.0535e-06, 1.8048e-06,\n",
        "            2.5225e-07, 1.8194e-05, 3.0471e-07, 5.5378e-06, 2.1559e-06, 3.7847e-07,\n",
        "            8.7585e-06, 1.3705e-06]],\n",
        "   [[9.9930e-01, 3.4964e-03, 1.3492e-03, 1.9468e-05, 3.3885e-04, 1.7016e-04,\n",
        "            2.5638e-04, 2.0690e-03, 4.1084e-04, 5.1789e-05, 4.1604e-05, 1.6871e-03,\n",
        "            2.1531e-06, 4.7367e-04, 8.2909e-06, 8.6476e-08, 3.1004e-06, 1.5432e-04,\n",
        "            1.3575e-05, 3.9793e-04, 1.2780e-04, 1.4848e-07, 1.0319e-07, 4.0423e-03,\n",
        "            1.7793e-08, 4.1139e-08, 3.8377e-09, 6.3258e-08, 4.1069e-05, 3.9185e-07,\n",
        "            1.5468e-07, 8.0581e-06, 1.3119e-08, 1.8022e-06, 3.8311e-09, 7.7896e-10,\n",
        "            3.6196e-03, 1.5581e-07, 3.4528e-05, 9.7702e-07],\n",
        "           [9.9999e-01, 4.3620e-07, 4.6028e-06, 2.8427e-08, 4.3693e-05, 1.1600e-06,\n",
        "            6.9035e-05, 1.5974e-05, 2.0386e-07, 1.5677e-07, 1.5428e-06, 2.6904e-05,\n",
        "            5.0124e-08, 1.0439e-05, 1.5219e-07, 1.1908e-09, 2.2039e-07, 4.3269e-06,\n",
        "            4.8003e-08, 2.1537e-06, 3.6123e-08, 7.4214e-10, 1.8802e-07, 3.1387e-06,\n",
        "            6.2190e-09, 1.9719e-08, 3.3745e-11, 5.5549e-07, 5.5277e-05, 2.7344e-09,\n",
        "            1.7280e-11, 3.1551e-08, 3.0665e-10, 1.5709e-05, 2.5999e-10, 8.0038e-10,\n",
        "            7.2878e-09, 7.1448e-08, 8.2714e-09, 2.9798e-05],\n",
        "           [9.9995e-01, 1.5602e-04, 8.6879e-06, 4.1921e-07, 5.8993e-03, 4.2933e-06,\n",
        "            1.7177e-04, 3.3202e-05, 2.9379e-06, 1.9037e-05, 9.8925e-08, 3.0141e-06,\n",
        "            4.9315e-07, 7.2444e-05, 1.2685e-08, 3.6499e-10, 2.3192e-07, 3.3128e-04,\n",
        "            1.4199e-08, 6.1670e-06, 1.4746e-07, 3.2350e-09, 7.7852e-06, 1.5856e-04,\n",
        "            1.4888e-08, 4.9276e-07, 4.6972e-08, 7.4957e-05, 7.5583e-06, 1.0418e-09,\n",
        "            4.8482e-07, 2.0623e-07, 3.1761e-09, 1.7007e-08, 4.7234e-09, 9.7949e-09,\n",
        "            5.3210e-09, 1.4460e-05, 2.3754e-08, 2.0618e-04],\n",
        "           [1.0000e+00, 3.3795e-07, 7.8053e-07, 7.3021e-09, 2.0321e-04, 4.1474e-07,\n",
        "            5.3281e-07, 8.6795e-07, 2.0570e-07, 7.4097e-06, 6.4485e-08, 6.1867e-06,\n",
        "            1.2504e-08, 9.6209e-05, 2.3024e-09, 2.7541e-10, 1.6890e-07, 3.4789e-08,\n",
        "            3.1825e-10, 1.9851e-06, 1.0361e-10, 7.9037e-11, 1.2290e-07, 2.4795e-06,\n",
        "            8.9808e-11, 1.4452e-09, 7.8110e-12, 2.5217e-08, 5.0534e-07, 1.7223e-11,\n",
        "            2.7415e-08, 1.0082e-07, 9.4611e-10, 1.0336e-08, 4.4469e-11, 1.7595e-11,\n",
        "            1.3172e-06, 1.3895e-05, 2.2550e-08, 1.4882e-05],\n",
        "           [1.0000e+00, 2.1921e-08, 1.3687e-06, 1.6492e-09, 1.3798e-06, 6.1836e-08,\n",
        "            2.0309e-07, 7.0326e-07, 3.4976e-08, 1.5905e-08, 6.5481e-09, 5.4095e-11,\n",
        "            2.5282e-11, 1.1455e-07, 4.4991e-12, 1.0406e-13, 4.9013e-11, 4.6626e-06,\n",
        "            3.0637e-11, 2.3787e-07, 7.1367e-11, 2.5262e-14, 3.0519e-11, 8.8912e-09,\n",
        "            2.4552e-12, 9.0621e-12, 9.1216e-13, 2.0793e-08, 1.4650e-06, 3.3957e-14,\n",
        "            2.0978e-12, 6.4689e-11, 3.8498e-11, 1.0870e-10, 6.7457e-10, 5.0096e-10,\n",
        "            3.5900e-09, 1.0174e-06, 3.7562e-11, 2.3541e-08],\n",
        "           [1.0000e+00, 4.5348e-05, 2.5893e-07, 8.4339e-09, 1.0580e-05, 2.7988e-08,\n",
        "            3.3975e-06, 3.6015e-07, 2.7474e-08, 2.5606e-07, 8.1708e-06, 7.8409e-07,\n",
        "            3.0773e-09, 8.4091e-05, 2.3090e-09, 2.3010e-10, 1.0470e-06, 8.7956e-06,\n",
        "            1.9499e-09, 1.2790e-06, 3.6366e-12, 7.4241e-13, 1.3919e-10, 2.3338e-07,\n",
        "            1.5636e-12, 1.9618e-12, 7.0751e-11, 1.3343e-08, 1.5987e-08, 1.3159e-12,\n",
        "            1.8397e-10, 2.1634e-08, 2.4879e-12, 4.9086e-10, 3.0545e-12, 3.8362e-10,\n",
        "            3.9457e-09, 2.9960e-07, 4.9722e-09, 6.9648e-08],\n",
        "           [1.0000e+00, 4.4549e-06, 1.6793e-06, 4.8367e-08, 5.9806e-05, 2.9915e-07,\n",
        "            4.7451e-05, 2.8241e-06, 1.6745e-07, 7.4010e-07, 1.4792e-06, 1.6820e-07,\n",
        "            1.8842e-07, 2.7761e-05, 3.8662e-09, 7.4129e-10, 7.7214e-07, 9.8708e-06,\n",
        "            6.8132e-09, 1.2586e-05, 7.2130e-08, 8.7902e-11, 8.9592e-08, 1.9448e-04,\n",
        "            6.4793e-09, 7.4679e-08, 2.1727e-08, 8.8417e-07, 4.8827e-07, 9.3565e-11,\n",
        "            6.6563e-07, 1.4157e-06, 1.1786e-09, 1.2155e-06, 2.0898e-08, 1.1963e-07,\n",
        "            1.3366e-08, 1.0636e-06, 4.5474e-08, 5.5819e-04],\n",
        "           [1.0000e+00, 1.1522e-07, 6.6042e-07, 3.1719e-09, 2.4061e-05, 7.5488e-08,\n",
        "            5.0119e-08, 2.4231e-07, 1.4487e-07, 1.0403e-05, 4.8204e-08, 5.1648e-06,\n",
        "            1.3413e-08, 2.2874e-06, 1.4565e-08, 2.3932e-10, 4.6539e-09, 1.2435e-08,\n",
        "            1.5930e-10, 4.1276e-06, 4.7770e-11, 5.2642e-12, 1.2320e-08, 1.6839e-06,\n",
        "            7.9093e-12, 1.0308e-10, 2.8893e-10, 1.0572e-08, 3.2462e-08, 2.2304e-11,\n",
        "            9.1616e-08, 2.7458e-07, 3.9305e-11, 9.5174e-09, 1.2614e-13, 2.3075e-11,\n",
        "            9.1532e-09, 1.2189e-08, 1.3360e-07, 2.6581e-09],\n",
        "           [1.0000e+00, 3.8530e-07, 3.2506e-06, 1.6358e-08, 2.6320e-05, 7.7503e-07,\n",
        "            7.3533e-07, 1.3253e-05, 1.1778e-06, 7.4081e-07, 4.6852e-07, 2.0589e-05,\n",
        "            1.8072e-09, 7.0578e-08, 2.8628e-08, 1.1880e-10, 4.3551e-08, 2.3032e-07,\n",
        "            8.1511e-08, 3.9765e-05, 3.1951e-09, 1.3875e-10, 4.2106e-07, 1.9214e-05,\n",
        "            1.3547e-10, 4.6571e-09, 1.0997e-10, 1.0589e-07, 1.9830e-06, 7.2109e-09,\n",
        "            2.8308e-09, 1.5366e-07, 2.6077e-09, 5.8049e-08, 2.1955e-10, 3.5720e-09,\n",
        "            5.7942e-07, 5.8262e-06, 1.9028e-04, 4.8196e-07],\n",
        "           [1.0000e+00, 1.7178e-05, 1.2843e-06, 1.1430e-07, 6.5136e-05, 6.7932e-07,\n",
        "            1.1452e-05, 7.2508e-06, 1.0122e-06, 4.2808e-06, 8.7652e-06, 7.3405e-07,\n",
        "            6.0894e-08, 2.1898e-05, 8.8198e-09, 2.2325e-09, 1.9128e-07, 8.1886e-07,\n",
        "            4.2345e-08, 3.2956e-06, 5.0887e-09, 2.5340e-08, 1.5552e-06, 2.4872e-04,\n",
        "            2.3543e-09, 2.1709e-08, 1.5488e-09, 1.8957e-07, 1.0603e-05, 4.0461e-10,\n",
        "            4.0522e-08, 3.2204e-07, 1.0033e-09, 9.5300e-08, 1.2791e-10, 7.0067e-09,\n",
        "            2.6234e-06, 9.4838e-06, 1.2595e-08, 1.1147e-06]]],\n",
        "  6: [[[9.6625e-01, 2.0775e-02, 5.3275e-03, 1.9789e-04, 1.6800e-02, 8.2670e-04,\n",
        "            6.9812e-02, 1.8075e-02, 1.1841e-03, 3.3188e-03, 1.3076e-02, 5.0121e-02,\n",
        "            2.3304e-04, 1.2598e-03, 1.3182e-03, 9.6500e-05, 6.8688e-03, 1.0209e-02,\n",
        "            3.6041e-03, 1.9661e-02, 1.0991e-02, 5.9641e-04, 1.0135e-03, 1.4027e-01,\n",
        "            9.4138e-05, 5.2635e-04, 6.2610e-04, 9.0894e-04, 6.8034e-04, 4.0973e-04,\n",
        "            1.0714e-04, 6.6983e-04, 1.3095e-04, 8.9184e-04, 2.1723e-04, 6.0595e-05,\n",
        "            1.0168e-01, 3.0869e-03, 1.9115e-02, 5.2460e-04, 2.6470e-03, 7.4283e-05,\n",
        "            5.5138e-04, 6.4523e-03, 7.9567e-04, 1.3789e-03, 5.8797e-02, 6.7361e-05,\n",
        "            4.1947e-05, 1.2245e-04, 7.9683e-04, 6.8793e-05, 4.4075e-03, 5.6924e-05,\n",
        "            2.6535e-04, 1.3077e-06, 2.3948e-06, 1.4012e-06, 1.4679e-05, 6.4401e-02],\n",
        "           [9.6298e-01, 1.8741e-03, 1.2137e-03, 5.4873e-05, 1.2967e-02, 3.1700e-04,\n",
        "            5.8401e-02, 7.9002e-03, 4.6629e-04, 1.9188e-03, 1.8103e-03, 1.4593e-03,\n",
        "            2.5851e-06, 3.3331e-03, 1.8843e-04, 1.8536e-04, 1.0823e-03, 1.4119e-02,\n",
        "            5.1937e-04, 2.5261e-03, 1.2942e-04, 8.1549e-06, 5.6557e-03, 6.3168e-03,\n",
        "            5.7812e-06, 2.8835e-05, 1.2557e-04, 3.5289e-04, 1.4762e-04, 3.2299e-06,\n",
        "            3.9482e-06, 3.2673e-04, 5.6148e-05, 1.2883e-04, 2.7505e-05, 5.6783e-06,\n",
        "            2.6581e-05, 2.7946e-04, 1.9952e-05, 5.7748e-04, 3.1884e-04, 2.7543e-06,\n",
        "            1.9507e-06, 4.9624e-06, 3.6924e-07, 3.5154e-04, 7.6907e-04, 1.2366e-05,\n",
        "            8.5343e-06, 1.4806e-05, 1.0774e-06, 3.1536e-09, 4.4162e-05, 2.8537e-08,\n",
        "            3.7939e-08, 1.2981e-07, 1.2211e-07, 1.4176e-09, 2.4146e-03, 1.7992e-04],\n",
        "           [9.6150e-01, 1.2608e-02, 4.0384e-03, 6.9556e-04, 1.5439e-02, 1.1947e-03,\n",
        "            4.0834e-02, 5.0562e-03, 1.1662e-03, 6.2005e-03, 8.3935e-03, 1.5060e-02,\n",
        "            7.4204e-05, 1.3235e-02, 2.6616e-04, 3.1836e-04, 9.6329e-04, 4.1558e-02,\n",
        "            2.4830e-03, 9.1242e-03, 3.0428e-04, 1.1207e-04, 5.4101e-03, 8.5781e-02,\n",
        "            2.1231e-04, 4.1865e-04, 1.8773e-03, 6.6026e-04, 2.5622e-04, 4.4230e-05,\n",
        "            2.6971e-04, 3.9487e-04, 2.2936e-04, 1.0833e-04, 7.0471e-05, 1.9137e-04,\n",
        "            3.5253e-03, 2.3961e-03, 2.3677e-04, 2.0326e-03, 4.3591e-04, 1.8634e-05,\n",
        "            1.9339e-05, 8.0228e-03, 1.8811e-05, 1.7913e-04, 1.6588e-03, 1.4097e-04,\n",
        "            7.9835e-05, 2.2357e-04, 4.6760e-06, 5.1502e-08, 9.0037e-04, 1.7102e-05,\n",
        "            4.8179e-07, 6.9494e-06, 5.8413e-05, 9.7174e-07, 5.9664e-04, 5.4727e-03],\n",
        "           [9.9322e-01, 7.3035e-03, 4.5330e-03, 1.4029e-04, 7.8861e-03, 4.0220e-04,\n",
        "            2.6182e-03, 4.0484e-03, 1.2452e-04, 4.8710e-04, 4.0570e-03, 1.5277e-03,\n",
        "            3.2901e-06, 3.0170e-03, 3.7307e-05, 4.2105e-05, 2.1767e-04, 2.5407e-03,\n",
        "            4.0670e-04, 1.5992e-02, 4.7359e-05, 5.7288e-06, 1.4670e-03, 2.9161e-03,\n",
        "            2.4194e-05, 3.8925e-06, 2.3995e-04, 1.4778e-05, 5.8929e-05, 7.6021e-06,\n",
        "            1.1333e-06, 1.1850e-04, 1.4804e-05, 1.6790e-06, 2.9051e-06, 2.9562e-07,\n",
        "            2.0706e-03, 6.7126e-05, 9.2882e-06, 2.0202e-04, 4.7668e-05, 9.3179e-07,\n",
        "            8.9660e-06, 1.9104e-05, 6.2623e-07, 1.4444e-05, 1.1501e-04, 1.5904e-07,\n",
        "            1.0464e-06, 4.3757e-07, 5.7486e-06, 9.8677e-11, 2.6075e-07, 4.8342e-07,\n",
        "            2.5039e-09, 2.1072e-11, 1.6851e-07, 6.8819e-09, 1.6363e-05, 2.4883e-06],\n",
        "           [9.9642e-01, 2.3487e-04, 2.7474e-03, 8.7630e-05, 2.2165e-03, 5.2773e-05,\n",
        "            4.8777e-04, 2.9871e-03, 1.2336e-04, 2.3388e-04, 1.5260e-04, 3.9283e-05,\n",
        "            8.2979e-08, 2.2421e-03, 1.8502e-06, 9.1344e-06, 8.3281e-05, 2.1330e-02,\n",
        "            4.2565e-04, 2.1043e-03, 1.0978e-05, 4.0099e-08, 4.0695e-05, 1.1124e-04,\n",
        "            4.5415e-06, 6.9619e-07, 2.5004e-04, 4.5484e-06, 4.3600e-06, 2.9041e-08,\n",
        "            1.2104e-08, 2.8077e-04, 5.5769e-07, 5.1161e-07, 3.8921e-08, 1.1463e-06,\n",
        "            6.3901e-07, 1.5093e-05, 1.0890e-07, 3.5126e-05, 3.8857e-07, 1.8089e-08,\n",
        "            2.2252e-09, 9.3749e-07, 3.0724e-08, 5.5582e-08, 8.7278e-08, 1.5567e-09,\n",
        "            7.4877e-08, 2.7417e-06, 5.7347e-12, 1.6669e-13, 3.1959e-09, 1.3979e-10,\n",
        "            1.3096e-10, 1.1758e-09, 1.9429e-13, 9.6697e-13, 8.2892e-07, 2.5372e-07],\n",
        "           [9.9421e-01, 2.0304e-03, 7.7034e-04, 1.0829e-04, 3.8973e-03, 9.9023e-05,\n",
        "            6.4473e-03, 6.2263e-03, 2.8466e-04, 5.2116e-04, 4.5086e-04, 1.2543e-03,\n",
        "            1.0991e-06, 1.3278e-03, 1.6740e-05, 4.9061e-05, 9.5803e-04, 3.3165e-02,\n",
        "            3.7219e-04, 1.7506e-03, 1.0294e-04, 2.6763e-06, 2.9184e-04, 9.3230e-03,\n",
        "            1.1559e-05, 1.4955e-05, 2.9554e-04, 5.2819e-05, 3.4575e-05, 7.6626e-07,\n",
        "            7.4034e-07, 2.3901e-04, 1.3835e-05, 1.6163e-05, 2.6288e-06, 2.1044e-05,\n",
        "            3.6155e-05, 2.4669e-04, 1.9964e-05, 1.3417e-03, 5.3273e-05, 8.3472e-06,\n",
        "            5.8155e-07, 3.5475e-05, 1.0817e-06, 2.7542e-05, 4.7553e-05, 8.7210e-07,\n",
        "            3.9048e-06, 1.9667e-05, 9.9815e-08, 1.5222e-09, 5.8771e-06, 3.3312e-07,\n",
        "            1.5390e-09, 4.8114e-07, 1.5687e-09, 3.0318e-09, 6.0314e-03, 3.8206e-05],\n",
        "           [9.8483e-01, 2.7494e-03, 7.9441e-03, 2.1807e-04, 7.8013e-03, 2.5638e-04,\n",
        "            8.7375e-03, 2.2215e-03, 3.3087e-04, 2.2806e-03, 3.6793e-03, 1.7346e-03,\n",
        "            5.4887e-06, 2.7878e-03, 2.3769e-05, 7.2475e-05, 3.0167e-04, 5.3036e-02,\n",
        "            6.6804e-04, 5.8231e-03, 1.0611e-04, 1.8615e-05, 3.8125e-03, 3.4588e-03,\n",
        "            3.0797e-05, 3.0019e-05, 1.7822e-04, 6.8900e-05, 6.1815e-05, 2.6259e-06,\n",
        "            4.4798e-06, 8.0441e-05, 3.8872e-05, 2.4489e-05, 1.1458e-05, 1.4263e-05,\n",
        "            9.5881e-05, 4.3999e-05, 4.5415e-05, 4.3623e-04, 6.1643e-05, 2.6713e-06,\n",
        "            7.2182e-07, 1.5917e-05, 1.3567e-06, 1.2609e-04, 6.4622e-05, 2.8418e-06,\n",
        "            6.1941e-06, 1.2270e-05, 3.6608e-07, 6.0311e-10, 2.9133e-06, 1.5315e-08,\n",
        "            9.5163e-10, 3.6805e-09, 2.2210e-07, 1.4165e-07, 9.3266e-05, 1.2332e-05],\n",
        "           [9.9304e-01, 4.7494e-04, 3.4960e-03, 3.0287e-05, 1.4881e-03, 5.8918e-05,\n",
        "            9.0730e-04, 1.5930e-03, 1.5759e-04, 1.2929e-03, 9.9918e-04, 4.2795e-04,\n",
        "            4.0693e-07, 1.8131e-04, 3.6603e-06, 7.7974e-06, 4.2304e-05, 1.7192e-03,\n",
        "            2.7080e-04, 9.8790e-03, 2.2877e-05, 2.1297e-07, 5.1070e-04, 6.9354e-04,\n",
        "            1.0366e-06, 2.9027e-06, 1.7000e-05, 1.0349e-05, 5.2052e-06, 4.2915e-07,\n",
        "            5.2195e-07, 2.9761e-05, 3.7380e-06, 4.3802e-06, 4.8972e-08, 4.6803e-07,\n",
        "            9.9734e-06, 8.3759e-06, 2.5090e-05, 2.5751e-05, 1.0067e-04, 3.5222e-08,\n",
        "            5.5617e-08, 1.0296e-06, 4.2528e-08, 3.6971e-08, 9.0960e-05, 5.8581e-08,\n",
        "            4.1348e-07, 1.9999e-06, 1.1372e-09, 5.6993e-12, 1.6046e-07, 4.5739e-07,\n",
        "            3.5184e-10, 8.8343e-12, 1.8374e-10, 4.0020e-14, 3.9617e-06, 3.4470e-05],\n",
        "           [9.8497e-01, 8.5363e-03, 5.1783e-03, 2.1356e-04, 5.8493e-03, 6.3799e-04,\n",
        "            1.1815e-02, 1.7349e-02, 1.7490e-03, 2.6033e-03, 1.0798e-02, 8.3146e-03,\n",
        "            3.5999e-05, 1.4963e-03, 2.2232e-04, 2.4122e-04, 1.4187e-03, 1.9877e-02,\n",
        "            2.5954e-03, 1.2077e-02, 1.4288e-03, 1.9764e-05, 4.2384e-03, 2.2270e-02,\n",
        "            6.2980e-05, 1.9504e-04, 6.4221e-04, 6.1871e-04, 3.3199e-04, 6.4309e-05,\n",
        "            2.4594e-05, 1.3561e-03, 5.9229e-05, 2.5389e-04, 5.6881e-05, 6.7459e-05,\n",
        "            8.1814e-04, 3.1866e-03, 7.2940e-04, 1.1255e-03, 5.0113e-04, 6.7082e-05,\n",
        "            5.0726e-05, 6.3248e-04, 2.9486e-06, 1.0603e-04, 3.8714e-03, 7.5288e-05,\n",
        "            1.4838e-04, 4.6203e-05, 4.3122e-06, 1.0585e-07, 1.0120e-03, 8.6222e-05,\n",
        "            5.0389e-07, 1.6962e-07, 4.8317e-06, 6.3460e-08, 3.1749e-04, 6.5976e-03],\n",
        "           [9.9081e-01, 3.6028e-03, 3.6458e-03, 3.7525e-04, 9.8203e-03, 5.8957e-04,\n",
        "            6.7820e-03, 1.4282e-02, 1.0498e-03, 1.0209e-03, 5.8081e-03, 7.6709e-04,\n",
        "            1.1199e-05, 1.1496e-02, 6.0918e-05, 1.3755e-04, 1.2248e-03, 3.8463e-02,\n",
        "            2.2468e-03, 6.8618e-03, 4.2708e-04, 3.0592e-05, 1.1631e-03, 8.5915e-03,\n",
        "            3.3837e-05, 4.0464e-05, 1.8803e-03, 1.5436e-04, 1.8130e-04, 7.1308e-06,\n",
        "            5.8713e-06, 8.6676e-04, 6.4513e-05, 6.0188e-05, 2.6017e-05, 1.2153e-04,\n",
        "            3.5927e-04, 5.5165e-04, 2.0969e-05, 1.2696e-03, 1.3183e-04, 1.6172e-05,\n",
        "            4.6421e-06, 1.0909e-04, 1.5207e-05, 6.9595e-05, 5.1274e-05, 8.0311e-06,\n",
        "            2.0533e-05, 9.3688e-05, 6.9494e-07, 1.2494e-08, 9.2789e-06, 1.2598e-06,\n",
        "            1.2486e-06, 1.2904e-07, 1.2058e-07, 4.0549e-07, 2.1010e-04, 9.2947e-05]],\n",
        "   [[9.9952e-01, 3.8379e-04, 4.9068e-04, 4.1837e-06, 2.0100e-04, 8.2541e-05,\n",
        "            1.1129e-04, 2.0430e-03, 2.4704e-04, 2.6966e-04, 2.9582e-04, 5.1474e-03,\n",
        "            2.4370e-05, 1.0196e-04, 2.6103e-06, 2.6148e-08, 1.6155e-05, 9.2343e-04,\n",
        "            1.1529e-05, 1.7585e-03, 4.8872e-04, 1.7593e-05, 1.0673e-06, 1.6827e-03,\n",
        "            4.4533e-07, 1.2285e-06, 1.8523e-07, 3.2338e-06, 3.0983e-05, 4.7807e-05,\n",
        "            3.5817e-07, 2.8352e-06, 1.6202e-07, 1.2518e-06, 4.4427e-08, 2.6378e-09,\n",
        "            1.2230e-02, 7.4272e-07, 1.8298e-03, 3.3777e-07, 2.2758e-05, 1.0237e-06,\n",
        "            1.0931e-04, 2.5701e-04, 1.9300e-05, 2.0782e-03, 4.0177e-02, 1.0862e-07,\n",
        "            4.3463e-07, 2.3999e-06],\n",
        "           [1.0000e+00, 5.5440e-07, 1.7854e-06, 1.2413e-08, 2.0628e-05, 3.8874e-07,\n",
        "            1.0352e-05, 4.8212e-06, 8.6769e-08, 6.3413e-08, 1.2988e-07, 2.8470e-05,\n",
        "            9.4089e-10, 7.5026e-07, 9.2082e-07, 1.4362e-10, 4.6063e-08, 3.9451e-06,\n",
        "            3.9425e-08, 1.6008e-06, 4.1239e-08, 5.5319e-11, 6.9609e-08, 6.0140e-07,\n",
        "            2.3894e-09, 1.1438e-08, 3.6823e-11, 7.0807e-07, 4.9564e-05, 9.1147e-10,\n",
        "            3.2170e-12, 2.9948e-08, 5.9315e-11, 2.8718e-06, 1.2815e-10, 3.4184e-10,\n",
        "            1.3231e-09, 1.0908e-07, 5.0081e-08, 9.8665e-06, 6.1158e-05, 3.3555e-07,\n",
        "            2.1264e-09, 3.7039e-09, 1.6695e-08, 3.2358e-03, 6.1952e-06, 4.0028e-08,\n",
        "            7.2554e-07, 4.4508e-07],\n",
        "           [9.9999e-01, 4.0428e-05, 2.9621e-05, 1.0985e-06, 3.7832e-04, 1.9881e-05,\n",
        "            8.8371e-05, 1.0079e-04, 1.9430e-05, 1.5589e-05, 5.1752e-05, 2.9459e-04,\n",
        "            4.6144e-06, 2.0224e-03, 2.1265e-05, 1.3020e-07, 3.8347e-05, 3.1758e-04,\n",
        "            3.3176e-06, 1.4347e-03, 8.4443e-07, 7.8736e-09, 6.6547e-05, 1.6354e-03,\n",
        "            3.5564e-08, 1.2310e-06, 1.5254e-06, 7.4639e-05, 7.1971e-06, 2.1031e-08,\n",
        "            3.6481e-05, 1.2919e-06, 6.4757e-08, 4.5643e-06, 2.5232e-08, 6.9255e-06,\n",
        "            1.7416e-06, 3.1580e-04, 1.2545e-06, 6.4945e-04, 2.1865e-04, 3.8538e-06,\n",
        "            3.1291e-06, 3.4071e-04, 2.0037e-06, 7.6282e-05, 2.2304e-04, 1.3907e-06,\n",
        "            4.3008e-04, 3.5910e-05],\n",
        "           [1.0000e+00, 9.5768e-07, 1.4170e-05, 2.2414e-08, 2.4437e-04, 2.7864e-06,\n",
        "            1.4355e-06, 5.1029e-06, 7.9092e-07, 8.5866e-06, 3.1734e-07, 4.7212e-06,\n",
        "            6.8808e-09, 1.0647e-04, 1.3301e-09, 4.3633e-10, 3.4840e-07, 1.0670e-08,\n",
        "            8.5234e-11, 7.7653e-07, 3.6506e-10, 7.0840e-11, 6.8726e-08, 2.2492e-07,\n",
        "            1.2103e-10, 1.1841e-09, 3.6439e-12, 1.7548e-08, 8.4871e-07, 4.7587e-11,\n",
        "            4.3908e-09, 1.2491e-07, 4.8760e-10, 1.0874e-08, 3.0048e-11, 1.5980e-11,\n",
        "            5.8613e-06, 4.8613e-06, 4.9100e-08, 1.0567e-05, 6.0393e-08, 2.2328e-09,\n",
        "            4.3719e-09, 4.1088e-07, 1.7065e-09, 1.8240e-06, 8.5372e-07, 1.7087e-10,\n",
        "            1.3910e-07, 3.9557e-10],\n",
        "           [1.0000e+00, 2.7254e-08, 4.5132e-07, 1.3151e-09, 2.5432e-06, 7.6345e-08,\n",
        "            3.4961e-07, 7.0405e-07, 2.3267e-08, 1.7591e-08, 6.8408e-10, 2.8742e-10,\n",
        "            1.7014e-10, 8.5509e-06, 7.4140e-12, 1.1872e-13, 4.0537e-11, 1.4030e-06,\n",
        "            1.5792e-11, 1.9506e-07, 5.8831e-12, 1.1636e-15, 1.8577e-11, 8.3228e-09,\n",
        "            5.2817e-13, 7.6163e-12, 8.8378e-13, 3.7880e-08, 5.0820e-09, 6.5924e-14,\n",
        "            2.3553e-13, 9.6396e-12, 2.6218e-12, 2.3322e-11, 1.0560e-13, 4.3313e-11,\n",
        "            2.8338e-11, 2.3310e-07, 3.7045e-12, 9.5814e-08, 9.7403e-09, 1.3800e-09,\n",
        "            5.1967e-12, 6.3960e-10, 2.3389e-11, 1.4249e-08, 5.4877e-11, 1.4541e-12,\n",
        "            9.3970e-09, 5.0772e-09],\n",
        "           [1.0000e+00, 1.4385e-05, 1.9928e-06, 1.0192e-07, 7.4869e-06, 5.9494e-07,\n",
        "            6.1088e-06, 1.6799e-05, 7.6193e-07, 7.3363e-07, 1.4575e-05, 3.0081e-07,\n",
        "            6.3097e-07, 4.3300e-06, 4.7598e-08, 1.1345e-09, 4.7483e-05, 4.4832e-05,\n",
        "            1.9985e-08, 5.0649e-06, 8.9523e-10, 1.0545e-11, 7.2189e-09, 8.0529e-06,\n",
        "            1.9622e-10, 3.0827e-10, 4.2762e-10, 1.1814e-06, 1.0876e-07, 2.7690e-10,\n",
        "            2.9446e-09, 2.1546e-07, 1.3331e-10, 7.3244e-10, 9.5984e-11, 5.1191e-08,\n",
        "            4.2319e-08, 4.5917e-05, 6.4756e-08, 2.8315e-06, 9.1961e-07, 1.6563e-06,\n",
        "            2.0412e-09, 4.9912e-07, 5.1309e-08, 5.7753e-06, 8.0029e-08, 9.5472e-09,\n",
        "            1.0590e-07, 9.2459e-08],\n",
        "           [1.0000e+00, 2.0436e-05, 1.1888e-06, 1.0836e-07, 8.7785e-06, 2.9152e-07,\n",
        "            3.5452e-05, 2.9310e-06, 7.8503e-07, 2.7943e-06, 8.5756e-07, 6.2397e-07,\n",
        "            4.0522e-08, 3.1617e-05, 4.3260e-09, 1.6207e-10, 1.6288e-07, 1.2459e-04,\n",
        "            2.0422e-08, 1.8717e-06, 2.8711e-09, 8.2174e-11, 5.2639e-06, 4.9298e-06,\n",
        "            2.7388e-09, 9.1333e-08, 1.2400e-08, 5.4151e-06, 3.7794e-06, 1.4277e-09,\n",
        "            1.2465e-07, 6.8673e-09, 8.7136e-09, 4.4000e-06, 1.4242e-10, 1.2751e-07,\n",
        "            1.0456e-08, 1.4044e-07, 4.7109e-08, 1.8316e-04, 8.4835e-06, 4.1445e-08,\n",
        "            2.4261e-08, 2.8669e-08, 1.7157e-08, 1.2315e-04, 1.3966e-06, 1.4509e-08,\n",
        "            2.4306e-06, 1.1572e-07],\n",
        "           [1.0000e+00, 5.3200e-08, 3.0020e-07, 2.1703e-09, 1.1181e-05, 3.1172e-08,\n",
        "            2.6702e-08, 1.2566e-07, 6.6592e-08, 3.6039e-06, 1.3716e-08, 8.7712e-08,\n",
        "            6.6032e-10, 4.4768e-07, 3.3748e-10, 8.2430e-12, 2.6901e-10, 6.7826e-10,\n",
        "            4.9494e-12, 4.0461e-07, 1.3133e-11, 2.1575e-12, 4.1637e-09, 5.5627e-07,\n",
        "            5.1064e-12, 5.2304e-11, 3.1740e-10, 5.7974e-09, 1.1446e-08, 7.1297e-12,\n",
        "            2.5745e-09, 3.7485e-08, 6.7526e-12, 4.0804e-09, 1.0346e-15, 2.7337e-12,\n",
        "            1.4547e-09, 3.4924e-09, 1.1324e-07, 3.2316e-10, 1.3823e-05, 4.0842e-09,\n",
        "            1.3744e-11, 1.0102e-09, 5.1775e-10, 4.8041e-09, 3.2120e-06, 1.2489e-11,\n",
        "            5.7364e-09, 2.1949e-09],\n",
        "           [1.0000e+00, 1.3200e-07, 8.4691e-06, 1.4428e-08, 2.6564e-06, 1.1860e-06,\n",
        "            7.1725e-07, 3.7994e-05, 1.0483e-06, 2.0940e-06, 4.5225e-07, 4.3981e-05,\n",
        "            1.3565e-08, 3.1343e-08, 7.6152e-08, 2.4247e-10, 5.2894e-08, 1.2118e-06,\n",
        "            8.1348e-08, 3.2324e-05, 7.8595e-09, 6.3630e-11, 2.0036e-06, 4.8471e-05,\n",
        "            2.9303e-09, 3.1534e-08, 3.1763e-10, 1.1838e-07, 3.3908e-06, 1.1483e-07,\n",
        "            5.5143e-08, 1.2050e-07, 1.6613e-08, 3.0658e-07, 1.0489e-09, 8.5696e-09,\n",
        "            4.2322e-08, 3.9969e-05, 5.7404e-06, 5.2512e-06, 5.5439e-05, 2.0501e-04,\n",
        "            4.8283e-07, 5.8207e-05, 5.0129e-08, 2.4042e-05, 1.8372e-03, 2.5727e-06,\n",
        "            2.9215e-05, 5.5780e-07],\n",
        "           [1.0000e+00, 9.2703e-06, 2.4333e-06, 5.8691e-08, 3.1374e-04, 1.0841e-06,\n",
        "            2.0841e-05, 7.4839e-06, 7.3218e-07, 4.6094e-06, 1.0454e-04, 1.2844e-06,\n",
        "            9.7351e-09, 5.0707e-05, 1.0702e-08, 8.3378e-09, 1.9667e-06, 5.4913e-07,\n",
        "            1.1242e-07, 2.5546e-06, 4.1393e-10, 2.2214e-09, 1.3380e-07, 1.2005e-04,\n",
        "            6.0941e-10, 2.6558e-09, 3.9145e-10, 5.2710e-08, 2.8451e-06, 2.3006e-10,\n",
        "            4.5127e-10, 4.0500e-08, 1.1807e-10, 3.5473e-09, 1.9427e-12, 2.9869e-09,\n",
        "            3.7667e-07, 2.3765e-05, 4.7875e-10, 5.0180e-08, 7.7936e-07, 3.5060e-07,\n",
        "            1.5464e-08, 2.0762e-06, 5.4587e-08, 2.2451e-07, 3.1058e-07, 3.1519e-07,\n",
        "            1.4051e-06, 5.2134e-08]]],\n",
        "  7: [[[9.6890e-01, 2.7504e-02, 7.3392e-03, 1.6639e-04, 1.7602e-02, 9.2176e-04,\n",
        "            3.1049e-02, 1.1750e-02, 1.2160e-03, 2.9780e-03, 1.1196e-02, 5.1184e-02,\n",
        "            2.5170e-04, 1.0196e-03, 5.0897e-04, 5.7380e-05, 5.3814e-03, 1.3460e-02,\n",
        "            2.1771e-03, 3.3553e-02, 1.4872e-02, 7.7254e-04, 1.0087e-03, 1.2713e-01,\n",
        "            2.6434e-04, 2.9501e-04, 3.3916e-04, 3.2965e-04, 4.7571e-04, 2.9128e-04,\n",
        "            8.2374e-05, 3.9244e-04, 7.8331e-05, 3.1398e-04, 2.0043e-04, 6.3160e-05,\n",
        "            1.2306e-01, 1.5489e-03, 1.2342e-02, 1.1666e-03, 7.3488e-04, 6.8453e-05,\n",
        "            2.3313e-04, 8.7195e-03, 9.5063e-04, 8.4867e-03, 2.2051e-02, 1.7614e-05,\n",
        "            2.4989e-05, 9.5908e-05, 1.0205e-04, 1.6967e-04, 4.3908e-03, 2.0253e-04,\n",
        "            3.3922e-04, 6.5394e-06, 9.3987e-06, 4.3554e-05, 1.3034e-05, 3.7712e-03,\n",
        "            3.9286e-09, 3.8041e-06, 5.1098e-03, 2.4826e-05, 3.0955e-04, 1.5223e-05,\n",
        "            6.1184e-08, 2.1137e-06, 9.1405e-07, 2.3657e-02],\n",
        "           [9.7226e-01, 1.1449e-03, 1.5333e-03, 1.1770e-04, 6.7839e-03, 1.6818e-04,\n",
        "            3.1403e-02, 7.6381e-03, 3.2528e-04, 7.8978e-04, 5.8502e-04, 1.6101e-03,\n",
        "            1.1620e-06, 1.1891e-03, 8.5433e-05, 8.4880e-05, 9.9797e-04, 2.4716e-02,\n",
        "            9.8939e-04, 2.3063e-03, 4.9451e-04, 9.7193e-06, 7.3805e-04, 9.2207e-03,\n",
        "            2.3399e-05, 2.5692e-05, 7.2339e-05, 3.6547e-05, 8.2076e-05, 5.5808e-06,\n",
        "            4.5549e-06, 3.4567e-04, 4.0731e-05, 2.5440e-05, 5.2065e-05, 6.0322e-06,\n",
        "            1.6269e-04, 2.4195e-04, 1.0232e-04, 6.3976e-05, 1.1178e-04, 1.5223e-05,\n",
        "            3.1859e-06, 2.2751e-05, 1.1785e-06, 4.8230e-04, 1.4767e-03, 1.3890e-05,\n",
        "            2.5153e-06, 6.0142e-06, 1.0838e-06, 2.6549e-07, 1.4331e-04, 4.3262e-06,\n",
        "            1.3205e-06, 2.6211e-05, 4.1147e-06, 1.6961e-07, 3.8454e-04, 3.2353e-04,\n",
        "            8.0329e-08, 3.6930e-06, 5.3673e-04, 4.5622e-07, 5.6224e-06, 2.5101e-09,\n",
        "            4.4664e-09, 6.2443e-08, 6.7195e-06, 1.8233e-09],\n",
        "           [9.9225e-01, 3.6034e-03, 1.6549e-03, 2.7650e-05, 5.6457e-03, 3.9422e-04,\n",
        "            6.9643e-03, 5.5329e-03, 7.3684e-04, 8.9164e-04, 3.0528e-03, 1.3793e-03,\n",
        "            2.0257e-06, 5.5171e-03, 3.0176e-05, 2.3178e-05, 1.6379e-03, 1.8171e-02,\n",
        "            8.0553e-04, 1.4300e-02, 6.3283e-05, 1.1260e-05, 2.1664e-03, 5.2773e-03,\n",
        "            4.7477e-05, 5.9961e-05, 5.2906e-04, 3.3589e-04, 2.4293e-05, 1.9800e-06,\n",
        "            2.1469e-05, 7.9692e-04, 7.6568e-05, 2.6158e-05, 7.9562e-05, 6.2525e-05,\n",
        "            4.8070e-05, 3.7495e-04, 4.7565e-05, 8.2162e-04, 6.0791e-05, 1.4447e-06,\n",
        "            6.5501e-06, 3.6947e-04, 2.9505e-06, 2.1528e-04, 1.9578e-04, 7.4936e-05,\n",
        "            2.4968e-06, 1.3911e-04, 1.7061e-06, 1.2508e-08, 1.6827e-04, 1.6317e-04,\n",
        "            4.2256e-06, 8.7007e-06, 6.1258e-06, 3.2721e-07, 9.2180e-05, 3.1198e-03,\n",
        "            6.3403e-10, 5.1926e-05, 2.1596e-05, 5.6546e-06, 1.6546e-06, 4.2116e-07,\n",
        "            2.7522e-08, 2.7655e-08, 2.5018e-06, 2.0765e-06],\n",
        "           [9.8614e-01, 2.3275e-02, 9.2989e-03, 4.8744e-04, 1.3938e-02, 6.2693e-04,\n",
        "            4.6314e-03, 4.1991e-03, 5.5129e-04, 1.2492e-03, 3.5697e-03, 8.5660e-03,\n",
        "            3.0122e-05, 3.7733e-03, 1.3446e-04, 1.7427e-04, 1.1902e-03, 1.3519e-02,\n",
        "            8.8381e-04, 3.7773e-02, 3.4520e-04, 3.6328e-05, 2.0684e-03, 5.4440e-02,\n",
        "            6.0822e-04, 1.2959e-04, 7.0011e-04, 2.9171e-05, 8.2950e-05, 9.4336e-05,\n",
        "            1.0272e-04, 2.8550e-04, 1.2688e-04, 1.7722e-05, 7.4225e-05, 9.5188e-06,\n",
        "            2.2821e-02, 3.5761e-04, 3.5482e-04, 6.7863e-04, 1.5733e-04, 2.8905e-05,\n",
        "            1.1885e-04, 1.5449e-03, 1.5079e-05, 6.1605e-04, 1.1885e-03, 5.3964e-06,\n",
        "            9.6603e-06, 9.2124e-06, 5.8185e-05, 8.0959e-07, 6.4100e-04, 1.4758e-04,\n",
        "            2.1984e-06, 5.1387e-06, 5.4351e-05, 3.7123e-06, 1.7632e-04, 1.1324e-04,\n",
        "            1.3704e-09, 5.2993e-05, 9.8574e-05, 3.8937e-05, 2.3171e-03, 9.0543e-08,\n",
        "            2.6471e-09, 3.2383e-08, 5.5599e-06, 3.5732e-06],\n",
        "           [9.3834e-01, 5.7781e-03, 1.1019e-02, 1.3435e-03, 8.4325e-02, 1.4811e-03,\n",
        "            4.2479e-02, 2.9150e-02, 2.3882e-03, 2.3234e-03, 1.3623e-03, 1.2728e-03,\n",
        "            5.2731e-05, 1.1063e-01, 3.4457e-03, 7.0528e-04, 5.9151e-03, 1.2401e-01,\n",
        "            6.7814e-03, 2.1819e-02, 2.4741e-03, 2.9721e-04, 3.0372e-03, 1.7611e-02,\n",
        "            2.2775e-03, 1.4072e-03, 1.4206e-02, 4.4413e-04, 3.0312e-04, 1.0905e-04,\n",
        "            3.8106e-04, 6.5005e-03, 6.1825e-04, 2.1956e-04, 2.1152e-03, 1.0470e-03,\n",
        "            1.5848e-03, 3.4130e-03, 1.5207e-04, 1.4043e-03, 1.8804e-04, 4.0857e-04,\n",
        "            1.9150e-04, 1.8341e-03, 3.5432e-04, 2.1809e-03, 1.1978e-04, 1.0401e-03,\n",
        "            8.7301e-05, 4.2017e-04, 2.2508e-04, 5.2261e-06, 1.2285e-03, 2.5135e-04,\n",
        "            5.6229e-05, 1.0512e-02, 8.4570e-05, 1.2083e-04, 2.7217e-03, 7.7639e-04,\n",
        "            1.7534e-05, 3.0050e-03, 4.0949e-04, 1.0236e-04, 9.3887e-05, 2.6311e-04,\n",
        "            1.9649e-05, 1.0731e-06, 7.0074e-05, 2.0413e-06],\n",
        "           [9.9174e-01, 3.0766e-03, 2.2971e-03, 2.0347e-04, 9.9685e-03, 2.6115e-04,\n",
        "            1.0520e-02, 9.9004e-03, 1.1486e-03, 4.3231e-04, 1.6676e-03, 2.8145e-03,\n",
        "            4.2457e-06, 5.1522e-03, 4.0769e-05, 1.2102e-04, 7.7810e-04, 4.9823e-02,\n",
        "            1.0014e-03, 7.6579e-03, 1.3175e-04, 1.3351e-05, 9.4745e-04, 2.9949e-02,\n",
        "            1.0186e-04, 1.2996e-04, 6.2517e-04, 6.5393e-05, 4.1619e-05, 9.0002e-06,\n",
        "            3.2517e-05, 7.3501e-04, 5.9941e-05, 1.5092e-05, 1.9275e-04, 9.2489e-05,\n",
        "            2.7071e-04, 3.3380e-04, 1.2730e-04, 4.1720e-04, 1.8369e-04, 9.6430e-06,\n",
        "            3.4062e-05, 4.1804e-04, 4.3960e-06, 2.3681e-04, 4.1945e-04, 6.0115e-05,\n",
        "            5.7906e-06, 5.6662e-05, 8.9227e-06, 1.5508e-07, 5.3604e-05, 2.0429e-05,\n",
        "            5.0393e-06, 2.4121e-05, 2.2147e-05, 5.6690e-06, 1.0007e-03, 9.2509e-04,\n",
        "            2.7737e-08, 8.9668e-06, 3.0475e-03, 7.0239e-06, 1.3461e-04, 4.6415e-06,\n",
        "            2.5048e-08, 1.8784e-08, 1.2829e-06, 7.2905e-07],\n",
        "           [9.6980e-01, 7.3591e-03, 5.0714e-03, 3.5182e-04, 2.5899e-02, 1.0458e-03,\n",
        "            2.1220e-02, 1.2901e-02, 2.0793e-03, 4.1231e-03, 1.1373e-02, 1.4884e-03,\n",
        "            2.3591e-05, 3.0039e-02, 1.3453e-04, 2.7518e-04, 4.1487e-03, 5.7978e-02,\n",
        "            2.4409e-03, 2.1436e-02, 2.9784e-04, 1.4241e-04, 5.5248e-03, 1.0775e-02,\n",
        "            2.9266e-04, 3.1134e-04, 1.3512e-03, 6.4459e-04, 1.8035e-04, 2.0099e-05,\n",
        "            1.8487e-04, 1.3227e-03, 4.8509e-04, 2.3273e-04, 3.3165e-04, 7.1714e-04,\n",
        "            2.1657e-04, 5.0315e-04, 1.7999e-04, 2.1545e-03, 5.0953e-04, 9.3259e-06,\n",
        "            7.8470e-05, 7.3151e-04, 4.4021e-05, 6.1647e-04, 3.1765e-04, 3.3293e-04,\n",
        "            1.6925e-05, 8.0045e-04, 1.0980e-05, 2.5268e-07, 3.2539e-04, 2.6808e-04,\n",
        "            5.9394e-05, 6.0885e-05, 2.1550e-05, 8.6607e-06, 2.8157e-04, 3.4705e-03,\n",
        "            3.1719e-08, 2.8039e-04, 5.5534e-05, 4.6821e-05, 2.3391e-05, 5.5682e-06,\n",
        "            2.9568e-07, 1.6819e-07, 6.8081e-06, 4.0544e-06],\n",
        "           [9.9499e-01, 1.5129e-03, 4.6684e-03, 1.4390e-05, 1.2884e-03, 5.3725e-05,\n",
        "            2.0380e-03, 3.8395e-03, 5.1612e-04, 8.7084e-04, 1.1502e-03, 8.9566e-04,\n",
        "            1.1443e-06, 2.3613e-04, 1.5771e-05, 1.0871e-05, 6.7178e-05, 5.1621e-03,\n",
        "            4.7117e-04, 2.9145e-02, 5.0234e-05, 1.2467e-06, 7.4300e-04, 2.0988e-03,\n",
        "            1.1895e-05, 1.9118e-05, 4.2424e-04, 2.6053e-05, 7.6936e-06, 1.1222e-06,\n",
        "            8.6335e-06, 1.2803e-04, 6.3508e-06, 1.7316e-05, 7.1030e-05, 7.3117e-06,\n",
        "            4.5800e-05, 8.8576e-05, 1.0442e-04, 1.1842e-04, 6.7051e-05, 7.8562e-07,\n",
        "            3.1115e-06, 3.1200e-05, 5.9345e-07, 5.2778e-05, 1.5293e-03, 1.0668e-05,\n",
        "            5.3933e-07, 1.3354e-05, 1.5986e-07, 1.6591e-08, 1.0153e-04, 2.7074e-05,\n",
        "            7.0787e-06, 1.0297e-06, 1.6299e-06, 7.6899e-08, 6.8635e-05, 2.0981e-03,\n",
        "            5.8081e-11, 1.7181e-07, 6.0104e-04, 1.3674e-06, 5.5262e-04, 1.7498e-07,\n",
        "            3.4863e-10, 2.2506e-09, 2.3341e-07, 3.8051e-07],\n",
        "           [9.8632e-01, 9.9877e-03, 4.1460e-03, 5.6357e-05, 5.0164e-03, 4.3204e-04,\n",
        "            9.3376e-03, 6.5038e-03, 1.6400e-03, 1.7265e-03, 8.2472e-03, 7.9396e-03,\n",
        "            1.8304e-05, 1.1960e-03, 9.0098e-05, 7.9688e-05, 6.9181e-04, 7.9132e-03,\n",
        "            3.9032e-03, 1.6359e-02, 2.2126e-04, 1.3388e-05, 3.7248e-03, 3.7489e-02,\n",
        "            6.5569e-05, 2.4476e-04, 1.0023e-03, 5.0164e-04, 4.8405e-05, 2.5397e-05,\n",
        "            6.1495e-05, 7.4199e-04, 2.5418e-05, 7.6345e-05, 2.4379e-04, 7.7066e-05,\n",
        "            3.7839e-04, 2.0228e-03, 7.3631e-04, 9.2070e-04, 1.0747e-04, 2.4364e-05,\n",
        "            2.6882e-05, 4.0778e-03, 2.1038e-06, 2.3489e-04, 1.6017e-03, 2.2867e-04,\n",
        "            2.7779e-05, 7.2280e-05, 1.5629e-06, 2.4379e-07, 1.7985e-03, 3.0055e-04,\n",
        "            3.4616e-05, 1.7379e-05, 2.9430e-05, 1.7216e-06, 1.8087e-04, 4.6090e-03,\n",
        "            1.4709e-09, 1.3350e-03, 6.1283e-03, 2.8958e-06, 4.3257e-06, 1.4645e-06,\n",
        "            8.9827e-08, 4.4932e-08, 8.3506e-07, 2.8038e-04],\n",
        "           [9.7990e-01, 1.1943e-02, 7.1060e-03, 2.1772e-04, 1.4237e-02, 5.0206e-04,\n",
        "            1.3128e-02, 7.0263e-03, 8.8643e-04, 6.1769e-04, 9.1054e-03, 2.1445e-03,\n",
        "            1.2813e-05, 5.5218e-03, 5.5117e-05, 2.0241e-04, 2.9821e-03, 3.6195e-02,\n",
        "            4.0644e-03, 1.8242e-02, 5.8384e-04, 7.3333e-05, 1.5921e-03, 1.6511e-02,\n",
        "            1.2617e-04, 1.6551e-04, 4.9520e-04, 2.8007e-04, 1.3413e-04, 2.8187e-05,\n",
        "            2.7280e-05, 5.4671e-04, 9.0779e-05, 1.1187e-04, 6.7912e-04, 2.8428e-04,\n",
        "            7.8830e-04, 2.4338e-04, 1.4503e-04, 6.1962e-04, 3.3010e-04, 5.9935e-05,\n",
        "            4.2936e-05, 7.8523e-04, 1.1889e-05, 6.0120e-04, 5.6846e-04, 3.4712e-04,\n",
        "            1.6084e-05, 3.6422e-05, 8.4081e-06, 8.0071e-07, 1.6606e-04, 6.7864e-05,\n",
        "            1.0811e-05, 5.2208e-05, 1.6081e-04, 1.8014e-05, 1.6220e-04, 1.7396e-03,\n",
        "            2.4324e-08, 5.5608e-05, 1.0606e-03, 7.5582e-06, 8.3062e-05, 9.7102e-06,\n",
        "            1.5828e-06, 4.3053e-08, 6.9687e-06, 3.5221e-06]],\n",
        "   [[9.9927e-01, 3.9342e-04, 5.1272e-04, 6.0621e-06, 1.9052e-04, 8.5856e-05,\n",
        "            7.7070e-05, 2.2836e-03, 2.4763e-04, 3.6148e-04, 4.7066e-04, 1.4098e-02,\n",
        "            1.6050e-05, 9.2360e-05, 6.4537e-06, 5.7107e-08, 3.9585e-05, 4.7655e-04,\n",
        "            2.3891e-05, 1.9992e-03, 3.8568e-04, 6.5616e-06, 2.8272e-07, 2.0973e-04,\n",
        "            6.1903e-08, 3.6320e-07, 3.0733e-08, 1.5800e-06, 3.7899e-05, 1.1037e-05,\n",
        "            1.5975e-07, 3.0903e-06, 3.8679e-08, 8.7625e-07, 3.4586e-08, 1.4697e-09,\n",
        "            1.6993e-02, 2.2452e-07, 5.5663e-04, 2.3183e-07, 9.7144e-06, 4.6621e-07,\n",
        "            1.9907e-05, 5.5930e-04, 1.2136e-05, 8.0715e-04, 2.0941e-02, 2.6373e-08,\n",
        "            3.2737e-07, 1.3468e-06, 4.1287e-04, 4.6418e-05, 3.9994e-03, 2.3659e-05,\n",
        "            1.3458e-04, 6.6790e-07, 1.8043e-06, 1.0251e-06, 5.3895e-06, 3.2548e-02],\n",
        "           [1.0000e+00, 2.4568e-07, 2.3508e-08, 5.0008e-10, 5.8313e-06, 2.3017e-09,\n",
        "            3.1309e-07, 6.2484e-07, 1.0166e-09, 1.4806e-09, 3.9021e-10, 1.0566e-07,\n",
        "            1.4479e-12, 6.0515e-09, 7.4929e-08, 6.0368e-13, 1.6323e-10, 4.1160e-08,\n",
        "            2.5670e-07, 1.4316e-06, 7.2576e-10, 2.4744e-14, 1.1605e-10, 2.7780e-07,\n",
        "            1.3869e-11, 5.6553e-11, 2.5437e-14, 2.8244e-08, 3.7202e-06, 3.4590e-11,\n",
        "            8.5202e-14, 8.7611e-09, 3.8926e-13, 1.5309e-07, 3.3844e-13, 4.5740e-13,\n",
        "            1.2850e-10, 1.2401e-08, 1.2963e-09, 3.4680e-07, 3.4880e-06, 7.5731e-08,\n",
        "            1.0785e-10, 2.4861e-09, 1.8972e-09, 5.8170e-04, 5.9601e-06, 2.0605e-09,\n",
        "            5.9333e-08, 9.6217e-08, 3.0728e-08, 2.6211e-10, 5.5850e-06, 3.7796e-10,\n",
        "            2.5080e-10, 3.5179e-08, 3.7819e-09, 3.9189e-11, 3.9195e-04, 5.9063e-05],\n",
        "           [1.0000e+00, 2.2188e-07, 5.1856e-08, 4.9071e-10, 4.5231e-06, 8.4993e-09,\n",
        "            1.0801e-07, 1.5561e-07, 1.4929e-08, 1.0177e-07, 1.4252e-08, 1.7477e-07,\n",
        "            2.9990e-10, 3.0984e-07, 1.2297e-10, 1.3584e-13, 9.0181e-11, 1.6455e-06,\n",
        "            3.6240e-11, 1.4877e-05, 1.9605e-11, 8.8002e-14, 1.1026e-06, 8.1037e-08,\n",
        "            8.7774e-13, 1.7127e-10, 1.9573e-11, 7.6499e-07, 1.2154e-07, 4.8776e-13,\n",
        "            1.6440e-08, 1.2556e-10, 9.5125e-11, 7.3250e-12, 4.9555e-13, 2.1954e-10,\n",
        "            1.8605e-11, 6.1106e-06, 1.1142e-09, 2.5430e-07, 1.1374e-07, 1.9780e-09,\n",
        "            1.0531e-09, 1.3625e-08, 2.3967e-10, 4.8607e-05, 1.0578e-07, 1.4626e-10,\n",
        "            3.2430e-07, 1.1138e-07, 3.9993e-08, 4.2846e-11, 7.5756e-07, 9.3886e-09,\n",
        "            4.1427e-10, 7.2794e-10, 2.8817e-09, 1.2560e-10, 2.6553e-06, 2.9935e-04],\n",
        "           [1.0000e+00, 9.4856e-07, 4.8593e-06, 2.4670e-08, 1.6362e-04, 1.9260e-06,\n",
        "            2.5038e-06, 3.5077e-06, 1.5535e-06, 3.1797e-05, 2.6290e-07, 1.2698e-05,\n",
        "            1.0108e-08, 1.1146e-05, 8.5684e-09, 2.7340e-10, 2.9390e-07, 3.4924e-07,\n",
        "            2.9434e-09, 1.4173e-06, 5.6813e-09, 1.3439e-09, 1.1319e-06, 1.0499e-05,\n",
        "            1.0749e-09, 1.6395e-08, 4.9640e-11, 3.8749e-08, 2.7732e-06, 3.8154e-10,\n",
        "            8.1940e-07, 1.7845e-07, 1.9053e-09, 3.0656e-09, 3.9889e-10, 1.1588e-10,\n",
        "            9.0931e-06, 2.1598e-05, 2.8672e-08, 1.2468e-05, 9.0050e-08, 9.2936e-09,\n",
        "            2.7001e-08, 3.5867e-06, 1.2417e-08, 4.2308e-07, 9.5963e-07, 7.7659e-10,\n",
        "            8.8221e-07, 4.9517e-09, 6.6145e-05, 1.2895e-09, 2.1270e-06, 2.7276e-06,\n",
        "            1.4949e-08, 2.4949e-09, 1.2377e-05, 8.1774e-08, 8.7188e-05, 1.2380e-05],\n",
        "           [9.9995e-01, 2.9795e-05, 4.3348e-05, 1.3063e-06, 2.3048e-04, 2.6753e-05,\n",
        "            2.3030e-03, 3.3170e-04, 1.8667e-05, 1.5334e-05, 8.9883e-07, 4.8731e-07,\n",
        "            5.2188e-08, 5.0687e-04, 2.2942e-06, 1.1812e-08, 1.3397e-07, 2.6309e-04,\n",
        "            3.9791e-06, 1.1946e-04, 1.5777e-06, 5.1350e-09, 1.5403e-06, 7.1578e-05,\n",
        "            1.2034e-07, 5.8340e-07, 1.6320e-07, 3.9796e-06, 4.9034e-05, 8.4519e-10,\n",
        "            2.1278e-06, 2.8150e-06, 1.8854e-07, 3.4464e-07, 3.1656e-05, 7.9739e-07,\n",
        "            1.6056e-05, 9.1662e-06, 4.9538e-08, 2.2761e-05, 5.1749e-06, 1.2024e-06,\n",
        "            3.7049e-07, 2.0874e-05, 1.2906e-07, 2.7000e-05, 1.1796e-07, 1.7741e-07,\n",
        "            1.2002e-05, 5.7216e-06, 9.1958e-06, 1.3046e-08, 7.5193e-05, 2.8850e-06,\n",
        "            1.2738e-06, 2.6354e-04, 4.2958e-08, 6.1338e-07, 6.3707e-03, 2.7306e-05],\n",
        "           [1.0000e+00, 5.5493e-06, 4.9551e-07, 5.9953e-09, 4.2849e-06, 4.3735e-08,\n",
        "            3.7643e-06, 1.9775e-06, 1.0067e-07, 5.2575e-08, 2.5466e-08, 4.7122e-07,\n",
        "            9.5430e-09, 1.8563e-05, 1.0443e-07, 7.6725e-10, 2.2273e-08, 7.0830e-06,\n",
        "            6.9178e-08, 7.6307e-06, 2.0708e-10, 1.6494e-12, 3.9421e-10, 8.8338e-05,\n",
        "            1.5904e-10, 4.6854e-10, 5.7947e-10, 4.5516e-08, 1.0254e-08, 6.9279e-10,\n",
        "            2.0116e-08, 1.0055e-07, 2.2855e-10, 3.2538e-10, 5.6779e-11, 2.4144e-09,\n",
        "            1.1517e-08, 1.6899e-06, 4.5128e-07, 6.0438e-06, 1.5827e-06, 4.7799e-06,\n",
        "            1.1485e-07, 1.0315e-06, 1.0415e-06, 2.0087e-04, 9.7981e-07, 3.2849e-08,\n",
        "            2.4656e-06, 1.7197e-05, 1.8398e-06, 4.2589e-09, 1.1612e-06, 1.3952e-07,\n",
        "            1.8763e-08, 1.8611e-07, 7.3270e-09, 6.4341e-10, 7.1877e-04, 9.4681e-05],\n",
        "           [9.9998e-01, 5.1588e-05, 6.8390e-06, 3.1175e-07, 2.5913e-04, 3.8555e-06,\n",
        "            2.2259e-04, 1.6019e-05, 3.4131e-06, 2.2234e-05, 1.1949e-04, 8.6391e-06,\n",
        "            4.0334e-07, 3.5593e-04, 2.7853e-08, 1.1682e-08, 1.9077e-05, 2.3124e-04,\n",
        "            1.2511e-07, 2.9340e-06, 3.4189e-08, 5.5165e-09, 5.6383e-06, 1.1972e-04,\n",
        "            6.8795e-08, 1.3088e-06, 6.3472e-08, 4.3563e-05, 7.6014e-06, 1.3298e-08,\n",
        "            3.5824e-07, 5.1395e-08, 4.0049e-08, 3.7162e-05, 3.8187e-10, 8.9925e-07,\n",
        "            5.7292e-08, 1.5643e-06, 4.3761e-07, 3.1078e-04, 5.1781e-05, 2.1836e-07,\n",
        "            9.5932e-08, 1.2068e-06, 1.3922e-07, 1.7287e-04, 4.1145e-06, 8.8073e-08,\n",
        "            8.1573e-06, 1.5472e-06, 5.7900e-07, 2.1413e-09, 9.5199e-06, 3.1488e-07,\n",
        "            6.1521e-08, 4.4516e-08, 1.7784e-07, 2.7168e-06, 1.9678e-04, 6.7951e-05],\n",
        "           [1.0000e+00, 3.9109e-07, 1.8599e-07, 6.0853e-09, 4.3095e-07, 9.8276e-09,\n",
        "            3.8196e-08, 1.1119e-07, 4.1832e-08, 2.7726e-06, 5.4474e-09, 4.1669e-07,\n",
        "            1.9527e-09, 1.2930e-07, 3.2435e-09, 1.0544e-11, 1.6556e-09, 1.0695e-08,\n",
        "            4.6442e-10, 5.0739e-07, 1.1793e-11, 1.7209e-13, 1.8773e-09, 3.4233e-06,\n",
        "            1.3031e-11, 5.8925e-11, 4.0480e-11, 8.2943e-10, 9.3676e-09, 3.5306e-11,\n",
        "            2.0301e-10, 3.0517e-10, 1.7622e-12, 2.0587e-10, 3.2865e-17, 7.6890e-13,\n",
        "            2.2530e-10, 4.4744e-09, 3.9067e-07, 7.2888e-11, 5.5270e-06, 1.7215e-09,\n",
        "            2.3077e-12, 1.5699e-09, 6.7193e-10, 1.0045e-09, 2.9880e-06, 9.3406e-12,\n",
        "            1.2668e-08, 7.4357e-09, 1.8692e-09, 4.9025e-11, 3.5685e-06, 5.0941e-07,\n",
        "            3.9314e-10, 2.9345e-11, 7.4447e-10, 8.9303e-13, 4.3171e-05, 2.1655e-05],\n",
        "           [1.0000e+00, 6.5613e-08, 9.5917e-06, 2.1568e-09, 2.3789e-07, 1.4092e-07,\n",
        "            1.2733e-08, 4.7697e-06, 1.9745e-07, 4.4170e-07, 2.4013e-09, 1.3069e-05,\n",
        "            3.0765e-11, 4.6565e-11, 6.1062e-11, 1.5396e-13, 3.3597e-10, 1.4312e-07,\n",
        "            7.2696e-10, 2.0488e-07, 5.5595e-11, 1.4662e-13, 8.8376e-09, 4.1971e-05,\n",
        "            4.8519e-11, 1.8745e-10, 4.8979e-12, 5.3752e-09, 3.4772e-07, 6.6039e-09,\n",
        "            2.6271e-10, 4.1502e-10, 4.8637e-10, 2.3074e-09, 2.1424e-13, 8.0791e-11,\n",
        "            1.9439e-10, 6.2058e-05, 1.5254e-06, 1.1175e-06, 1.4883e-07, 5.5778e-06,\n",
        "            6.5616e-09, 2.1496e-06, 6.1604e-10, 1.0197e-06, 4.0868e-04, 7.1638e-08,\n",
        "            5.3466e-07, 3.4897e-09, 2.6962e-08, 2.1234e-09, 1.7170e-04, 1.8253e-06,\n",
        "            5.3423e-08, 2.7172e-09, 6.0674e-08, 4.6317e-10, 1.7139e-05, 4.4370e-04],\n",
        "           [9.9998e-01, 3.7573e-05, 5.5461e-05, 6.2451e-07, 2.1278e-04, 1.1761e-05,\n",
        "            1.5162e-05, 5.2794e-05, 1.1974e-05, 1.7163e-05, 1.4967e-05, 3.0585e-06,\n",
        "            8.1064e-08, 1.0978e-06, 4.2806e-08, 3.7034e-09, 1.7299e-06, 5.3450e-06,\n",
        "            1.2228e-07, 8.0584e-06, 7.0016e-09, 1.4730e-08, 5.1300e-07, 6.1863e-06,\n",
        "            4.4303e-09, 1.4334e-08, 1.6538e-10, 4.1551e-07, 4.5467e-05, 3.0982e-09,\n",
        "            5.5373e-08, 1.8149e-07, 3.4292e-09, 9.9317e-08, 1.1302e-10, 7.1736e-09,\n",
        "            7.5328e-07, 3.1819e-06, 6.8555e-08, 4.8033e-05, 1.4120e-05, 7.5598e-06,\n",
        "            3.3956e-07, 1.6536e-06, 8.7146e-07, 2.3346e-05, 5.9618e-06, 1.1699e-06,\n",
        "            1.4795e-06, 1.7455e-07, 1.2758e-05, 6.7129e-08, 3.6943e-05, 4.0345e-06,\n",
        "            1.1317e-06, 1.0772e-07, 1.5819e-05, 6.9153e-05, 1.1729e-03, 1.3393e-03]]],\n",
        "  8: [[[9.2063e-01, 6.6914e-02, 1.3863e-02, 8.7412e-04, 4.1343e-02, 1.1921e-03,\n",
        "            2.1934e-02, 1.5954e-02, 2.4651e-03, 5.1817e-03, 1.6006e-02, 1.2067e-01,\n",
        "            9.0780e-04, 2.4302e-03, 1.1055e-03, 2.1675e-04, 6.6171e-03, 1.8995e-02,\n",
        "            4.9220e-03, 3.6336e-02, 2.9821e-02, 9.4875e-04, 1.4603e-03, 2.6018e-01,\n",
        "            9.5330e-04, 7.5970e-04, 9.8422e-04, 1.1379e-03, 1.4913e-03, 6.3715e-04,\n",
        "            4.2457e-04, 3.6239e-03, 1.0038e-04, 2.3801e-04, 1.3030e-03, 1.1486e-04,\n",
        "            1.0719e-01, 1.8132e-03, 1.5868e-02, 2.9531e-03, 5.1489e-04, 3.1863e-04,\n",
        "            7.4333e-04, 2.1798e-02, 1.7136e-03, 7.1539e-03, 1.7848e-02, 5.5337e-05,\n",
        "            5.8083e-04, 2.1022e-04, 2.3543e-04, 1.0350e-03, 2.0184e-03, 4.5565e-04,\n",
        "            3.3456e-04, 3.7038e-05, 8.3337e-05, 3.9906e-04, 6.9956e-05, 3.9833e-03,\n",
        "            2.0338e-06, 3.3216e-05, 1.4050e-02, 3.2832e-04, 4.2203e-04, 1.0888e-03,\n",
        "            1.0887e-04, 2.2997e-05, 1.9815e-05, 1.6800e-02, 1.1687e-03, 1.6160e-04,\n",
        "            1.0066e-03, 9.1672e-06, 1.0063e-07, 7.7191e-06, 2.4545e-03, 1.5228e-06,\n",
        "            3.6136e-06, 2.2102e-07],\n",
        "           [9.6329e-01, 3.8270e-03, 4.5934e-03, 2.8797e-04, 1.2063e-02, 5.3015e-04,\n",
        "            4.3568e-02, 1.2422e-02, 1.1313e-03, 1.1389e-03, 7.9302e-03, 3.9034e-03,\n",
        "            9.8179e-06, 4.4604e-03, 6.1805e-04, 2.1031e-04, 1.6021e-03, 4.7175e-02,\n",
        "            2.1865e-03, 7.8213e-03, 6.4078e-04, 8.9026e-05, 1.2845e-03, 6.8757e-02,\n",
        "            1.4996e-04, 8.0221e-05, 4.3983e-04, 8.1735e-04, 6.2555e-04, 1.5582e-05,\n",
        "            5.5415e-05, 1.4782e-03, 8.4285e-05, 3.2028e-05, 6.7485e-04, 1.4408e-04,\n",
        "            6.5292e-04, 1.0056e-03, 2.2978e-04, 4.4343e-04, 1.9253e-04, 2.2187e-05,\n",
        "            6.0487e-05, 3.8609e-04, 1.5899e-05, 1.9671e-03, 1.7751e-03, 4.4586e-04,\n",
        "            2.3216e-05, 5.3312e-05, 5.5049e-06, 5.7442e-06, 3.9632e-04, 6.2481e-06,\n",
        "            3.1558e-05, 8.4038e-05, 1.3830e-04, 1.2923e-05, 1.1992e-03, 1.8269e-03,\n",
        "            1.6994e-05, 3.0413e-05, 1.7716e-03, 9.4329e-05, 4.7123e-05, 1.0413e-06,\n",
        "            8.8005e-06, 5.4709e-05, 2.2612e-05, 2.6441e-06, 5.2693e-06, 1.9623e-05,\n",
        "            1.2140e-05, 1.4497e-08, 1.3555e-06, 8.8108e-06, 1.9414e-07, 4.7174e-08,\n",
        "            9.6145e-08, 1.0471e-07],\n",
        "           [9.2099e-01, 4.1681e-02, 1.4407e-02, 1.0010e-03, 1.5601e-02, 2.4403e-03,\n",
        "            2.0597e-02, 1.3967e-02, 4.3292e-03, 4.5819e-03, 2.3369e-02, 2.2624e-02,\n",
        "            1.8711e-04, 7.6285e-03, 4.9673e-04, 7.1181e-04, 4.8593e-03, 6.3473e-02,\n",
        "            2.8950e-03, 3.1309e-02, 1.0826e-03, 6.3325e-04, 1.7144e-02, 3.5411e-02,\n",
        "            8.5072e-04, 7.9685e-04, 3.6550e-03, 2.9520e-03, 5.4520e-04, 1.6195e-04,\n",
        "            9.0438e-04, 2.6267e-03, 1.5197e-03, 1.1112e-03, 1.6413e-03, 1.2518e-03,\n",
        "            3.3344e-03, 2.8996e-03, 1.3499e-03, 8.1753e-03, 1.2144e-03, 2.7935e-04,\n",
        "            3.4395e-04, 5.2921e-03, 1.4513e-04, 6.6158e-03, 7.3058e-03, 2.3318e-03,\n",
        "            9.0466e-05, 2.2240e-03, 7.2644e-05, 1.3976e-05, 4.1933e-03, 2.0075e-03,\n",
        "            1.1949e-04, 5.3233e-04, 2.0406e-03, 4.4126e-04, 2.3218e-03, 1.6908e-02,\n",
        "            6.4812e-05, 1.1428e-03, 9.9666e-04, 9.9751e-04, 4.1258e-04, 7.4046e-05,\n",
        "            3.3807e-04, 2.8034e-04, 2.1189e-03, 1.6830e-03, 2.4427e-03, 6.1013e-04,\n",
        "            1.7398e-03, 1.6891e-03, 1.2708e-03, 4.1027e-05, 1.0324e-06, 1.4537e-06,\n",
        "            4.1499e-06, 1.9074e-07],\n",
        "           [9.6509e-01, 4.0645e-02, 2.5464e-02, 2.6104e-03, 1.2808e-02, 7.5398e-04,\n",
        "            6.1345e-03, 8.5401e-03, 1.0746e-03, 2.6794e-03, 8.6877e-03, 1.9791e-02,\n",
        "            1.7017e-04, 2.1610e-03, 1.9002e-04, 1.2076e-03, 1.3551e-03, 2.7451e-02,\n",
        "            2.3069e-03, 5.7185e-02, 1.4211e-03, 1.9170e-04, 3.2118e-03, 8.9296e-02,\n",
        "            1.6765e-03, 3.1601e-04, 9.6274e-04, 7.7431e-05, 3.3409e-04, 4.7079e-04,\n",
        "            4.9368e-04, 8.4968e-04, 3.3153e-04, 1.2246e-04, 1.5877e-04, 7.1102e-05,\n",
        "            1.1929e-01, 7.2599e-04, 1.7758e-03, 1.2092e-03, 1.7196e-03, 2.8049e-04,\n",
        "            2.1019e-04, 6.7553e-03, 5.1882e-05, 1.2623e-03, 5.4192e-03, 4.6384e-05,\n",
        "            1.0086e-04, 7.7770e-05, 3.4403e-05, 2.8720e-05, 3.1348e-03, 4.3114e-04,\n",
        "            2.5822e-05, 3.2549e-05, 3.1005e-04, 1.0023e-04, 1.8245e-03, 8.8897e-04,\n",
        "            5.3142e-06, 9.9276e-05, 4.8073e-03, 1.2366e-03, 1.1555e-02, 4.3459e-06,\n",
        "            2.5541e-05, 7.0208e-05, 2.2786e-05, 2.6505e-04, 3.0350e-04, 3.8295e-03,\n",
        "            7.4347e-03, 3.7044e-07, 9.0032e-06, 1.4956e-04, 1.0029e-06, 2.7254e-06,\n",
        "            2.3684e-05, 9.7104e-08],\n",
        "           [9.6969e-01, 7.7151e-03, 8.5717e-03, 7.5097e-04, 1.1506e-02, 2.5955e-04,\n",
        "            4.9589e-03, 5.5190e-03, 1.0891e-03, 1.3182e-03, 5.4904e-03, 5.4249e-04,\n",
        "            7.3880e-06, 1.5190e-02, 1.3112e-04, 2.1265e-04, 7.6516e-04, 4.6429e-02,\n",
        "            1.2221e-03, 1.1697e-02, 1.0956e-04, 6.6758e-05, 9.1528e-04, 5.7308e-03,\n",
        "            2.9351e-04, 1.1527e-04, 1.6668e-03, 1.1454e-04, 6.6291e-05, 4.5812e-06,\n",
        "            6.1612e-05, 5.4628e-04, 7.3782e-05, 1.9099e-05, 1.8907e-04, 4.0871e-04,\n",
        "            2.0502e-04, 4.5521e-04, 3.8770e-05, 7.0290e-04, 1.3005e-04, 9.8609e-06,\n",
        "            3.1209e-05, 4.7910e-04, 1.5915e-05, 1.3793e-04, 5.1975e-05, 1.7387e-04,\n",
        "            1.0505e-05, 1.5160e-04, 1.9871e-06, 2.3778e-07, 8.1604e-05, 4.0499e-05,\n",
        "            2.8103e-06, 9.7754e-05, 4.5938e-05, 1.5280e-05, 1.5034e-03, 6.2883e-04,\n",
        "            5.5939e-07, 6.4395e-04, 2.7175e-05, 6.7048e-05, 1.1371e-04, 8.7293e-06,\n",
        "            4.0108e-06, 9.2643e-07, 1.5968e-05, 1.4281e-06, 6.5683e-06, 2.3076e-06,\n",
        "            1.5445e-03, 3.5124e-07, 8.8307e-07, 4.2285e-06, 3.5930e-09, 3.3237e-09,\n",
        "            1.5345e-08, 3.3146e-09],\n",
        "           [9.5772e-01, 1.7834e-02, 7.1169e-03, 6.0577e-04, 1.1505e-02, 2.3842e-04,\n",
        "            8.0136e-03, 1.0679e-02, 2.5029e-03, 1.7569e-03, 6.6888e-03, 1.1125e-02,\n",
        "            3.1619e-05, 2.4199e-03, 8.0387e-05, 5.2496e-04, 1.2725e-03, 2.6258e-02,\n",
        "            1.4192e-03, 1.0798e-02, 2.9975e-04, 7.9334e-05, 1.9289e-03, 3.6931e-02,\n",
        "            1.5264e-04, 1.7043e-04, 9.9404e-04, 4.5868e-04, 2.2776e-04, 1.4928e-05,\n",
        "            9.3446e-05, 1.9515e-03, 9.2181e-05, 5.7318e-05, 4.4950e-04, 1.9025e-04,\n",
        "            7.6192e-04, 9.2334e-04, 7.7726e-04, 1.6790e-03, 7.6485e-04, 4.9810e-05,\n",
        "            7.6202e-05, 6.6744e-04, 1.9241e-05, 7.2248e-04, 3.5282e-03, 2.0724e-04,\n",
        "            2.7537e-05, 2.2649e-04, 8.3542e-06, 3.3590e-06, 3.7007e-04, 9.8740e-05,\n",
        "            1.3071e-05, 1.9186e-05, 4.3383e-05, 7.5308e-05, 3.4601e-03, 5.0185e-03,\n",
        "            1.6219e-05, 2.1456e-04, 1.4693e-03, 2.1543e-04, 1.0791e-04, 1.2261e-05,\n",
        "            8.6749e-06, 9.0811e-06, 7.5983e-06, 1.8520e-04, 2.3112e-03, 3.8638e-05,\n",
        "            5.3390e-05, 4.2908e-06, 2.3316e-07, 9.5069e-06, 6.1364e-07, 1.9418e-07,\n",
        "            1.2257e-08, 1.5815e-08],\n",
        "           [9.4308e-01, 1.9832e-02, 1.9149e-02, 1.4244e-03, 6.1465e-03, 6.0581e-04,\n",
        "            7.7156e-03, 9.1903e-03, 2.4901e-03, 2.4226e-03, 3.9778e-02, 2.6948e-03,\n",
        "            3.8203e-05, 3.7184e-03, 9.8287e-05, 2.1216e-04, 3.1261e-03, 1.5846e-01,\n",
        "            1.9175e-03, 1.1860e-02, 6.1697e-04, 5.0096e-04, 2.7316e-03, 1.3259e-02,\n",
        "            5.2764e-04, 2.2371e-04, 7.5539e-04, 4.2475e-04, 3.0269e-04, 2.5201e-05,\n",
        "            2.4342e-04, 6.0737e-04, 4.8865e-04, 2.0190e-04, 1.7349e-04, 1.6725e-03,\n",
        "            1.0698e-03, 2.6384e-04, 2.6397e-04, 3.6400e-03, 6.1146e-04, 3.3149e-05,\n",
        "            1.2248e-04, 1.0806e-03, 6.7634e-05, 2.4370e-03, 3.9021e-04, 2.7822e-04,\n",
        "            3.2609e-05, 8.2780e-04, 3.7607e-06, 1.6773e-06, 4.7531e-04, 1.2048e-04,\n",
        "            2.8155e-05, 1.3139e-04, 1.6925e-04, 1.8591e-04, 5.6701e-04, 1.9760e-03,\n",
        "            2.1011e-06, 1.2613e-03, 1.7561e-05, 1.5728e-04, 1.5188e-04, 9.2287e-06,\n",
        "            6.2110e-05, 8.8021e-06, 1.6010e-04, 6.8782e-05, 7.4316e-06, 5.7953e-04,\n",
        "            3.8817e-04, 2.5325e-05, 4.1805e-06, 1.0961e-06, 1.7014e-08, 4.9080e-08,\n",
        "            1.7243e-06, 3.6783e-08],\n",
        "           [9.6587e-01, 1.8390e-02, 1.1914e-02, 4.6663e-04, 9.6868e-03, 2.1528e-04,\n",
        "            3.4945e-03, 2.8673e-03, 1.7318e-03, 4.4489e-03, 6.0764e-03, 1.1155e-02,\n",
        "            3.0715e-05, 1.2451e-03, 6.4504e-05, 2.5790e-04, 4.3608e-04, 8.9571e-03,\n",
        "            7.7766e-04, 3.6298e-02, 2.9282e-04, 1.7031e-05, 2.4064e-03, 2.3420e-02,\n",
        "            1.2093e-04, 2.1124e-04, 6.9809e-04, 2.0464e-04, 1.2246e-04, 1.3006e-05,\n",
        "            1.6948e-04, 1.1296e-03, 3.9002e-05, 7.7093e-05, 1.5450e-04, 3.0608e-05,\n",
        "            1.3558e-03, 3.4331e-04, 7.1782e-04, 4.8568e-04, 4.4092e-04, 1.0765e-05,\n",
        "            2.8090e-05, 1.4300e-03, 1.8405e-05, 1.0851e-04, 3.2032e-03, 2.3579e-05,\n",
        "            3.1656e-05, 1.0506e-04, 1.9996e-06, 9.9367e-07, 2.7419e-04, 5.3270e-04,\n",
        "            7.4737e-06, 5.6137e-06, 2.5337e-05, 9.6225e-06, 3.0217e-04, 2.2139e-03,\n",
        "            8.0378e-07, 1.8311e-05, 4.6780e-04, 3.1801e-04, 3.4993e-04, 5.6198e-06,\n",
        "            4.2266e-06, 2.0823e-06, 3.7718e-06, 1.5974e-04, 2.1903e-05, 9.3872e-04,\n",
        "            4.1798e-04, 5.1748e-06, 1.5119e-08, 1.7442e-06, 2.2628e-08, 3.4451e-08,\n",
        "            3.2656e-08, 9.1066e-09],\n",
        "           [9.3582e-01, 3.1345e-02, 1.0958e-02, 3.0498e-04, 1.5668e-02, 8.8958e-04,\n",
        "            1.4816e-02, 9.6043e-03, 4.0247e-03, 2.4529e-03, 1.4100e-02, 8.1668e-02,\n",
        "            9.0688e-05, 2.5139e-03, 7.2453e-04, 1.3672e-04, 3.2818e-03, 2.0042e-02,\n",
        "            6.1209e-03, 9.9961e-03, 1.3164e-03, 1.4660e-04, 3.6571e-03, 1.2221e-01,\n",
        "            4.8121e-04, 5.0463e-04, 1.8680e-03, 3.5567e-03, 4.4327e-04, 6.0867e-05,\n",
        "            6.0264e-05, 6.2720e-03, 6.9933e-05, 9.2245e-05, 2.2734e-03, 1.2949e-04,\n",
        "            1.4774e-03, 3.1238e-03, 2.2403e-03, 4.9887e-03, 6.0930e-05, 1.1964e-04,\n",
        "            3.1673e-04, 7.3283e-03, 5.8436e-05, 1.5426e-03, 4.8019e-03, 1.6272e-04,\n",
        "            6.0782e-05, 1.4502e-04, 1.1234e-05, 2.8366e-05, 3.3027e-04, 5.9646e-05,\n",
        "            2.0381e-05, 4.6256e-05, 1.2423e-04, 2.1569e-04, 2.7501e-04, 1.5799e-03,\n",
        "            1.0415e-05, 1.7172e-04, 3.6756e-03, 3.1185e-05, 6.2570e-06, 2.9883e-05,\n",
        "            2.9456e-05, 3.4598e-06, 7.6650e-06, 3.3972e-03, 6.3969e-04, 3.1252e-06,\n",
        "            1.5905e-06, 6.2417e-07, 6.8975e-08, 1.9241e-06, 1.3010e-06, 6.0971e-07,\n",
        "            2.6773e-08, 2.9471e-07],\n",
        "           [9.8279e-01, 1.0286e-02, 9.0206e-03, 3.3758e-04, 8.7593e-03, 1.3648e-04,\n",
        "            3.5829e-03, 4.8569e-03, 8.1524e-04, 7.5225e-04, 1.3287e-02, 1.4877e-03,\n",
        "            6.7430e-06, 2.8535e-03, 3.8151e-05, 1.3107e-04, 8.2469e-04, 3.5864e-02,\n",
        "            1.6213e-03, 1.0303e-02, 2.6975e-04, 7.1495e-05, 7.0783e-04, 2.1523e-02,\n",
        "            8.2666e-05, 3.4731e-05, 5.3993e-04, 9.7609e-05, 1.6383e-04, 5.8355e-06,\n",
        "            1.2095e-05, 5.8473e-04, 3.2381e-05, 1.7908e-05, 3.6043e-04, 1.1221e-04,\n",
        "            3.8921e-04, 2.2278e-04, 1.3052e-04, 5.7715e-04, 8.4249e-05, 1.3969e-05,\n",
        "            2.9363e-05, 2.9584e-04, 1.6329e-05, 1.8425e-04, 3.5593e-04, 9.3731e-05,\n",
        "            2.0375e-05, 3.9462e-05, 5.4168e-07, 1.0927e-06, 4.2513e-05, 1.3903e-05,\n",
        "            3.9905e-06, 7.2045e-06, 6.6540e-05, 4.2205e-05, 1.6694e-04, 4.2029e-04,\n",
        "            7.2708e-07, 6.2858e-05, 8.4267e-05, 3.5410e-05, 2.7549e-05, 3.5952e-06,\n",
        "            2.2637e-05, 3.9175e-07, 2.0440e-06, 6.9071e-06, 2.1417e-06, 1.5742e-06,\n",
        "            1.2016e-04, 3.3701e-07, 1.0578e-07, 1.5978e-07, 3.7139e-08, 2.2594e-08,\n",
        "            4.9661e-09, 2.0311e-09]],\n",
        "   [[9.9908e-01, 6.9200e-04, 8.0072e-04, 6.9625e-06, 7.4145e-04, 1.4711e-04,\n",
        "            2.4716e-04, 3.2379e-03, 1.9919e-04, 6.0684e-05, 8.7689e-04, 1.4795e-03,\n",
        "            4.0972e-05, 1.3472e-03, 4.8064e-06, 1.4410e-07, 4.2784e-05, 7.0886e-04,\n",
        "            5.9732e-06, 3.4133e-03, 4.3562e-04, 4.6387e-06, 2.1214e-07, 5.8658e-04,\n",
        "            6.9392e-07, 3.9865e-07, 7.9708e-08, 1.3555e-06, 3.4763e-05, 1.3704e-05,\n",
        "            1.9209e-08, 1.9403e-06, 4.3153e-08, 4.2020e-07, 3.7238e-08, 1.5826e-10,\n",
        "            1.7362e-03, 7.0725e-07, 2.4322e-04, 6.2077e-07, 3.0596e-05, 2.0491e-07,\n",
        "            1.2148e-04, 7.7927e-05, 5.6224e-05, 1.6285e-03, 5.4466e-02, 2.9517e-08,\n",
        "            2.0784e-07, 3.2835e-06, 3.8881e-04, 4.2056e-05, 4.0017e-03, 2.5409e-04,\n",
        "            2.4236e-05, 8.2359e-07, 2.4384e-06, 1.9035e-07, 2.3073e-05, 1.1428e-02,\n",
        "            8.1056e-09, 2.9243e-06, 7.6995e-03, 7.2274e-05, 1.2191e-04, 2.2691e-05,\n",
        "            5.2998e-08, 1.2170e-06, 2.0950e-07, 1.9599e-02],\n",
        "           [1.0000e+00, 4.8492e-07, 8.1150e-07, 1.0362e-08, 4.0270e-05, 2.7533e-07,\n",
        "            3.3184e-05, 8.4204e-06, 8.8716e-08, 2.0187e-07, 4.2573e-07, 4.3933e-05,\n",
        "            2.5652e-09, 6.8812e-07, 1.7923e-07, 2.0900e-10, 2.3889e-07, 5.1605e-05,\n",
        "            1.2743e-07, 2.0778e-06, 2.9044e-08, 5.9167e-12, 5.4330e-09, 6.8410e-07,\n",
        "            3.7926e-10, 3.3011e-09, 5.6423e-12, 3.0810e-07, 6.7190e-05, 3.7466e-10,\n",
        "            1.3435e-12, 5.1881e-09, 1.8564e-11, 4.3423e-07, 1.6364e-11, 2.9239e-11,\n",
        "            4.3400e-10, 1.1583e-07, 1.0789e-07, 7.9823e-07, 4.2861e-06, 3.0959e-07,\n",
        "            1.2852e-09, 3.6185e-09, 1.9886e-08, 1.7517e-03, 1.6409e-05, 1.8498e-07,\n",
        "            1.0856e-06, 4.6288e-07, 6.8154e-08, 1.3247e-09, 9.9926e-06, 5.5676e-09,\n",
        "            1.2263e-08, 3.2483e-08, 2.2112e-08, 2.9702e-10, 4.8004e-04, 1.7813e-04,\n",
        "            1.1269e-07, 2.1631e-05, 1.2634e-03, 8.1985e-07, 4.1963e-06, 5.5841e-09,\n",
        "            9.4943e-09, 2.2211e-08, 3.6684e-06, 1.1148e-08],\n",
        "           [1.0000e+00, 4.4235e-05, 3.9204e-06, 2.1221e-07, 5.3139e-05, 1.9269e-06,\n",
        "            1.1930e-05, 1.4104e-05, 3.2766e-06, 5.0207e-06, 1.3716e-05, 2.2490e-05,\n",
        "            6.1373e-07, 7.1266e-05, 4.3726e-07, 9.0238e-09, 4.7590e-06, 1.4343e-04,\n",
        "            3.3249e-07, 3.3315e-04, 4.2677e-08, 9.9578e-10, 3.0770e-05, 1.5500e-05,\n",
        "            2.0124e-09, 1.0573e-07, 1.9891e-07, 3.5305e-05, 6.4607e-06, 1.0431e-09,\n",
        "            8.2108e-06, 2.0103e-06, 2.0106e-08, 7.7414e-07, 1.0650e-09, 1.4474e-06,\n",
        "            1.5022e-07, 1.0330e-04, 2.8796e-07, 3.0610e-04, 3.1960e-05, 9.1784e-07,\n",
        "            5.7860e-07, 2.5497e-05, 4.1775e-07, 2.3450e-04, 5.2293e-05, 2.1351e-07,\n",
        "            2.0445e-05, 8.8480e-06, 1.7400e-06, 1.1241e-08, 1.0254e-04, 7.4010e-06,\n",
        "            2.7599e-07, 9.2165e-07, 1.1783e-06, 8.7492e-08, 1.2582e-04, 3.2487e-03,\n",
        "            3.3307e-07, 1.7513e-03, 7.8850e-03, 3.7759e-04, 3.4265e-05, 6.5769e-05,\n",
        "            1.6974e-05, 6.5886e-06, 3.3915e-05, 2.0580e-04],\n",
        "           [9.9999e-01, 2.2478e-05, 4.0819e-05, 5.1062e-07, 4.5774e-04, 1.8481e-05,\n",
        "            2.8058e-05, 6.8651e-05, 1.6414e-05, 4.3917e-05, 1.0857e-05, 3.7650e-04,\n",
        "            7.4395e-07, 1.7993e-04, 1.3578e-06, 2.3530e-08, 4.4231e-06, 1.4510e-05,\n",
        "            1.0204e-06, 6.8003e-05, 3.4125e-07, 1.0105e-08, 3.5128e-06, 1.8945e-03,\n",
        "            9.3111e-08, 7.9602e-07, 2.6428e-08, 9.9818e-07, 5.1420e-06, 3.5291e-08,\n",
        "            7.3058e-06, 4.6001e-07, 1.1120e-08, 4.4645e-08, 4.8225e-09, 8.4143e-09,\n",
        "            4.3047e-04, 5.3224e-05, 2.4786e-07, 8.6821e-05, 9.8074e-07, 6.8903e-08,\n",
        "            8.5169e-08, 6.0948e-05, 1.0632e-07, 1.0041e-06, 1.4642e-05, 2.9089e-09,\n",
        "            5.3177e-06, 3.3957e-08, 1.1648e-04, 7.6467e-09, 6.6409e-06, 2.8094e-05,\n",
        "            4.4627e-08, 2.8971e-08, 2.9342e-05, 4.5039e-08, 2.8066e-04, 1.1379e-05,\n",
        "            4.6465e-09, 6.3909e-05, 1.6577e-04, 7.5948e-05, 8.7874e-03, 4.4715e-07,\n",
        "            2.1162e-08, 1.5308e-07, 8.5811e-06, 5.0737e-05],\n",
        "           [1.0000e+00, 3.2892e-06, 2.3595e-05, 1.3481e-07, 2.0522e-04, 7.1492e-06,\n",
        "            7.5380e-06, 4.7893e-05, 1.5782e-06, 8.2644e-07, 4.9282e-08, 3.7144e-08,\n",
        "            7.4850e-08, 4.1440e-05, 9.9630e-10, 2.0470e-10, 9.0763e-08, 1.3555e-04,\n",
        "            4.4645e-09, 1.1499e-05, 6.9140e-10, 2.4573e-12, 3.0633e-09, 2.2534e-06,\n",
        "            1.7030e-10, 3.4079e-09, 7.4912e-10, 1.8549e-06, 1.0884e-07, 2.4170e-12,\n",
        "            3.9477e-09, 1.0089e-08, 1.2726e-10, 8.1568e-09, 4.9966e-11, 3.2332e-09,\n",
        "            2.9195e-09, 2.3752e-07, 2.1880e-10, 2.9423e-06, 1.2972e-07, 1.4374e-08,\n",
        "            6.9272e-09, 5.3385e-07, 4.8447e-09, 9.4277e-07, 7.9305e-09, 5.9686e-09,\n",
        "            2.7876e-08, 3.3089e-07, 6.0583e-08, 6.6004e-11, 2.9463e-06, 2.9613e-07,\n",
        "            9.8864e-08, 2.3464e-07, 1.6869e-09, 6.1995e-09, 1.2356e-04, 8.7223e-06,\n",
        "            3.8794e-10, 2.8762e-04, 1.1962e-06, 4.4601e-06, 3.6969e-06, 3.7261e-06,\n",
        "            3.9959e-09, 5.4237e-10, 1.2262e-06, 2.1665e-07],\n",
        "           [1.0000e+00, 2.8102e-05, 3.3007e-06, 1.8039e-07, 1.7867e-05, 4.5562e-07,\n",
        "            2.3666e-05, 3.0321e-06, 7.7598e-07, 3.5545e-07, 2.1866e-06, 5.6248e-07,\n",
        "            7.2865e-08, 1.5414e-05, 2.1945e-09, 6.3591e-10, 7.9638e-08, 3.3080e-07,\n",
        "            1.7027e-09, 7.5247e-06, 3.4821e-10, 7.1898e-11, 5.3652e-09, 3.9638e-06,\n",
        "            1.1701e-10, 2.2745e-10, 1.1439e-07, 1.5616e-07, 1.8453e-07, 1.1493e-10,\n",
        "            3.5014e-09, 2.8371e-07, 4.5338e-11, 1.8242e-08, 2.6334e-12, 2.4513e-08,\n",
        "            3.6720e-08, 3.3587e-06, 2.2110e-07, 3.2221e-08, 3.8417e-06, 1.2377e-05,\n",
        "            2.9879e-08, 2.6192e-07, 7.6754e-08, 1.0275e-06, 4.4659e-05, 2.6043e-07,\n",
        "            1.2410e-06, 8.3409e-07, 3.6930e-07, 5.8822e-09, 1.0074e-05, 1.4728e-06,\n",
        "            3.6508e-08, 7.2212e-08, 5.0332e-09, 9.2354e-10, 4.0093e-03, 4.2112e-04,\n",
        "            7.9061e-08, 1.7951e-05, 5.0802e-03, 1.1939e-05, 1.2618e-04, 9.1541e-07,\n",
        "            1.8525e-08, 4.8036e-08, 5.8320e-07, 2.3856e-06],\n",
        "           [1.0000e+00, 1.1520e-04, 2.7779e-06, 4.1368e-07, 1.2517e-05, 9.8886e-07,\n",
        "            1.6817e-04, 1.4803e-05, 3.6708e-06, 8.3260e-06, 1.5695e-06, 4.7092e-07,\n",
        "            1.7338e-07, 4.7419e-05, 1.0294e-08, 7.8285e-10, 6.5684e-07, 5.2428e-05,\n",
        "            2.2145e-08, 2.7994e-06, 4.5749e-09, 1.1231e-10, 2.6104e-06, 1.2351e-05,\n",
        "            1.2798e-09, 8.2072e-08, 2.0546e-08, 1.3941e-05, 1.6354e-06, 8.2434e-11,\n",
        "            5.6648e-07, 5.3840e-09, 2.8903e-08, 1.0028e-06, 3.3167e-10, 6.2886e-07,\n",
        "            1.8063e-08, 1.2763e-07, 3.0293e-09, 1.1358e-03, 1.5005e-06, 7.3845e-09,\n",
        "            1.0343e-09, 5.7215e-08, 8.3859e-10, 6.8186e-05, 1.3064e-07, 2.4548e-10,\n",
        "            1.7721e-06, 1.0804e-08, 1.7062e-07, 3.5804e-10, 4.5781e-07, 5.7791e-09,\n",
        "            3.0184e-10, 6.8824e-09, 2.6051e-07, 3.1972e-07, 7.2086e-05, 3.0404e-06,\n",
        "            9.5294e-09, 1.4193e-04, 7.3911e-06, 7.0133e-05, 5.4532e-05, 4.1165e-06,\n",
        "            6.6870e-07, 9.0109e-08, 2.2419e-05, 2.4760e-06],\n",
        "           [9.9999e-01, 2.6787e-08, 1.7338e-06, 9.4711e-09, 5.5578e-05, 4.0109e-07,\n",
        "            2.7156e-07, 1.0116e-06, 3.9826e-07, 7.6756e-06, 6.6933e-08, 3.0601e-06,\n",
        "            3.3783e-08, 4.9536e-06, 5.0261e-09, 1.5874e-10, 2.3674e-08, 4.2293e-09,\n",
        "            1.4111e-11, 2.6479e-06, 4.5071e-09, 2.2931e-10, 1.7908e-07, 1.4718e-05,\n",
        "            1.2824e-09, 1.0668e-08, 3.5781e-08, 2.4240e-07, 2.5301e-07, 2.0920e-09,\n",
        "            1.4184e-08, 1.0575e-07, 1.0346e-10, 6.2776e-09, 4.5551e-15, 9.4344e-12,\n",
        "            1.0496e-08, 1.0608e-07, 8.2065e-06, 2.1395e-09, 6.4866e-05, 9.4885e-08,\n",
        "            6.5590e-10, 2.7408e-08, 6.7827e-09, 9.1735e-09, 7.7947e-05, 8.3855e-10,\n",
        "            2.0550e-07, 2.7558e-08, 1.5966e-08, 1.9500e-10, 1.9377e-06, 2.6023e-05,\n",
        "            2.6528e-09, 4.4533e-10, 1.3984e-08, 1.2303e-11, 1.7141e-04, 5.7072e-05,\n",
        "            2.5996e-09, 2.1057e-06, 3.7349e-04, 3.6164e-05, 3.6989e-04, 3.4500e-07,\n",
        "            3.4941e-09, 8.3525e-09, 2.2675e-07, 1.3285e-05],\n",
        "           [1.0000e+00, 5.1635e-07, 1.0300e-04, 9.9058e-09, 3.2265e-07, 6.1867e-07,\n",
        "            1.9642e-07, 2.4536e-06, 7.4995e-07, 8.6155e-07, 5.4114e-09, 3.4940e-05,\n",
        "            1.1758e-10, 1.1173e-10, 4.3528e-10, 5.7353e-13, 5.4245e-10, 5.1669e-07,\n",
        "            3.7378e-09, 1.3266e-06, 5.0680e-10, 3.2484e-12, 9.3181e-08, 3.3493e-04,\n",
        "            4.4336e-10, 6.1385e-10, 3.8011e-11, 8.1712e-09, 1.3309e-06, 4.2855e-08,\n",
        "            7.5056e-10, 3.2844e-10, 1.9126e-10, 8.1122e-09, 9.3865e-12, 1.0376e-09,\n",
        "            3.0539e-10, 3.3390e-05, 9.1770e-08, 6.9320e-06, 1.7867e-07, 1.3434e-05,\n",
        "            1.9522e-09, 1.5855e-06, 1.0299e-09, 2.3800e-06, 2.4416e-04, 3.2834e-08,\n",
        "            1.8295e-06, 4.2985e-09, 3.1876e-08, 1.5773e-09, 6.8505e-05, 3.1715e-07,\n",
        "            1.6754e-08, 1.8301e-09, 8.9405e-08, 4.6261e-10, 2.2130e-05, 4.7266e-05,\n",
        "            1.6206e-08, 1.1123e-03, 4.8956e-03, 6.0807e-06, 1.0776e-06, 1.5779e-06,\n",
        "            1.0567e-06, 1.2508e-08, 5.9781e-07, 5.4273e-04],\n",
        "           [1.0000e+00, 1.2937e-05, 2.3677e-05, 5.6655e-07, 2.8152e-05, 6.6959e-06,\n",
        "            5.3308e-06, 1.2006e-04, 1.2946e-05, 4.2006e-06, 3.3186e-05, 2.5173e-06,\n",
        "            5.2835e-09, 5.9312e-06, 5.0463e-09, 3.3154e-09, 9.2776e-07, 4.3737e-07,\n",
        "            3.9427e-08, 1.4702e-06, 4.7996e-11, 5.3613e-09, 2.3804e-08, 2.5086e-06,\n",
        "            7.5243e-11, 5.7315e-10, 6.5152e-11, 3.4224e-08, 3.4850e-06, 2.7782e-11,\n",
        "            5.9758e-11, 1.2988e-08, 2.1525e-11, 9.5504e-10, 4.3375e-13, 3.7756e-10,\n",
        "            4.2299e-08, 1.5204e-06, 2.8593e-10, 3.1248e-08, 3.1075e-07, 1.0578e-07,\n",
        "            4.8334e-09, 1.8225e-07, 2.5807e-08, 9.7184e-08, 9.8732e-08, 1.7799e-07,\n",
        "            3.5595e-07, 1.0382e-08, 1.1590e-07, 2.3672e-09, 7.0763e-07, 4.9935e-08,\n",
        "            1.8740e-07, 8.3083e-09, 5.0570e-09, 1.4904e-07, 1.0815e-04, 9.0862e-06,\n",
        "            1.2391e-09, 3.4619e-05, 1.8271e-05, 1.3404e-06, 3.2980e-06, 3.2864e-07,\n",
        "            1.0092e-07, 7.3097e-10, 2.3534e-07, 2.2890e-07]]],\n",
        "  9: [[[9.3244e-01, 8.0438e-02, 1.7978e-02, 1.2825e-03, 4.3520e-02, 2.4212e-03,\n",
        "            1.8792e-02, 1.1131e-02, 3.6004e-03, 1.1801e-02, 7.2559e-03, 1.6994e-01,\n",
        "            2.3011e-03, 2.2866e-03, 1.5450e-03, 4.3313e-04, 6.6715e-03, 6.5911e-02,\n",
        "            4.1955e-03, 3.3933e-02, 2.4877e-02, 1.5966e-03, 1.8695e-03, 3.4885e-01,\n",
        "            1.1903e-03, 6.8600e-04, 1.5033e-03, 1.4729e-03, 1.7423e-03, 1.1343e-03,\n",
        "            8.4370e-04, 2.2544e-03, 6.0807e-04, 6.4059e-04, 6.5322e-04, 1.4383e-04,\n",
        "            2.9058e-01, 1.8315e-03, 1.5853e-02, 2.3603e-03, 1.2780e-03, 1.7674e-04,\n",
        "            2.9480e-04, 2.4561e-02, 2.4741e-03, 1.7691e-02, 4.3905e-02, 1.4085e-04,\n",
        "            6.2409e-04, 4.0183e-04, 1.3235e-04, 1.5573e-03, 6.0027e-03, 2.2047e-04,\n",
        "            4.2496e-04, 1.0476e-04, 2.4690e-04, 1.0505e-03, 2.0984e-04, 1.6865e-03,\n",
        "            2.1677e-05, 3.6117e-05, 1.8185e-02, 3.4202e-04, 2.0219e-03, 1.8683e-04,\n",
        "            5.4200e-04, 1.0018e-04, 8.4957e-05, 1.0948e-02, 1.4891e-02, 2.7753e-03,\n",
        "            3.7107e-04, 1.0015e-04, 1.2850e-05, 4.0294e-05, 4.4675e-04, 8.3974e-05,\n",
        "            4.9371e-04, 1.0154e-06, 1.0783e-04, 6.9569e-09, 7.7065e-07, 1.8454e-05,\n",
        "            2.8709e-06, 3.3601e-03, 2.8257e-07, 1.9695e-05, 3.6996e-08, 5.2568e-06],\n",
        "           [9.3032e-01, 6.8645e-03, 7.8931e-03, 2.8308e-03, 1.8050e-02, 6.7103e-04,\n",
        "            5.8748e-02, 4.9866e-02, 6.0494e-03, 2.3433e-03, 6.5195e-03, 1.3176e-02,\n",
        "            4.6959e-05, 4.3449e-03, 3.1924e-03, 7.5755e-04, 3.1492e-03, 2.0223e-01,\n",
        "            2.4959e-03, 4.4070e-03, 1.6903e-03, 4.6819e-04, 1.6984e-03, 1.7355e-01,\n",
        "            3.4665e-04, 3.0862e-04, 1.5996e-03, 1.0223e-03, 3.7029e-03, 6.9560e-05,\n",
        "            5.1459e-04, 2.1655e-03, 2.1886e-04, 4.5491e-05, 8.7513e-04, 9.4813e-04,\n",
        "            2.9917e-03, 2.6170e-03, 1.1033e-03, 7.8529e-04, 7.9580e-04, 1.3701e-04,\n",
        "            9.4507e-05, 1.1319e-03, 1.0907e-04, 7.4774e-03, 6.5261e-03, 2.0542e-03,\n",
        "            1.5665e-04, 7.0180e-04, 1.4124e-05, 6.8016e-05, 1.1795e-03, 1.4613e-05,\n",
        "            1.0876e-03, 7.8803e-04, 3.0772e-04, 2.3339e-04, 1.1220e-03, 3.6564e-03,\n",
        "            4.7869e-05, 2.9496e-04, 6.4041e-03, 2.7609e-04, 1.5659e-04, 5.7716e-05,\n",
        "            2.0884e-04, 3.3371e-04, 2.0394e-04, 1.3297e-04, 3.7272e-04, 7.6629e-05,\n",
        "            1.4389e-04, 1.0577e-05, 2.2718e-06, 2.7142e-05, 5.2922e-05, 1.5303e-04,\n",
        "            1.1584e-04, 1.1534e-05, 6.1533e-04, 1.3008e-08, 1.9410e-08, 6.1056e-07,\n",
        "            1.4512e-08, 6.9283e-05, 4.9542e-07, 1.3963e-04, 3.6785e-07, 3.2630e-04],\n",
        "           [9.6410e-01, 1.5849e-02, 8.3041e-03, 2.0580e-04, 8.3709e-03, 5.9966e-04,\n",
        "            2.9065e-03, 1.2492e-02, 2.2495e-03, 6.5672e-04, 5.9422e-03, 5.1555e-03,\n",
        "            1.4520e-05, 2.2602e-03, 5.5664e-05, 8.9451e-05, 3.1717e-03, 7.6289e-02,\n",
        "            5.9824e-04, 1.4355e-02, 1.4136e-04, 2.1879e-04, 1.7259e-03, 8.0472e-03,\n",
        "            5.6628e-05, 5.5896e-05, 8.2786e-04, 1.1054e-03, 6.5280e-05, 4.3453e-06,\n",
        "            1.2158e-04, 1.3416e-03, 4.2005e-04, 1.6514e-05, 6.6651e-04, 3.4024e-04,\n",
        "            1.7973e-04, 1.0136e-04, 1.0361e-04, 8.6531e-04, 1.7146e-04, 4.9734e-06,\n",
        "            1.9533e-05, 1.2052e-04, 4.4662e-05, 2.2265e-03, 6.8223e-04, 1.1549e-03,\n",
        "            5.3255e-06, 2.0944e-03, 3.8053e-06, 6.7900e-07, 1.5323e-04, 2.8974e-05,\n",
        "            1.2378e-05, 2.3303e-05, 2.1708e-04, 5.2434e-05, 1.4720e-04, 7.6373e-03,\n",
        "            2.3822e-06, 2.0339e-04, 7.3582e-06, 3.6168e-05, 2.3316e-05, 7.2700e-06,\n",
        "            4.0441e-05, 1.0171e-04, 6.9732e-04, 1.1021e-04, 8.2465e-05, 1.2709e-04,\n",
        "            3.4797e-05, 8.2473e-05, 6.9906e-06, 1.2266e-06, 1.7265e-06, 6.8976e-06,\n",
        "            1.8808e-07, 1.3948e-08, 9.6990e-07, 1.2239e-08, 7.7302e-11, 3.6880e-06,\n",
        "            1.1324e-09, 6.2820e-09, 1.3344e-08, 8.1074e-09, 2.3544e-09, 1.7203e-03],\n",
        "           [9.8423e-01, 1.9530e-02, 1.3152e-02, 1.2624e-03, 1.5393e-02, 4.1074e-04,\n",
        "            2.3607e-03, 1.1465e-02, 1.7338e-03, 7.1125e-04, 7.0556e-03, 4.0425e-03,\n",
        "            2.1563e-05, 5.4140e-03, 9.5516e-05, 3.4767e-04, 1.4649e-03, 1.9927e-02,\n",
        "            1.2931e-03, 5.7071e-02, 2.3024e-04, 1.6530e-04, 1.0594e-03, 4.7153e-02,\n",
        "            4.8321e-04, 1.5277e-04, 2.3460e-03, 1.9825e-04, 1.6919e-04, 2.4027e-05,\n",
        "            1.6913e-04, 2.0003e-03, 3.4573e-04, 2.7417e-05, 3.5226e-04, 1.4561e-04,\n",
        "            9.9872e-03, 4.4125e-04, 4.3167e-04, 3.8642e-04, 4.3470e-04, 2.6438e-05,\n",
        "            1.1190e-04, 1.2822e-03, 3.2346e-05, 9.0108e-04, 6.0608e-04, 1.3279e-04,\n",
        "            4.5029e-05, 6.0684e-04, 8.0180e-06, 2.7864e-06, 2.7088e-04, 1.6559e-04,\n",
        "            1.1650e-04, 9.6356e-06, 1.4058e-04, 1.0330e-04, 2.0023e-04, 3.3673e-03,\n",
        "            2.4178e-06, 1.7928e-04, 9.9446e-05, 4.7380e-04, 1.0047e-03, 1.9098e-05,\n",
        "            1.0675e-04, 1.7713e-05, 8.4957e-05, 1.5299e-04, 3.7166e-04, 6.5652e-04,\n",
        "            2.8207e-03, 1.8610e-04, 8.9772e-07, 1.6744e-05, 8.1253e-06, 7.6791e-06,\n",
        "            1.4735e-05, 1.2607e-07, 9.8291e-09, 2.1045e-08, 1.1378e-09, 1.8577e-04,\n",
        "            8.3176e-06, 1.1085e-04, 4.1068e-09, 1.5166e-07, 1.5045e-09, 4.9642e-05],\n",
        "           [9.6699e-01, 5.3879e-03, 2.0219e-02, 1.5281e-03, 3.3274e-02, 8.8114e-04,\n",
        "            7.8306e-03, 1.7274e-02, 3.0681e-03, 1.6059e-03, 2.1109e-03, 2.7159e-03,\n",
        "            3.6074e-05, 1.3162e-02, 5.9139e-04, 3.0474e-04, 3.1365e-03, 1.8260e-01,\n",
        "            1.9695e-03, 2.4823e-02, 6.1541e-04, 4.0010e-04, 5.9885e-04, 1.4600e-02,\n",
        "            3.2946e-04, 3.4928e-04, 3.0588e-03, 7.7209e-04, 2.1707e-04, 2.3282e-05,\n",
        "            2.2498e-04, 1.1159e-03, 5.4441e-04, 5.9624e-05, 4.4081e-04, 1.5892e-03,\n",
        "            8.2352e-04, 5.9437e-04, 1.8300e-04, 2.6643e-04, 3.7011e-04, 3.8374e-05,\n",
        "            1.7053e-05, 8.3276e-04, 2.1888e-04, 9.5403e-04, 3.5491e-04, 1.3456e-03,\n",
        "            2.7192e-05, 2.0051e-03, 5.9136e-06, 4.1776e-06, 3.3822e-04, 6.2479e-05,\n",
        "            3.0947e-05, 7.1259e-04, 2.1575e-04, 5.6121e-05, 3.8857e-04, 3.7013e-03,\n",
        "            4.1335e-06, 2.9276e-04, 4.6872e-05, 1.5099e-04, 1.9869e-04, 4.9768e-05,\n",
        "            1.0039e-04, 5.2907e-05, 8.4045e-04, 3.4089e-05, 2.1133e-04, 1.5783e-04,\n",
        "            1.8705e-03, 6.1776e-04, 1.8951e-06, 3.3222e-06, 6.0935e-06, 1.3011e-05,\n",
        "            1.1266e-05, 8.0061e-08, 1.1408e-06, 1.1136e-06, 1.0034e-09, 2.4786e-06,\n",
        "            3.0881e-08, 5.9695e-06, 6.8997e-10, 1.3387e-06, 2.3720e-08, 8.3725e-06],\n",
        "           [9.8598e-01, 3.6963e-03, 5.6586e-03, 6.2305e-04, 8.5198e-03, 1.4766e-04,\n",
        "            5.2206e-03, 1.4932e-02, 1.5462e-03, 7.0245e-04, 1.3289e-03, 4.4176e-03,\n",
        "            7.1583e-06, 1.9251e-03, 5.0921e-05, 9.2474e-05, 1.3261e-03, 8.7419e-02,\n",
        "            4.4766e-04, 6.0020e-03, 8.3478e-05, 7.3486e-05, 2.3948e-04, 2.5541e-02,\n",
        "            3.7875e-05, 3.4430e-05, 6.4716e-04, 1.6136e-04, 4.7222e-05, 3.7139e-06,\n",
        "            4.2425e-05, 5.2191e-04, 8.6869e-05, 3.2921e-06, 7.0012e-05, 1.9657e-04,\n",
        "            3.4602e-04, 1.6294e-04, 3.1998e-04, 1.9628e-04, 1.4407e-04, 4.5677e-06,\n",
        "            9.5733e-06, 2.0415e-04, 1.6876e-05, 4.3998e-04, 8.7973e-04, 1.4869e-04,\n",
        "            3.0086e-06, 6.9990e-04, 2.8807e-06, 9.3176e-07, 1.5284e-04, 9.5297e-06,\n",
        "            6.3378e-06, 4.0115e-05, 9.1526e-06, 9.2230e-06, 3.2742e-04, 3.2499e-03,\n",
        "            1.0487e-06, 5.8278e-05, 7.0871e-05, 4.5794e-05, 5.1379e-05, 1.2944e-05,\n",
        "            1.9968e-06, 2.0584e-05, 4.6729e-05, 8.7316e-05, 2.5812e-04, 3.7704e-05,\n",
        "            9.1997e-05, 4.1599e-06, 4.4364e-07, 1.7032e-06, 4.4097e-07, 4.5084e-06,\n",
        "            6.4815e-07, 7.3309e-09, 3.1487e-08, 1.9152e-09, 2.8069e-12, 8.7355e-08,\n",
        "            7.3058e-10, 6.3019e-06, 1.1123e-09, 3.8013e-07, 2.2221e-10, 2.9787e-05],\n",
        "           [9.4669e-01, 1.5969e-02, 1.3717e-02, 9.3854e-04, 2.9763e-02, 1.1259e-03,\n",
        "            7.8245e-03, 1.8702e-02, 2.9702e-03, 2.3816e-03, 1.5943e-02, 2.8683e-03,\n",
        "            5.4046e-05, 1.8809e-02, 2.0942e-04, 2.4768e-04, 1.0313e-02, 1.6350e-01,\n",
        "            2.2486e-03, 1.8140e-02, 3.6275e-04, 1.6921e-03, 1.6247e-03, 1.8667e-02,\n",
        "            4.4128e-04, 4.2982e-04, 1.5103e-03, 1.7267e-03, 2.9398e-04, 1.7368e-05,\n",
        "            3.8838e-04, 1.7687e-03, 1.3589e-03, 6.6166e-05, 1.4134e-03, 3.4823e-03,\n",
        "            6.6051e-04, 2.1436e-04, 2.1989e-04, 2.3734e-03, 4.1401e-04, 1.8782e-05,\n",
        "            1.8460e-04, 6.2177e-04, 1.8380e-04, 3.4200e-03, 3.2379e-04, 4.5642e-03,\n",
        "            4.4852e-05, 3.5136e-03, 9.7835e-06, 2.5080e-06, 1.2481e-04, 7.5477e-05,\n",
        "            1.3312e-04, 1.1040e-04, 4.9188e-04, 1.9554e-03, 2.4881e-04, 7.8624e-03,\n",
        "            1.0139e-05, 9.6893e-04, 1.9062e-05, 1.2787e-04, 1.5320e-04, 4.0729e-05,\n",
        "            4.0834e-04, 1.9660e-04, 9.7734e-04, 3.1829e-04, 8.8333e-05, 3.5786e-04,\n",
        "            7.8255e-05, 2.4137e-03, 2.3758e-06, 8.1525e-06, 3.4081e-06, 1.0403e-04,\n",
        "            1.0914e-05, 2.3831e-07, 2.5977e-07, 1.7075e-08, 1.2008e-09, 6.8195e-05,\n",
        "            1.7521e-05, 4.0347e-08, 1.8639e-08, 5.0557e-08, 6.5490e-09, 4.8979e-03],\n",
        "           [9.8566e-01, 5.2592e-03, 1.1663e-02, 4.2809e-04, 8.1834e-03, 2.1638e-04,\n",
        "            3.8347e-03, 6.6723e-03, 1.9150e-03, 1.9844e-03, 3.9992e-03, 1.4844e-02,\n",
        "            8.2308e-06, 1.5718e-03, 5.6638e-05, 7.4718e-05, 6.3743e-04, 3.2922e-02,\n",
        "            7.0767e-04, 3.3718e-02, 2.5485e-04, 7.2841e-05, 6.5401e-04, 2.4803e-02,\n",
        "            6.6798e-05, 9.4472e-05, 7.6679e-04, 2.0707e-04, 8.5915e-05, 6.6945e-06,\n",
        "            1.3393e-04, 1.1385e-03, 1.1214e-04, 1.6279e-05, 1.2970e-04, 8.3153e-05,\n",
        "            2.0590e-03, 2.1339e-04, 4.2193e-04, 1.3439e-04, 2.4448e-04, 4.6033e-06,\n",
        "            1.2043e-05, 8.1352e-04, 2.9067e-05, 4.3606e-04, 3.3115e-03, 9.8422e-05,\n",
        "            6.6416e-06, 3.2543e-04, 1.8336e-06, 6.1130e-07, 5.6328e-04, 1.0534e-04,\n",
        "            6.3215e-06, 6.8739e-06, 5.5629e-05, 1.2270e-05, 6.0565e-05, 3.0538e-03,\n",
        "            6.9864e-07, 1.6010e-05, 6.2150e-05, 1.6775e-04, 2.1542e-04, 7.2062e-06,\n",
        "            1.5974e-05, 7.7388e-06, 1.1528e-04, 1.5186e-04, 1.4417e-04, 1.0833e-03,\n",
        "            7.2898e-04, 3.5720e-05, 3.1026e-07, 7.3415e-07, 5.9272e-07, 2.4826e-06,\n",
        "            2.7875e-06, 3.0702e-08, 2.4409e-07, 2.0546e-08, 5.0713e-12, 4.0821e-07,\n",
        "            1.3123e-07, 3.1717e-05, 3.6242e-10, 2.8738e-08, 1.7544e-09, 1.7337e-05],\n",
        "           [9.0465e-01, 5.2198e-02, 1.9440e-02, 1.6560e-03, 2.9360e-02, 2.2583e-03,\n",
        "            1.7080e-02, 6.0776e-03, 6.9196e-03, 6.3609e-03, 1.4683e-02, 7.5297e-02,\n",
        "            3.8913e-04, 2.3419e-03, 4.0856e-04, 1.1596e-03, 3.9206e-03, 2.3891e-02,\n",
        "            6.6942e-03, 2.7823e-02, 1.0498e-03, 4.7654e-04, 7.1675e-03, 9.3247e-02,\n",
        "            3.4518e-04, 5.9186e-04, 1.5644e-03, 1.8036e-03, 4.3881e-04, 4.8648e-04,\n",
        "            5.1345e-04, 1.0881e-03, 5.9874e-04, 2.2604e-04, 9.1103e-04, 3.8574e-04,\n",
        "            8.1492e-03, 1.5983e-03, 8.7726e-03, 2.5081e-03, 9.7682e-04, 3.4232e-04,\n",
        "            3.3894e-04, 1.1799e-02, 1.6564e-04, 8.2879e-04, 1.7003e-02, 9.3757e-04,\n",
        "            3.2239e-04, 3.8824e-04, 4.7283e-05, 6.1959e-05, 1.2831e-03, 1.1273e-03,\n",
        "            7.1482e-05, 1.1784e-04, 6.2650e-04, 1.4614e-04, 8.2562e-04, 2.0783e-03,\n",
        "            4.7264e-05, 6.2839e-04, 1.6831e-03, 1.6432e-04, 6.2594e-04, 6.3637e-05,\n",
        "            3.7202e-05, 3.8471e-05, 6.6085e-04, 1.3628e-02, 1.2272e-03, 3.1521e-04,\n",
        "            7.1920e-03, 2.6911e-04, 1.1955e-05, 1.0721e-04, 1.2813e-05, 2.4951e-05,\n",
        "            1.5260e-05, 4.1339e-06, 1.9896e-04, 1.3062e-06, 8.8286e-10, 6.3489e-07,\n",
        "            6.5136e-08, 4.7242e-04, 2.3174e-08, 1.3460e-04, 7.7047e-07, 7.1415e-06],\n",
        "           [9.7157e-01, 1.4559e-02, 1.3301e-02, 1.6095e-03, 2.6458e-02, 7.0683e-04,\n",
        "            1.4899e-02, 3.1804e-02, 2.9666e-03, 1.2287e-03, 1.6909e-02, 8.0889e-03,\n",
        "            7.5353e-05, 8.6553e-03, 4.2494e-04, 3.0119e-04, 5.1992e-03, 1.0943e-01,\n",
        "            6.7168e-03, 1.2426e-02, 1.2368e-03, 1.3626e-03, 7.6887e-04, 1.2717e-01,\n",
        "            4.2596e-04, 3.5373e-04, 3.4445e-03, 7.4356e-04, 5.5620e-04, 6.6020e-05,\n",
        "            1.3829e-04, 2.2389e-03, 3.5262e-04, 6.6041e-05, 3.8085e-03, 1.8228e-03,\n",
        "            6.8779e-03, 8.6109e-04, 7.6106e-04, 1.6828e-03, 8.1977e-04, 1.2998e-04,\n",
        "            2.6488e-04, 2.5762e-03, 1.3669e-04, 2.6402e-03, 2.1932e-03, 1.4727e-03,\n",
        "            1.5087e-04, 8.9510e-04, 1.0426e-05, 2.4319e-05, 2.5650e-04, 2.6112e-05,\n",
        "            2.3736e-04, 1.1665e-04, 8.4462e-04, 1.5341e-03, 7.9611e-04, 3.3479e-03,\n",
        "            1.4132e-05, 2.8185e-04, 6.6610e-04, 1.9117e-04, 2.7230e-04, 1.5030e-04,\n",
        "            8.0376e-04, 3.7865e-05, 2.5404e-04, 2.7322e-04, 6.7235e-04, 3.7713e-05,\n",
        "            1.4713e-03, 2.8991e-04, 2.5387e-06, 2.9492e-05, 7.6138e-05, 7.7035e-05,\n",
        "            1.2879e-05, 1.0991e-06, 7.1672e-08, 1.3618e-07, 8.3295e-09, 2.4436e-05,\n",
        "            1.9391e-06, 8.1152e-05, 3.8273e-08, 3.8523e-05, 3.9162e-08, 8.1332e-05]],\n",
        "   [[9.9588e-01, 2.3390e-03, 2.2199e-03, 3.7238e-05, 6.3291e-03, 9.8143e-04,\n",
        "            1.8453e-03, 5.1647e-03, 5.8960e-04, 2.4653e-04, 2.3658e-03, 1.0801e-02,\n",
        "            1.2801e-05, 5.6695e-03, 2.2348e-05, 1.1380e-06, 3.2061e-04, 1.6561e-04,\n",
        "            7.2345e-05, 3.7950e-03, 1.9761e-04, 1.0559e-06, 1.0919e-06, 3.4084e-03,\n",
        "            9.2692e-07, 2.5322e-06, 2.3525e-07, 8.0215e-06, 2.6101e-05, 1.8874e-05,\n",
        "            2.2272e-07, 1.7287e-06, 9.1725e-08, 8.9510e-08, 5.5087e-08, 1.9176e-09,\n",
        "            2.2664e-03, 6.3557e-07, 1.6434e-05, 5.1960e-07, 1.5684e-05, 1.3739e-07,\n",
        "            7.7095e-06, 1.2741e-04, 7.7055e-05, 4.2096e-04, 2.0622e-02, 2.2073e-08,\n",
        "            7.1547e-07, 3.2050e-06, 1.9807e-04, 1.1096e-04, 1.1728e-03, 9.6705e-05,\n",
        "            2.1716e-04, 1.1105e-06, 8.6633e-07, 4.3099e-08, 8.0480e-06, 1.4380e-02,\n",
        "            6.0298e-09, 2.7838e-06, 1.0482e-02, 1.2181e-04, 4.4168e-04, 5.0553e-05,\n",
        "            1.3737e-07, 1.0775e-06, 5.7808e-07, 2.8296e-02, 2.0488e-03, 2.0671e-04,\n",
        "            9.5544e-04, 8.2062e-06, 4.7637e-07, 1.6726e-05, 2.4198e-03, 4.9513e-07,\n",
        "            1.7526e-05, 4.1272e-07],\n",
        "           [1.0000e+00, 1.5790e-06, 1.0343e-06, 3.3592e-08, 1.1915e-04, 3.1194e-07,\n",
        "            6.1787e-05, 4.9264e-05, 6.8516e-08, 4.2586e-08, 1.8073e-07, 7.3177e-05,\n",
        "            2.3955e-09, 6.3154e-06, 7.2798e-07, 2.0381e-09, 2.8211e-07, 7.3340e-06,\n",
        "            4.0362e-06, 1.3023e-06, 2.1524e-07, 2.4518e-10, 2.6250e-07, 9.5452e-06,\n",
        "            3.4235e-09, 1.2552e-08, 1.3603e-10, 4.6024e-07, 9.9055e-05, 2.4018e-09,\n",
        "            1.1834e-10, 2.5395e-06, 5.3649e-10, 1.2280e-05, 7.8908e-09, 1.8357e-10,\n",
        "            2.6017e-08, 5.1994e-08, 3.2749e-09, 4.4411e-04, 2.9745e-05, 7.2476e-07,\n",
        "            6.5132e-10, 4.1345e-08, 1.4918e-08, 4.7502e-03, 2.9501e-05, 7.2420e-09,\n",
        "            2.0497e-06, 5.4684e-07, 1.8447e-06, 3.8423e-08, 8.2077e-05, 4.7367e-08,\n",
        "            1.2912e-07, 4.9301e-07, 4.9047e-08, 3.3877e-09, 8.1491e-04, 8.7336e-04,\n",
        "            2.4615e-05, 3.6916e-05, 2.2374e-02, 5.2254e-06, 3.2485e-05, 1.2703e-07,\n",
        "            2.5641e-07, 2.6493e-06, 3.0835e-05, 2.0359e-07, 1.0997e-05, 4.0785e-05,\n",
        "            3.0943e-05, 6.0856e-08, 3.0227e-05, 3.7559e-05, 1.6184e-06, 2.2626e-07,\n",
        "            1.7525e-06, 3.6540e-06],\n",
        "           [1.0000e+00, 4.2556e-07, 4.6050e-07, 5.1574e-09, 4.6189e-05, 1.7922e-07,\n",
        "            2.4283e-06, 1.3648e-06, 1.3391e-07, 3.1818e-07, 1.5268e-07, 7.1951e-07,\n",
        "            1.7179e-08, 1.2489e-05, 1.8463e-09, 7.3837e-12, 7.9665e-09, 1.0529e-05,\n",
        "            1.3605e-10, 2.6523e-05, 3.5432e-11, 1.1684e-13, 1.4428e-07, 5.5376e-07,\n",
        "            3.4624e-12, 3.3754e-10, 1.5038e-11, 3.8027e-07, 4.3051e-08, 1.4756e-12,\n",
        "            4.4288e-09, 6.2904e-10, 1.5751e-10, 1.2598e-09, 5.5469e-13, 1.0022e-09,\n",
        "            1.8858e-10, 2.0268e-06, 4.0189e-09, 1.9199e-07, 7.0115e-08, 4.8351e-10,\n",
        "            6.5989e-10, 8.2777e-10, 8.1299e-11, 1.2793e-04, 1.3538e-08, 4.8475e-11,\n",
        "            6.9962e-08, 1.4866e-08, 1.1261e-08, 5.4147e-12, 1.3615e-07, 1.0140e-09,\n",
        "            3.8502e-11, 1.9754e-11, 2.5644e-09, 1.1931e-10, 1.4152e-06, 1.4706e-05,\n",
        "            5.8410e-10, 2.6341e-04, 4.1391e-06, 6.0933e-06, 8.9961e-07, 5.2628e-07,\n",
        "            1.4639e-08, 4.6956e-08, 7.2416e-06, 8.3190e-07, 2.1020e-04, 1.1892e-04,\n",
        "            1.0342e-05, 9.9328e-06, 1.8637e-05, 3.9227e-06, 2.6172e-08, 5.3768e-09,\n",
        "            9.7627e-09, 2.3188e-09],\n",
        "           [1.0000e+00, 3.3746e-07, 4.2053e-06, 1.7141e-08, 1.4401e-04, 1.1512e-06,\n",
        "            8.1250e-07, 2.7447e-06, 7.0187e-07, 8.7920e-06, 2.9803e-08, 9.6664e-06,\n",
        "            1.2860e-09, 1.0632e-06, 9.9578e-09, 1.7387e-11, 8.1297e-09, 5.8390e-08,\n",
        "            5.5432e-10, 3.6173e-06, 7.9785e-10, 1.1908e-10, 1.1160e-06, 4.3782e-06,\n",
        "            1.7298e-10, 3.7847e-09, 2.5745e-11, 2.4709e-08, 3.3741e-06, 1.6492e-10,\n",
        "            2.9150e-07, 3.9220e-08, 6.9260e-10, 2.8664e-10, 2.5997e-11, 1.5436e-11,\n",
        "            3.7267e-06, 1.7174e-06, 4.1739e-09, 9.2223e-07, 3.0226e-08, 7.4661e-10,\n",
        "            6.3543e-10, 3.3990e-07, 3.2651e-09, 1.7232e-07, 2.0447e-07, 1.2310e-10,\n",
        "            1.5328e-07, 6.3746e-10, 1.0002e-05, 7.6673e-11, 3.5194e-07, 1.8699e-07,\n",
        "            5.2315e-10, 1.2339e-10, 2.8807e-06, 7.0202e-10, 1.3076e-05, 1.4312e-06,\n",
        "            2.1189e-10, 2.2365e-05, 2.2081e-05, 2.5274e-05, 1.7043e-03, 2.8199e-08,\n",
        "            6.9348e-10, 1.2698e-08, 2.1263e-06, 2.7413e-06, 1.3112e-04, 1.2110e-03,\n",
        "            9.6432e-04, 1.2563e-08, 8.0824e-07, 2.2054e-05, 8.8213e-08, 9.2619e-08,\n",
        "            5.7640e-07, 6.3655e-09],\n",
        "           [1.0000e+00, 1.1420e-06, 2.2119e-05, 1.0107e-07, 6.3365e-05, 4.2046e-06,\n",
        "            7.4724e-05, 1.0581e-04, 2.7766e-06, 6.4663e-07, 9.6705e-07, 1.6672e-08,\n",
        "            1.0297e-08, 1.6618e-06, 2.2108e-08, 2.4181e-10, 1.6769e-08, 1.1526e-05,\n",
        "            3.1006e-08, 5.6049e-05, 2.1548e-08, 6.5086e-11, 7.2454e-08, 1.6885e-06,\n",
        "            5.7630e-10, 3.6295e-09, 1.1662e-09, 4.6836e-07, 2.8146e-05, 1.5371e-11,\n",
        "            3.6148e-08, 3.9928e-07, 2.9793e-09, 2.9493e-08, 5.6337e-07, 4.7364e-08,\n",
        "            9.6681e-07, 4.5739e-07, 4.6346e-09, 1.1216e-06, 1.9842e-06, 4.4128e-07,\n",
        "            3.1141e-08, 2.3461e-06, 2.7500e-08, 8.9916e-06, 9.3410e-08, 1.5924e-08,\n",
        "            2.6245e-06, 1.6182e-06, 2.5298e-08, 3.0047e-10, 6.0900e-06, 5.2467e-07,\n",
        "            7.8472e-08, 1.7994e-05, 4.4129e-10, 3.1054e-09, 2.9578e-04, 4.0481e-06,\n",
        "            6.1538e-08, 8.0008e-05, 2.4193e-05, 1.2507e-05, 1.7919e-05, 4.5072e-05,\n",
        "            8.6750e-07, 4.4945e-08, 1.6894e-05, 6.5167e-07, 2.6490e-05, 2.5445e-05,\n",
        "            7.7331e-03, 2.4881e-04, 5.1734e-06, 1.4517e-06, 1.5910e-06, 1.6005e-07,\n",
        "            3.1835e-07, 1.5074e-08],\n",
        "           [1.0000e+00, 2.6018e-06, 1.4774e-06, 2.0996e-08, 9.7799e-07, 2.3837e-07,\n",
        "            6.7930e-07, 8.3132e-06, 8.9151e-07, 4.4883e-07, 9.1584e-09, 4.5765e-07,\n",
        "            7.7409e-08, 4.1808e-06, 4.2837e-08, 2.0405e-10, 6.5086e-08, 8.5110e-05,\n",
        "            1.0626e-08, 8.0593e-06, 1.8694e-10, 1.6572e-13, 3.2545e-10, 6.2562e-06,\n",
        "            5.6829e-11, 4.3702e-10, 6.3919e-10, 3.8822e-08, 8.2933e-09, 1.2296e-10,\n",
        "            1.1702e-08, 1.6157e-08, 2.3383e-10, 8.1281e-11, 5.2455e-13, 6.9098e-10,\n",
        "            1.8402e-09, 5.6387e-07, 2.8242e-05, 3.0506e-08, 1.6458e-06, 7.7414e-07,\n",
        "            1.6144e-09, 1.9215e-07, 6.3592e-08, 5.1262e-06, 1.9849e-06, 5.6545e-09,\n",
        "            4.6426e-08, 2.0279e-06, 1.0733e-07, 6.4934e-10, 7.6699e-06, 1.5700e-07,\n",
        "            7.3539e-10, 3.4185e-08, 1.1789e-10, 8.1187e-11, 7.5938e-04, 1.0696e-04,\n",
        "            6.0916e-10, 3.1725e-06, 8.5104e-05, 1.3628e-06, 3.0997e-05, 1.6310e-06,\n",
        "            3.2725e-10, 2.3277e-09, 2.3063e-07, 1.8812e-06, 9.1048e-04, 6.6911e-06,\n",
        "            4.1260e-05, 2.2835e-07, 1.0177e-08, 3.2675e-06, 8.4826e-09, 9.2159e-08,\n",
        "            4.8613e-09, 1.3939e-09],\n",
        "           [1.0000e+00, 5.9124e-05, 1.2201e-06, 4.6669e-08, 1.7909e-04, 3.0240e-07,\n",
        "            3.3339e-05, 1.5705e-06, 3.7828e-07, 1.2375e-05, 2.5564e-05, 3.6742e-06,\n",
        "            1.4585e-07, 1.8926e-05, 3.6501e-09, 9.0818e-10, 5.4474e-06, 1.8664e-05,\n",
        "            4.8867e-09, 2.4893e-06, 2.2676e-09, 2.0188e-10, 1.4179e-06, 2.7424e-05,\n",
        "            6.0779e-09, 1.0853e-07, 4.4220e-09, 1.1840e-05, 1.7391e-06, 7.7223e-10,\n",
        "            8.5637e-08, 3.5662e-09, 1.0632e-08, 2.9766e-06, 1.9224e-10, 8.8833e-08,\n",
        "            6.6804e-09, 1.8734e-07, 1.4250e-08, 1.7073e-04, 7.5390e-06, 1.2706e-08,\n",
        "            3.7459e-09, 1.0592e-07, 8.1055e-09, 5.2721e-05, 1.3812e-07, 1.5672e-09,\n",
        "            1.6761e-06, 5.5332e-07, 1.4876e-07, 2.2930e-10, 7.7118e-07, 2.3047e-08,\n",
        "            1.1675e-08, 2.8615e-08, 5.6049e-08, 8.1943e-07, 4.9237e-05, 1.5074e-05,\n",
        "            9.5022e-09, 2.6753e-04, 1.1968e-05, 2.7166e-05, 4.1639e-05, 2.5793e-06,\n",
        "            1.3116e-07, 1.3323e-07, 9.8397e-06, 1.7221e-06, 4.5397e-05, 5.9755e-04,\n",
        "            7.3872e-05, 1.3383e-04, 7.9239e-06, 4.1756e-06, 2.1117e-08, 4.6008e-08,\n",
        "            8.2303e-07, 1.1696e-08],\n",
        "           [1.0000e+00, 2.8388e-08, 2.1861e-07, 1.3620e-09, 3.4180e-05, 2.5489e-08,\n",
        "            8.7798e-09, 3.8969e-07, 9.3255e-08, 1.6967e-06, 3.8718e-08, 1.4816e-07,\n",
        "            8.2539e-10, 7.8882e-07, 3.2433e-10, 4.8749e-12, 5.2194e-10, 5.0821e-10,\n",
        "            9.4965e-12, 8.1547e-07, 1.8700e-11, 2.0879e-13, 6.5520e-09, 2.3216e-06,\n",
        "            1.2558e-12, 4.2806e-11, 1.1186e-11, 2.4991e-09, 9.5531e-09, 4.2284e-12,\n",
        "            1.8261e-08, 4.1892e-09, 1.4273e-11, 9.6973e-09, 3.1219e-14, 6.6913e-12,\n",
        "            8.4735e-10, 7.9987e-10, 6.0318e-08, 3.2332e-09, 8.2372e-05, 5.1866e-09,\n",
        "            2.3439e-11, 3.3587e-09, 3.5282e-09, 3.4389e-08, 3.9837e-06, 7.7442e-12,\n",
        "            2.3888e-08, 2.6841e-08, 3.1544e-09, 2.3036e-11, 2.3200e-06, 3.2891e-07,\n",
        "            2.1902e-10, 4.8172e-11, 5.8608e-09, 3.9186e-13, 3.4354e-05, 7.5397e-06,\n",
        "            7.2161e-11, 1.2118e-07, 7.5793e-05, 1.0185e-05, 3.7251e-04, 3.1170e-07,\n",
        "            2.3006e-09, 1.8277e-09, 1.7386e-07, 1.1026e-06, 4.6410e-06, 8.2880e-04,\n",
        "            7.9356e-04, 8.0709e-07, 8.4713e-09, 1.5928e-07, 2.4214e-09, 3.3737e-09,\n",
        "            7.5731e-09, 2.1023e-09],\n",
        "           [9.9996e-01, 2.8709e-06, 1.4179e-04, 4.4837e-07, 9.9528e-05, 1.6856e-05,\n",
        "            3.6115e-06, 6.2199e-05, 1.9178e-05, 2.0411e-06, 8.9425e-07, 7.2160e-05,\n",
        "            8.4731e-09, 1.1158e-06, 2.3761e-07, 2.1212e-09, 1.0621e-07, 1.1290e-07,\n",
        "            3.1852e-07, 5.8168e-05, 8.6807e-08, 4.4254e-09, 5.9383e-06, 1.2614e-04,\n",
        "            2.6027e-09, 1.1898e-07, 6.7629e-09, 9.8572e-07, 1.2356e-05, 4.5312e-08,\n",
        "            2.3920e-08, 7.3084e-08, 1.1626e-08, 1.8726e-06, 6.3578e-09, 3.6031e-07,\n",
        "            4.3588e-07, 3.3693e-04, 1.9769e-05, 1.2855e-04, 7.9590e-05, 3.2010e-05,\n",
        "            7.2860e-07, 7.1314e-06, 9.3757e-06, 9.7731e-06, 5.5818e-03, 2.0180e-06,\n",
        "            1.1682e-05, 9.7893e-06, 2.3887e-06, 8.7477e-08, 9.8487e-05, 1.2847e-05,\n",
        "            9.8425e-07, 5.0124e-07, 2.3308e-06, 1.9017e-08, 1.1507e-04, 5.7715e-04,\n",
        "            4.2202e-07, 8.4777e-04, 9.2448e-02, 6.5968e-05, 1.2528e-04, 6.3759e-06,\n",
        "            4.2197e-06, 1.9836e-07, 2.3886e-06, 1.4890e-03, 2.8430e-04, 6.9013e-05,\n",
        "            8.6944e-04, 2.9493e-05, 9.8954e-07, 9.7847e-05, 7.1304e-07, 2.3879e-07,\n",
        "            9.5480e-07, 2.7202e-07],\n",
        "           [1.0000e+00, 2.5933e-06, 2.4950e-06, 3.9233e-08, 1.2527e-04, 1.1281e-06,\n",
        "            3.1023e-06, 9.2178e-06, 1.6403e-06, 1.3988e-05, 2.2142e-05, 2.5020e-06,\n",
        "            2.3343e-08, 1.1300e-05, 1.7355e-08, 2.5440e-09, 1.4530e-06, 5.4018e-06,\n",
        "            6.2615e-07, 1.9303e-06, 5.7033e-09, 8.9038e-09, 1.3261e-06, 4.1390e-05,\n",
        "            3.1321e-09, 4.3912e-08, 1.3351e-10, 3.6484e-07, 1.7988e-05, 8.2675e-10,\n",
        "            9.3956e-10, 1.3733e-08, 5.0931e-09, 8.0614e-09, 2.1652e-09, 2.0816e-08,\n",
        "            1.1780e-06, 1.3840e-06, 1.4100e-08, 8.1499e-06, 1.1463e-05, 1.4225e-05,\n",
        "            4.6074e-07, 2.7818e-06, 6.8231e-07, 4.3677e-05, 1.9350e-06, 8.8037e-06,\n",
        "            7.3260e-06, 2.5244e-07, 1.8243e-06, 3.3143e-08, 1.8635e-05, 3.2163e-07,\n",
        "            1.4100e-07, 1.1287e-07, 1.5528e-05, 7.3741e-06, 8.5410e-04, 1.0908e-04,\n",
        "            2.9984e-09, 1.7318e-04, 5.7468e-05, 2.0781e-06, 6.5529e-04, 1.4003e-06,\n",
        "            2.7435e-07, 4.3167e-09, 2.0205e-06, 1.2966e-06, 2.9839e-04, 3.0314e-06,\n",
        "            3.0545e-03, 6.8545e-06, 1.3950e-06, 8.3435e-06, 1.4881e-06, 1.9786e-06,\n",
        "            2.6845e-07, 4.7670e-08]]]}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jICRWSARLUuD",
        "colab_type": "text"
      },
      "source": [
        "#### Analisys"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsZJSVHNFfin",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''ANALISYS:\n",
        "How same node scores are differently distributed from the ad hoc scores to the last network scores.\n",
        "The distribution analysis must be done on a logarithmic scale to be significant\n",
        "Distribuzione: punti sul grafico: \n",
        "asse x = nodo\n",
        "asse y(log) = score. Vedo che si differenziano proprio in termini di ODG quindi sarebbe interessante \n",
        "plottarli coome unti di due colori diversi e vedere come si comportanoo sul grafico. \n",
        "Intanto inizio a farlo per lo split numero 9\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYqv1p2QGYfD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5b383ab1-6afd-4825-91ae-ffb447fa9423"
      },
      "source": [
        "len(logs_analisys)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg747VOAHFqz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Last net scores over 10 selected exemplars\n",
        "# Scres over all old nodes\n",
        "# need to remove last 10 old nodes since they are produced by the same net in the 2 cases\n",
        "\n",
        "ln_split_nine_first = logs_analisys[0][9][0] # first = 1st random state\n",
        "ln_split_nine_second = logs_analisys[1][9][0] # # second = 2nd random state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g17fu2Q_HWZq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert into numpy array\n",
        "ln_split_nine_first = np.array(ln_split_nine_first)\n",
        "ln_split_nine_second = np.array(ln_split_nine_second)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2YJo1PtIJFt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove last ten nodes. Not meaningful since produced by the same net\n",
        "ln_split_nine_first = ln_split_nine_first[:, 0:-10]\n",
        "ln_split_nine_second = ln_split_nine_second[:, :-10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIGHwwslIgfk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ad hoc old nets scores over 10 selected exemplars\n",
        "# Scores over all old nodes from 0 to 80\n",
        "on_split_nine_first = logs_analisys[0][9][1]\n",
        "on_split_nine_second = logs_analisys[1][9][1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gue4hJAsJxbQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ad hoc old nets scores over 10 selected exemplars\n",
        "# Scores over all old nodes from 0 to 80\n",
        "on_split_nine_first = np.array(on_split_nine_first)\n",
        "on_split_nine_second = np.array(on_split_nine_first)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9zI9MYNKGMV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "on_random_seeds_avg = np.mean((on_split_nine_first, on_split_nine_second), axis = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eK0eMQtKyPw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ln_random_seeds_avg = np.mean((ln_split_nine_first, ln_split_nine_second), axis = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mhjDj2GQHSH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "on_images_mean = on_random_seeds_avg.mean(0)\n",
        "ln_images_mean = ln_random_seeds_avg.mean(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_wLy7f9aF6_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "e6ab503e-e73f-4ff1-c68e-b82f43457999"
      },
      "source": [
        "on_images_mean"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9.99996000e-01, 4.74067748e-07, 1.68915409e-07, 1.59078106e-05,\n",
              "       1.54497589e-06, 8.94846783e-08, 8.19395320e-08, 9.73920698e-09,\n",
              "       5.07651622e-06, 5.99073371e-06, 7.68106537e-05, 1.07396850e-06,\n",
              "       4.88770108e-06, 5.45032883e-05, 7.76093280e-07, 6.45066687e-07,\n",
              "       4.80904180e-07, 1.48368015e-07, 1.76778308e-04, 1.83218663e-05,\n",
              "       5.09219597e-05, 2.04199722e-04, 8.50381460e-07, 4.05315051e-05,\n",
              "       2.86953560e-04, 1.39862685e-05, 5.65815246e-05, 9.60939336e-06,\n",
              "       1.21603840e-05, 8.49538999e-05, 6.59140589e-06, 1.45837964e-04,\n",
              "       1.37212808e-08, 7.79799430e-09, 3.57592690e-05, 1.99746490e-07,\n",
              "       2.75325600e-06, 1.56400425e-05, 3.48471320e-03, 4.04186501e-06,\n",
              "       6.49151768e-09, 1.12618865e-06, 5.23703504e-05, 7.08472565e-04,\n",
              "       9.64336600e-06, 3.19339277e-05, 1.73286704e-06, 1.68838706e-06,\n",
              "       4.75163210e-08, 3.35318000e-06, 9.78973100e-07, 5.72819145e-03,\n",
              "       2.98230963e-06, 4.85057838e-06, 1.41581403e-05, 9.46876886e-05,\n",
              "       9.52081519e-08, 5.75062812e-04, 2.43306154e-05, 2.85409725e-05,\n",
              "       7.24742272e-06, 1.64909248e-08, 1.46882211e-05, 9.40843568e-06,\n",
              "       1.47085853e-05, 7.28929861e-07, 2.98370510e-04, 2.24521880e-07,\n",
              "       4.23193290e-03, 1.51225968e-04, 5.38985584e-06, 2.01369510e-06,\n",
              "       9.27707274e-03, 7.97191274e-07, 1.92410018e-04, 3.30430738e-07,\n",
              "       5.45635151e-05, 6.24720280e-05, 2.01443830e-06, 7.71420355e-04])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igu9J_D-aLRZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "716efd8d-fd7b-4941-fffd-8e9eedfd3442"
      },
      "source": [
        "ln_images_mean"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9.58800000e-01, 1.14788624e-02, 1.28017650e-02, 3.14299400e-03,\n",
              "       1.44152100e-02, 1.61696140e-03, 1.44313700e-02, 1.76103535e-02,\n",
              "       3.36083850e-03, 1.40260960e-02, 2.42239300e-02, 1.64266440e-02,\n",
              "       1.01222067e-02, 7.63405500e-03, 1.86699215e-03, 2.78246115e-03,\n",
              "       2.38209860e-03, 5.42230650e-02, 4.44442600e-03, 1.37699710e-02,\n",
              "       4.18494740e-03, 4.28614485e-03, 4.26385600e-03, 4.57139095e-02,\n",
              "       1.68346805e-03, 3.14604945e-04, 6.67565750e-03, 1.51063205e-03,\n",
              "       7.69365350e-04, 9.22756035e-04, 2.98290475e-03, 1.68374000e-03,\n",
              "       4.85240150e-04, 4.43546510e-04, 9.04045700e-04, 2.14338390e-03,\n",
              "       1.63847125e-02, 3.73841600e-03, 6.45954020e-02, 1.18486225e-03,\n",
              "       9.04401750e-04, 2.92819605e-04, 4.22010196e-03, 3.04306155e-03,\n",
              "       1.67172930e-03, 2.86021340e-03, 4.24374055e-03, 1.05627380e-03,\n",
              "       4.77810735e-04, 9.44174100e-04, 8.24641635e-04, 1.19002740e-03,\n",
              "       1.02296340e-03, 1.14778658e-03, 6.53365815e-04, 5.61440955e-04,\n",
              "       2.48055490e-04, 6.67743260e-04, 9.87856600e-04, 3.77007010e-03,\n",
              "       2.54453047e-04, 1.63284118e-04, 1.63621671e-03, 1.73378671e-04,\n",
              "       7.42614665e-04, 1.52745200e-04, 1.94739764e-03, 3.65420295e-04,\n",
              "       1.61086794e-03, 1.54027923e-03, 9.41527919e-04, 3.83729920e-04,\n",
              "       4.54687580e-03, 2.27520491e-04, 4.49689748e-04, 7.66790656e-05,\n",
              "       8.57889861e-05, 7.85611085e-04, 1.04022092e-04, 7.76493406e-04])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5vbpFwKYTo1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "on_images_mean_std = np.array((on_random_seeds_avg.mean(0), on_random_seeds_avg.std(0))).transpose()\n",
        "ln_images_mean_std = np.array((ln_random_seeds_avg.mean(0), ln_random_seeds_avg.std(0))).transpose()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geNwh2BGZpTi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def outputs_delta_errorbar(last_net_outputs, old_net_outputs):\n",
        "  '''\n",
        "  Args:\n",
        "  last_net_outputs (numpy array): average over all random seeds and over all images of outputs on old classes obtained\n",
        "                                  with last net logic. Outputs are related to a single split\n",
        "  old_net_outputs (numpy array): average over all random seeds and over all images of outputs on old classes obtained \n",
        "                                 with old nets logic. Outputs are related to a single split\n",
        "  '''\n",
        "  # Posso fare due cose: creare tanti plot quanto è il numero di split\n",
        "  # Comparando gli scores dei nodi presi 10 a 10\n",
        "  # Oppure comparare tutti gli scores tra tutti i nodi. Per ora\n",
        "  # implemento questa seconda opzione\n",
        "\n",
        "  fig, ax = plt.subplots()\n",
        "\n",
        "  # Set y scale to logarithmic\n",
        "  plt.yscale('log')\n",
        "\n",
        "  x = np.array(range(0, last_net_outputs.shape[0]))\n",
        "\n",
        "  # Posso fare un plot unidimensionale o usare l'indice come \n",
        "  ax.errorbar(x, last_net_outputs[:, 0],  last_net_outputs[:, 1] , color = '#450c8d', label = 'Last net', fmt='o', mew = 0.1)\n",
        "  ax.errorbar(x, old_net_outputs[:, 0],  old_net_outputs[:, 1], color = '#e1c30c' , label = 'Old nets', fmt='o', mew = 0.1)\n",
        "\n",
        "\n",
        "  ax.legend()\n",
        "\n",
        "  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_p2lUro2OUPd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def outputs_delta(last_net_outputs, old_net_outputs):\n",
        "  '''\n",
        "  Args:\n",
        "  last_net_outputs (numpy array): average over all random seeds and over all images of outputs on old classes obtained\n",
        "                                  with last net logic. Outputs are related to a single split\n",
        "  old_net_outputs (numpy array): average over all random seeds and over all images of outputs on old classes obtained \n",
        "                                 with old nets logic. Outputs are related to a single split\n",
        "  '''\n",
        "  # Posso fare due cose: creare tanti plot quanto è il numero di split\n",
        "  # Comparando gli scores dei nodi presi 10 a 10\n",
        "  # Oppure comparare tutti gli scores tra tutti i nodi. Per ora\n",
        "  # implemento questa seconda opzione\n",
        "\n",
        "  fig, ax = plt.subplots()\n",
        "\n",
        "  # Set y scale to logarithmic\n",
        "  plt.yscale('log')\n",
        "\n",
        "  x = np.array(range(0, last_net_outputs.shape[0]))\n",
        "\n",
        "  # Posso fare un plot unidimensionale o usare l'indice come \n",
        "  ax.scatter(x, last_net_outputs, color = '#450c8d', label = 'Last net', s = 10)\n",
        "  ax.scatter(x, old_net_outputs, color = '#e1c30c' , label = 'Old nets', s = 10)\n",
        "\n",
        "\n",
        "  ax.legend()\n",
        "\n",
        "  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_BErEkIZ8Gq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "9871870b-7bd3-4bc5-86ae-05d102ce9985"
      },
      "source": [
        "outputs_delta_errorbar(ln_images_mean_std, on_images_mean_std)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16GztQLzRyhG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "5c004101-6e5c-416d-a4eb-783c69a4b965"
      },
      "source": [
        "outputs_delta(ln_images_mean, on_images_mean)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0ACqN60SfGJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "''' \n",
        " Perché fa piu schifo con le vecchie reti? perché i target sono piu piccoli:\n",
        " devo renderli soft targets come fatto da Hinton\n",
        " Vedi punti in alto a sinistra? entrambe predicono correttamente la classe, ma old nets\n",
        " e' molto più precisa nella distinzione! Per rendere quest' informazione utile dobbiamo renredere più soft i targets\n",
        " Std deviation piu alta nelle old nets perché le roedizioni sono piu precise, last net policy tende a uniformare \n",
        " i risultati essendo che è meno capace a distinguere\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pW81-20BebQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "41aa4460-c372-481c-cd92-dad97d3a034e"
      },
      "source": [
        "'''\n",
        "Try to apply a temperature to outputs\n",
        "1. logits, which is iverse of sigmoid\n",
        "2. divide by T and apply logits\n",
        "3. avg over random seeds\n",
        "4. plots\n",
        "\n",
        "'''\n",
        "\n",
        "# x = ln(y/(1-y)) logits function\n",
        "\n",
        "T = 2\n",
        "\n",
        "sigmoid = nn.Sigmoid()\n",
        "\n",
        "soften_targets_first = sigmoid(torch.tensor(np.log(on_split_nine_first/(1-on_split_nine_first)))/T).numpy()\n",
        "soften_targets_second = sigmoid(torch.tensor(np.log(on_split_nine_second/(1-on_split_nine_second)))/T).numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: RuntimeWarning: divide by zero encountered in true_divide\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKGv5aoeav8P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "354c255a-2672-4026-b741-62991fef26e3"
      },
      "source": [
        "'''\n",
        "Try to apply a temperature to outputs\n",
        "1. logits, which is iverse of sigmoid\n",
        "2. divide by T and apply logits\n",
        "3. avg over random seeds\n",
        "4. plots\n",
        "\n",
        "'''\n",
        "\n",
        "# x = ln(y/(1-y)) logits function\n",
        "\n",
        "T = 2.5\n",
        "\n",
        "sigmoid = nn.Sigmoid()\n",
        "\n",
        "soften_targets_first_T4 = sigmoid(torch.tensor(np.log(on_split_nine_first/(1-on_split_nine_first)))/T).numpy()\n",
        "soften_targets_second_T4 = sigmoid(torch.tensor(np.log(on_split_nine_second/(1-on_split_nine_second)))/T).numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: RuntimeWarning: divide by zero encountered in true_divide\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHdZLL9QEgNn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "soften_targets_seeds_avg = np.mean((soften_targets_first, soften_targets_second), axis = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRKOyyica0if",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "soften_targets_seeds_avg_T4 = np.mean((soften_targets_first_T4, soften_targets_second_T4), axis = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFoHbWmfE8zY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "on_soften_targets = soften_targets_seeds_avg.mean(0)\n",
        "on_soften_targets_T4 = soften_targets_seeds_avg_T4.mean(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fy8_ys2NCzCT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def compare_targets(not_soften, soften, color1, color2, T):\n",
        "  '''\n",
        "  Args:\n",
        "  last_net_outputs (numpy array): average over all random seeds and over all images of outputs on old classes obtained\n",
        "                                  with last net logic. Outputs are related to a single split\n",
        "  old_net_outputs (numpy array): average over all random seeds and over all images of outputs on old classes obtained \n",
        "                                 with old nets logic. Outputs are related to a single split\n",
        "  '''\n",
        "  # Posso fare due cose: creare tanti plot quanto è il numero di split\n",
        "  # Comparando gli scores dei nodi presi 10 a 10\n",
        "  # Oppure comparare tutti gli scores tra tutti i nodi. Per ora\n",
        "  # implemento questa seconda opzione\n",
        "\n",
        "  fig, ax = plt.subplots()\n",
        "\n",
        "  # Set y scale to logarithmic\n",
        "  plt.yscale('log')\n",
        "\n",
        "  x = np.array(range(0, soften.shape[0]))\n",
        "\n",
        "  # Posso fare un plot unidimensionale o usare l'indice come \n",
        "  ax.scatter(x, soften, color = color2, label = 'Old Nets - T: {}'.format(T), s = 10)\n",
        "  ax.scatter(x, not_soften, color = color1, label = f'Old Nets - T: {1}', s = 10)\n",
        "\n",
        "  ax.legend()\n",
        "\n",
        "  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPepptayDkzL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "a2aad140-c6f3-41c0-fb3c-e547f4b3273c"
      },
      "source": [
        "# Compare old nets policy targets soften by T = 2 and not soften (T = 1)\n",
        "\n",
        "compare_targets(on_images_mean, on_soften_targets, '#e1c30c', '#008080', 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3df5AV5b3n8feXYeJAUIGRZNGRQAiZqxAuKvgjuhbiFY1YmogVJSa5ChZ7b2GtiZQbrZRxTa0xqYpXTaQ2oRRTWglxI2ZDCYncDRrc7BoBnesKOsrkKowxoiNocCAO+uwf58zkcDgzc/r0r6e7P68qS07PzOnvOd397ae/z9NPm3MOERHJvxFpByAiIslQwhcRKQglfBGRglDCFxEpCCV8EZGCGJl2AEM55phj3OTJk9MOQ0QkU7Zu3fqWc25C9XKvE/7kyZPZsmVL2mGIiGSKmb1aa7lKOiIiBaGELyJSEEr4IiIF4XUNX0TS0dfXR3d3NwcOHEg7FBlCS0sLbW1tNDc31/X7Svgicpju7m6OPPJIJk+ejJmlHY7U4Jyjp6eH7u5upkyZUtffqKQjIoc5cOAAra2tSvYeMzNaW1sDXYXlsoX/xHMr2fPmBsZNmM/cmUvTDkckk5Ts/Rd0G+Uu4T/x3Eom7vkGnzziIPv3/JYnnkNJX0SEHJZ09ry5gVFNBwEY1XSQPW9uSDkiEWlEd3c3l1xyCdOmTWPq1Klcd911vP/++wA88cQTXHTRRTX/bvLkybz11ls1ly9cuHDg9cMPP8xVV101ZAwdHR2sX7++8Q9R9thjjzFr1ixmzZrFmDFjaG9vZ9asWXz1q1+t+fu7du3inHPO4cQTT2T69OncfffdoWOAHCb8cRPms/+D0oXL/g9GMm7C/JQjEpGgnHNceumlfP7zn+fll1/mpZdeYt++fXzzm98M9b5bt25l+/btdf9+VAn//PPPp6Ojg46ODmbPns1Pf/pTOjo6eOCBB2r+/siRI7njjjvYvn07Tz31FCtWrAgU92Byl/DnzlzK6+O+x9a/ns/r476nco5IBm3cuJGWlhauvvpqAJqamrjzzjtZtWoVvb29h/xuT08P8+fPZ/r06VxzzTUM9RS/5cuXc9tttx22/L333mPx4sWceuqpnHTSSfzqV7/i/fff51vf+hYPPfQQs2bN4qGHHuJ3v/vdQEv9pJNO4i9/+Uu0H7xs4sSJnHzyyQAceeSRnHDCCbz22muh3zd3CR9KSf8L5z6sZC+SoLWdnVy7fj1rOztDv9e2bds45ZRTDll21FFHMWnSJHbs2HHI8ltvvZWzzjqLbdu28YUvfIGdO3cO+r5f/OIXeeaZZw57j9tuu4158+bx9NNP8/jjj3PDDTfQ19fHt7/9bS6//HI6Ojq4/PLL+f73v8+KFSvo6OjgySefZNSoUaE+55YtW7jmmmuG/J1XXnmFZ599ltNOOy3UuiCnCV9EkrW2s5NFa9awYvNmFq1ZE0nSr9emTZv48pe/DMCCBQsYN27coL/b1NTEDTfcwO23337I8g0bNvDd736XWbNmMXfuXA4cOFDzxHHmmWdy/fXX84Mf/IC9e/cycmS4cS+zZ8/m3nvvHfTn+/btY+HChdx1110cddRRodYFSvgiEoENXV309vUB0NvXx4aurlDvd+KJJ7J169ZDlr377rvs3LmTT33qU6He+ytf+QqbNm1i165dA8ucc6xZs2agzr5z505OOOGEw/72xhtv5N5772X//v2ceeaZvPjii4f8fMWKFQMlnz/96U+h4uzr62PhwoVceeWVXHrppaHeq58SvoiENn/qVEaXb+8f3dzM/KlTQ73fueeeS29v70Cn5gcffMDy5cu56qqrGD169CG/e/bZZ/Ozn/0MgF//+tfs2bNnyPdubm7m61//OnfeeefAsvPPP58f/vCHA/X/Z599FijVzyvr9F1dXXzmM5/hG9/4BnPmzDks4S9btmzgpHHsscc2+OlLJ6AlS5ZwwgkncP311zf8PtWU8EUktIvb21m9cCHL5sxh9cKFXNzeHur9zIxf/vKX/OIXv2DatGl8+tOfpqWlhe985zuH/e4tt9zCpk2bmD59Oo888giTJk0a9v2XLFnCwYMHB17ffPPN9PX1MXPmTKZPn87NN98MwDnnnMP27dsHOm3vuusuZsyYwcyZM2lubuZzn/tcqM85WA3/97//PQ8++CAbN24cuGKIYrSQDdWjnbbZs2c7PQBFJHkvvPBCzZKG+KfWtjKzrc652dW/qxa+iEhBKOGLiBSEEr6ISEEo4YuIFIQSvohIQSjhi4gUhBK+iHipyNMjAyxevJiPfexjzJgxI/T6+ynhi4h3ij49MsBVV13Fb37zm9DrrqSELyLeKfr0yFCaMmL8+PGRvqcSvohEordnHW93Lae3Z13o99L0yPFQwheR0Hp71tHTeTX7Xl9JT+fVkST9euV5euSoKeGLSGgH9m7EfbgfAPfhfg7s3Rjq/TQ9cjwSS/hm9kkzu8/MHk5qnSKSjJax87ARpfKGjRhFy9h5od6v6NMjx6WuhG9mq8xst5k9X7X8AjPrNLMdZnbjUO/hnPujc25JmGBFxE+jWxfQ2n4/YyYupbX9fka3Lgj1fkWfHhlg0aJFnHHGGXR2dtLW1sZ9990Xal1Q5/TIZnY2sA94wDk3o7ysCXgJOA/oBjYDi4Am4Paqt1jsnNtd/ruHnXOX1ROcpkcWSYemR86OINMj19Xj4JzbZGaTqxafCuxwzv2xvIKfA5c4524Hat8RUQczWwosBeo6U4uISH3C1PCPA3ZVvO4uL6vJzFrN7EfASWZ202C/55xb6Zyb7ZybPWHChBDhiYhIpXBjigJwzvUA/5TU+kQkHOccZpZ2GDKEoE8sDNPCfw04vuJ1W3mZiGRcS0sLPT09gROKJMc5R09PDy0tLXX/TZgW/mZgmplNoZTorwC+FOL9RMQTbW1tdHd38+abb6YdigyhpaWFtra2un+/roRvZquBucAxZtYN3OKcu8/MrgUeozQyZ5VzblvwkEXEN83NzUyZMiXtMCRi9Y7SWTTI8vVA+KnkREQ8trazkw1dXcyfOpWL29vTDqdhmlpBRGQIazs7WbRmDSs2b2bRmjWs7exMO6SGKeGLiAxhQ1cXvX19APT29bGhqyvliBqnhC8yiLWdnVy7fn2mW3QS3vypUxnd3AzA6OZm5k+dmnJEjatraoW0aGoFSUv/ZXxvXx+jm5tZvXBhpmu3Ek7WavihplYQKZpal/FZONAlHhe3t+di+6ukI1JDni7jRfqphS9Sw8Xt7axeuDBTl/FDyVpJQuKhGr5Izqk/oqRIJ73Bavgq6YjkXJ6GFTYqT2Ppw1DCF8k59Udk66QX53BgJXyRhKQ1rr+/P2LZnDmFLedk5aQX95WIOm1FElBZR7+/oyPxxJuXYYWNykonfNzDgdXCF0lAlkoKeXVxezv3XHiht8ke4r8SUcIXSUBWSgqN0BQU0Ym7/KZhmSIJyeOwQA359JOmVpBAgiSnPCayOOSxjq4pKLJFJR05TJCRAhrfXGw+lariLC319qzj7a7l9Pasi/y9k6SEL4cJ0sGozshi82XIZ5wNj96edfR0Xs2+11fS03l1ppO+Er4cJkirLekWnjoI/ePD6JdGGh717ksH9m7EfbgfAPfhfg7s3djwe6VNnbZSk481fHUQymCC7htBfr+/he8+3I+NGEVr+/2Mbl3Q8LqToE5bCSRIB2NSnZHqIJTBBL2xKsi+NLp1AbTfz4G9G2kZO++QZB/0vdKmkk7CsnLp5yOfOgizJkynY1b22SClpaD70ujWBYyfesdhyb6R94L0vlOVdBKU5qVfXoZO5uVzJGm4ksRQfCxXRCXKfSloCTTu71QlHQ+kdemX9jwuUcrjWPa41ep0rDfhZ6lcEVSU+1KQ90rzO1VJJ0FBL/2iuuzT0Ml0+FIKaRk7DxsxCgAbMYqWsfPq/luV0aKX5neqkk7C6r30i/Kyr573UqkkWr6VQnp71g3a6TicvOwbYb6DqMX9nQ5W0lHC99S169ezYvPmgdfL5szhngsvbPj9htrBGklOPg7b9GndUW8/CSdMP0YW6RGHGRP1Zd9QIxiClnzinnohqlJI2Lsvw4xsKWopxJcyVrV6bp4qAnXaeiruBzZUtnznT53K/R0dAy384ZJTkE6noB1UUXYwh+kcq2wRvvfGgxCwRZiVB25Eqda2A7z4DlrGzuO9Nx4caOEH6cfIEyV8j8U1IqXWgRkkOQU5QcR5MhlO0HVXCjOypV/RRhRVb7sfb9nCE6++GujkHVcJbribp+LmSz+IEn4B1UqqQeZCCdJ6DdrSDZOkw64b/nZgXtbWztQRowrfIgyietsBkV/dhUmco1sXpFK392lYtBJ+AUWRVKOceqH6II6yFBIkzkMPzGbWXfTfmPnRzkRahL60AMOo3nbAQAs/iqs7nxJnED7dy6CETz4OtiCS7B8Ictdh5UGcxnaoPjAf7m5j7oVLY1tf//d0dEsLdz31lDeJLMzxUL3tory68ylxBhHlVWtYhR+W6dt46awLOuZ/Q1eXN8MXk9wXKtfVZMYHFcdhUb6DwdZfeYKofA1k9lhNulGpqRUGkdVWg6+CXpZ/7fTTGd3c7EXrJ8mRNZXf0wfOMXLECA5++GHq30Hax0PlFULYwQU+8aUDv/AJ36fLrTwIeln+zoEDXh3ESR2Y1d/T104/nXcOHEj9O/DpeAg7uEAOV/iSDhSvhh+3NO/qjVPUcaQ1W+Nwf+vT951kCceXzx0FTa2QkjztRFHxbSrZevgSRy1hYvM9qeppao1JfWoFMzvBzH5kZg+b2T8ntd40Bb2139fb0qM21DQP1eKe6bPe79znGUcbmRqj/zMn+bkameoiyL4Shs/bN0p1JXwzW2Vmu83s+arlF5hZp5ntMLMbh3oP59wLzrl/Ar4InNl4yNkRZCcKO+9LXsU5J02Q79znuXGCxFb9mY9uaUnsc/mcVH3evlGqt9P2J8A9wAP9C8ysCVgBnAd0A5vNbC3QBNxe9feLnXO7zexi4J+BB0PGnQlBOsDSHh3hqzhHzgT5ztOeG2eo0kaQ2NLsNPepQ7ha2ts3KXXX8M1sMvCoc25G+fUZwH91zp1ffn0TgHOuOtnXeq91zrlhb13MYg2/0Q6wvNUQs8Dn7zyu8edpf2b1adUW9fcSutO2RsK/DLjAOXdN+fVXgNOcc9cO8vdzgUuBI4DnnHMrBvm9pcBSgEmTJp3y6quv1hWfD4IeTL6OjigSH7/z6v1o7ic+wfodOwZ+HuezESR51dt73UXHhJ7SI/Ubr5xzTwBP1PF7K4GVUGrhxxtVtIKUCHyaUqAeeU0SSX7n9T5xqXo/AiK9Oc3n/cwnSe3zldv7s0e/wPHvrGffu+83NC33cMKM0nkNOL7idVt5WWEF6fjxuQOrmjqU6zPUiJ/++fX3vb6Sns6rh3yoSvV+9J9mz2b1woUsmzOn7hJMUUZ8xSXJfb5ye59zzC6a7X0gnge1hGnhbwammdkUSon+CuBLkUSVUUE6fhrpwEqrla0O5eENN5NjkPn1B9uPGpv1M/7J2NJ6Vmycx0OS+3zl9v5s20Rs3/bYpuWuK+Gb2WpgLnCMmXUDtzjn7jOza4HHKI3MWeWc2xZpdCkIuxPVe7kcdFRAmk8T8nl0hS+GSxBBn7gUpuySZLIK+2SwRsV9Ukt6n6/c3r09x8V2Aq0r4TvnFg2yfD2wPtKIUpR0yyjIQR3F04TCxFmEIWthDJcgknziUpLJKoongzUi7pPacPt8nFcXcT6opfCTp1XyuXQR9mlCYamjb2j1nBSTeuJSkifotJ4Vm8RJbbB9PqsPYgEl/EP4XLqoPojh8KcJ5XUkTVb4dFJMKpa0nhWb5lWnzw3D4RRi8rSgk3VlJWnm5eEQInGI61hO++a1ehR2tswsbJwoXLt+vTdPjhJJW9zHve8Nw9Rny0xLlsa7h1GUyZ9EBtPbs463u5bT27Mu9uM+qVk8o5b7hF+URNhf0wxyc05UKg803+mGpHyqvrHtsrbuVI97X/ez3Jd0QHPWxKlyHLaNGEVrQuOwG1GU8l4Rvd21nH2vrxx4PWbiUv73waWpHOc+7GeFLenAoZdfmiYgWrXGYfuqKOW9ImoZOw8bMQpgYHhoWmUXn/ezQiT8Sj5vDJ/UW6apdaD5qijlvSIa3bqA1vb7GTNxaepXmT7vZ4Uo6VQKe7mVpXJQo7EGLdOkNZdKI7K0/SQ7qo+BtPezwg7LrKXRjeFDba5eYebYrlUPHT/1jrhDloxIO5n5xsd+rELX8Ks1WtvLUjno8Dm2b6pral7IVpmmqNIaBZKnPrCoRpdlqR+rkAm/UT7X5qqFmWPbp3potSwNAY1Lmkk3S42eoQR5PsFwstRA0lw6AWRp1siwc2wnNdFXEGlNxeubNOdy8Xm+qSCinOUzrfmEGqGEP4zqeqVPE2QNJ6k5tpOS1lS8vkkz6Wap0TOUqGf59LGBVEshO23rlaVO2iLwsXMsLeo4DS9Lo8uCSv0h5lmU5WlQ8yhLl85x8/Hh61mTlVZ5lNRpO4QsddIWxejWBYyfekfhDtS0RNm5KelTC38IealXZk1eW5RZpH6TfFHCH0bUl85KZkPTSBy/xP0IQ/VFJEsJP0FKZsML2qJUwohXnP0mWX42bFYp4SdIl8fDC9KirJUwAJ0AIhZX52aRB0WkdaWvhJ+goJfHeSn/BPkcQVqU1Qnjx1u2DDzYXS1G/+XlJq56VB4DQGpX+kr4IQUpKQRJZkmXf+I6uTTyOeptUVYnDMCrFmNeTthxKcqgiOpj4Iijz07tSl8JP4RGapD1JrMkyz9xnlzi/BzVCQMYaOEn0WIc6mSv/pr6ZOnO9UZVHwPgsBGjYusIH4rG4YcQ50RSSU7I1Mhsf748IKVy5tMkn+s73ARmWZpBUeJVfQyM+Q+LU5ucUC38EOKsQSZ5V2kjfQv1tl6Tvjs2qRbjcB2OcQ9nlOwY7BhI44pPc+mElJdhgUHqzVl6QEpcdfR65llSDV/SoideSWSyMolZ3HFGebLXyUGipMnTJDJZmcQs7o7vqMpHee7g1YnML+q0lYZkYRKzrDyJKK8dvJp4zT9K+JJbPj+qsVJWTkz1qBy9ldcTWZappCO5loU5z7NSIhtOdWlqzLHLUhtvLrUp4Yt4IAsnpuFUt+jdB+/SmoMTWZ4o4ReUOtMkarXuPcjDiSxPlPApXvLL86iQsIq2L0QpL6WpPCt8wi9i8ot7uGJWk2YR94Vawmy/sC364dad1X3LF4UfpVPEkQRxjgrJ8lC8Iu4L1dLcfsOtO8v7li8Kn/DzNCSuXnEOV4xzIra4FXFfqJbmSW+4deuEHF5iCd/M5prZk2b2IzObm9R6h5OVsdpRi+vGqaBJ06dWW1H3hUppnvSGW7dOyOHVVcM3s1XARcBu59yMiuUXAHcDTcC9zrnvDvE2DtgHtADdDUccA40kiE49HXeVdVjfHvuY5L7gYz06zY7X4datTuHw6po8zczOppSsH+hP+GbWBLwEnEcpgW8GFlFK/rdXvcVi4C3n3Idm9nHgX5xzVw63Xk2elj/VE5qNOXYZ+/60wvuJ2KKWlQno0ubjSTELQk2e5pzbZGaTqxafCuxwzv2xvIKfA5c4526ndDUwmD3AEUMEuhRYCjBp0qR6wpMM0c05Jb5d2fhIo6aiF6aGfxywq+J1d3lZTWZ2qZn9GHgQuGew33POrXTOzXbOzZ4wYUKI8MRHteqwWZiILWpFrUcH6aBXJ230EhuH75x7BHgkqfWJnxqpw+bxsr6I9eigLXY9NSx6YRL+a8DxFa/bysukQh6TVVhBOkbzfFlftMECQctYRTwpxi1MSWczMM3MppjZR4ArgLXRhJUPPg05zCpd1udHI2WsJMt9vtwPEqe6Er6ZrQb+L9BuZt1mtsQ5dxC4FngMeAH4H865bfGFmg1h5gMvwg4XVFFr3Xnk830ORWmc1TtKZ9Egy9cD6yONKMPCzAee59JFGLqsj1+SZUdfy1hFGTVV+MnTohRmyGFRdrhG+JIk8tgfo4ZGSVE6iAs/l06Uwgw5VOnCb3m95FcfSYnP5aYoqYUfoTDlB5Uu/Ob7FVijVx9FadnWw5cryTjVNbVCWjS1gvjC56kQwsaWx1JV0YWaWkEkr+pNdj5fgQW9+qj+zEVo2UqJEr4UVtAOS18TY5CyjDppi02dtlJYeemwDNLhmJfPLI1RwpfCytPIKI0Gk3qopCOF5XNdPi5F/MyNSrIzO6l1aZSOiIc0ciZdSY7KimNdGqUjkhG1OlYBnQASlOR9F0muSzX8KprATNJWnQD2/XlVLu/y9VmSfR1Jrkst/AoasiY+qB5mCeb1Xb55lGRfR5LrUsKv4Pvt81IM1QkA4K/vbNL0BwlL8r6LpNalhF8h6XlF1DGXL1Fuz8MSgEbWSAQ0SqdKUknY57lZJDjftqcaE8U22CgdddpWSeqRarrjMV982p55ncpZwlPCT0nW7njU6KWh+bQ9fTr55FVWjwfV8FPSSM98WpfpGr00PJ/uYC3KHPc6HoJTwk9RkJ75NHcyjV6qjy+zafp08omLjofGqKSTEbV2sqQuK30qV0h9kuqLSkuaZassHw9q4WdE9WW6NR2VWAunCC1GyZY0y1ZZPh40LDNDKmuWB/ZuZN/rKwd+NmbiUsZPvSPF6ESSpaGngyv05Gl52TGqa8TVLZy8fE6RevjSZ5IluU/4We5RH0qt2+/z+DlFJDq577TN85jkyo65PH9OEYlG7hN+lnvUgyjK5xSRxuW+pJPlHvUgivI5RbLA1/40jdIREYmQDxPpafI0EZEE+NyfpoQvIhIhn/vTcl/DF5FiSquO7nN/mhK+FIqvnWkSrbTvv/H1pjCVdKQw9GCQ4vC5jp6mQib8rD68QMJREigOn+voaSpcSSftS70kqXxxqKI8GET8rqOnqXAJP8sPLwiiSCe2eikJFIuvdfQ0Fa6kU5RLPZUvasv7g0FEhpJYC9/M/iNwZXmdJzrnPpvUuisVpZWn8oWIVKsr4ZvZKuAiYLdzbkbF8guAu4Em4F7n3HcHew/n3JPAk2b2eWBzqKhDKsKlXlFObCJSv3pb+D8B7gEe6F9gZk3ACuA8oBvYbGZrKSX/26v+frFzbnf5318CloSIOVFZ7vgswolNkpflY6Lo6kr4zrlNZja5avGpwA7n3B8BzOznwCXOudspXQ0cxswmAe845/4y2LrMbCmwFGDSpEn1hBebWh2fgHZ2KSwNBsi2MJ22xwG7Kl53l5cNZQlw/1C/4Jxb6Zyb7ZybPWHChBDhhVfd8bnvz6t0444UmgYDZFuio3Scc7c45/5PkusMo3pED5h2dim0ooxyy6swo3ReA46veN1WXpYbtZ4b+9d3NmnkixSWBgNkW5iEvxmYZmZTKCX6Kyh1yObKYR2f2tml4DQYILvqHZa5GpgLHGNm3cAtzrn7zOxa4DFKI3NWOee2xRapJ7Szi0hW1TtKZ9Egy9cD6yONSESGpaGR0ojCzaUjknUaGimNKtxcOiJZp6GR0iglfJGM0dBIaZRKOiIZo6GR0iglfJEM0mgxaYRKOiIiBaGELyJSEEr4IiIFoYQvIlIQSvgiIgWhhC8iqentWcfbXcv1bImEaFimiKRCU0QkTy18yTS1ELNLU0QkTwlfMqu/hahHTmaTpohInko6klm1WogqCWSHpohInhK+ZFbL2Hm898aDeuRkhmmKiGQp4YekB1GkRy1EkWCU8EPQKIP0qYUoUj912oagUQb+0agdkcEp4YegUQZ+0agdkaGppBOCash+SXrUjvpvJGuU8ENSDdkfSY7aUf+NZJESvuRGkldcugdAskgJX3IlqSsu3QMgWaSEL9IA9d9IFinhizRI/TeSNRqWKSJSEEr4IiIFoYQvIlIQSvgiIgWhhC8iUhBK+CIiBWHOubRjGJSZvQm82uCfHwO8FWE4UfI1Nl/jAn9j8zUu8Dc2X+MCf2MLGtcnnHMTqhd6nfDDMLMtzrnZacdRi6+x+RoX+Bubr3GBv7H5Ghf4G1tUcamkIyJSEEr4IiIFkeeEvzLtAIbga2y+xgX+xuZrXOBvbL7GBf7GFklcua3hi4jIofLcwhcRkQpK+CIiBZHLhG9mF5hZp5ntMLMbU4xjlZntNrPnK5aNN7N/NbOXy/8fl1Jsx5vZ42a23cy2mdl1PsRnZi1m9rSZ/Vs5rlvLy6eY2R/K2/QhM/tIknFVxNdkZs+a2aOexfWKmf0/M+swsy3lZb7sa2PN7GEze9HMXjCzM9KOzczay99V/3/vmtnX0o6rIr6vl/f/581sdfm4CL2v5S7hm1kTsAL4HHAisMjMTkwpnJ8AF1QtuxH4rXNuGvDb8us0HASWO+dOBE4HlpW/p7Tj+yswzzn398As4AIzOx34HnCnc+5TwB5gScJx9bsOeKHitS9xAZzjnJtVMV477W3Z727gN865vwP+ntL3l2pszrnO8nc1CzgF6AV+mXZcAGZ2HPCfgdnOuRlAE3AFUexrzrlc/QecATxW8fom4KYU45kMPF/xuhOYWP73RKAz7e+sHMuvgPN8ig8YDTwDnEbpLsORtbZxgvG0UUoC84BHAfMhrvK6XwGOqVqW+rYEjgb+nfIAEZ9iq4hlPvB7X+ICjgN2AeMpPaTqUeD8KPa13LXw+duX1a+7vMwXH3fOvV7+95+Bj6cZDICZTQZOAv6AB/GVyyYdwG7gX4EuYK9z7mD5V9LapncB/wX4sPy61ZO4ABywwcy2mtnS8rLUtyUwBXgTuL9cCrvXzD7qSWz9rgBWl/+delzOudeA7wM7gdeBd4CtRLCv5THhZ4YrnapTHRdrZmOANcDXnHPvVv4srficcx+40qV2G3Aq8HdJx1DNzC4CdjvntqYdyyDOcs6dTKmUuczMzq78YYr72kjgZOC/O+dOAt6jqkyS5nFQroNfDPyi+mdpxVXuN7iE0snyWOCjHF4abkgeE/5rwPEVr9vKy3zxhplNBCj/f3dagZhZM6Vk/1Pn3CO+xeec2ws8TunydayZ9T+DOY1teiZwsZm9AvycUlnnbg/iAr5bpnkAAAF7SURBVAZahTjndlOqRZ+KH9uyG+h2zv2h/PphSicAH2KD0gnyGefcG+XXPsT1D8C/O+fedM71AY9Q2v9C72t5TPibgWnlHu2PULpcW5tyTJXWAv9Y/vc/UqqdJ87MDLgPeME59y8VP0o1PjObYGZjy/8eRalf4QVKif+ytOJyzt3knGtzzk2mtE9tdM5dmXZcAGb2UTM7sv/flGrSz+PBvuac+zOwy8zay4vOBbb7EFvZIv5WzgE/4toJnG5mo8vHaf93Fn5fS6ujJOZOjwuBlyjVfr+ZYhyrKdXg+ii1dJZQqvv+FngZ+F/A+JRiO4vS5epzQEf5vwvTjg+YCTxbjut54Fvl5Z8EngZ2ULr8PiLF7ToXeNSXuMox/Fv5v239+3za27IivlnAlvI2/Z/AOB9io1Qq6QGOrliWelzlOG4FXiwfAw8CR0Sxr2lqBRGRgshjSUdERGpQwhcRKQglfBGRglDCFxEpCCV8EZGCUMIXESkIJXwRkYL4/8l+826eNqzLAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvS1DzVBbhXA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YHbSmnyGxKq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "8e8c03e4-d9c4-4934-f71e-fab7e1a18533"
      },
      "source": [
        "# Compare old nets policy targets soften by T = 2 last nets policy targets\n",
        "\n",
        "compare_targets(ln_images_mean, on_soften_targets, '#450c8d', '#008080', 2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCgSYKqobdrO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "4038c99a-4309-4d4b-fc2e-136d1225ac70"
      },
      "source": [
        "on_soften_targets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9.99371507e-01, 3.65436097e-04, 2.53972373e-04, 2.11948766e-03,\n",
              "       5.43583298e-04, 1.17955943e-04, 1.82778993e-04, 5.01304183e-05,\n",
              "       9.20311164e-04, 1.24669599e-03, 6.18139196e-03, 8.21926347e-04,\n",
              "       1.16133177e-03, 4.67244204e-03, 6.25254542e-04, 5.51964047e-04,\n",
              "       4.22341709e-04, 1.90317197e-04, 5.62379375e-03, 2.97492020e-03,\n",
              "       4.04134667e-03, 1.01184616e-02, 7.17772435e-04, 3.56993570e-03,\n",
              "       1.02657213e-02, 2.10143235e-03, 3.59309478e-03, 1.91700673e-03,\n",
              "       2.31642620e-03, 3.40925869e-03, 1.40511134e-03, 8.25348977e-03,\n",
              "       6.58416127e-05, 6.21916850e-05, 3.71531793e-03, 2.76055932e-04,\n",
              "       1.21954262e-03, 2.63573568e-03, 3.56703515e-02, 1.37933754e-03,\n",
              "       4.74161971e-05, 6.77855775e-04, 4.38557248e-03, 1.72268308e-02,\n",
              "       2.06874085e-03, 2.24480671e-03, 9.03137276e-04, 9.76245660e-04,\n",
              "       1.65608024e-04, 1.37583978e-03, 6.79590561e-04, 2.58567065e-02,\n",
              "       1.11949034e-03, 1.37778866e-03, 1.99883736e-03, 5.74996961e-03,\n",
              "       1.67047670e-04, 1.22405603e-02, 3.20093520e-03, 3.10823884e-03,\n",
              "       1.25794172e-03, 7.57119499e-05, 2.67555938e-03, 1.91321619e-03,\n",
              "       2.52913904e-03, 5.75516912e-04, 9.92801488e-03, 3.66761713e-04,\n",
              "       2.18409878e-02, 8.17443028e-03, 1.36213027e-03, 7.21917394e-04,\n",
              "       4.74319558e-02, 5.04482056e-04, 7.74006482e-03, 2.67601464e-04,\n",
              "       2.81227838e-03, 6.02807713e-03, 8.49683700e-04, 1.82630532e-02])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vm9iNzpubcPZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "0dd5c062-f415-47e1-e6a1-24db6046b5fa"
      },
      "source": [
        "# Compare old nets policy targets soften by T = 4 last nets policy targets\n",
        "\n",
        "compare_targets(ln_images_mean, on_soften_targets_T4, '#450c8d', '#008080', T)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cNGfn9_jgw7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input = torch.randn(3, 5, requires_grad=True)\n",
        "b = torch.tensor([0, 1, 0])\n",
        "ce_target = torch.tensor([2])\n",
        "\n",
        "ce = nn.CrossEntropyLoss()\n",
        "bce = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x54Heb6GkU_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ce_target = torch.tensor([2,3,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkZTdDmOklax",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "0800480e-3803-46be-f7f5-a11f1b8eb6a2"
      },
      "source": [
        ">>> target = torch.ones([[0,0,1,0,0], [0,1,0,0,0],[0,0,0,0,1]]) \n",
        ">>> pos_weight = torch.ones([5])  # All weights are equal to 1\n",
        ">>> criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        ">>> criterion(input, target)  # -log(sigmoid(1.5))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-00d243340026>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpos_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# All weights are equal to 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# -log(sigmoid(1.5))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: ones(): argument 'size' must be tuple of ints, but found element of type list at pos 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PvcEwy3lSmk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "d4148130-eb61-4d1d-a03f-f7a51f5b93db"
      },
      "source": [
        ">>> target"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_FtjBFkkeUT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5bca8417-f179-46d4-8ca4-e1dc5a702593"
      },
      "source": [
        "target"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 1, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBCMjrmrjnro",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        },
        "outputId": "e592c97b-c00d-4c77-9f47-761f5c21b65c"
      },
      "source": [
        "ce_loss = ce(input, ce_target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-057c69e88a78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mce_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mce_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    914\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 916\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2019\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2020\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2021\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlog_softmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1315\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log_softmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'log_softmax'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vsb3dRhYGg_F",
        "colab_type": "text"
      },
      "source": [
        "## iCaRL - Distillation Soften Targets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFRIiPpHHNXW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
        "from torch.backends import cudnn\n",
        "\n",
        "from math import floor\n",
        "from copy import deepcopy\n",
        "import random\n",
        "\n",
        "sigmoid = nn.Sigmoid() # Sigmoid function\n",
        "\n",
        "\n",
        "''' \n",
        "Utilizziamo targets soften perché le vecchie reti separno meglio ma troppo ==> più difficile apprendere\n",
        "avendo distanze eccesive tra:\n",
        "\n",
        "1. current net e old nets\n",
        "2. nodi di old nets: la std deviation è molto elevata, è difficile apprendere pesi che accontentino tutti\n",
        "3. Vedi Hinton\n",
        "\n",
        "Soluzione: \n",
        "Soften targets\n",
        "\n",
        "'''\n",
        "\n",
        "class Exemplars(torch.utils.data.Dataset):\n",
        "    def __init__(self, exemplars, transform=None):\n",
        "        # exemplars = [\n",
        "        #     [ex0_class0, ex1_class0, ex2_class0, ...],\n",
        "        #     [ex0_class1, ex1_class1, ex2_class1, ...],\n",
        "        #     ...\n",
        "        #     [ex0_classN, ex1_classN, ex2_classN, ...]\n",
        "        # ]\n",
        "\n",
        "        self.dataset = []\n",
        "        self.targets = []\n",
        "\n",
        "        for y, exemplar_y in enumerate(exemplars):\n",
        "            self.dataset.extend(exemplar_y)\n",
        "            self.targets.extend([y] * len(exemplar_y))\n",
        "\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        image = self.dataset[index]\n",
        "        target = self.targets[index]\n",
        "\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.targets)\n",
        "\n",
        "class iCaRLDist:\n",
        "    \"\"\"Implement iCaRL, a strategy for simultaneously learning classifiers and a\n",
        "    feature representation in the class-incremental setting.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, device, net, lr, momentum, weight_decay, milestones, gamma, num_epochs, batch_size, train_transform, test_transform, T):\n",
        "        self.device = device\n",
        "        self.net = net\n",
        "\n",
        "        # Set hyper-parameters\n",
        "        self.LR = lr\n",
        "        self.MOMENTUM = momentum\n",
        "        self.WEIGHT_DECAY = weight_decay\n",
        "        self.MILESTONES = milestones\n",
        "        self.GAMMA = gamma\n",
        "        self.NUM_EPOCHS = num_epochs\n",
        "        self.BATCH_SIZE = batch_size\n",
        "        \n",
        "        # Set transformations\n",
        "        self.train_transform = train_transform\n",
        "        self.test_transform = test_transform\n",
        "\n",
        "        # List of exemplar sets. Each set contains memory_size/num_classes exemplars\n",
        "        # with num_classes the number of classes seen until now by the network.\n",
        "        self.exemplars = []\n",
        "\n",
        "        # Initialize the copy of the old network, used to compute outputs of the\n",
        "        # previous network for the distillation loss, to None. This is useful to\n",
        "        # correctly apply the first function when training the network for the\n",
        "        # first time.\n",
        "        self.old_net = None\n",
        "        self.old_nets = []\n",
        "        self.T = T\n",
        "\n",
        "        # Maximum number of exemplars\n",
        "        self.memory_size = 2000\n",
        "    \n",
        "        # Loss function\n",
        "        self.criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "        # If True, test on the best model found (e.g., minimize loss). If False,\n",
        "        # test on the last model build (of the last epoch).\n",
        "        self.VALIDATE = False\n",
        "\n",
        "    def classify(self, batch, train_dataset=None):\n",
        "        \"\"\"Mean-of-exemplars classifier used to classify images into the set of\n",
        "        classes observed so far.\n",
        "        Args:\n",
        "            batch (torch.tensor): batch to classify\n",
        "        Returns:\n",
        "            label (int): class label assigned to the image\n",
        "        \"\"\"\n",
        "\n",
        "        batch_features = self.extract_features(batch) # (batch size, 64)\n",
        "        for i in range(batch_features.size(0)):\n",
        "            batch_features[i] = batch_features[i]/batch_features[i].norm() # Normalize sample feature representation\n",
        "        batch_features = batch_features.to(self.device)\n",
        "\n",
        "        if self.cached_means is None:\n",
        "            print(\"Computing mean of exemplars... \", end=\"\")\n",
        "\n",
        "            self.cached_means = []\n",
        "\n",
        "            # Number of known classes\n",
        "            num_classes = len(self.exemplars)\n",
        "\n",
        "            # Compute the means of classes with all the data available,\n",
        "            # including training data which contains samples belonging to\n",
        "            # the latest 10 classes. This will remove noise from the mean\n",
        "            # estimate, improving the results.\n",
        "            if train_dataset is not None:\n",
        "                train_features_list = [[] for _ in range(10)]\n",
        "\n",
        "                for train_sample, label in train_dataset:\n",
        "                    features = self.extract_features(train_sample, batch=False, transform=self.test_transform)\n",
        "                    features = features/features.norm()\n",
        "                    train_features_list[label % 10].append(features)\n",
        "\n",
        "            # Compute means of exemplars for all known classes\n",
        "            for y in range(num_classes):\n",
        "                if (train_dataset is not None) and (y in range(num_classes-10, num_classes)):\n",
        "                    features_list = train_features_list[y % 10]\n",
        "                else:\n",
        "                    features_list = []\n",
        "\n",
        "                for exemplar in self.exemplars[y]:\n",
        "                    features = self.extract_features(exemplar, batch=False, transform=self.test_transform)\n",
        "                    features = features/features.norm() # Normalize the feature representation of the exemplar\n",
        "                    features_list.append(features)\n",
        "                \n",
        "                features_list = torch.stack(features_list)\n",
        "                class_means = features_list.mean(dim=0)\n",
        "                class_means = class_means/class_means.norm() # Normalize the class means\n",
        "\n",
        "                self.cached_means.append(class_means)\n",
        "            \n",
        "            self.cached_means = torch.stack(self.cached_means).to(self.device)\n",
        "            print(\"done\")\n",
        "\n",
        "        preds = []\n",
        "        for i in range(batch_features.size(0)):\n",
        "            f_arg = torch.norm(batch_features[i] - self.cached_means, dim=1)\n",
        "            preds.append(torch.argmin(f_arg))\n",
        "        \n",
        "        return torch.stack(preds)\n",
        "    \n",
        "    def extract_features(self, sample, batch=True, transform=None):\n",
        "        \"\"\"Extract features from single sample or from batch.\n",
        "        \n",
        "        Args:\n",
        "            sample (PIL image or torch.tensor): sample(s) from which to\n",
        "                extract features\n",
        "            batch (bool): if True, sample is a torch.tensor containing a batch\n",
        "                of images with dimensions (batch_size, 3, 32, 32)\n",
        "            transform: transformations to apply to the PIL image before\n",
        "                processing\n",
        "        Returns:\n",
        "            features: torch.tensor, 1-D of dimension 64 for single samples or\n",
        "                2-D of dimension (batch_size, 64) for batch\n",
        "        \"\"\"\n",
        "\n",
        "        assert not (batch is False and transform is None), \"if a PIL image is passed to extract_features, a transform must be defined\"\n",
        "\n",
        "        self.net.train(False)\n",
        "        if self.best_net is not None: self.best_net.train(False)\n",
        "        if self.old_net is not None: \n",
        "          self.old_net.train(False)\n",
        "          for i in range(len(self.old_nets)):\n",
        "            self.old_nets[i] = self.old_nets[i].train(False)\n",
        "\n",
        "        if batch is False: # Treat sample as single PIL image\n",
        "            sample = transform(sample)\n",
        "            sample = sample.unsqueeze(0) # https://stackoverflow.com/a/59566009/6486336\n",
        "\n",
        "        sample = sample.to(self.device)\n",
        "\n",
        "        if self.VALIDATE:\n",
        "            features = self.best_net.features(sample)\n",
        "        else:\n",
        "            features = self.net.features(sample)\n",
        "\n",
        "        if batch is False:\n",
        "            features = features[0]\n",
        "\n",
        "        return features\n",
        "\n",
        "    def incremental_train(self, split, train_dataset, val_dataset):\n",
        "        \"\"\"Adjust internal knowledge based on the additional information\n",
        "        available in the new observations.\n",
        "        Args:\n",
        "            split (int): current split number, counting from zero\n",
        "            train_dataset: dataset for training the model\n",
        "            val_dataset: dataset for validating the model\n",
        "        Returns:\n",
        "            train_logs: tuple of four metrics (train_loss, train_accuracy,\n",
        "            val_loss, val_accuracy) obtained during network training\n",
        "        \"\"\"\n",
        "\n",
        "        if split is not 0:\n",
        "            # Increment the number of output nodes for the new network by 10\n",
        "            self.increment_classes(10)\n",
        "        \n",
        "        self.split = split\n",
        "\n",
        "        # Improve network parameters upon receiving new classes. Effectively\n",
        "        # train a new network starting from the current network parameters.\n",
        "        train_logs = self.update_representation(train_dataset, val_dataset)\n",
        "\n",
        "        # Compute the number of exemplars per class\n",
        "        num_classes = self.output_neurons_count()\n",
        "        m = floor(self.memory_size / num_classes)\n",
        "\n",
        "        print(f\"Target number of exemplars per class: {m}\")\n",
        "        print(f\"Target total number of exemplars: {m*num_classes}\")\n",
        "\n",
        "        # Reduce pre-existing exemplar sets in order to fit new exemplars\n",
        "        for y in range(len(self.exemplars)):\n",
        "            self.exemplars[y] = self.reduce_exemplar_set(self.exemplars[y], m)\n",
        "\n",
        "        # Construct exemplar set for new classes\n",
        "        new_exemplars = self.construct_exemplar_set_rand(train_dataset, m)\n",
        "        self.exemplars.extend(new_exemplars)\n",
        "\n",
        "        return train_logs\n",
        "\n",
        "    def update_representation(self, train_dataset, val_dataset):\n",
        "        \"\"\"Update the parameters of the network.\n",
        "        Args:\n",
        "            train_dataset: dataset for training the model\n",
        "            val_dataset: dataset for validating the model\n",
        "        Returns:\n",
        "            train_logs: tuple of four metrics (train_loss, train_accuracy,\n",
        "            val_loss, val_accuracy) obtained during network training\n",
        "        \"\"\"\n",
        "\n",
        "        # Combine the new training data with existing exemplars.\n",
        "        print(f\"Length of exemplars set: {sum([len(self.exemplars[y]) for y in range(len(self.exemplars))])}\")\n",
        "        exemplars_dataset = Exemplars(self.exemplars, self.train_transform)\n",
        "        train_dataset_with_exemplars = ConcatDataset([exemplars_dataset, train_dataset])\n",
        "\n",
        "        # Train the network on combined dataset\n",
        "        train_logs = self.train(train_dataset_with_exemplars, val_dataset) # @todo: include exemplars in validation set?\n",
        "\n",
        "        # Keep a copy of the current network in order to compute its outputs for\n",
        "        # the distillation loss while the new network is being trained.\n",
        "        self.old_net = deepcopy(self.net)\n",
        "        self.old_nets.append(self.old_net)\n",
        "\n",
        "        return train_logs\n",
        "\n",
        "    def construct_exemplar_set_rand(self, dataset, m):\n",
        "        \"\"\"Randomly sample m elements from a dataset without replacement.\n",
        "        Args:\n",
        "            dataset: dataset containing a split (samples from 10 classes) from\n",
        "                which to take exemplars\n",
        "            m (int): target number of exemplars per class\n",
        "        Returns:\n",
        "            exemplars: list of samples extracted from the dataset\n",
        "        \"\"\"\n",
        "\n",
        "        dataset.dataset.disable_transform()\n",
        "\n",
        "        samples = [[] for _ in range(10)]\n",
        "        for image, label in dataset:\n",
        "            label = label % 10 # Map labels to 0-9 range\n",
        "            samples[label].append(image)\n",
        "\n",
        "        dataset.dataset.enable_transform()\n",
        "\n",
        "        exemplars = [[] for _ in range(10)]\n",
        "\n",
        "        for y in range(10):\n",
        "            print(f\"Randomly extracting exemplars from class {y} of current split... \", end=\"\")\n",
        "\n",
        "            # Randomly choose m samples from samples[y] without replacement\n",
        "            exemplars[y] = random.sample(samples[y], m)\n",
        "\n",
        "            print(f\"Extracted {len(exemplars[y])} exemplars.\")\n",
        "\n",
        "        return exemplars\n",
        "\n",
        "    def reduce_exemplar_set(self, exemplar_set, m):\n",
        "        \"\"\"Procedure for removing exemplars from a given set.\n",
        "        Args:\n",
        "            exemplar_set (set): set of exemplars belonging to a certain class\n",
        "            m (int): target number of exemplars\n",
        "        Returns:\n",
        "            exemplar_set: reduced exemplar set\n",
        "        \"\"\"\n",
        "\n",
        "        return exemplar_set[:m]\n",
        "\n",
        "    def train(self, train_dataset, val_dataset):\n",
        "        \"\"\"Train the network for a specified number of epochs, and save\n",
        "        the best performing model on the validation set.\n",
        "        \n",
        "        Args:\n",
        "            train_dataset: dataset for training the model\n",
        "            val_dataset: dataset for validating the model\n",
        "        Returns: train_logs: tuple of four metrics (train_loss, train_accuracy,\n",
        "            val_loss, val_accuracy) obtained during network training. If\n",
        "            validation is enabled, return scores of the best epoch, otherwise\n",
        "            return scores of the last epoch.\n",
        "        \"\"\"\n",
        "\n",
        "        # Define the optimization algorithm\n",
        "\n",
        "        if self.split == 0:\n",
        "          parameters_to_optimize = self.net.parameters()\n",
        "          self.optimizer = optim.SGD(parameters_to_optimize, \n",
        "                                    lr=2,\n",
        "                                    momentum=self.MOMENTUM,\n",
        "                                    weight_decay=self.WEIGHT_DECAY)\n",
        "        else: \n",
        "          parameters_to_optimize = self.net.parameters()\n",
        "          self.optimizer = optim.SGD(parameters_to_optimize, \n",
        "                                    lr=self.LR,\n",
        "                                    momentum=self.MOMENTUM,\n",
        "                                    weight_decay=self.WEIGHT_DECAY)\n",
        "        \n",
        "        # Define the learning rate decaying policy\n",
        "        self.scheduler = optim.lr_scheduler.MultiStepLR(self.optimizer,\n",
        "                                                        milestones=self.MILESTONES,\n",
        "                                                        gamma=self.GAMMA)\n",
        "\n",
        "        # Create DataLoaders for training and validation\n",
        "        self.train_dataloader = DataLoader(train_dataset, batch_size=self.BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
        "        self.val_dataloader = DataLoader(val_dataset, batch_size=self.BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
        "\n",
        "        # Send networks to chosen device\n",
        "        self.net = self.net.to(self.device)\n",
        "        if self.old_net is not None: \n",
        "          self.old_net.train(False)\n",
        "          for i in range(len(self.old_nets)):\n",
        "            self.old_nets[i] = self.old_nets[i].train(False)\n",
        "\n",
        "        cudnn.benchmark  # Calling this optimizes runtime\n",
        "\n",
        "        self.best_val_loss = float('inf')\n",
        "        self.best_val_accuracy = 0\n",
        "        self.best_train_loss = float('inf')\n",
        "        self.best_train_accuracy = 0\n",
        "        \n",
        "        self.best_net = None\n",
        "        self.best_epoch = -1\n",
        "\n",
        "        for epoch in range(self.NUM_EPOCHS):\n",
        "            # Run an epoch (start counting form 1)\n",
        "            train_loss, train_accuracy = self.do_epoch(epoch+1)\n",
        "        \n",
        "            # Validate after each epoch \n",
        "            val_loss, val_accuracy = self.validate()    \n",
        "\n",
        "            # Validation criterion: best net is the one that minimizes the loss\n",
        "            # on the validation set.\n",
        "            if self.VALIDATE and val_loss < self.best_val_loss:\n",
        "                self.best_val_loss = val_loss\n",
        "                self.best_val_accuracy = val_accuracy\n",
        "                self.best_train_loss = train_loss\n",
        "                self.best_train_accuracy = train_accuracy\n",
        "\n",
        "                self.best_net = deepcopy(self.net)\n",
        "                self.best_epoch = epoch\n",
        "                print(\"Best model updated\")\n",
        "\n",
        "        if self.VALIDATE:\n",
        "            val_loss = self.best_val_loss\n",
        "            val_accuracy = self.best_val_accuracy\n",
        "            train_loss = self.best_train_loss\n",
        "            train_accuracy = self.best_train_accuracy\n",
        "\n",
        "            print(f\"Best model found at epoch {self.best_epoch+1}\")\n",
        "\n",
        "        return train_loss, train_accuracy, val_loss, val_accuracy\n",
        "    \n",
        "    def do_epoch(self, current_epoch):\n",
        "        \"\"\"Trains model for one epoch.\n",
        "        \n",
        "        Args:\n",
        "            current_epoch (int): current epoch number (begins from 1)\n",
        "        Returns:\n",
        "            train_loss: average training loss over all batches of the\n",
        "                current epoch.\n",
        "            train_accuracy: training accuracy of the current epoch over\n",
        "                all samples.\n",
        "        \"\"\"\n",
        "\n",
        "        # Set the current network in training mode\n",
        "        self.net.train()\n",
        "        if self.old_net is not None: \n",
        "          self.old_net.train(False)\n",
        "          for i in range(len(self.old_nets)):\n",
        "            self.old_nets[i] = self.old_nets[i].train(False)\n",
        "        if self.best_net is not None: self.best_net.train(False)\n",
        "\n",
        "        running_train_loss = 0\n",
        "        running_corrects = 0\n",
        "        total = 0\n",
        "        batch_idx = 0\n",
        "\n",
        "        print(f\"Epoch: {current_epoch}, LR: {self.scheduler.get_last_lr()}\")\n",
        "\n",
        "        for images, labels in self.train_dataloader:\n",
        "            loss, corrects = self.do_batch(images, labels)\n",
        "\n",
        "            running_train_loss += loss.item()\n",
        "            running_corrects += corrects\n",
        "            total += labels.size(0)\n",
        "            batch_idx += 1\n",
        "\n",
        "        self.scheduler.step()\n",
        "\n",
        "        # Calculate average scores\n",
        "        train_loss = running_train_loss / batch_idx # Average over all batches\n",
        "        train_accuracy = running_corrects / float(total) # Average over all samples\n",
        "\n",
        "        print(f\"Train loss: {train_loss}, Train accuracy: {train_accuracy}\")\n",
        "\n",
        "        return train_loss, train_accuracy\n",
        "\n",
        "    def do_batch(self, batch, labels):\n",
        "        \"\"\"Train network for a batch. Loss is applied here.\n",
        "        Args:\n",
        "            batch: batch of data used for training the network\n",
        "            labels: targets of the batch\n",
        "        Returns:\n",
        "            loss: output of the criterion applied\n",
        "            running_corrects: number of correctly classified elements\n",
        "        \"\"\"\n",
        "        batch = batch.to(self.device)\n",
        "        labels = labels.to(self.device)\n",
        "\n",
        "        # Zero-ing the gradients\n",
        "        self.optimizer.zero_grad()\n",
        "        \n",
        "        # One-hot encoding of labels of the new training data (new classes)\n",
        "        # Size: batch size (rows) by number of classes seen until now (columns)\n",
        "        #\n",
        "        # e.g., suppose we have four images in a batch, and each incremental\n",
        "        #   step adds three new classes. At the second step, the one-hot\n",
        "        #   encoding may return the following tensor:\n",
        "        #\n",
        "        #       tensor([[0., 0., 0., 1., 0., 0.],   # image 0 (label 3)\n",
        "        #               [0., 0., 0., 0., 1., 0.],   # image 1 (label 4)\n",
        "        #               [0., 0., 0., 0., 0., 1.],   # image 2 (label 5)\n",
        "        #               [0., 0., 0., 0., 1., 0.]])  # image 3 (label 4)\n",
        "        #\n",
        "        #   The first three elements of each vector will always be 0, as the\n",
        "        #   new training batch does not contain images belonging to classes\n",
        "        #   already seen in previous steps.\n",
        "        #\n",
        "        #   The last three elements of each vector will contain the actual\n",
        "        #   information about the class of each image (one-hot encoding of the\n",
        "        #   label). Therefore, we slice the tensor and remove the columns \n",
        "        #   related to old classes (all zeros).\n",
        "        num_classes = self.output_neurons_count() # Number of classes seen until now, including new classes\n",
        "        one_hot_labels = self.to_onehot(labels)[:, num_classes-10:num_classes]\n",
        "\n",
        "        if self.old_net is None:\n",
        "            # Network is training for the first time, so we only apply the\n",
        "            # classification loss.\n",
        "            targets = one_hot_labels\n",
        "            # Forward pass\n",
        "            outputs = self.net(batch)\n",
        "\n",
        "        else:\n",
        "            # Old net forward pass. We compute the outputs of the old network\n",
        "            # and apply a sigmoid function. These are used in the distillation\n",
        "            # loss. We discard the output of the new neurons, as they are not\n",
        "            # considered in the distillation loss.\n",
        "            # if self.split == 1:\n",
        "            #    old_net_outputs = sigmoid(self.old_nets[0](batch))\n",
        "            # else:\n",
        "            old_net_outputs = sigmoid(self.old_nets[0](batch)/self.T)\n",
        "            for i, old_net in enumerate(self.old_nets[1:]):\n",
        "              old_net_outputs = torch.cat((old_net_outputs, sigmoid(old_net(batch)[:, (i+1)*10:]/self.T)), dim=1)\n",
        "\n",
        "            # Concatenate the outputs of the old network and the one-hot encoded\n",
        "            # labels along dimension 1 (columns).\n",
        "            # \n",
        "            # Each row refers to an image in the training set, and contains:\n",
        "            # - the output of the old network for that image, used by the\n",
        "            #   distillation loss\n",
        "            # - the one-hot label of the image, used by the classification loss\n",
        "            targets = torch.cat((old_net_outputs, one_hot_labels), dim=1)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = self.net(batch)\n",
        "            outputs = torch.cat((outputs[:, :num_classes-10]/self.T, outputs[:, num_classes-10:]), dim=1)\n",
        "\n",
        "        \n",
        "        loss = self.criterion(outputs, targets)\n",
        "\n",
        "        # Get predictions\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "        # Accuracy over NEW IMAGES, not over all images\n",
        "        running_corrects = torch.sum(preds == labels.data).data.item() \n",
        "\n",
        "        # Backward pass: computes gradients\n",
        "        loss.backward()\n",
        "\n",
        "        self.optimizer.step()\n",
        "\n",
        "        return loss, running_corrects\n",
        "\n",
        "    def validate(self):\n",
        "        \"\"\"Validate the model.\n",
        "        \n",
        "        Returns:\n",
        "            val_loss: average loss function computed on the network outputs\n",
        "                of the validation set (val_dataloader).\n",
        "            val_accuracy: accuracy computed on the validation set.\n",
        "        \"\"\"\n",
        "\n",
        "        self.net.train(False)\n",
        "        if self.old_net is not None: \n",
        "          self.old_net.train(False)\n",
        "          for i in range(len(self.old_nets)):\n",
        "            self.old_nets[i] = self.old_nets[i].train(False)\n",
        "        if self.best_net is not None: self.best_net.train(False)\n",
        "\n",
        "        running_val_loss = 0\n",
        "        running_corrects = 0\n",
        "        total = 0\n",
        "        batch_idx = 0\n",
        "\n",
        "        for images, labels in self.val_dataloader:\n",
        "            images = images.to(self.device)\n",
        "            labels = labels.to(self.device)\n",
        "            total += labels.size(0)\n",
        "\n",
        "            # One hot encoding of new task labels \n",
        "            one_hot_labels = self.to_onehot(labels)\n",
        "\n",
        "            # New net forward pass\n",
        "            outputs = self.net(images)  \n",
        "            loss = self.criterion(outputs, one_hot_labels) # BCE Loss with sigmoids over outputs\n",
        "\n",
        "            running_val_loss += loss.item()\n",
        "\n",
        "            # Get predictions\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "            # Update the number of correctly classified validation samples\n",
        "            running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "            batch_idx += 1\n",
        "\n",
        "        # Calculate scores\n",
        "        val_loss = running_val_loss / batch_idx\n",
        "        val_accuracy = running_corrects / float(total)\n",
        "\n",
        "        print(f\"Validation loss: {val_loss}, Validation accuracy: {val_accuracy}\")\n",
        "\n",
        "        return val_loss, val_accuracy\n",
        "\n",
        "    def test(self, test_dataset, train_dataset=None):\n",
        "        \"\"\"Test the model.\n",
        "        Args:\n",
        "            test_dataset: dataset on which to test the network\n",
        "            train_dataset: training set used to train the last split, if\n",
        "                available\n",
        "        Returns:\n",
        "            accuracy (float): accuracy of the model on the test set\n",
        "        \"\"\"\n",
        "\n",
        "        self.net.train(False)\n",
        "        if self.best_net is not None: self.best_net.train(False)  # Set Network to evaluation mode\n",
        "        if self.old_net is not None: \n",
        "          self.old_net.train(False)\n",
        "          for i in range(len(self.old_nets)):\n",
        "            self.old_nets[i] = self.old_nets[i].train(False)\n",
        "\n",
        "        self.test_dataloader = DataLoader(test_dataset, batch_size=self.BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "\n",
        "        running_corrects = 0\n",
        "        total = 0\n",
        "\n",
        "        # To store all predictions\n",
        "        all_preds = torch.tensor([])\n",
        "        all_preds = all_preds.type(torch.LongTensor)\n",
        "\n",
        "        # Clear mean of exemplars cache\n",
        "        self.cached_means = None\n",
        "        \n",
        "        # Disable transformations for train_dataset, if available, as we will\n",
        "        # need original PIL images from which to extract features.\n",
        "        if train_dataset is not None: train_dataset.dataset.disable_transform()\n",
        "\n",
        "        for images, labels in self.test_dataloader:\n",
        "            images = images.to(self.device)\n",
        "            labels = labels.to(self.device)\n",
        "\n",
        "            total += labels.size(0)\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                preds = self.classify(images, train_dataset)\n",
        "\n",
        "            running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "            all_preds = torch.cat(\n",
        "                (all_preds.to(self.device), preds.to(self.device)), dim=0\n",
        "            )\n",
        "\n",
        "        if train_dataset is not None: train_dataset.dataset.enable_transform()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        accuracy = running_corrects / float(total)  \n",
        "\n",
        "        print(f\"Test accuracy (iCaRL): {accuracy} \", end=\"\")\n",
        "\n",
        "        if train_dataset is None:\n",
        "            print(\"(only exemplars)\")\n",
        "        else:\n",
        "            print(\"(exemplars and training data)\")\n",
        "\n",
        "        return accuracy, all_preds\n",
        "\n",
        "    def test_without_classifier(self, test_dataset):\n",
        "        \"\"\"Test the model without classifier, using the outputs of the\n",
        "        network instead.\n",
        "        Args:\n",
        "            test_dataset: dataset on which to test the network\n",
        "        Returns:\n",
        "            accuracy (float): accuracy of the model on the test set\n",
        "        \"\"\"\n",
        "\n",
        "        self.net.train(False)\n",
        "        if self.best_net is not None: self.best_net.train(False) # Set Network to evaluation mode\n",
        "        if self.old_net is not None: \n",
        "          self.old_net.train(False)\n",
        "          for i in range(len(self.old_nets)):\n",
        "            self.old_nets[i] = self.old_nets[i].train(False)\n",
        "\n",
        "        self.test_dataloader = DataLoader(test_dataset, batch_size=self.BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "\n",
        "        running_corrects = 0\n",
        "        total = 0\n",
        "\n",
        "        all_preds = torch.tensor([]) # to store all predictions\n",
        "        all_preds = all_preds.type(torch.LongTensor)\n",
        "        \n",
        "        for images, labels in self.test_dataloader:\n",
        "            images = images.to(self.device)\n",
        "            labels = labels.to(self.device)\n",
        "            total += labels.size(0)\n",
        "\n",
        "            # Forward Pass\n",
        "            with torch.no_grad():\n",
        "                if self.VALIDATE:\n",
        "                    outputs = self.best_net(images)\n",
        "                else:\n",
        "                    outputs = self.net(images)\n",
        "\n",
        "            # Get predictions\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "            # Update Corrects\n",
        "            running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "            # Append batch predictions\n",
        "            all_preds = torch.cat(\n",
        "                (all_preds.to(self.device), preds.to(self.device)), dim=0\n",
        "            )\n",
        "\n",
        "        # Calculate accuracy\n",
        "        accuracy = running_corrects / float(total)  \n",
        "\n",
        "        print(f\"Test accuracy (hybrid1): {accuracy}\")\n",
        "\n",
        "        return accuracy, all_preds\n",
        "    \n",
        "    def increment_classes(self, n=10):\n",
        "        \"\"\"Add n classes in the final fully connected layer.\"\"\"\n",
        "        in_features = self.net.fc.in_features  # size of each input sample\n",
        "        out_features = self.net.fc.out_features  # size of each output sample\n",
        "        weight = self.net.fc.weight.data\n",
        "        bias = self.net.fc.bias.data\n",
        "\n",
        "        self.net.fc = nn.Linear(in_features, out_features+n)\n",
        "        self.net.fc.weight.data[:out_features] = weight\n",
        "        self.net.fc.bias.data[:out_features] = bias\n",
        "    \n",
        "    \n",
        "    def output_neurons_count(self):\n",
        "        \"\"\"Return the number of output neurons of the current network.\"\"\"\n",
        "\n",
        "        return self.net.fc.out_features\n",
        "    \n",
        "    def feature_neurons_count(self):\n",
        "        \"\"\"Return the number of neurons of the last layer of the feature extractor.\"\"\"\n",
        "\n",
        "        return self.net.fc.in_features\n",
        "    \n",
        "    def to_onehot(self, targets):\n",
        "        \"\"\"Convert targets to one-hot encoding (for BCE loss).\n",
        "        Args:\n",
        "            targets: dataloader.dataset.targets of the new task images\n",
        "        \"\"\"\n",
        "        num_classes = self.net.fc.out_features\n",
        "        one_hot_targets = torch.eye(num_classes)[targets]\n",
        "\n",
        "        return one_hot_targets.to(self.device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udUGrKrkNfBU",
        "colab_type": "text"
      },
      "source": [
        "### Pre saved distillation targets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qYtfGFRNAcd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "We try to save old nets scores at the beginning\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
        "from torch.backends import cudnn\n",
        "\n",
        "from math import floor\n",
        "from copy import deepcopy\n",
        "import random\n",
        "\n",
        "sigmoid = nn.Sigmoid() # Sigmoid function\n",
        "\n",
        "\n",
        "''' \n",
        "Utilizziamo targets soften perché le vecchie reti separno meglio ma troppo ==> più difficile apprendere\n",
        "avendo distanze eccesive tra:\n",
        "\n",
        "1. current net e old nets\n",
        "2. nodi di old nets: la std deviation è molto elevata, è difficile apprendere pesi che accontentino tutti\n",
        "3. Vedi Hinton\n",
        "\n",
        "Soluzione: \n",
        "Soften targets\n",
        "\n",
        "'''\n",
        "\n",
        "class Exemplars(torch.utils.data.Dataset):\n",
        "    def __init__(self, exemplars, transform=None):\n",
        "        # exemplars = [\n",
        "        #     [ex0_class0, ex1_class0, ex2_class0, ...],\n",
        "        #     [ex0_class1, ex1_class1, ex2_class1, ...],\n",
        "        #     ...\n",
        "        #     [ex0_classN, ex1_classN, ex2_classN, ...]\n",
        "        # ]\n",
        "\n",
        "        self.dataset = []\n",
        "        self.targets = []\n",
        "\n",
        "        for y, exemplar_y in enumerate(exemplars):\n",
        "            self.dataset.extend(exemplar_y)\n",
        "            self.targets.extend([y] * len(exemplar_y))\n",
        "\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        image = self.dataset[index]\n",
        "        target = self.targets[index]\n",
        "\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.targets)\n",
        "\n",
        "class iCaRLDist:\n",
        "    \"\"\"Implement iCaRL, a strategy for simultaneously learning classifiers and a\n",
        "    feature representation in the class-incremental setting.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, device, net, lr, momentum, weight_decay, milestones, gamma, num_epochs, batch_size, train_transform, test_transform, T):\n",
        "        self.device = device\n",
        "        self.net = net\n",
        "\n",
        "        # Set hyper-parameters\n",
        "        self.LR = lr\n",
        "        self.MOMENTUM = momentum\n",
        "        self.WEIGHT_DECAY = weight_decay\n",
        "        self.MILESTONES = milestones\n",
        "        self.GAMMA = gamma\n",
        "        self.NUM_EPOCHS = num_epochs\n",
        "        self.BATCH_SIZE = batch_size\n",
        "        \n",
        "        # Set transformations\n",
        "        self.train_transform = train_transform\n",
        "        self.test_transform = test_transform\n",
        "\n",
        "        # List of exemplar sets. Each set contains memory_size/num_classes exemplars\n",
        "        # with num_classes the number of classes seen until now by the network.\n",
        "        self.exemplars = []\n",
        "\n",
        "        # Initialize the copy of the old network, used to compute outputs of the\n",
        "        # previous network for the distillation loss, to None. This is useful to\n",
        "        # correctly apply the first function when training the network for the\n",
        "        # first time.\n",
        "        self.old_net = None\n",
        "        self.old_nets = []\n",
        "        self.T = T\n",
        "\n",
        "        # Maximum number of exemplars\n",
        "        self.memory_size = 2000\n",
        "    \n",
        "        # Loss function\n",
        "        self.criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "        # If True, test on the best model found (e.g., minimize loss). If False,\n",
        "        # test on the last model build (of the last epoch).\n",
        "        self.VALIDATE = False\n",
        "\n",
        "    def classify(self, batch, train_dataset=None):\n",
        "        \"\"\"Mean-of-exemplars classifier used to classify images into the set of\n",
        "        classes observed so far.\n",
        "        Args:\n",
        "            batch (torch.tensor): batch to classify\n",
        "        Returns:\n",
        "            label (int): class label assigned to the image\n",
        "        \"\"\"\n",
        "\n",
        "        batch_features = self.extract_features(batch) # (batch size, 64)\n",
        "        for i in range(batch_features.size(0)):\n",
        "            batch_features[i] = batch_features[i]/batch_features[i].norm() # Normalize sample feature representation\n",
        "        batch_features = batch_features.to(self.device)\n",
        "\n",
        "        if self.cached_means is None:\n",
        "            print(\"Computing mean of exemplars... \", end=\"\")\n",
        "\n",
        "            self.cached_means = []\n",
        "\n",
        "            # Number of known classes\n",
        "            num_classes = len(self.exemplars)\n",
        "\n",
        "            # Compute the means of classes with all the data available,\n",
        "            # including training data which contains samples belonging to\n",
        "            # the latest 10 classes. This will remove noise from the mean\n",
        "            # estimate, improving the results.\n",
        "            if train_dataset is not None:\n",
        "                train_features_list = [[] for _ in range(10)]\n",
        "\n",
        "                for train_sample, label in train_dataset:\n",
        "                    features = self.extract_features(train_sample, batch=False, transform=self.test_transform)\n",
        "                    features = features/features.norm()\n",
        "                    train_features_list[label % 10].append(features)\n",
        "\n",
        "            # Compute means of exemplars for all known classes\n",
        "            for y in range(num_classes):\n",
        "                if (train_dataset is not None) and (y in range(num_classes-10, num_classes)):\n",
        "                    features_list = train_features_list[y % 10]\n",
        "                else:\n",
        "                    features_list = []\n",
        "\n",
        "                for exemplar in self.exemplars[y]:\n",
        "                    features = self.extract_features(exemplar, batch=False, transform=self.test_transform)\n",
        "                    features = features/features.norm() # Normalize the feature representation of the exemplar\n",
        "                    features_list.append(features)\n",
        "                \n",
        "                features_list = torch.stack(features_list)\n",
        "                class_means = features_list.mean(dim=0)\n",
        "                class_means = class_means/class_means.norm() # Normalize the class means\n",
        "\n",
        "                self.cached_means.append(class_means)\n",
        "            \n",
        "            self.cached_means = torch.stack(self.cached_means).to(self.device)\n",
        "            print(\"done\")\n",
        "\n",
        "        preds = []\n",
        "        for i in range(batch_features.size(0)):\n",
        "            f_arg = torch.norm(batch_features[i] - self.cached_means, dim=1)\n",
        "            preds.append(torch.argmin(f_arg))\n",
        "        \n",
        "        return torch.stack(preds)\n",
        "    \n",
        "    def extract_features(self, sample, batch=True, transform=None):\n",
        "        \"\"\"Extract features from single sample or from batch.\n",
        "        \n",
        "        Args:\n",
        "            sample (PIL image or torch.tensor): sample(s) from which to\n",
        "                extract features\n",
        "            batch (bool): if True, sample is a torch.tensor containing a batch\n",
        "                of images with dimensions (batch_size, 3, 32, 32)\n",
        "            transform: transformations to apply to the PIL image before\n",
        "                processing\n",
        "        Returns:\n",
        "            features: torch.tensor, 1-D of dimension 64 for single samples or\n",
        "                2-D of dimension (batch_size, 64) for batch\n",
        "        \"\"\"\n",
        "\n",
        "        assert not (batch is False and transform is None), \"if a PIL image is passed to extract_features, a transform must be defined\"\n",
        "\n",
        "        self.net.train(False)\n",
        "        if self.best_net is not None: self.best_net.train(False)\n",
        "        if self.old_net is not None: \n",
        "          self.old_net.train(False)\n",
        "          for i in range(len(self.old_nets)):\n",
        "            self.old_nets[i] = self.old_nets[i].train(False)\n",
        "\n",
        "        if batch is False: # Treat sample as single PIL image\n",
        "            sample = transform(sample)\n",
        "            sample = sample.unsqueeze(0) # https://stackoverflow.com/a/59566009/6486336\n",
        "\n",
        "        sample = sample.to(self.device)\n",
        "\n",
        "        if self.VALIDATE:\n",
        "            features = self.best_net.features(sample)\n",
        "        else:\n",
        "            features = self.net.features(sample)\n",
        "\n",
        "        if batch is False:\n",
        "            features = features[0]\n",
        "\n",
        "        return features\n",
        "\n",
        "    def incremental_train(self, split, train_dataset, val_dataset):\n",
        "        \"\"\"Adjust internal knowledge based on the additional information\n",
        "        available in the new observations.\n",
        "        Args:\n",
        "            split (int): current split number, counting from zero\n",
        "            train_dataset: dataset for training the model\n",
        "            val_dataset: dataset for validating the model\n",
        "        Returns:\n",
        "            train_logs: tuple of four metrics (train_loss, train_accuracy,\n",
        "            val_loss, val_accuracy) obtained during network training\n",
        "        \"\"\"\n",
        "\n",
        "        if split is not 0:\n",
        "            # Increment the number of output nodes for the new network by 10\n",
        "            self.increment_classes(10)\n",
        "\n",
        "        # Improve network parameters upon receiving new classes. Effectively\n",
        "        # train a new network starting from the current network parameters.\n",
        "        train_logs = self.update_representation(train_dataset, val_dataset)\n",
        "\n",
        "        # Compute the number of exemplars per class\n",
        "        num_classes = self.output_neurons_count()\n",
        "        m = floor(self.memory_size / num_classes)\n",
        "\n",
        "        print(f\"Target number of exemplars per class: {m}\")\n",
        "        print(f\"Target total number of exemplars: {m*num_classes}\")\n",
        "\n",
        "        # Reduce pre-existing exemplar sets in order to fit new exemplars\n",
        "        for y in range(len(self.exemplars)):\n",
        "            self.exemplars[y] = self.reduce_exemplar_set(self.exemplars[y], m)\n",
        "\n",
        "        # Construct exemplar set for new classes\n",
        "        new_exemplars = self.construct_exemplar_set_rand(train_dataset, m)\n",
        "        self.exemplars.extend(new_exemplars)\n",
        "\n",
        "        return train_logs\n",
        "\n",
        "    def update_representation(self, train_dataset, val_dataset):\n",
        "        \"\"\"Update the parameters of the network.\n",
        "        Args:\n",
        "            train_dataset: dataset for training the model\n",
        "            val_dataset: dataset for validating the model\n",
        "        Returns:\n",
        "            train_logs: tuple of four metrics (train_loss, train_accuracy,\n",
        "            val_loss, val_accuracy) obtained during network training\n",
        "        \"\"\"\n",
        "\n",
        "        # Combine the new training data with existing exemplars.\n",
        "        print(f\"Length of exemplars set: {sum([len(self.exemplars[y]) for y in range(len(self.exemplars))])}\")\n",
        "        exemplars_dataset = Exemplars(self.exemplars, self.train_transform)\n",
        "        train_dataset_with_exemplars = ConcatDataset([exemplars_dataset, train_dataset])\n",
        "\n",
        "        # Train the network on combined dataset\n",
        "        train_logs = self.train(train_dataset_with_exemplars, val_dataset) # @todo: include exemplars in validation set?\n",
        "\n",
        "        # Keep a copy of the current network in order to compute its outputs for\n",
        "        # the distillation loss while the new network is being trained.\n",
        "        self.old_net = deepcopy(self.net)\n",
        "        self.old_nets.append(self.old_net)\n",
        "\n",
        "        return train_logs\n",
        "\n",
        "    def construct_exemplar_set_rand(self, dataset, m):\n",
        "        \"\"\"Randomly sample m elements from a dataset without replacement.\n",
        "        Args:\n",
        "            dataset: dataset containing a split (samples from 10 classes) from\n",
        "                which to take exemplars\n",
        "            m (int): target number of exemplars per class\n",
        "        Returns:\n",
        "            exemplars: list of samples extracted from the dataset\n",
        "        \"\"\"\n",
        "\n",
        "        dataset.dataset.disable_transform()\n",
        "\n",
        "        samples = [[] for _ in range(10)]\n",
        "        for image, label in dataset:\n",
        "            label = label % 10 # Map labels to 0-9 range\n",
        "            samples[label].append(image)\n",
        "\n",
        "        dataset.dataset.enable_transform()\n",
        "\n",
        "        exemplars = [[] for _ in range(10)]\n",
        "\n",
        "        for y in range(10):\n",
        "            print(f\"Randomly extracting exemplars from class {y} of current split... \", end=\"\")\n",
        "\n",
        "            # Randomly choose m samples from samples[y] without replacement\n",
        "            exemplars[y] = random.sample(samples[y], m)\n",
        "\n",
        "            print(f\"Extracted {len(exemplars[y])} exemplars.\")\n",
        "\n",
        "        return exemplars\n",
        "\n",
        "    def reduce_exemplar_set(self, exemplar_set, m):\n",
        "        \"\"\"Procedure for removing exemplars from a given set.\n",
        "        Args:\n",
        "            exemplar_set (set): set of exemplars belonging to a certain class\n",
        "            m (int): target number of exemplars\n",
        "        Returns:\n",
        "            exemplar_set: reduced exemplar set\n",
        "        \"\"\"\n",
        "\n",
        "        return exemplar_set[:m]\n",
        "\n",
        "    def train(self, train_dataset, val_dataset):\n",
        "        \"\"\"Train the network for a specified number of epochs, and save\n",
        "        the best performing model on the validation set.\n",
        "        \n",
        "        Args:\n",
        "            train_dataset: dataset for training the model\n",
        "            val_dataset: dataset for validating the model\n",
        "        Returns: train_logs: tuple of four metrics (train_loss, train_accuracy,\n",
        "            val_loss, val_accuracy) obtained during network training. If\n",
        "            validation is enabled, return scores of the best epoch, otherwise\n",
        "            return scores of the last epoch.\n",
        "        \"\"\"\n",
        "\n",
        "        # Define the optimization algorithm\n",
        "        parameters_to_optimize = self.net.parameters()\n",
        "        self.optimizer = optim.SGD(parameters_to_optimize, \n",
        "                                   lr=self.LR,\n",
        "                                   momentum=self.MOMENTUM,\n",
        "                                   weight_decay=self.WEIGHT_DECAY)\n",
        "        \n",
        "        # Define the learning rate decaying policy\n",
        "        self.scheduler = optim.lr_scheduler.MultiStepLR(self.optimizer,\n",
        "                                                        milestones=self.MILESTONES,\n",
        "                                                        gamma=self.GAMMA)\n",
        "\n",
        "        # Create DataLoaders for training and validation\n",
        "        self.train_dataloader = DataLoader(train_dataset, batch_size=self.BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
        "        self.val_dataloader = DataLoader(val_dataset, batch_size=self.BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
        "\n",
        "        # Se non funzimona la faccenda del seed, setto num_workers = 0\n",
        "        # Define seed for deterministic shiffle in the dataloader\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        random.seed(1)\n",
        "        torch.manual_seed(1)\n",
        "        torch.cuda.manual_seed(1)\n",
        "        np.random.seed(1)\n",
        "        \n",
        "\n",
        "        # Send networks to chosen device\n",
        "        self.net = self.net.to(self.device)\n",
        "        if self.old_net is not None: \n",
        "          self.old_nets = [net.to(self.device) for net in self.old_nets]\n",
        "          self.old_nets = [net.train(False) for net in self.old_nets]\n",
        "\n",
        "          old_net_targets = [] # will contain targets divided in batches\n",
        "\n",
        "          with torch.no_grad():\n",
        "            # save targets from each net, selecting only those of interest\n",
        "            for batch, _ in self.train_dataloader:\n",
        "            \n",
        "              batch = batch.to(self.device)\n",
        "              old_net_outputs = sigmoid(self.old_nets[0](batch)/self.T)[:, :10] # only one when step = 1\n",
        "\n",
        "              for i in range(1, self.step):\n",
        "                old_net_outputs = torch.cat((old_net_outputs,sigmoid(self.old_nets[i](batch)/self.T)[:, i*10:(i+1)*10]), dim = 1)\n",
        "                \n",
        "            # append current batch to targets\n",
        "            # mantain the batch division that will be used in self.do_batch\n",
        "            # to associate targets and outputs correctly\n",
        "            old_net_targets.append(old_net_outputs) # soften the targets\n",
        "              \n",
        "\n",
        "          # size = [number of batches, num_classes-10]\n",
        "          self.old_net_targets = torch.stack(old_net_targets).to(self.device)\n",
        "\n",
        "        cudnn.benchmark  # Calling this optimizes runtime\n",
        "\n",
        "        self.best_val_loss = float('inf')\n",
        "        self.best_val_accuracy = 0\n",
        "        self.best_train_loss = float('inf')\n",
        "        self.best_train_accuracy = 0\n",
        "        \n",
        "        self.best_net = None\n",
        "        self.best_epoch = -1\n",
        "\n",
        "        for epoch in range(self.NUM_EPOCHS):\n",
        "            # Run an epoch (start counting form 1)\n",
        "            train_loss, train_accuracy = self.do_epoch(epoch+1)\n",
        "        \n",
        "            # Validate after each epoch \n",
        "            val_loss, val_accuracy = self.validate()    \n",
        "\n",
        "            # Validation criterion: best net is the one that minimizes the loss\n",
        "            # on the validation set.\n",
        "            if self.VALIDATE and val_loss < self.best_val_loss:\n",
        "                self.best_val_loss = val_loss\n",
        "                self.best_val_accuracy = val_accuracy\n",
        "                self.best_train_loss = train_loss\n",
        "                self.best_train_accuracy = train_accuracy\n",
        "\n",
        "                self.best_net = deepcopy(self.net)\n",
        "                self.best_epoch = epoch\n",
        "                print(\"Best model updated\")\n",
        "\n",
        "        if self.VALIDATE:\n",
        "            val_loss = self.best_val_loss\n",
        "            val_accuracy = self.best_val_accuracy\n",
        "            train_loss = self.best_train_loss\n",
        "            train_accuracy = self.best_train_accuracy\n",
        "\n",
        "            print(f\"Best model found at epoch {self.best_epoch+1}\")\n",
        "\n",
        "        return train_loss, train_accuracy, val_loss, val_accuracy\n",
        "    \n",
        "    def do_epoch(self, current_epoch):\n",
        "        \"\"\"Trains model for one epoch.\n",
        "        \n",
        "        Args:\n",
        "            current_epoch (int): current epoch number (begins from 1)\n",
        "        Returns:\n",
        "            train_loss: average training loss over all batches of the\n",
        "                current epoch.\n",
        "            train_accuracy: training accuracy of the current epoch over\n",
        "                all samples.\n",
        "        \"\"\"\n",
        "\n",
        "        # Set the current network in training mode\n",
        "        self.net.train()\n",
        "        if self.old_net is not None: \n",
        "          self.old_net.train(False)\n",
        "          for i in range(len(self.old_nets)):\n",
        "            self.old_nets[i] = self.old_nets[i].train(False)\n",
        "        if self.best_net is not None: self.best_net.train(False)\n",
        "\n",
        "        running_train_loss = 0\n",
        "        running_corrects = 0\n",
        "        total = 0\n",
        "        batch_idx = 0\n",
        "\n",
        "        print(f\"Epoch: {current_epoch}, LR: {self.scheduler.get_last_lr()}\")\n",
        "\n",
        "        for images, labels in self.train_dataloader:\n",
        "            loss, corrects = self.do_batch(images, labels)\n",
        "\n",
        "            running_train_loss += loss.item()\n",
        "            running_corrects += corrects\n",
        "            total += labels.size(0)\n",
        "            batch_idx += 1\n",
        "\n",
        "        self.scheduler.step()\n",
        "\n",
        "        # Calculate average scores\n",
        "        train_loss = running_train_loss / batch_idx # Average over all batches\n",
        "        train_accuracy = running_corrects / float(total) # Average over all samples\n",
        "\n",
        "        print(f\"Train loss: {train_loss}, Train accuracy: {train_accuracy}\")\n",
        "\n",
        "        return train_loss, train_accuracy\n",
        "\n",
        "    def do_batch(self, batch, labels):\n",
        "        \"\"\"Train network for a batch. Loss is applied here.\n",
        "        Args:\n",
        "            batch: batch of data used for training the network\n",
        "            labels: targets of the batch\n",
        "        Returns:\n",
        "            loss: output of the criterion applied\n",
        "            running_corrects: number of correctly classified elements\n",
        "        \"\"\"\n",
        "        batch = batch.to(self.device)\n",
        "        labels = labels.to(self.device)\n",
        "\n",
        "        # Zero-ing the gradients\n",
        "        self.optimizer.zero_grad()\n",
        "        \n",
        "        # One-hot encoding of labels of the new training data (new classes)\n",
        "        # Size: batch size (rows) by number of classes seen until now (columns)\n",
        "        #\n",
        "        # e.g., suppose we have four images in a batch, and each incremental\n",
        "        #   step adds three new classes. At the second step, the one-hot\n",
        "        #   encoding may return the following tensor:\n",
        "        #\n",
        "        #       tensor([[0., 0., 0., 1., 0., 0.],   # image 0 (label 3)\n",
        "        #               [0., 0., 0., 0., 1., 0.],   # image 1 (label 4)\n",
        "        #               [0., 0., 0., 0., 0., 1.],   # image 2 (label 5)\n",
        "        #               [0., 0., 0., 0., 1., 0.]])  # image 3 (label 4)\n",
        "        #\n",
        "        #   The first three elements of each vector will always be 0, as the\n",
        "        #   new training batch does not contain images belonging to classes\n",
        "        #   already seen in previous steps.\n",
        "        #\n",
        "        #   The last three elements of each vector will contain the actual\n",
        "        #   information about the class of each image (one-hot encoding of the\n",
        "        #   label). Therefore, we slice the tensor and remove the columns \n",
        "        #   related to old classes (all zeros).\n",
        "        num_classes = self.output_neurons_count() # Number of classes seen until now, including new classes\n",
        "        one_hot_labels = self.to_onehot(labels)[:, num_classes-10:num_classes]\n",
        "\n",
        "        if self.old_net is None:\n",
        "            # Network is training for the first time, so we only apply the\n",
        "            # classification loss.\n",
        "            targets = one_hot_labels\n",
        "            # Forward pass\n",
        "            outputs = self.net(batch)\n",
        "\n",
        "         else:\n",
        "            # Old net forward pass. We compute the outputs of the old network\n",
        "            # and apply a sigmoid function. These are used in the distillation\n",
        "            # loss. We discard the output of the new neurons, as they are not\n",
        "            # considered in the distillation loss.\n",
        "\n",
        "            old_net_outputs = self.old_net_targets[i] # select targets from the correspondent batch\n",
        "              \n",
        "\n",
        "            # Concatenate the outputs of the old network and the one-hot encoded\n",
        "            # labels along dimension 1 (columns).\n",
        "            # \n",
        "            # Each row refers to an image in the training set, and contains:\n",
        "            # - the output of the old network for that image, used by the\n",
        "            #   distillation loss\n",
        "            # - the one-hot label of the image, used by the classification loss\n",
        "            targets = torch.cat((old_net_outputs, one_hot_labels), dim=1)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = self.net(batch)\n",
        "            outputs = torch.cat((outputs[:, :num_classes-10]/self.T, outputs[:, num_classes-10:]), dim=1)\n",
        "\n",
        "        \n",
        "        loss = self.criterion(outputs, targets)\n",
        "\n",
        "        # Get predictions\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "        # Accuracy over NEW IMAGES, not over all images\n",
        "        running_corrects = torch.sum(preds == labels.data).data.item() \n",
        "\n",
        "        # Backward pass: computes gradients\n",
        "        loss.backward()\n",
        "\n",
        "        self.optimizer.step()\n",
        "\n",
        "        return loss, running_corrects\n",
        "\n",
        "    def validate(self):\n",
        "        \"\"\"Validate the model.\n",
        "        \n",
        "        Returns:\n",
        "            val_loss: average loss function computed on the network outputs\n",
        "                of the validation set (val_dataloader).\n",
        "            val_accuracy: accuracy computed on the validation set.\n",
        "        \"\"\"\n",
        "\n",
        "        self.net.train(False)\n",
        "        if self.old_net is not None: \n",
        "          self.old_net.train(False)\n",
        "          for i in range(len(self.old_nets)):\n",
        "            self.old_nets[i] = self.old_nets[i].train(False)\n",
        "        if self.best_net is not None: self.best_net.train(False)\n",
        "\n",
        "        running_val_loss = 0\n",
        "        running_corrects = 0\n",
        "        total = 0\n",
        "        batch_idx = 0\n",
        "\n",
        "        for images, labels in self.val_dataloader:\n",
        "            images = images.to(self.device)\n",
        "            labels = labels.to(self.device)\n",
        "            total += labels.size(0)\n",
        "\n",
        "            # One hot encoding of new task labels \n",
        "            one_hot_labels = self.to_onehot(labels)\n",
        "\n",
        "            # New net forward pass\n",
        "            outputs = self.net(images)  \n",
        "            loss = self.criterion(outputs, one_hot_labels) # BCE Loss with sigmoids over outputs\n",
        "\n",
        "            running_val_loss += loss.item()\n",
        "\n",
        "            # Get predictions\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "            # Update the number of correctly classified validation samples\n",
        "            running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "            batch_idx += 1\n",
        "\n",
        "        # Calculate scores\n",
        "        val_loss = running_val_loss / batch_idx\n",
        "        val_accuracy = running_corrects / float(total)\n",
        "\n",
        "        print(f\"Validation loss: {val_loss}, Validation accuracy: {val_accuracy}\")\n",
        "\n",
        "        return val_loss, val_accuracy\n",
        "\n",
        "    def test(self, test_dataset, train_dataset=None):\n",
        "        \"\"\"Test the model.\n",
        "        Args:\n",
        "            test_dataset: dataset on which to test the network\n",
        "            train_dataset: training set used to train the last split, if\n",
        "                available\n",
        "        Returns:\n",
        "            accuracy (float): accuracy of the model on the test set\n",
        "        \"\"\"\n",
        "\n",
        "        self.net.train(False)\n",
        "        if self.best_net is not None: self.best_net.train(False)  # Set Network to evaluation mode\n",
        "        if self.old_net is not None: \n",
        "          self.old_net.train(False)\n",
        "          for i in range(len(self.old_nets)):\n",
        "            self.old_nets[i] = self.old_nets[i].train(False)\n",
        "\n",
        "        self.test_dataloader = DataLoader(test_dataset, batch_size=self.BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "\n",
        "        running_corrects = 0\n",
        "        total = 0\n",
        "\n",
        "        # To store all predictions\n",
        "        all_preds = torch.tensor([])\n",
        "        all_preds = all_preds.type(torch.LongTensor)\n",
        "\n",
        "        # Clear mean of exemplars cache\n",
        "        self.cached_means = None\n",
        "        \n",
        "        # Disable transformations for train_dataset, if available, as we will\n",
        "        # need original PIL images from which to extract features.\n",
        "        if train_dataset is not None: train_dataset.dataset.disable_transform()\n",
        "\n",
        "        for images, labels in self.test_dataloader:\n",
        "            images = images.to(self.device)\n",
        "            labels = labels.to(self.device)\n",
        "\n",
        "            total += labels.size(0)\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                preds = self.classify(images, train_dataset)\n",
        "\n",
        "            running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "            all_preds = torch.cat(\n",
        "                (all_preds.to(self.device), preds.to(self.device)), dim=0\n",
        "            )\n",
        "\n",
        "        if train_dataset is not None: train_dataset.dataset.enable_transform()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        accuracy = running_corrects / float(total)  \n",
        "\n",
        "        print(f\"Test accuracy (iCaRL): {accuracy} \", end=\"\")\n",
        "\n",
        "        if train_dataset is None:\n",
        "            print(\"(only exemplars)\")\n",
        "        else:\n",
        "            print(\"(exemplars and training data)\")\n",
        "\n",
        "        return accuracy, all_preds\n",
        "\n",
        "    def test_without_classifier(self, test_dataset):\n",
        "        \"\"\"Test the model without classifier, using the outputs of the\n",
        "        network instead.\n",
        "        Args:\n",
        "            test_dataset: dataset on which to test the network\n",
        "        Returns:\n",
        "            accuracy (float): accuracy of the model on the test set\n",
        "        \"\"\"\n",
        "\n",
        "        self.net.train(False)\n",
        "        if self.best_net is not None: self.best_net.train(False) # Set Network to evaluation mode\n",
        "        if self.old_net is not None: \n",
        "          self.old_net.train(False)\n",
        "          for i in range(len(self.old_nets)):\n",
        "            self.old_nets[i] = self.old_nets[i].train(False)\n",
        "\n",
        "        self.test_dataloader = DataLoader(test_dataset, batch_size=self.BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "\n",
        "        running_corrects = 0\n",
        "        total = 0\n",
        "\n",
        "        all_preds = torch.tensor([]) # to store all predictions\n",
        "        all_preds = all_preds.type(torch.LongTensor)\n",
        "        \n",
        "        for images, labels in self.test_dataloader:\n",
        "            images = images.to(self.device)\n",
        "            labels = labels.to(self.device)\n",
        "            total += labels.size(0)\n",
        "\n",
        "            # Forward Pass\n",
        "            with torch.no_grad():\n",
        "                if self.VALIDATE:\n",
        "                    outputs = self.best_net(images)\n",
        "                else:\n",
        "                    outputs = self.net(images)\n",
        "\n",
        "            # Get predictions\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "            # Update Corrects\n",
        "            running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "            # Append batch predictions\n",
        "            all_preds = torch.cat(\n",
        "                (all_preds.to(self.device), preds.to(self.device)), dim=0\n",
        "            )\n",
        "\n",
        "        # Calculate accuracy\n",
        "        accuracy = running_corrects / float(total)  \n",
        "\n",
        "        print(f\"Test accuracy (hybrid1): {accuracy}\")\n",
        "\n",
        "        return accuracy, all_preds\n",
        "    \n",
        "    def increment_classes(self, n=10):\n",
        "        \"\"\"Add n classes in the final fully connected layer.\"\"\"\n",
        "        in_features = self.net.fc.in_features  # size of each input sample\n",
        "        out_features = self.net.fc.out_features  # size of each output sample\n",
        "        weight = self.net.fc.weight.data\n",
        "        bias = self.net.fc.bias.data\n",
        "\n",
        "        self.net.fc = nn.Linear(in_features, out_features+n)\n",
        "        self.net.fc.weight.data[:out_features] = weight\n",
        "        self.net.fc.bias.data[:out_features] = bias\n",
        "    \n",
        "    \n",
        "    def output_neurons_count(self):\n",
        "        \"\"\"Return the number of output neurons of the current network.\"\"\"\n",
        "\n",
        "        return self.net.fc.out_features\n",
        "    \n",
        "    def feature_neurons_count(self):\n",
        "        \"\"\"Return the number of neurons of the last layer of the feature extractor.\"\"\"\n",
        "\n",
        "        return self.net.fc.in_features\n",
        "    \n",
        "    def to_onehot(self, targets):\n",
        "        \"\"\"Convert targets to one-hot encoding (for BCE loss).\n",
        "        Args:\n",
        "            targets: dataloader.dataset.targets of the new task images\n",
        "        \"\"\"\n",
        "        num_classes = self.net.fc.out_features\n",
        "        one_hot_targets = torch.eye(num_classes)[targets]\n",
        "\n",
        "        return one_hot_targets.to(self.device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3dtSmVxJKUi",
        "colab_type": "text"
      },
      "source": [
        "### Execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aKLPSKn_JWPW",
        "colab": {}
      },
      "source": [
        "# iCaRL hyperparameters\n",
        "LR = 3\n",
        "MOMENTUM = 0.9\n",
        "WEIGHT_DECAY = 0.00001\n",
        "MILESTONES = [49, 63]\n",
        "GAMMA = 0.2\n",
        "NUM_EPOCHS = 70\n",
        "BATCH_SIZE = 64\n",
        "T = 2.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "haxZn4AFJWPf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9c518f02-a958-4ab7-a9e2-b9385ec69aef"
      },
      "source": [
        "# Define what tests to run\n",
        "TEST_ICARL = True # Run test with iCaRL (exemplars + train dataset)\n",
        "TEST_HYBRID1 = False # Run test with hybrid1\n",
        "\n",
        "# Initialize logs\n",
        "logs_icarl = [[] for _ in range(NUM_RUNS)]\n",
        "logs_hybrid1 = [[] for _ in range(NUM_RUNS)]\n",
        "\n",
        "for run_i in range(NUM_RUNS):\n",
        "    net = resnet32()\n",
        "    icarl = iCaRLDist(DEVICE, net, LR, MOMENTUM, WEIGHT_DECAY, MILESTONES, GAMMA, NUM_EPOCHS, BATCH_SIZE, train_transform, test_transform, T)\n",
        "\n",
        "    for split_i in range(10):\n",
        "        print(f\"## Split {split_i} of run {run_i} ##\")\n",
        "        \n",
        "        train_logs = icarl.incremental_train(split_i, train_subsets[run_i][split_i], val_subsets[run_i][split_i])\n",
        "\n",
        "        all_targets = torch.stack([label[0] for _, label in DataLoader(test_subsets[run_i][split_i])])\n",
        "\n",
        "        if TEST_ICARL:\n",
        "            logs_icarl[run_i].append({})\n",
        "\n",
        "            acc, all_preds = icarl.test(test_subsets[run_i][split_i], train_subsets[run_i][split_i])\n",
        "\n",
        "            logs_icarl[run_i][split_i]['accuracy'] = acc\n",
        "            logs_icarl[run_i][split_i]['conf_mat'] = confusion_matrix(all_targets.to('cpu'), all_preds.to('cpu'))\n",
        "\n",
        "            logs_icarl[run_i][split_i]['train_loss'] = train_logs[0]\n",
        "            logs_icarl[run_i][split_i]['train_accuracy'] = train_logs[1]\n",
        "            logs_icarl[run_i][split_i]['val_loss'] = train_logs[2]\n",
        "            logs_icarl[run_i][split_i]['val_accuracy'] = train_logs[3]\n",
        "\n",
        "        if TEST_HYBRID1:\n",
        "            logs_hybrid1[run_i].append({})\n",
        "\n",
        "            acc, all_preds = icarl.test_without_classifier(test_subsets[run_i][split_i])\n",
        "\n",
        "            logs_hybrid1[run_i][split_i]['accuracy'] = acc\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "## Split 0 of run 0 ##\n",
            "Length of exemplars set: 0\n",
            "Epoch: 1, LR: [2]\n",
            "Train loss: 0.36990503115313395, Train accuracy: 0.13013392857142858\n",
            "Validation loss: 0.32140350341796875, Validation accuracy: 0.12053571428571429\n",
            "Epoch: 2, LR: [2]\n",
            "Train loss: 0.31891383699008397, Train accuracy: 0.14017857142857143\n",
            "Validation loss: 0.31365772230284555, Validation accuracy: 0.16294642857142858\n",
            "Epoch: 3, LR: [2]\n",
            "Train loss: 0.31459089134420665, Train accuracy: 0.15669642857142857\n",
            "Validation loss: 0.30802622011729647, Validation accuracy: 0.16517857142857142\n",
            "Epoch: 4, LR: [2]\n",
            "Train loss: 0.3084752231836319, Train accuracy: 0.18526785714285715\n",
            "Validation loss: 0.302692357982908, Validation accuracy: 0.21205357142857142\n",
            "Epoch: 5, LR: [2]\n",
            "Train loss: 0.3014115244150162, Train accuracy: 0.2140625\n",
            "Validation loss: 0.3123576555933271, Validation accuracy: 0.16071428571428573\n",
            "Epoch: 6, LR: [2]\n",
            "Train loss: 0.2936580321618489, Train accuracy: 0.2814732142857143\n",
            "Validation loss: 0.3002384432724544, Validation accuracy: 0.265625\n",
            "Epoch: 7, LR: [2]\n",
            "Train loss: 0.2856817986283984, Train accuracy: 0.3046875\n",
            "Validation loss: 0.27994573967797415, Validation accuracy: 0.34598214285714285\n",
            "Epoch: 8, LR: [2]\n",
            "Train loss: 0.27689783892461234, Train accuracy: 0.33058035714285716\n",
            "Validation loss: 0.27963087814194815, Validation accuracy: 0.30580357142857145\n",
            "Epoch: 9, LR: [2]\n",
            "Train loss: 0.26880543104239873, Train accuracy: 0.3573660714285714\n",
            "Validation loss: 0.259528181382588, Validation accuracy: 0.3794642857142857\n",
            "Epoch: 10, LR: [2]\n",
            "Train loss: 0.26340909004211427, Train accuracy: 0.3783482142857143\n",
            "Validation loss: 0.25425562049661365, Validation accuracy: 0.40848214285714285\n",
            "Epoch: 11, LR: [2]\n",
            "Train loss: 0.2560647821852139, Train accuracy: 0.4078125\n",
            "Validation loss: 0.2579477195228849, Validation accuracy: 0.40401785714285715\n",
            "Epoch: 12, LR: [2]\n",
            "Train loss: 0.2512602039745876, Train accuracy: 0.42566964285714287\n",
            "Validation loss: 0.2555309406348637, Validation accuracy: 0.41294642857142855\n",
            "Epoch: 13, LR: [2]\n",
            "Train loss: 0.24386465570756366, Train accuracy: 0.4484375\n",
            "Validation loss: 0.23181807569095067, Validation accuracy: 0.46205357142857145\n",
            "Epoch: 14, LR: [2]\n",
            "Train loss: 0.2306148301277842, Train accuracy: 0.48995535714285715\n",
            "Validation loss: 0.21857514551707677, Validation accuracy: 0.5022321428571429\n",
            "Epoch: 15, LR: [2]\n",
            "Train loss: 0.22333710534232004, Train accuracy: 0.5084821428571429\n",
            "Validation loss: 0.2163728837456022, Validation accuracy: 0.5022321428571429\n",
            "Epoch: 16, LR: [2]\n",
            "Train loss: 0.2134716700230326, Train accuracy: 0.5430803571428572\n",
            "Validation loss: 0.24869658265795028, Validation accuracy: 0.45982142857142855\n",
            "Epoch: 17, LR: [2]\n",
            "Train loss: 0.20931373898472105, Train accuracy: 0.5571428571428572\n",
            "Validation loss: 0.2400285622903279, Validation accuracy: 0.4888392857142857\n",
            "Epoch: 18, LR: [2]\n",
            "Train loss: 0.19247424261910576, Train accuracy: 0.5955357142857143\n",
            "Validation loss: 0.20221641659736633, Validation accuracy: 0.5714285714285714\n",
            "Epoch: 19, LR: [2]\n",
            "Train loss: 0.18774435754333224, Train accuracy: 0.6049107142857143\n",
            "Validation loss: 0.21109625697135925, Validation accuracy: 0.5691964285714286\n",
            "Epoch: 20, LR: [2]\n",
            "Train loss: 0.1755625821650028, Train accuracy: 0.6428571428571429\n",
            "Validation loss: 0.2083335029227393, Validation accuracy: 0.5491071428571429\n",
            "Epoch: 21, LR: [2]\n",
            "Train loss: 0.1643755799957684, Train accuracy: 0.6640625\n",
            "Validation loss: 0.19198987313679286, Validation accuracy: 0.609375\n",
            "Epoch: 22, LR: [2]\n",
            "Train loss: 0.16021381190844944, Train accuracy: 0.6752232142857143\n",
            "Validation loss: 0.17405630861009871, Validation accuracy: 0.6473214285714286\n",
            "Epoch: 23, LR: [2]\n",
            "Train loss: 0.14845772736838886, Train accuracy: 0.7017857142857142\n",
            "Validation loss: 0.24989811863218034, Validation accuracy: 0.5892857142857143\n",
            "Epoch: 24, LR: [2]\n",
            "Train loss: 0.14414824077061245, Train accuracy: 0.709375\n",
            "Validation loss: 0.24022956831114634, Validation accuracy: 0.6026785714285714\n",
            "Epoch: 25, LR: [2]\n",
            "Train loss: 0.13697485231927464, Train accuracy: 0.7254464285714286\n",
            "Validation loss: 0.18369322376591818, Validation accuracy: 0.6138392857142857\n",
            "Epoch: 26, LR: [2]\n",
            "Train loss: 0.12945553543312208, Train accuracy: 0.7412946428571429\n",
            "Validation loss: 0.13916404013122832, Validation accuracy: 0.7589285714285714\n",
            "Epoch: 27, LR: [2]\n",
            "Train loss: 0.12727825439402035, Train accuracy: 0.7508928571428571\n",
            "Validation loss: 0.13587860869509832, Validation accuracy: 0.7098214285714286\n",
            "Epoch: 28, LR: [2]\n",
            "Train loss: 0.12222296712653978, Train accuracy: 0.7611607142857143\n",
            "Validation loss: 0.12309858628681727, Validation accuracy: 0.7700892857142857\n",
            "Epoch: 29, LR: [2]\n",
            "Train loss: 0.11366023921540805, Train accuracy: 0.7774553571428572\n",
            "Validation loss: 0.20000249786036356, Validation accuracy: 0.6584821428571429\n",
            "Epoch: 30, LR: [2]\n",
            "Train loss: 0.11539203620382718, Train accuracy: 0.7649553571428571\n",
            "Validation loss: 0.1403489730187825, Validation accuracy: 0.7165178571428571\n",
            "Epoch: 31, LR: [2]\n",
            "Train loss: 0.11071149855852128, Train accuracy: 0.7870535714285715\n",
            "Validation loss: 0.1394322525177683, Validation accuracy: 0.75\n",
            "Epoch: 32, LR: [2]\n",
            "Train loss: 0.10334639932428087, Train accuracy: 0.8006696428571428\n",
            "Validation loss: 0.12373882851430348, Validation accuracy: 0.765625\n",
            "Epoch: 33, LR: [2]\n",
            "Train loss: 0.10575672121984618, Train accuracy: 0.7986607142857143\n",
            "Validation loss: 0.11028766632080078, Validation accuracy: 0.7901785714285714\n",
            "Epoch: 34, LR: [2]\n",
            "Train loss: 0.10161859808223588, Train accuracy: 0.8024553571428571\n",
            "Validation loss: 0.12685452933822358, Validation accuracy: 0.7410714285714286\n",
            "Epoch: 35, LR: [2]\n",
            "Train loss: 0.09247873750116144, Train accuracy: 0.8185267857142857\n",
            "Validation loss: 0.10475865645068032, Validation accuracy: 0.8147321428571429\n",
            "Epoch: 36, LR: [2]\n",
            "Train loss: 0.09150648968560356, Train accuracy: 0.8256696428571428\n",
            "Validation loss: 0.10604502792869296, Validation accuracy: 0.7946428571428571\n",
            "Epoch: 37, LR: [2]\n",
            "Train loss: 0.08585062575127397, Train accuracy: 0.8401785714285714\n",
            "Validation loss: 0.12730525327580317, Validation accuracy: 0.7633928571428571\n",
            "Epoch: 38, LR: [2]\n",
            "Train loss: 0.08010682484933308, Train accuracy: 0.8488839285714286\n",
            "Validation loss: 0.1074137996350016, Validation accuracy: 0.7857142857142857\n",
            "Epoch: 39, LR: [2]\n",
            "Train loss: 0.07862455264798232, Train accuracy: 0.8544642857142857\n",
            "Validation loss: 0.1075755927179541, Validation accuracy: 0.8147321428571429\n",
            "Epoch: 40, LR: [2]\n",
            "Train loss: 0.08331269201423441, Train accuracy: 0.8448660714285714\n",
            "Validation loss: 0.12604648513453348, Validation accuracy: 0.7633928571428571\n",
            "Epoch: 41, LR: [2]\n",
            "Train loss: 0.07427483802395207, Train accuracy: 0.8651785714285715\n",
            "Validation loss: 0.10470962417977196, Validation accuracy: 0.8236607142857143\n",
            "Epoch: 42, LR: [2]\n",
            "Train loss: 0.07358058193432433, Train accuracy: 0.8712053571428572\n",
            "Validation loss: 0.09168539196252823, Validation accuracy: 0.828125\n",
            "Epoch: 43, LR: [2]\n",
            "Train loss: 0.0729829598750387, Train accuracy: 0.8625\n",
            "Validation loss: 0.11991209856101445, Validation accuracy: 0.8035714285714286\n",
            "Epoch: 44, LR: [2]\n",
            "Train loss: 0.06676744941089835, Train accuracy: 0.8758928571428571\n",
            "Validation loss: 0.09171374940446445, Validation accuracy: 0.8392857142857143\n",
            "Epoch: 45, LR: [2]\n",
            "Train loss: 0.06681136318615505, Train accuracy: 0.8799107142857143\n",
            "Validation loss: 0.1111372145158904, Validation accuracy: 0.7901785714285714\n",
            "Epoch: 46, LR: [2]\n",
            "Train loss: 0.06423711377595152, Train accuracy: 0.8828125\n",
            "Validation loss: 0.09753810774002757, Validation accuracy: 0.8236607142857143\n",
            "Epoch: 47, LR: [2]\n",
            "Train loss: 0.06450236455670424, Train accuracy: 0.8819196428571429\n",
            "Validation loss: 0.09110827318259648, Validation accuracy: 0.828125\n",
            "Epoch: 48, LR: [2]\n",
            "Train loss: 0.05997066806469645, Train accuracy: 0.8955357142857143\n",
            "Validation loss: 0.11815997532435826, Validation accuracy: 0.7879464285714286\n",
            "Epoch: 49, LR: [2]\n",
            "Train loss: 0.05761421038103955, Train accuracy: 0.8988839285714286\n",
            "Validation loss: 0.09556794858404569, Validation accuracy: 0.8459821428571429\n",
            "Epoch: 50, LR: [0.4]\n",
            "Train loss: 0.03801283333450556, Train accuracy: 0.9352678571428571\n",
            "Validation loss: 0.06735330420945372, Validation accuracy: 0.890625\n",
            "Epoch: 51, LR: [0.4]\n",
            "Train loss: 0.03065571936645678, Train accuracy: 0.9491071428571428\n",
            "Validation loss: 0.06351073405572347, Validation accuracy: 0.8950892857142857\n",
            "Epoch: 52, LR: [0.4]\n",
            "Train loss: 0.028990204885069815, Train accuracy: 0.9529017857142857\n",
            "Validation loss: 0.06458473578095436, Validation accuracy: 0.875\n",
            "Epoch: 53, LR: [0.4]\n",
            "Train loss: 0.026537942074771437, Train accuracy: 0.9580357142857143\n",
            "Validation loss: 0.06267266826970237, Validation accuracy: 0.8973214285714286\n",
            "Epoch: 54, LR: [0.4]\n",
            "Train loss: 0.02545474601377334, Train accuracy: 0.9604910714285714\n",
            "Validation loss: 0.061683383371148794, Validation accuracy: 0.90625\n",
            "Epoch: 55, LR: [0.4]\n",
            "Train loss: 0.023546444079173463, Train accuracy: 0.9611607142857143\n",
            "Validation loss: 0.057583716831036975, Validation accuracy: 0.9040178571428571\n",
            "Epoch: 56, LR: [0.4]\n",
            "Train loss: 0.021881570700289947, Train accuracy: 0.9665178571428571\n",
            "Validation loss: 0.06337924461279597, Validation accuracy: 0.8973214285714286\n",
            "Epoch: 57, LR: [0.4]\n",
            "Train loss: 0.02067801042326859, Train accuracy: 0.9649553571428572\n",
            "Validation loss: 0.06573653061475072, Validation accuracy: 0.875\n",
            "Epoch: 58, LR: [0.4]\n",
            "Train loss: 0.01975901071647448, Train accuracy: 0.9676339285714286\n",
            "Validation loss: 0.06791960235152926, Validation accuracy: 0.875\n",
            "Epoch: 59, LR: [0.4]\n",
            "Train loss: 0.019792882685682602, Train accuracy: 0.9685267857142857\n",
            "Validation loss: 0.06075592205992767, Validation accuracy: 0.8973214285714286\n",
            "Epoch: 60, LR: [0.4]\n",
            "Train loss: 0.020485499860452755, Train accuracy: 0.9651785714285714\n",
            "Validation loss: 0.06612941888826233, Validation accuracy: 0.8816964285714286\n",
            "Epoch: 61, LR: [0.4]\n",
            "Train loss: 0.01894535053787487, Train accuracy: 0.9729910714285714\n",
            "Validation loss: 0.07847984933427402, Validation accuracy: 0.8839285714285714\n",
            "Epoch: 62, LR: [0.4]\n",
            "Train loss: 0.016887790696429355, Train accuracy: 0.9765625\n",
            "Validation loss: 0.07264236600271293, Validation accuracy: 0.8794642857142857\n",
            "Epoch: 63, LR: [0.4]\n",
            "Train loss: 0.017728369024449162, Train accuracy: 0.9723214285714286\n",
            "Validation loss: 0.06629918089934758, Validation accuracy: 0.875\n",
            "Epoch: 64, LR: [0.08000000000000002]\n",
            "Train loss: 0.014757002471014857, Train accuracy: 0.9794642857142857\n",
            "Validation loss: 0.05511730483600071, Validation accuracy: 0.9084821428571429\n",
            "Epoch: 65, LR: [0.08000000000000002]\n",
            "Train loss: 0.012822527571448259, Train accuracy: 0.9837053571428571\n",
            "Validation loss: 0.059759726215686114, Validation accuracy: 0.9084821428571429\n",
            "Epoch: 66, LR: [0.08000000000000002]\n",
            "Train loss: 0.012473164562002889, Train accuracy: 0.9823660714285715\n",
            "Validation loss: 0.05502214016658919, Validation accuracy: 0.90625\n",
            "Epoch: 67, LR: [0.08000000000000002]\n",
            "Train loss: 0.011689702318316059, Train accuracy: 0.9859375\n",
            "Validation loss: 0.06995234532015664, Validation accuracy: 0.8883928571428571\n",
            "Epoch: 68, LR: [0.08000000000000002]\n",
            "Train loss: 0.011757958894928118, Train accuracy: 0.9821428571428571\n",
            "Validation loss: 0.0669451214905296, Validation accuracy: 0.90625\n",
            "Epoch: 69, LR: [0.08000000000000002]\n",
            "Train loss: 0.011271736837391343, Train accuracy: 0.9868303571428572\n",
            "Validation loss: 0.06437883153557777, Validation accuracy: 0.90625\n",
            "Epoch: 70, LR: [0.08000000000000002]\n",
            "Train loss: 0.010659142477171762, Train accuracy: 0.9861607142857143\n",
            "Validation loss: 0.061478418963296075, Validation accuracy: 0.8950892857142857\n",
            "Target number of exemplars per class: 200\n",
            "Target total number of exemplars: 2000\n",
            "Randomly extracting exemplars from class 0 of current split... Extracted 200 exemplars.\n",
            "Randomly extracting exemplars from class 1 of current split... Extracted 200 exemplars.\n",
            "Randomly extracting exemplars from class 2 of current split... Extracted 200 exemplars.\n",
            "Randomly extracting exemplars from class 3 of current split... Extracted 200 exemplars.\n",
            "Randomly extracting exemplars from class 4 of current split... Extracted 200 exemplars.\n",
            "Randomly extracting exemplars from class 5 of current split... Extracted 200 exemplars.\n",
            "Randomly extracting exemplars from class 6 of current split... Extracted 200 exemplars.\n",
            "Randomly extracting exemplars from class 7 of current split... Extracted 200 exemplars.\n",
            "Randomly extracting exemplars from class 8 of current split... Extracted 200 exemplars.\n",
            "Randomly extracting exemplars from class 9 of current split... Extracted 200 exemplars.\n",
            "Computing mean of exemplars... done\n",
            "Test accuracy (iCaRL): 0.901 (exemplars and training data)\n",
            "## Split 1 of run 0 ##\n",
            "Length of exemplars set: 2000\n",
            "Epoch: 1, LR: [3]\n",
            "Train loss: 0.20327060057385132, Train accuracy: 0.34560643564356436\n",
            "Validation loss: 0.2261185688631875, Validation accuracy: 0.24107142857142858\n",
            "Epoch: 2, LR: [3]\n",
            "Train loss: 0.17326616222905641, Train accuracy: 0.49814356435643564\n",
            "Validation loss: 0.21029316101755416, Validation accuracy: 0.30357142857142855\n",
            "Epoch: 3, LR: [3]\n",
            "Train loss: 0.16501815912157003, Train accuracy: 0.5586324257425742\n",
            "Validation loss: 0.19325221010616847, Validation accuracy: 0.39732142857142855\n",
            "Epoch: 4, LR: [3]\n",
            "Train loss: 0.16052704577398771, Train accuracy: 0.6016398514851485\n",
            "Validation loss: 0.20005319799695695, Validation accuracy: 0.375\n",
            "Epoch: 5, LR: [3]\n",
            "Train loss: 0.1560648920217363, Train accuracy: 0.6285581683168316\n",
            "Validation loss: 0.19562377887112753, Validation accuracy: 0.4263392857142857\n",
            "Epoch: 6, LR: [3]\n",
            "Train loss: 0.1554288842742986, Train accuracy: 0.6352103960396039\n",
            "Validation loss: 0.17829870751925878, Validation accuracy: 0.47767857142857145\n",
            "Epoch: 7, LR: [3]\n",
            "Train loss: 0.15210481969141723, Train accuracy: 0.6594987623762376\n",
            "Validation loss: 0.18103396892547607, Validation accuracy: 0.45535714285714285\n",
            "Epoch: 8, LR: [3]\n",
            "Train loss: 0.1508586011310615, Train accuracy: 0.6737314356435643\n",
            "Validation loss: 0.18241525760718755, Validation accuracy: 0.48214285714285715\n",
            "Epoch: 9, LR: [3]\n",
            "Train loss: 0.14982299499287463, Train accuracy: 0.6836324257425742\n",
            "Validation loss: 0.16035887386117662, Validation accuracy: 0.5044642857142857\n",
            "Epoch: 10, LR: [3]\n",
            "Train loss: 0.14696592564630037, Train accuracy: 0.6933787128712872\n",
            "Validation loss: 0.1917990062917982, Validation accuracy: 0.4486607142857143\n",
            "Epoch: 11, LR: [3]\n",
            "Train loss: 0.1454936676096208, Train accuracy: 0.7025061881188119\n",
            "Validation loss: 0.17415226570197515, Validation accuracy: 0.5245535714285714\n",
            "Epoch: 12, LR: [3]\n",
            "Train loss: 0.14466291813567134, Train accuracy: 0.7052908415841584\n",
            "Validation loss: 0.20626600299562728, Validation accuracy: 0.45089285714285715\n",
            "Epoch: 13, LR: [3]\n",
            "Train loss: 0.1438636731098194, Train accuracy: 0.7179764851485149\n",
            "Validation loss: 0.1734295700277601, Validation accuracy: 0.5044642857142857\n",
            "Epoch: 14, LR: [3]\n",
            "Train loss: 0.14220564141131864, Train accuracy: 0.7255569306930693\n",
            "Validation loss: 0.2029237768479756, Validation accuracy: 0.46651785714285715\n",
            "Epoch: 15, LR: [3]\n",
            "Train loss: 0.14147294497135843, Train accuracy: 0.7244740099009901\n",
            "Validation loss: 0.23940643668174744, Validation accuracy: 0.41964285714285715\n",
            "Epoch: 16, LR: [3]\n",
            "Train loss: 0.13949839055243105, Train accuracy: 0.7382425742574258\n",
            "Validation loss: 0.21514407226017543, Validation accuracy: 0.46875\n",
            "Epoch: 17, LR: [3]\n",
            "Train loss: 0.1410627004386175, Train accuracy: 0.7360767326732673\n",
            "Validation loss: 0.1789465844631195, Validation accuracy: 0.5267857142857143\n",
            "Epoch: 18, LR: [3]\n",
            "Train loss: 0.13841282222235557, Train accuracy: 0.7501547029702971\n",
            "Validation loss: 0.17122921986239298, Validation accuracy: 0.5379464285714286\n",
            "Epoch: 19, LR: [3]\n",
            "Train loss: 0.13752073661820724, Train accuracy: 0.7532487623762376\n",
            "Validation loss: 0.19120373257568904, Validation accuracy: 0.5290178571428571\n",
            "Epoch: 20, LR: [3]\n",
            "Train loss: 0.137303959172551, Train accuracy: 0.7594368811881188\n",
            "Validation loss: 0.2023225107363292, Validation accuracy: 0.5022321428571429\n",
            "Epoch: 21, LR: [3]\n",
            "Train loss: 0.13570432401824706, Train accuracy: 0.7701113861386139\n",
            "Validation loss: 0.1996434884411948, Validation accuracy: 0.5267857142857143\n",
            "Epoch: 22, LR: [3]\n",
            "Train loss: 0.13721247710803947, Train accuracy: 0.7625309405940595\n",
            "Validation loss: 0.19431746006011963, Validation accuracy: 0.5022321428571429\n",
            "Epoch: 23, LR: [3]\n",
            "Train loss: 0.13526076019400418, Train accuracy: 0.7704207920792079\n",
            "Validation loss: 0.21809147085462297, Validation accuracy: 0.5446428571428571\n",
            "Epoch: 24, LR: [3]\n",
            "Train loss: 0.13692047336313984, Train accuracy: 0.7657797029702971\n",
            "Validation loss: 0.17568567182336534, Validation accuracy: 0.5334821428571429\n",
            "Epoch: 25, LR: [3]\n",
            "Train loss: 0.1349090171037334, Train accuracy: 0.7728960396039604\n",
            "Validation loss: 0.20084186111177718, Validation accuracy: 0.5022321428571429\n",
            "Epoch: 26, LR: [3]\n",
            "Train loss: 0.13327519566115767, Train accuracy: 0.7823329207920792\n",
            "Validation loss: 0.19159711258752005, Validation accuracy: 0.5044642857142857\n",
            "Epoch: 27, LR: [3]\n",
            "Train loss: 0.13612659260778143, Train accuracy: 0.7735148514851485\n",
            "Validation loss: 0.19420369395187922, Validation accuracy: 0.484375\n",
            "Epoch: 28, LR: [3]\n",
            "Train loss: 0.1333063020564542, Train accuracy: 0.7795482673267327\n",
            "Validation loss: 0.19247106356280191, Validation accuracy: 0.5691964285714286\n",
            "Epoch: 29, LR: [3]\n",
            "Train loss: 0.13279684278929588, Train accuracy: 0.7834158415841584\n",
            "Validation loss: 0.2173488289117813, Validation accuracy: 0.5\n",
            "Epoch: 30, LR: [3]\n",
            "Train loss: 0.1337289189053054, Train accuracy: 0.7874381188118812\n",
            "Validation loss: 0.17068663239479065, Validation accuracy: 0.6004464285714286\n",
            "Epoch: 31, LR: [3]\n",
            "Train loss: 0.13040229921588803, Train accuracy: 0.7923886138613861\n",
            "Validation loss: 0.17542241087981633, Validation accuracy: 0.5513392857142857\n",
            "Epoch: 32, LR: [3]\n",
            "Train loss: 0.1297382954323646, Train accuracy: 0.8046101485148515\n",
            "Validation loss: 0.18552017424787795, Validation accuracy: 0.5178571428571429\n",
            "Epoch: 33, LR: [3]\n",
            "Train loss: 0.13334951284203198, Train accuracy: 0.7886757425742574\n",
            "Validation loss: 0.19163982570171356, Validation accuracy: 0.5491071428571429\n",
            "Epoch: 34, LR: [3]\n",
            "Train loss: 0.1291511106756654, Train accuracy: 0.802444306930693\n",
            "Validation loss: 0.14229480496474675, Validation accuracy: 0.6205357142857143\n",
            "Epoch: 35, LR: [3]\n",
            "Train loss: 0.12923357089852341, Train accuracy: 0.8002784653465347\n",
            "Validation loss: 0.17373641473906382, Validation accuracy: 0.6339285714285714\n",
            "Epoch: 36, LR: [3]\n",
            "Train loss: 0.13020114659672916, Train accuracy: 0.8107982673267327\n",
            "Validation loss: 0.16352053625243052, Validation accuracy: 0.5803571428571429\n",
            "Epoch: 37, LR: [3]\n",
            "Train loss: 0.13131449828938682, Train accuracy: 0.8012066831683168\n",
            "Validation loss: 0.210896658045905, Validation accuracy: 0.5379464285714286\n",
            "Epoch: 38, LR: [3]\n",
            "Train loss: 0.13180796182391666, Train accuracy: 0.7981126237623762\n",
            "Validation loss: 0.17141993130956376, Validation accuracy: 0.5669642857142857\n",
            "Epoch: 39, LR: [3]\n",
            "Train loss: 0.12687504239896735, Train accuracy: 0.8191522277227723\n",
            "Validation loss: 0.18751247440065658, Validation accuracy: 0.5580357142857143\n",
            "Epoch: 40, LR: [3]\n",
            "Train loss: 0.12966011162146485, Train accuracy: 0.8050742574257426\n",
            "Validation loss: 0.2042631698506219, Validation accuracy: 0.5446428571428571\n",
            "Epoch: 41, LR: [3]\n",
            "Train loss: 0.12979326190629809, Train accuracy: 0.8117264851485149\n",
            "Validation loss: 0.19592863534178054, Validation accuracy: 0.5401785714285714\n",
            "Epoch: 42, LR: [3]\n",
            "Train loss: 0.12842631081838418, Train accuracy: 0.8146658415841584\n",
            "Validation loss: 0.16864648461341858, Validation accuracy: 0.5870535714285714\n",
            "Epoch: 43, LR: [3]\n",
            "Train loss: 0.12825292850484943, Train accuracy: 0.8182240099009901\n",
            "Validation loss: 0.15384973266295024, Validation accuracy: 0.640625\n",
            "Epoch: 44, LR: [3]\n",
            "Train loss: 0.12861547434684073, Train accuracy: 0.818069306930693\n",
            "Validation loss: 0.1886858833687646, Validation accuracy: 0.5401785714285714\n",
            "Epoch: 45, LR: [3]\n",
            "Train loss: 0.12913102678733296, Train accuracy: 0.8159034653465347\n",
            "Validation loss: 0.18281821055071695, Validation accuracy: 0.5892857142857143\n",
            "Epoch: 46, LR: [3]\n",
            "Train loss: 0.12693827105040598, Train accuracy: 0.8318378712871287\n",
            "Validation loss: 0.17062728532723018, Validation accuracy: 0.6071428571428571\n",
            "Epoch: 47, LR: [3]\n",
            "Train loss: 0.12799479347644466, Train accuracy: 0.8194616336633663\n",
            "Validation loss: 0.17588174768856593, Validation accuracy: 0.5915178571428571\n",
            "Epoch: 48, LR: [3]\n",
            "Train loss: 0.1269269129722425, Train accuracy: 0.8234839108910891\n",
            "Validation loss: 0.17857658863067627, Validation accuracy: 0.6294642857142857\n",
            "Epoch: 49, LR: [3]\n",
            "Train loss: 0.12664132351332372, Train accuracy: 0.818069306930693\n",
            "Validation loss: 0.1877080989735467, Validation accuracy: 0.578125\n",
            "Epoch: 50, LR: [0.6000000000000001]\n",
            "Train loss: 0.11505704114932826, Train accuracy: 0.8779393564356436\n",
            "Validation loss: 0.17551277577877045, Validation accuracy: 0.6205357142857143\n",
            "Epoch: 51, LR: [0.6000000000000001]\n",
            "Train loss: 0.10957209227403791, Train accuracy: 0.9019183168316832\n",
            "Validation loss: 0.16657778833593642, Validation accuracy: 0.6607142857142857\n",
            "Epoch: 52, LR: [0.6000000000000001]\n",
            "Train loss: 0.10812567934246346, Train accuracy: 0.9085705445544554\n",
            "Validation loss: 0.17919794363634928, Validation accuracy: 0.6339285714285714\n",
            "Epoch: 53, LR: [0.6000000000000001]\n",
            "Train loss: 0.10669648094047414, Train accuracy: 0.9200185643564357\n",
            "Validation loss: 0.1807731602873121, Validation accuracy: 0.6517857142857143\n",
            "Epoch: 54, LR: [0.6000000000000001]\n",
            "Train loss: 0.1054472103714943, Train accuracy: 0.9211014851485149\n",
            "Validation loss: 0.18070071297032492, Validation accuracy: 0.6517857142857143\n",
            "Epoch: 55, LR: [0.6000000000000001]\n",
            "Train loss: 0.10518381515941998, Train accuracy: 0.9237314356435643\n",
            "Validation loss: 0.18325001852852957, Validation accuracy: 0.6584821428571429\n",
            "Epoch: 56, LR: [0.6000000000000001]\n",
            "Train loss: 0.10422820634771102, Train accuracy: 0.9300742574257426\n",
            "Validation loss: 0.16595961579254695, Validation accuracy: 0.6897321428571429\n",
            "Epoch: 57, LR: [0.6000000000000001]\n",
            "Train loss: 0.10462608431825543, Train accuracy: 0.9266707920792079\n",
            "Validation loss: 0.18524526059627533, Validation accuracy: 0.6629464285714286\n",
            "Epoch: 58, LR: [0.6000000000000001]\n",
            "Train loss: 0.10407304535112759, Train accuracy: 0.9331683168316832\n",
            "Validation loss: 0.1733189501932689, Validation accuracy: 0.6674107142857143\n",
            "Epoch: 59, LR: [0.6000000000000001]\n",
            "Train loss: 0.10319265907648767, Train accuracy: 0.937809405940594\n",
            "Validation loss: 0.19049087379659926, Validation accuracy: 0.6473214285714286\n",
            "Epoch: 60, LR: [0.6000000000000001]\n",
            "Train loss: 0.10346234641452827, Train accuracy: 0.9376547029702971\n",
            "Validation loss: 0.1918367828641619, Validation accuracy: 0.6763392857142857\n",
            "Epoch: 61, LR: [0.6000000000000001]\n",
            "Train loss: 0.10385750182489357, Train accuracy: 0.9393564356435643\n",
            "Validation loss: 0.18246999382972717, Validation accuracy: 0.6428571428571429\n",
            "Epoch: 62, LR: [0.6000000000000001]\n",
            "Train loss: 0.10282277854362337, Train accuracy: 0.9421410891089109\n",
            "Validation loss: 0.17917963649545396, Validation accuracy: 0.6741071428571429\n",
            "Epoch: 63, LR: [0.6000000000000001]\n",
            "Train loss: 0.10253586266005393, Train accuracy: 0.9390470297029703\n",
            "Validation loss: 0.18989141711166926, Validation accuracy: 0.6651785714285714\n",
            "Epoch: 64, LR: [0.12000000000000002]\n",
            "Train loss: 0.10210305275303302, Train accuracy: 0.948019801980198\n",
            "Validation loss: 0.18771076841013773, Validation accuracy: 0.6517857142857143\n",
            "Epoch: 65, LR: [0.12000000000000002]\n",
            "Train loss: 0.10117060477190679, Train accuracy: 0.953125\n",
            "Validation loss: 0.18288537859916687, Validation accuracy: 0.6763392857142857\n",
            "Epoch: 66, LR: [0.12000000000000002]\n",
            "Train loss: 0.1011596171572657, Train accuracy: 0.9517326732673267\n",
            "Validation loss: 0.19018554474626267, Validation accuracy: 0.6629464285714286\n",
            "Epoch: 67, LR: [0.12000000000000002]\n",
            "Train loss: 0.10209836412479381, Train accuracy: 0.9525061881188119\n",
            "Validation loss: 0.1822668888739177, Validation accuracy: 0.6428571428571429\n",
            "Epoch: 68, LR: [0.12000000000000002]\n",
            "Train loss: 0.10092764605980108, Train accuracy: 0.9565284653465347\n",
            "Validation loss: 0.18923336906092508, Validation accuracy: 0.6517857142857143\n",
            "Epoch: 69, LR: [0.12000000000000002]\n",
            "Train loss: 0.10134439671983814, Train accuracy: 0.9494121287128713\n",
            "Validation loss: 0.18801922031811305, Validation accuracy: 0.6540178571428571\n",
            "Epoch: 70, LR: [0.12000000000000002]\n",
            "Train loss: 0.10067600823274933, Train accuracy: 0.9569925742574258\n",
            "Validation loss: 0.18993338303906576, Validation accuracy: 0.671875\n",
            "Target number of exemplars per class: 100\n",
            "Target total number of exemplars: 2000\n",
            "Randomly extracting exemplars from class 0 of current split... Extracted 100 exemplars.\n",
            "Randomly extracting exemplars from class 1 of current split... Extracted 100 exemplars.\n",
            "Randomly extracting exemplars from class 2 of current split... Extracted 100 exemplars.\n",
            "Randomly extracting exemplars from class 3 of current split... Extracted 100 exemplars.\n",
            "Randomly extracting exemplars from class 4 of current split... Extracted 100 exemplars.\n",
            "Randomly extracting exemplars from class 5 of current split... Extracted 100 exemplars.\n",
            "Randomly extracting exemplars from class 6 of current split... Extracted 100 exemplars.\n",
            "Randomly extracting exemplars from class 7 of current split... Extracted 100 exemplars.\n",
            "Randomly extracting exemplars from class 8 of current split... Extracted 100 exemplars.\n",
            "Randomly extracting exemplars from class 9 of current split... Extracted 100 exemplars.\n",
            "Computing mean of exemplars... done\n",
            "Test accuracy (iCaRL): 0.809 (exemplars and training data)\n",
            "## Split 2 of run 0 ##\n",
            "Length of exemplars set: 2000\n",
            "Epoch: 1, LR: [3]\n",
            "Train loss: 0.20212852586023877, Train accuracy: 0.34452351485148514\n",
            "Validation loss: 0.17322225655828202, Validation accuracy: 0.15625\n",
            "Epoch: 2, LR: [3]\n",
            "Train loss: 0.1792314595515185, Train accuracy: 0.46782178217821785\n",
            "Validation loss: 0.15413769228117807, Validation accuracy: 0.24776785714285715\n",
            "Epoch: 3, LR: [3]\n",
            "Train loss: 0.17450519894609356, Train accuracy: 0.5283106435643564\n",
            "Validation loss: 0.13542837223836354, Validation accuracy: 0.32589285714285715\n",
            "Epoch: 4, LR: [3]\n",
            "Train loss: 0.17261855259980305, Train accuracy: 0.5609529702970297\n",
            "Validation loss: 0.11773210338183812, Validation accuracy: 0.4174107142857143\n",
            "Epoch: 5, LR: [3]\n",
            "Train loss: 0.17013423410382603, Train accuracy: 0.5853960396039604\n",
            "Validation loss: 0.1433920477117811, Validation accuracy: 0.31473214285714285\n",
            "Epoch: 6, LR: [3]\n",
            "Train loss: 0.16873333256433506, Train accuracy: 0.604269801980198\n",
            "Validation loss: 0.1494084596633911, Validation accuracy: 0.4107142857142857\n",
            "Epoch: 7, LR: [3]\n",
            "Train loss: 0.16826277572919826, Train accuracy: 0.6192759900990099\n",
            "Validation loss: 0.13263515063694545, Validation accuracy: 0.40401785714285715\n",
            "Epoch: 8, LR: [3]\n",
            "Train loss: 0.16640358115776932, Train accuracy: 0.6287128712871287\n",
            "Validation loss: 0.18255233126027243, Validation accuracy: 0.28125\n",
            "Epoch: 9, LR: [3]\n",
            "Train loss: 0.16604489073304846, Train accuracy: 0.6381497524752475\n",
            "Validation loss: 0.1385574553694044, Validation accuracy: 0.4575892857142857\n",
            "Epoch: 10, LR: [3]\n",
            "Train loss: 0.16534056403849384, Train accuracy: 0.65625\n",
            "Validation loss: 0.1388444368328367, Validation accuracy: 0.4174107142857143\n",
            "Epoch: 11, LR: [3]\n",
            "Train loss: 0.16481822802878843, Train accuracy: 0.6547029702970297\n",
            "Validation loss: 0.12635274976491928, Validation accuracy: 0.44642857142857145\n",
            "Epoch: 12, LR: [3]\n",
            "Train loss: 0.16215581646059998, Train accuracy: 0.6743502475247525\n",
            "Validation loss: 0.15923174789973668, Validation accuracy: 0.4017857142857143\n",
            "Epoch: 13, LR: [3]\n",
            "Train loss: 0.16375598606496755, Train accuracy: 0.6714108910891089\n",
            "Validation loss: 0.12250686756202153, Validation accuracy: 0.4799107142857143\n",
            "Epoch: 14, LR: [3]\n",
            "Train loss: 0.16324305829435293, Train accuracy: 0.676980198019802\n",
            "Validation loss: 0.122410420860563, Validation accuracy: 0.484375\n",
            "Epoch: 15, LR: [3]\n",
            "Train loss: 0.16181160125992086, Train accuracy: 0.6885829207920792\n",
            "Validation loss: 0.1439869361264365, Validation accuracy: 0.4419642857142857\n",
            "Epoch: 16, LR: [3]\n",
            "Train loss: 0.1615979681805809, Train accuracy: 0.6921410891089109\n",
            "Validation loss: 0.12935364246368408, Validation accuracy: 0.47767857142857145\n",
            "Epoch: 17, LR: [3]\n",
            "Train loss: 0.16069985395020778, Train accuracy: 0.6995668316831684\n",
            "Validation loss: 0.1260403192469052, Validation accuracy: 0.5133928571428571\n",
            "Epoch: 18, LR: [3]\n",
            "Train loss: 0.16106588518855594, Train accuracy: 0.6998762376237624\n",
            "Validation loss: 0.12222287058830261, Validation accuracy: 0.5044642857142857\n",
            "Epoch: 19, LR: [3]\n",
            "Train loss: 0.16121269733008772, Train accuracy: 0.6972462871287128\n",
            "Validation loss: 0.12064812758139201, Validation accuracy: 0.44419642857142855\n",
            "Epoch: 20, LR: [3]\n",
            "Train loss: 0.15981126938125875, Train accuracy: 0.7147277227722773\n",
            "Validation loss: 0.12156706090484347, Validation accuracy: 0.5111607142857143\n",
            "Epoch: 21, LR: [3]\n",
            "Train loss: 0.15936654983180584, Train accuracy: 0.7159653465346535\n",
            "Validation loss: 0.13069297692605428, Validation accuracy: 0.5022321428571429\n",
            "Epoch: 22, LR: [3]\n",
            "Train loss: 0.15786972523915885, Train accuracy: 0.7189047029702971\n",
            "Validation loss: 0.11641493013926915, Validation accuracy: 0.5290178571428571\n",
            "Epoch: 23, LR: [3]\n",
            "Train loss: 0.1583514799280922, Train accuracy: 0.7298886138613861\n",
            "Validation loss: 0.14972580330712454, Validation accuracy: 0.46875\n",
            "Epoch: 24, LR: [3]\n",
            "Train loss: 0.1584328879224192, Train accuracy: 0.7227722772277227\n",
            "Validation loss: 0.13130888129983628, Validation accuracy: 0.515625\n",
            "Epoch: 25, LR: [3]\n",
            "Train loss: 0.15775427473063516, Train accuracy: 0.7360767326732673\n",
            "Validation loss: 0.15823233872652054, Validation accuracy: 0.4107142857142857\n",
            "Epoch: 26, LR: [3]\n",
            "Train loss: 0.1584873898784713, Train accuracy: 0.7229269801980198\n",
            "Validation loss: 0.1102770556296621, Validation accuracy: 0.6004464285714286\n",
            "Epoch: 27, LR: [3]\n",
            "Train loss: 0.15741579677208817, Train accuracy: 0.739634900990099\n",
            "Validation loss: 0.10732623615435191, Validation accuracy: 0.5625\n",
            "Epoch: 28, LR: [3]\n",
            "Train loss: 0.1562461522546145, Train accuracy: 0.7379331683168316\n",
            "Validation loss: 0.12484415833439146, Validation accuracy: 0.5602678571428571\n",
            "Epoch: 29, LR: [3]\n",
            "Train loss: 0.1553840430656282, Train accuracy: 0.7439665841584159\n",
            "Validation loss: 0.10642566744770322, Validation accuracy: 0.5267857142857143\n",
            "Epoch: 30, LR: [3]\n",
            "Train loss: 0.15590943071511712, Train accuracy: 0.7478341584158416\n",
            "Validation loss: 0.1171089346919741, Validation accuracy: 0.5625\n",
            "Epoch: 31, LR: [3]\n",
            "Train loss: 0.15476534050880092, Train accuracy: 0.7571163366336634\n",
            "Validation loss: 0.1302184792501586, Validation accuracy: 0.45535714285714285\n",
            "Epoch: 32, LR: [3]\n",
            "Train loss: 0.15407708434775325, Train accuracy: 0.7657797029702971\n",
            "Validation loss: 0.13808019778558187, Validation accuracy: 0.4642857142857143\n",
            "Epoch: 33, LR: [3]\n",
            "Train loss: 0.15436056108758, Train accuracy: 0.7609839108910891\n",
            "Validation loss: 0.14682068356445857, Validation accuracy: 0.5044642857142857\n",
            "Epoch: 34, LR: [3]\n",
            "Train loss: 0.15447550539923185, Train accuracy: 0.7591274752475248\n",
            "Validation loss: 0.12703697276966913, Validation accuracy: 0.5334821428571429\n",
            "Epoch: 35, LR: [3]\n",
            "Train loss: 0.15518863145077583, Train accuracy: 0.7560334158415841\n",
            "Validation loss: 0.10867722864661898, Validation accuracy: 0.5825892857142857\n",
            "Epoch: 36, LR: [3]\n",
            "Train loss: 0.15414670699893837, Train accuracy: 0.765934405940594\n",
            "Validation loss: 0.12903442340237753, Validation accuracy: 0.5513392857142857\n",
            "Epoch: 37, LR: [3]\n",
            "Train loss: 0.15344803079520122, Train accuracy: 0.765934405940594\n",
            "Validation loss: 0.1306769134742873, Validation accuracy: 0.53125\n",
            "Epoch: 38, LR: [3]\n",
            "Train loss: 0.15351098141457775, Train accuracy: 0.7611386138613861\n",
            "Validation loss: 0.12184443431241172, Validation accuracy: 0.5089285714285714\n",
            "Epoch: 39, LR: [3]\n",
            "Train loss: 0.1540380195520892, Train accuracy: 0.7724319306930693\n",
            "Validation loss: 0.1337193867989949, Validation accuracy: 0.5558035714285714\n",
            "Epoch: 40, LR: [3]\n",
            "Train loss: 0.15245590764697237, Train accuracy: 0.7718131188118812\n",
            "Validation loss: 0.10811009790216174, Validation accuracy: 0.6116071428571429\n",
            "Epoch: 41, LR: [3]\n",
            "Train loss: 0.15368073809855054, Train accuracy: 0.7677908415841584\n",
            "Validation loss: 0.1590920239686966, Validation accuracy: 0.42410714285714285\n",
            "Epoch: 42, LR: [3]\n",
            "Train loss: 0.1542922410339412, Train accuracy: 0.7690284653465347\n",
            "Validation loss: 0.1188652366399765, Validation accuracy: 0.546875\n",
            "Epoch: 43, LR: [3]\n",
            "Train loss: 0.1534952100845847, Train accuracy: 0.7693378712871287\n",
            "Validation loss: 0.1272820383310318, Validation accuracy: 0.5959821428571429\n",
            "Epoch: 44, LR: [3]\n",
            "Train loss: 0.150949954839036, Train accuracy: 0.7886757425742574\n",
            "Validation loss: 0.13806905171700887, Validation accuracy: 0.5379464285714286\n",
            "Epoch: 45, LR: [3]\n",
            "Train loss: 0.151100958190342, Train accuracy: 0.7906868811881188\n",
            "Validation loss: 0.11601722346884864, Validation accuracy: 0.5848214285714286\n",
            "Epoch: 46, LR: [3]\n",
            "Train loss: 0.15335320983782852, Train accuracy: 0.7770730198019802\n",
            "Validation loss: 0.1333745036806379, Validation accuracy: 0.5401785714285714\n",
            "Epoch: 47, LR: [3]\n",
            "Train loss: 0.15209043616115456, Train accuracy: 0.7767636138613861\n",
            "Validation loss: 0.12774332399879182, Validation accuracy: 0.5602678571428571\n",
            "Epoch: 48, LR: [3]\n",
            "Train loss: 0.15163072515832315, Train accuracy: 0.7838799504950495\n",
            "Validation loss: 0.13121139790330613, Validation accuracy: 0.5022321428571429\n",
            "Epoch: 49, LR: [3]\n",
            "Train loss: 0.15238364070358842, Train accuracy: 0.7770730198019802\n",
            "Validation loss: 0.1317587462919099, Validation accuracy: 0.5535714285714286\n",
            "Epoch: 50, LR: [0.6000000000000001]\n",
            "Train loss: 0.14090648256611116, Train accuracy: 0.8456064356435643\n",
            "Validation loss: 0.11384775596005577, Validation accuracy: 0.609375\n",
            "Epoch: 51, LR: [0.6000000000000001]\n",
            "Train loss: 0.13663378527553954, Train accuracy: 0.8777846534653465\n",
            "Validation loss: 0.1167264176266534, Validation accuracy: 0.6071428571428571\n",
            "Epoch: 52, LR: [0.6000000000000001]\n",
            "Train loss: 0.1351727368955565, Train accuracy: 0.8869121287128713\n",
            "Validation loss: 0.1145540720650128, Validation accuracy: 0.640625\n",
            "Epoch: 53, LR: [0.6000000000000001]\n",
            "Train loss: 0.13433950490290575, Train accuracy: 0.8994430693069307\n",
            "Validation loss: 0.11482420244387218, Validation accuracy: 0.6361607142857143\n",
            "Epoch: 54, LR: [0.6000000000000001]\n",
            "Train loss: 0.1343937523589276, Train accuracy: 0.8978960396039604\n",
            "Validation loss: 0.11935062067849296, Validation accuracy: 0.6160714285714286\n",
            "Epoch: 55, LR: [0.6000000000000001]\n",
            "Train loss: 0.13343803134590093, Train accuracy: 0.9053217821782178\n",
            "Validation loss: 0.1161354152219636, Validation accuracy: 0.6450892857142857\n",
            "Epoch: 56, LR: [0.6000000000000001]\n",
            "Train loss: 0.13262041127032573, Train accuracy: 0.9110457920792079\n",
            "Validation loss: 0.13182071596384048, Validation accuracy: 0.5915178571428571\n",
            "Epoch: 57, LR: [0.6000000000000001]\n",
            "Train loss: 0.13189391098400155, Train accuracy: 0.9026918316831684\n",
            "Validation loss: 0.12534551322460175, Validation accuracy: 0.625\n",
            "Epoch: 58, LR: [0.6000000000000001]\n",
            "Train loss: 0.13211354775594011, Train accuracy: 0.9122834158415841\n",
            "Validation loss: 0.1224500664642879, Validation accuracy: 0.625\n",
            "Epoch: 59, LR: [0.6000000000000001]\n",
            "Train loss: 0.1322445485113871, Train accuracy: 0.9135210396039604\n",
            "Validation loss: 0.11801610567740031, Validation accuracy: 0.6517857142857143\n",
            "Epoch: 60, LR: [0.6000000000000001]\n",
            "Train loss: 0.13125014865752493, Train accuracy: 0.9172339108910891\n",
            "Validation loss: 0.12468158560139793, Validation accuracy: 0.6227678571428571\n",
            "Epoch: 61, LR: [0.6000000000000001]\n",
            "Train loss: 0.1305769523329074, Train accuracy: 0.9170792079207921\n",
            "Validation loss: 0.12798932301146643, Validation accuracy: 0.6205357142857143\n",
            "Epoch: 62, LR: [0.6000000000000001]\n",
            "Train loss: 0.13044203987511077, Train accuracy: 0.9156868811881188\n",
            "Validation loss: 0.13764615676232747, Validation accuracy: 0.6227678571428571\n",
            "Epoch: 63, LR: [0.6000000000000001]\n",
            "Train loss: 0.13062192211941917, Train accuracy: 0.9193997524752475\n",
            "Validation loss: 0.1183180883526802, Validation accuracy: 0.6540178571428571\n",
            "Epoch: 64, LR: [0.12000000000000002]\n",
            "Train loss: 0.1300579145698264, Train accuracy: 0.9320853960396039\n",
            "Validation loss: 0.12345804593392781, Validation accuracy: 0.6473214285714286\n",
            "Epoch: 65, LR: [0.12000000000000002]\n",
            "Train loss: 0.12953232088596514, Train accuracy: 0.9353341584158416\n",
            "Validation loss: 0.12394560554197856, Validation accuracy: 0.6450892857142857\n",
            "Epoch: 66, LR: [0.12000000000000002]\n",
            "Train loss: 0.1295264063052612, Train accuracy: 0.9294554455445545\n",
            "Validation loss: 0.13730420172214508, Validation accuracy: 0.6138392857142857\n",
            "Epoch: 67, LR: [0.12000000000000002]\n",
            "Train loss: 0.12932780857133394, Train accuracy: 0.9302289603960396\n",
            "Validation loss: 0.12318663618394307, Validation accuracy: 0.6428571428571429\n",
            "Epoch: 68, LR: [0.12000000000000002]\n",
            "Train loss: 0.12906786769923598, Train accuracy: 0.9314665841584159\n",
            "Validation loss: 0.12815428099461965, Validation accuracy: 0.6316964285714286\n",
            "Epoch: 69, LR: [0.12000000000000002]\n",
            "Train loss: 0.12884258021517556, Train accuracy: 0.9344059405940595\n",
            "Validation loss: 0.12358020884650094, Validation accuracy: 0.6540178571428571\n",
            "Epoch: 70, LR: [0.12000000000000002]\n",
            "Train loss: 0.12948781775661033, Train accuracy: 0.9344059405940595\n",
            "Validation loss: 0.13149101925747736, Validation accuracy: 0.6339285714285714\n",
            "Target number of exemplars per class: 66\n",
            "Target total number of exemplars: 1980\n",
            "Randomly extracting exemplars from class 0 of current split... Extracted 66 exemplars.\n",
            "Randomly extracting exemplars from class 1 of current split... Extracted 66 exemplars.\n",
            "Randomly extracting exemplars from class 2 of current split... Extracted 66 exemplars.\n",
            "Randomly extracting exemplars from class 3 of current split... Extracted 66 exemplars.\n",
            "Randomly extracting exemplars from class 4 of current split... Extracted 66 exemplars.\n",
            "Randomly extracting exemplars from class 5 of current split... Extracted 66 exemplars.\n",
            "Randomly extracting exemplars from class 6 of current split... Extracted 66 exemplars.\n",
            "Randomly extracting exemplars from class 7 of current split... Extracted 66 exemplars.\n",
            "Randomly extracting exemplars from class 8 of current split... Extracted 66 exemplars.\n",
            "Randomly extracting exemplars from class 9 of current split... Extracted 66 exemplars.\n",
            "Computing mean of exemplars... done\n",
            "Test accuracy (iCaRL): 0.7306666666666667 (exemplars and training data)\n",
            "## Split 3 of run 0 ##\n",
            "Length of exemplars set: 1980\n",
            "Epoch: 1, LR: [3]\n",
            "Train loss: 0.17602372626857002, Train accuracy: 0.4051670792079208\n",
            "Validation loss: 0.13249904662370682, Validation accuracy: 0.19642857142857142\n",
            "Epoch: 2, LR: [3]\n",
            "Train loss: 0.16368414432105452, Train accuracy: 0.5182549504950495\n",
            "Validation loss: 0.12262330204248428, Validation accuracy: 0.2767857142857143\n",
            "Epoch: 3, LR: [3]\n",
            "Train loss: 0.16019929974976152, Train accuracy: 0.5643564356435643\n",
            "Validation loss: 0.1305882324065481, Validation accuracy: 0.3236607142857143\n",
            "Epoch: 4, LR: [3]\n",
            "Train loss: 0.1591554564414638, Train accuracy: 0.5926670792079208\n",
            "Validation loss: 0.11726084777287074, Validation accuracy: 0.31026785714285715\n",
            "Epoch: 5, LR: [3]\n",
            "Train loss: 0.1581838048330628, Train accuracy: 0.6081373762376238\n",
            "Validation loss: 0.12292492815426417, Validation accuracy: 0.33482142857142855\n",
            "Epoch: 6, LR: [3]\n",
            "Train loss: 0.1566065335922902, Train accuracy: 0.6378403465346535\n",
            "Validation loss: 0.11294890514441899, Validation accuracy: 0.4174107142857143\n",
            "Epoch: 7, LR: [3]\n",
            "Train loss: 0.15684012950646994, Train accuracy: 0.6396967821782178\n",
            "Validation loss: 0.10239390496696744, Validation accuracy: 0.5\n",
            "Epoch: 8, LR: [3]\n",
            "Train loss: 0.15651126751805297, Train accuracy: 0.6489789603960396\n",
            "Validation loss: 0.11619631094591958, Validation accuracy: 0.4263392857142857\n",
            "Epoch: 9, LR: [3]\n",
            "Train loss: 0.15634393072364353, Train accuracy: 0.6633663366336634\n",
            "Validation loss: 0.12145004740783147, Validation accuracy: 0.4330357142857143\n",
            "Epoch: 10, LR: [3]\n",
            "Train loss: 0.15533829959902432, Train accuracy: 0.6745049504950495\n",
            "Validation loss: 0.11018814359392438, Validation accuracy: 0.48214285714285715\n",
            "Epoch: 11, LR: [3]\n",
            "Train loss: 0.15440322709555673, Train accuracy: 0.6864170792079208\n",
            "Validation loss: 0.1175424296941076, Validation accuracy: 0.484375\n",
            "Epoch: 12, LR: [3]\n",
            "Train loss: 0.15575738000397635, Train accuracy: 0.6915222772277227\n",
            "Validation loss: 0.11396363164697375, Validation accuracy: 0.38839285714285715\n",
            "Epoch: 13, LR: [3]\n",
            "Train loss: 0.15423175722065538, Train accuracy: 0.6953898514851485\n",
            "Validation loss: 0.11582004066024508, Validation accuracy: 0.46875\n",
            "Epoch: 14, LR: [3]\n",
            "Train loss: 0.1543776654075868, Train accuracy: 0.6918316831683168\n",
            "Validation loss: 0.10427561402320862, Validation accuracy: 0.453125\n",
            "Epoch: 15, LR: [3]\n",
            "Train loss: 0.15411544878884118, Train accuracy: 0.7066831683168316\n",
            "Validation loss: 0.12226661614009313, Validation accuracy: 0.4799107142857143\n",
            "Epoch: 16, LR: [3]\n",
            "Train loss: 0.1538661792136655, Train accuracy: 0.7062190594059405\n",
            "Validation loss: 0.10800506387438093, Validation accuracy: 0.40848214285714285\n",
            "Epoch: 17, LR: [3]\n",
            "Train loss: 0.15361828556155213, Train accuracy: 0.7085396039603961\n",
            "Validation loss: 0.10980164366109031, Validation accuracy: 0.5424107142857143\n",
            "Epoch: 18, LR: [3]\n",
            "Train loss: 0.1526293534748625, Train accuracy: 0.7167388613861386\n",
            "Validation loss: 0.10164343246391841, Validation accuracy: 0.53125\n",
            "Epoch: 19, LR: [3]\n",
            "Train loss: 0.15232477418266901, Train accuracy: 0.7258663366336634\n",
            "Validation loss: 0.11120360983269555, Validation accuracy: 0.48214285714285715\n",
            "Epoch: 20, LR: [3]\n",
            "Train loss: 0.15242037590187374, Train accuracy: 0.7232363861386139\n",
            "Validation loss: 0.13803943991661072, Validation accuracy: 0.359375\n",
            "Epoch: 21, LR: [3]\n",
            "Train loss: 0.15196660131511122, Train accuracy: 0.7312809405940595\n",
            "Validation loss: 0.12215584090777806, Validation accuracy: 0.5111607142857143\n",
            "Epoch: 22, LR: [3]\n",
            "Train loss: 0.152999477221234, Train accuracy: 0.7271039603960396\n",
            "Validation loss: 0.11978470746959959, Validation accuracy: 0.5357142857142857\n",
            "Epoch: 23, LR: [3]\n",
            "Train loss: 0.1527494782268411, Train accuracy: 0.7260210396039604\n",
            "Validation loss: 0.13291066884994507, Validation accuracy: 0.4017857142857143\n",
            "Epoch: 24, LR: [3]\n",
            "Train loss: 0.15280822819412346, Train accuracy: 0.7233910891089109\n",
            "Validation loss: 0.11618257633277349, Validation accuracy: 0.49107142857142855\n",
            "Epoch: 25, LR: [3]\n",
            "Train loss: 0.15183765448556089, Train accuracy: 0.739944306930693\n",
            "Validation loss: 0.11578151477234704, Validation accuracy: 0.47098214285714285\n",
            "Epoch: 26, LR: [3]\n",
            "Train loss: 0.1504435272204994, Train accuracy: 0.7517017326732673\n",
            "Validation loss: 0.12254736253193446, Validation accuracy: 0.5066964285714286\n",
            "Epoch: 27, LR: [3]\n",
            "Train loss: 0.15224482104329778, Train accuracy: 0.7385519801980198\n",
            "Validation loss: 0.11324371503932136, Validation accuracy: 0.5111607142857143\n",
            "Epoch: 28, LR: [3]\n",
            "Train loss: 0.15212361426046578, Train accuracy: 0.7490717821782178\n",
            "Validation loss: 0.11081370072705406, Validation accuracy: 0.5111607142857143\n",
            "Epoch: 29, LR: [3]\n",
            "Train loss: 0.15139019076186833, Train accuracy: 0.7388613861386139\n",
            "Validation loss: 0.11628243540014539, Validation accuracy: 0.5245535714285714\n",
            "Epoch: 30, LR: [3]\n",
            "Train loss: 0.15096383962300744, Train accuracy: 0.7455136138613861\n",
            "Validation loss: 0.10825402928250176, Validation accuracy: 0.5825892857142857\n",
            "Epoch: 31, LR: [3]\n",
            "Train loss: 0.15006221550526005, Train accuracy: 0.7535581683168316\n",
            "Validation loss: 0.1317017993756703, Validation accuracy: 0.4486607142857143\n",
            "Epoch: 32, LR: [3]\n",
            "Train loss: 0.14968199747623784, Train accuracy: 0.7591274752475248\n",
            "Validation loss: 0.11167205657277789, Validation accuracy: 0.5\n",
            "Epoch: 33, LR: [3]\n",
            "Train loss: 0.14968962893627658, Train accuracy: 0.7608292079207921\n",
            "Validation loss: 0.10425444053752082, Validation accuracy: 0.5625\n",
            "Epoch: 34, LR: [3]\n",
            "Train loss: 0.15149018891377025, Train accuracy: 0.7510829207920792\n",
            "Validation loss: 0.11303601094654628, Validation accuracy: 0.53125\n",
            "Epoch: 35, LR: [3]\n",
            "Train loss: 0.15005267883586412, Train accuracy: 0.7623762376237624\n",
            "Validation loss: 0.11784683806555611, Validation accuracy: 0.5379464285714286\n",
            "Epoch: 36, LR: [3]\n",
            "Train loss: 0.14907246016629852, Train accuracy: 0.7645420792079208\n",
            "Validation loss: 0.11987753425325666, Validation accuracy: 0.5044642857142857\n",
            "Epoch: 37, LR: [3]\n",
            "Train loss: 0.15038059061706657, Train accuracy: 0.7578898514851485\n",
            "Validation loss: 0.14212411642074585, Validation accuracy: 0.49776785714285715\n",
            "Epoch: 38, LR: [3]\n",
            "Train loss: 0.15035962468326683, Train accuracy: 0.7523205445544554\n",
            "Validation loss: 0.11826993631465095, Validation accuracy: 0.5379464285714286\n",
            "Epoch: 39, LR: [3]\n",
            "Train loss: 0.1488354570499741, Train accuracy: 0.7648514851485149\n",
            "Validation loss: 0.11884934774466924, Validation accuracy: 0.5401785714285714\n",
            "Epoch: 40, LR: [3]\n",
            "Train loss: 0.1491133431987007, Train accuracy: 0.7685643564356436\n",
            "Validation loss: 0.12065646265234266, Validation accuracy: 0.4888392857142857\n",
            "Epoch: 41, LR: [3]\n",
            "Train loss: 0.1502529357624526, Train accuracy: 0.7597462871287128\n",
            "Validation loss: 0.11109883551086698, Validation accuracy: 0.53125\n",
            "Epoch: 42, LR: [3]\n",
            "Train loss: 0.1484458558630235, Train accuracy: 0.7704207920792079\n",
            "Validation loss: 0.13413571566343307, Validation accuracy: 0.45535714285714285\n",
            "Epoch: 43, LR: [3]\n",
            "Train loss: 0.15000665143574818, Train accuracy: 0.7612933168316832\n",
            "Validation loss: 0.11324664524623326, Validation accuracy: 0.5691964285714286\n",
            "Epoch: 44, LR: [3]\n",
            "Train loss: 0.1501704608597378, Train accuracy: 0.7599009900990099\n",
            "Validation loss: 0.12388418721301216, Validation accuracy: 0.5044642857142857\n",
            "Epoch: 45, LR: [3]\n",
            "Train loss: 0.14947608482129504, Train accuracy: 0.7665532178217822\n",
            "Validation loss: 0.11765341034957341, Validation accuracy: 0.5357142857142857\n",
            "Epoch: 46, LR: [3]\n",
            "Train loss: 0.1488575017688298, Train accuracy: 0.7739789603960396\n",
            "Validation loss: 0.12469014418976647, Validation accuracy: 0.5334821428571429\n",
            "Epoch: 47, LR: [3]\n",
            "Train loss: 0.1472225957872844, Train accuracy: 0.7937809405940595\n",
            "Validation loss: 0.108676158956119, Validation accuracy: 0.5535714285714286\n",
            "Epoch: 48, LR: [3]\n",
            "Train loss: 0.1496240974652885, Train accuracy: 0.7728960396039604\n",
            "Validation loss: 0.11420761687414986, Validation accuracy: 0.5245535714285714\n",
            "Epoch: 49, LR: [3]\n",
            "Train loss: 0.14834851823230782, Train accuracy: 0.7696472772277227\n",
            "Validation loss: 0.11711154133081436, Validation accuracy: 0.546875\n",
            "Epoch: 50, LR: [0.6000000000000001]\n",
            "Train loss: 0.14100815363154554, Train accuracy: 0.8312190594059405\n",
            "Validation loss: 0.11850045514958245, Validation accuracy: 0.515625\n",
            "Epoch: 51, LR: [0.6000000000000001]\n",
            "Train loss: 0.13752108045143657, Train accuracy: 0.853805693069307\n",
            "Validation loss: 0.11540261336735316, Validation accuracy: 0.5691964285714286\n",
            "Epoch: 52, LR: [0.6000000000000001]\n",
            "Train loss: 0.13652885277377497, Train accuracy: 0.8739170792079208\n",
            "Validation loss: 0.1176246064049857, Validation accuracy: 0.5758928571428571\n",
            "Epoch: 53, LR: [0.6000000000000001]\n",
            "Train loss: 0.13638288254785066, Train accuracy: 0.8785581683168316\n",
            "Validation loss: 0.11486977125917162, Validation accuracy: 0.5669642857142857\n",
            "Epoch: 54, LR: [0.6000000000000001]\n",
            "Train loss: 0.13525928224962536, Train accuracy: 0.8833539603960396\n",
            "Validation loss: 0.11217715910502843, Validation accuracy: 0.5691964285714286\n",
            "Epoch: 55, LR: [0.6000000000000001]\n",
            "Train loss: 0.13471729964903084, Train accuracy: 0.8807240099009901\n",
            "Validation loss: 0.12607913890055247, Validation accuracy: 0.5446428571428571\n",
            "Epoch: 56, LR: [0.6000000000000001]\n",
            "Train loss: 0.13416107434152377, Train accuracy: 0.8849009900990099\n",
            "Validation loss: 0.12316556381327766, Validation accuracy: 0.5736607142857143\n",
            "Epoch: 57, LR: [0.6000000000000001]\n",
            "Train loss: 0.13485495222382027, Train accuracy: 0.895884900990099\n",
            "Validation loss: 0.11994226915495736, Validation accuracy: 0.5669642857142857\n",
            "Epoch: 58, LR: [0.6000000000000001]\n",
            "Train loss: 0.13400160108167347, Train accuracy: 0.890625\n",
            "Validation loss: 0.1162446779864175, Validation accuracy: 0.5513392857142857\n",
            "Epoch: 59, LR: [0.6000000000000001]\n",
            "Train loss: 0.1342871524024718, Train accuracy: 0.8994430693069307\n",
            "Validation loss: 0.12159739541155952, Validation accuracy: 0.5580357142857143\n",
            "Epoch: 60, LR: [0.6000000000000001]\n",
            "Train loss: 0.13373866618269742, Train accuracy: 0.8944925742574258\n",
            "Validation loss: 0.12347008820090975, Validation accuracy: 0.5691964285714286\n",
            "Epoch: 61, LR: [0.6000000000000001]\n",
            "Train loss: 0.13348656531312678, Train accuracy: 0.8954207920792079\n",
            "Validation loss: 0.12328122024025236, Validation accuracy: 0.5803571428571429\n",
            "Epoch: 62, LR: [0.6000000000000001]\n",
            "Train loss: 0.13350510029214444, Train accuracy: 0.8983601485148515\n",
            "Validation loss: 0.12077546439000539, Validation accuracy: 0.5959821428571429\n",
            "Epoch: 63, LR: [0.6000000000000001]\n",
            "Train loss: 0.13318559379860906, Train accuracy: 0.9022277227722773\n",
            "Validation loss: 0.12637382319995336, Validation accuracy: 0.5602678571428571\n",
            "Epoch: 64, LR: [0.12000000000000002]\n",
            "Train loss: 0.13291782089094123, Train accuracy: 0.9045482673267327\n",
            "Validation loss: 0.12568215067897523, Validation accuracy: 0.5736607142857143\n",
            "Epoch: 65, LR: [0.12000000000000002]\n",
            "Train loss: 0.13195374718692043, Train accuracy: 0.911509900990099\n",
            "Validation loss: 0.11916578986815043, Validation accuracy: 0.5714285714285714\n",
            "Epoch: 66, LR: [0.12000000000000002]\n",
            "Train loss: 0.1315633542466872, Train accuracy: 0.9096534653465347\n",
            "Validation loss: 0.12018101343086787, Validation accuracy: 0.5982142857142857\n",
            "Epoch: 67, LR: [0.12000000000000002]\n",
            "Train loss: 0.13189620266456414, Train accuracy: 0.9084158415841584\n",
            "Validation loss: 0.12905215684856688, Validation accuracy: 0.5602678571428571\n",
            "Epoch: 68, LR: [0.12000000000000002]\n",
            "Train loss: 0.13161878236154517, Train accuracy: 0.9142945544554455\n",
            "Validation loss: 0.12589959055185318, Validation accuracy: 0.5446428571428571\n",
            "Epoch: 69, LR: [0.12000000000000002]\n",
            "Train loss: 0.13172042473117904, Train accuracy: 0.9081064356435643\n",
            "Validation loss: 0.12234307506254741, Validation accuracy: 0.578125\n",
            "Epoch: 70, LR: [0.12000000000000002]\n",
            "Train loss: 0.13180717043947465, Train accuracy: 0.9121287128712872\n",
            "Validation loss: 0.12536624393292836, Validation accuracy: 0.5758928571428571\n",
            "Target number of exemplars per class: 50\n",
            "Target total number of exemplars: 2000\n",
            "Randomly extracting exemplars from class 0 of current split... Extracted 50 exemplars.\n",
            "Randomly extracting exemplars from class 1 of current split... Extracted 50 exemplars.\n",
            "Randomly extracting exemplars from class 2 of current split... Extracted 50 exemplars.\n",
            "Randomly extracting exemplars from class 3 of current split... Extracted 50 exemplars.\n",
            "Randomly extracting exemplars from class 4 of current split... Extracted 50 exemplars.\n",
            "Randomly extracting exemplars from class 5 of current split... Extracted 50 exemplars.\n",
            "Randomly extracting exemplars from class 6 of current split... Extracted 50 exemplars.\n",
            "Randomly extracting exemplars from class 7 of current split... Extracted 50 exemplars.\n",
            "Randomly extracting exemplars from class 8 of current split... Extracted 50 exemplars.\n",
            "Randomly extracting exemplars from class 9 of current split... Extracted 50 exemplars.\n",
            "Computing mean of exemplars... done\n",
            "Test accuracy (iCaRL): 0.66775 (exemplars and training data)\n",
            "## Split 4 of run 0 ##\n",
            "Length of exemplars set: 2000\n",
            "Epoch: 1, LR: [3]\n",
            "Train loss: 0.1803378774092929, Train accuracy: 0.3533415841584158\n",
            "Validation loss: 0.1269541989479746, Validation accuracy: 0.12723214285714285\n",
            "Epoch: 2, LR: [3]\n",
            "Train loss: 0.16802994464293564, Train accuracy: 0.4447710396039604\n",
            "Validation loss: 0.11198906600475311, Validation accuracy: 0.24776785714285715\n",
            "Epoch: 3, LR: [3]\n",
            "Train loss: 0.16630832732904074, Train accuracy: 0.48932549504950495\n",
            "Validation loss: 0.09703927167824336, Validation accuracy: 0.3482142857142857\n",
            "Epoch: 4, LR: [3]\n",
            "Train loss: 0.16546159953174025, Train accuracy: 0.521194306930693\n",
            "Validation loss: 0.11567920339959008, Validation accuracy: 0.22544642857142858\n",
            "Epoch: 5, LR: [3]\n",
            "Train loss: 0.1640297444445072, Train accuracy: 0.5324876237623762\n",
            "Validation loss: 0.11070349173886436, Validation accuracy: 0.28794642857142855\n",
            "Epoch: 6, LR: [3]\n",
            "Train loss: 0.16373281962800734, Train accuracy: 0.5586324257425742\n",
            "Validation loss: 0.1167279418025698, Validation accuracy: 0.2924107142857143\n",
            "Epoch: 7, LR: [3]\n",
            "Train loss: 0.1628519755483854, Train accuracy: 0.5632735148514851\n",
            "Validation loss: 0.10847578942775726, Validation accuracy: 0.30580357142857145\n",
            "Epoch: 8, LR: [3]\n",
            "Train loss: 0.1626779193630313, Train accuracy: 0.5809096534653465\n",
            "Validation loss: 0.1200793491942542, Validation accuracy: 0.35714285714285715\n",
            "Epoch: 9, LR: [3]\n",
            "Train loss: 0.16288046848655927, Train accuracy: 0.5840037128712872\n",
            "Validation loss: 0.13074112577097757, Validation accuracy: 0.2857142857142857\n",
            "Epoch: 10, LR: [3]\n",
            "Train loss: 0.16164606352253716, Train accuracy: 0.5985457920792079\n",
            "Validation loss: 0.1120981542127473, Validation accuracy: 0.39285714285714285\n",
            "Epoch: 11, LR: [3]\n",
            "Train loss: 0.16162148059004605, Train accuracy: 0.6045792079207921\n",
            "Validation loss: 0.10652487192835126, Validation accuracy: 0.3861607142857143\n",
            "Epoch: 12, LR: [3]\n",
            "Train loss: 0.16117199665248985, Train accuracy: 0.6150990099009901\n",
            "Validation loss: 0.11141424306801387, Validation accuracy: 0.39285714285714285\n",
            "Epoch: 13, LR: [3]\n",
            "Train loss: 0.15985130850631413, Train accuracy: 0.6243811881188119\n",
            "Validation loss: 0.10563613474369049, Validation accuracy: 0.39285714285714285\n",
            "Epoch: 14, LR: [3]\n",
            "Train loss: 0.15852081156013034, Train accuracy: 0.6304146039603961\n",
            "Validation loss: 0.10341542001281466, Validation accuracy: 0.41964285714285715\n",
            "Epoch: 15, LR: [3]\n",
            "Train loss: 0.1605140245196843, Train accuracy: 0.6318069306930693\n",
            "Validation loss: 0.10902284937245506, Validation accuracy: 0.41517857142857145\n",
            "Epoch: 16, LR: [3]\n",
            "Train loss: 0.15975845155149404, Train accuracy: 0.635519801980198\n",
            "Validation loss: 0.1151425912976265, Validation accuracy: 0.3794642857142857\n",
            "Epoch: 17, LR: [3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2s8T-lwvA0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "[[0.902, 0.8125, 0.731, 0.679, 0.609]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Y1xhv1cA9JL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4251cdae-0abf-4554-f90a-5f6c6eb6ad1c"
      },
      "source": [
        "logs_icarl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'accuracy': 0.902,\n",
              "   'conf_mat': array([[12,  7, 12,  9,  6, 10,  9, 12, 11, 12],\n",
              "          [ 8,  6, 13, 15,  7, 11, 15,  8, 10,  7],\n",
              "          [ 6, 13, 15, 10,  9,  7,  6, 15,  7, 12],\n",
              "          [ 7, 16,  8, 10,  8, 13, 12,  8,  6, 12],\n",
              "          [12,  9, 13,  6, 12,  9, 11, 10, 10,  8],\n",
              "          [12,  5,  7, 11, 11, 10,  9, 12, 11, 12],\n",
              "          [15,  6, 10,  9,  7,  8, 10, 11, 13, 11],\n",
              "          [10, 15,  8,  9,  5,  9, 10, 12, 13,  9],\n",
              "          [10, 12, 13,  7,  9, 11,  9, 10, 10,  9],\n",
              "          [11, 13,  7, 11, 10,  7, 12, 15,  6,  8]]),\n",
              "   'train_accuracy': 0.9904017857142857,\n",
              "   'train_loss': 0.007862901730862046,\n",
              "   'val_accuracy': 0.9107142857142857,\n",
              "   'val_loss': 0.056337807327508926},\n",
              "  {'accuracy': 0.8045,\n",
              "   'conf_mat': array([[ 5,  5,  1,  2,  4,  5,  2,  7,  8,  5, 10,  3,  5,  3,  7,  5,\n",
              "            4,  6,  6,  7],\n",
              "          [ 2,  7,  4,  4,  7,  8,  2,  6,  5,  8,  4,  7,  5,  3,  9,  6,\n",
              "            2,  3,  3,  5],\n",
              "          [ 9,  5,  6,  3,  1,  4,  2, 11,  8, 10,  5,  5,  3,  4,  6,  7,\n",
              "            6,  1,  2,  2],\n",
              "          [ 3,  6,  6,  4,  1,  4,  8,  5,  2,  6,  5,  6,  6,  8,  6,  4,\n",
              "            6,  5,  5,  4],\n",
              "          [ 6,  3,  9,  5,  8,  2,  4,  4,  4,  2,  6,  6,  3,  9,  3,  3,\n",
              "            6,  6,  6,  5],\n",
              "          [ 9,  4,  3,  6,  6,  9,  3,  7,  2,  5,  6,  4,  2,  5,  4,  6,\n",
              "            9,  5,  1,  4],\n",
              "          [ 1,  5,  5,  3,  4,  9,  4, 11,  4,  5,  5,  7,  9,  1,  4,  2,\n",
              "            4,  8,  6,  3],\n",
              "          [ 4,  7,  6,  6,  8,  7,  3,  5,  8,  8,  1,  2,  4,  2,  7,  3,\n",
              "            7,  5,  5,  2],\n",
              "          [ 3,  3,  6,  5,  4,  4,  7,  7, 10,  6,  3,  6,  5,  3,  2,  7,\n",
              "            5,  6,  5,  3],\n",
              "          [ 7,  4,  7, 10,  4,  6,  3,  7,  8,  4,  7,  5,  5,  2,  3,  5,\n",
              "            3,  1,  7,  2],\n",
              "          [ 6,  9,  7,  6,  4,  7, 10,  5,  5,  5,  7,  5,  2,  2,  4,  4,\n",
              "            4,  4,  2,  2],\n",
              "          [ 8,  5,  3,  5,  3,  5,  8,  5,  8,  8,  1,  7,  1,  4,  5,  6,\n",
              "           10,  0,  7,  1],\n",
              "          [ 8,  4,  4,  4,  4,  6,  9,  8,  4,  2,  6,  2,  5,  5,  5,  3,\n",
              "            5,  5,  7,  4],\n",
              "          [ 9,  6,  4,  6,  1,  7,  5,  5,  5,  5,  0,  2,  5,  9,  4,  5,\n",
              "            5,  5,  6,  6],\n",
              "          [ 4,  0,  5,  5,  7,  4,  8,  5,  7,  7,  4, 13,  3,  2,  6,  5,\n",
              "            4,  5,  3,  3],\n",
              "          [ 6,  7,  4,  5,  5,  5,  2,  7,  2,  4,  3,  4,  9,  5,  7,  4,\n",
              "            5,  5,  5,  6],\n",
              "          [ 2,  6,  7,  4,  4,  8,  7,  2,  2,  8,  4,  3,  7,  1,  6,  5,\n",
              "            6,  7,  5,  6],\n",
              "          [ 6,  8,  7,  2,  2,  2,  6,  8,  3,  4,  6,  6,  5,  4, 10,  4,\n",
              "            3,  6,  6,  2],\n",
              "          [ 6,  5,  8,  5,  2,  6,  4,  7,  5,  3, 11,  2,  1,  7,  6,  7,\n",
              "            0,  4,  3,  8],\n",
              "          [10,  3,  4,  7,  5,  8,  7, 15,  4,  3,  3,  1,  2,  7,  3,  2,\n",
              "            2,  4,  4,  6]]),\n",
              "   'train_accuracy': 0.9576113861386139,\n",
              "   'train_loss': 0.08977070524550901,\n",
              "   'val_accuracy': 0.65625,\n",
              "   'val_loss': 0.180380146418299},\n",
              "  {'accuracy': 0.7366666666666667,\n",
              "   'conf_mat': array([[ 3,  3,  5,  4,  3,  5,  3,  3,  2,  4,  2,  4,  2,  2,  5,  5,\n",
              "            2,  3,  4,  4,  4,  3,  4,  5,  0,  2,  3,  3,  5,  3],\n",
              "          [ 4,  5,  6,  3,  3,  3,  2,  3,  3,  3,  6,  4,  4,  3,  7,  6,\n",
              "            3,  4,  4,  3,  3,  2,  4,  0,  3,  2,  0,  1,  2,  4],\n",
              "          [ 4,  5,  2,  4,  4,  2,  3,  6,  5,  4,  4,  4,  1,  3,  4,  2,\n",
              "            5,  3,  4,  1,  5,  1,  4,  4,  0,  0,  4,  6,  2,  4],\n",
              "          [ 3,  4,  3,  2,  1,  7,  4,  3,  5,  3,  4,  1,  0,  3,  2,  7,\n",
              "            0,  3,  5,  3,  3,  0,  3,  1,  4,  5,  9,  4,  4,  4],\n",
              "          [ 3,  3,  4,  5,  5,  6,  2,  8,  5,  6,  3,  0,  4,  3,  0,  4,\n",
              "            4,  2,  1,  3,  3,  2,  4,  3,  5,  3,  1,  2,  4,  2],\n",
              "          [ 2,  3,  3,  8,  6,  4,  4,  5,  2,  3,  4,  3,  2,  0,  4,  6,\n",
              "            2,  2,  5,  3,  3,  1,  2,  4,  0,  1,  7,  0,  7,  4],\n",
              "          [ 5,  4,  2,  1,  4,  2,  4,  5,  0,  4,  3,  2,  6,  3,  2,  3,\n",
              "            6,  2,  5,  6,  5,  3,  2,  2,  1,  2,  4,  5,  2,  5],\n",
              "          [ 4,  5,  3,  1,  1,  5,  2,  5,  1,  5,  6,  6,  5,  5,  1,  2,\n",
              "            0,  3,  4,  6,  3,  4,  5,  3,  2,  2,  6,  1,  2,  2],\n",
              "          [ 3,  1,  6,  2,  4,  5,  6,  7,  4,  5,  2,  6,  1,  5,  0,  4,\n",
              "            0,  2,  2,  4,  3,  3,  1,  2,  3,  4,  3,  3,  3,  6],\n",
              "          [ 4,  3,  3,  2,  2,  3,  1, 11,  4,  3,  2,  4,  1,  1,  4,  2,\n",
              "            3,  6,  3,  2,  5,  5,  1,  3,  3,  3,  2,  5,  4,  5],\n",
              "          [ 3,  4,  4,  7,  4,  3,  6,  9,  4,  3,  4,  2,  2,  2,  3,  6,\n",
              "            2,  3,  1,  3,  1,  5,  2,  2,  1,  2,  3,  4,  4,  1],\n",
              "          [ 9,  5,  3,  2,  3,  4,  5,  9,  1,  7,  1,  7,  1,  2,  4,  2,\n",
              "            1,  3,  0,  2,  3,  3,  3,  2,  1,  5,  8,  2,  2,  0],\n",
              "          [ 8,  3,  4,  3,  3,  3,  2,  8,  4, 12,  3,  5,  2,  4,  3,  3,\n",
              "            3,  3,  4,  1,  1,  4,  0,  0,  3,  2,  2,  1,  2,  4],\n",
              "          [ 6,  7,  3,  3,  4,  3,  3,  6,  3,  1,  3,  5,  1,  3,  7,  0,\n",
              "            4,  5,  2,  2,  2,  3,  4,  7,  2,  3,  1,  5,  0,  2],\n",
              "          [ 7,  4,  4,  4,  2,  3,  6,  6,  3,  2,  2,  3,  3,  1,  4,  0,\n",
              "            6,  6,  0,  2,  3,  2,  2,  0,  1,  3, 10,  5,  3,  3],\n",
              "          [ 8,  5,  6,  4,  1,  2,  3,  7,  5,  5,  3,  4,  3,  3,  2,  2,\n",
              "            2,  1,  1,  1,  6,  3,  2,  3,  0,  4,  1,  3,  7,  3],\n",
              "          [ 3,  3,  2,  4,  3,  5,  1,  4,  3,  1,  1,  1,  6,  5,  4,  7,\n",
              "            2,  7,  0,  8,  2,  3,  5,  3,  3,  1,  3,  6,  3,  1],\n",
              "          [ 5,  6,  3,  0,  1,  3,  3,  4,  6,  7,  5,  2,  2,  1,  1,  2,\n",
              "            6,  3,  3,  2,  2,  7,  3,  3,  5,  1,  2,  3,  5,  4],\n",
              "          [ 3,  5,  4,  7,  4,  5,  4,  7,  0,  6,  5,  5,  3,  2,  3,  4,\n",
              "            4,  3,  2,  4,  3,  1,  2,  5,  1,  2,  2,  1,  1,  2],\n",
              "          [ 6,  6,  4,  7,  4,  3,  1,  9,  5,  2,  1,  2,  3,  3,  1,  2,\n",
              "            2,  1,  4,  3,  0,  8,  1,  3,  1,  4,  1,  5,  4,  4],\n",
              "          [ 3,  3,  4,  3,  2,  2,  5,  4,  7,  3,  1,  3,  4,  5,  5,  1,\n",
              "            2,  2,  4,  3,  1,  5,  5,  4,  3,  3,  3,  3,  5,  2],\n",
              "          [ 5,  4,  1,  2,  3,  2,  5,  7,  3,  2,  4,  3,  4,  4,  3,  1,\n",
              "            4,  5,  0,  2,  7,  5,  2,  4,  3,  3,  5,  3,  3,  1],\n",
              "          [ 3,  2,  3,  7,  2,  3,  8,  4,  4,  4,  9,  6,  1,  1,  2,  4,\n",
              "            6,  3,  4,  2,  4,  3,  3,  2,  1,  1,  3,  4,  0,  1],\n",
              "          [ 1,  4,  3,  1,  5,  3,  7, 10,  5,  3,  3,  2,  3,  2,  2,  3,\n",
              "            4,  3,  5,  4,  4,  4,  1,  1,  3,  6,  6,  0,  2,  0],\n",
              "          [ 1,  3,  3,  5,  1,  5, 10,  6,  3,  4,  4,  2,  4,  3,  2,  2,\n",
              "            5,  4,  2,  5,  3,  2,  3,  6,  2,  2,  2,  1,  1,  4],\n",
              "          [ 4,  5,  4,  4,  0,  3,  5,  9,  3,  7,  4,  5,  2,  0,  4,  0,\n",
              "            5,  0,  4,  3,  3,  2,  1,  3,  4,  2,  5,  3,  4,  2],\n",
              "          [ 4,  1,  4,  1,  3,  6,  2,  5,  6,  7,  5,  4,  5,  4,  3,  3,\n",
              "            2,  1,  2,  5,  5,  0,  2,  1,  3,  2,  1,  7,  4,  2],\n",
              "          [ 2,  2,  7,  2,  3,  7,  2,  7,  2,  4,  5,  3,  6,  2,  2,  1,\n",
              "            4,  2,  6,  5,  1,  4,  2,  6,  2,  4,  0,  2,  4,  1],\n",
              "          [ 5,  3,  3,  0,  3,  2,  5,  7,  8,  5,  0,  5,  1,  4,  5,  5,\n",
              "            1,  1,  1,  3,  4,  3,  3,  2,  5,  3,  4,  4,  3,  2],\n",
              "          [ 3,  3,  6,  6,  2,  5,  6,  8,  8,  6,  3,  6,  3,  2,  3,  1,\n",
              "            4,  1,  3,  2,  1,  0,  4,  0,  2,  3,  3,  4,  2,  0]]),\n",
              "   'train_accuracy': 0.9422957920792079,\n",
              "   'train_loss': 0.11336346546022019,\n",
              "   'val_accuracy': 0.6205357142857143,\n",
              "   'val_loss': 0.1355728166443961},\n",
              "  {'accuracy': 0.6675, 'conf_mat': array([[3, 7, 1, ..., 1, 8, 5],\n",
              "          [3, 3, 4, ..., 1, 3, 0],\n",
              "          [2, 2, 5, ..., 1, 7, 2],\n",
              "          ...,\n",
              "          [1, 0, 4, ..., 4, 1, 3],\n",
              "          [2, 4, 0, ..., 0, 3, 3],\n",
              "          [2, 5, 4, ..., 1, 3, 4]]), 'train_accuracy': 0.9129022277227723, 'train_loss': 0.11936950816376375, 'val_accuracy': 0.5848214285714286, 'val_loss': 0.12798649285520827},\n",
              "  {'accuracy': 0.604, 'conf_mat': array([[4, 1, 0, ..., 2, 4, 0],\n",
              "          [1, 0, 2, ..., 4, 5, 3],\n",
              "          [2, 3, 0, ..., 2, 0, 1],\n",
              "          ...,\n",
              "          [2, 4, 5, ..., 3, 0, 2],\n",
              "          [0, 2, 1, ..., 5, 3, 1],\n",
              "          [0, 3, 2, ..., 2, 2, 2]]), 'train_accuracy': 0.8663366336633663, 'train_loss': 0.12269257407377263, 'val_accuracy': 0.5178571428571429, 'val_loss': 0.11643717863730021},\n",
              "  {'accuracy': 0.559, 'conf_mat': array([[2, 1, 2, ..., 3, 0, 3],\n",
              "          [0, 3, 1, ..., 1, 2, 1],\n",
              "          [0, 3, 0, ..., 2, 3, 1],\n",
              "          ...,\n",
              "          [1, 1, 3, ..., 3, 1, 1],\n",
              "          [0, 2, 3, ..., 4, 2, 2],\n",
              "          [1, 2, 2, ..., 0, 2, 1]]), 'train_accuracy': 0.8545792079207921, 'train_loss': 0.133579118933418, 'val_accuracy': 0.5401785714285714, 'val_loss': 0.09677583937134061},\n",
              "  {'accuracy': 0.5364285714285715, 'conf_mat': array([[0, 2, 1, ..., 1, 2, 1],\n",
              "          [1, 2, 3, ..., 4, 1, 1],\n",
              "          [0, 1, 2, ..., 2, 0, 1],\n",
              "          ...,\n",
              "          [1, 1, 0, ..., 5, 3, 3],\n",
              "          [1, 0, 1, ..., 1, 1, 1],\n",
              "          [1, 2, 4, ..., 2, 1, 1]]), 'train_accuracy': 0.8358601485148515, 'train_loss': 0.1287359615953842, 'val_accuracy': 0.6071428571428571, 'val_loss': 0.09106448824916567},\n",
              "  {'accuracy': 0.505125, 'conf_mat': array([[1, 2, 2, ..., 0, 1, 2],\n",
              "          [3, 1, 5, ..., 0, 0, 0],\n",
              "          [3, 2, 1, ..., 1, 4, 1],\n",
              "          ...,\n",
              "          [0, 3, 0, ..., 0, 2, 0],\n",
              "          [2, 2, 0, ..., 1, 2, 2],\n",
              "          [0, 0, 2, ..., 2, 0, 2]]), 'train_accuracy': 0.820625, 'train_loss': 0.1310063470900059, 'val_accuracy': 0.5446428571428571, 'val_loss': 0.09240031348807472},\n",
              "  {'accuracy': 0.4703333333333333, 'conf_mat': array([[1, 2, 2, ..., 2, 1, 0],\n",
              "          [1, 0, 1, ..., 0, 1, 0],\n",
              "          [0, 1, 2, ..., 1, 1, 0],\n",
              "          ...,\n",
              "          [1, 1, 3, ..., 2, 0, 0],\n",
              "          [2, 1, 1, ..., 0, 1, 0],\n",
              "          [1, 0, 0, ..., 0, 2, 1]]), 'train_accuracy': 0.7831064356435643, 'train_loss': 0.12499636640348057, 'val_accuracy': 0.45535714285714285, 'val_loss': 0.09036011461700712}],\n",
              " [],\n",
              " []]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vr_tjdSeJWPl"
      },
      "source": [
        "### Plots"
      ]
    }
  ]
}