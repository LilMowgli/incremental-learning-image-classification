{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "notebook.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzqxHIh4OCdW",
        "colab_type": "text"
      },
      "source": [
        "# Incremental learning on image classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBHSznCZxpNB",
        "colab_type": "text"
      },
      "source": [
        "## Libraries and packages\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eQ6O12jxMFf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install 'torch==1.5.0'\n",
        "!pip3 install 'torchvision==0.5.0'\n",
        "!pip3 install 'Pillow-SIMD'\n",
        "!pip3 install 'tqdm'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAYXtIdpx0Yy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import urllib\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader, ConcatDataset\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.models import resnet34\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YFLG4yRVwi9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "username = ''\n",
        "password = ''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09iWc_oCotu2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download packages from repository\n",
        "\n",
        "password = urllib.parse.quote(password)\n",
        "!git clone https://$username:$password@github.com/manuelemacchia/incremental-learning-image-classification.git\n",
        "password = ''\n",
        "\n",
        "!mv -v incremental-learning-image-classification/* .\n",
        "!rm -rf incremental-learning-image-classification README.md"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fePsy3BLSiXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# @todo: put in model package once finished\n",
        "\n",
        "from torchvision.datasets import VisionDataset\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import os\n",
        "import os.path\n",
        "import sys\n",
        "import pickle\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "class CIFAR100(VisionDataset):\n",
        "    \"\"\"CIFAR-100 dataset handler.\n",
        "    \n",
        "    Args:\n",
        "        root (string): Root directory of the dataset where directory\n",
        "            cifar-100-python exists.\n",
        "        split (string, optional): If 'train', creates dataset from training\n",
        "            set, otherwise creates from test set.\n",
        "        transform (callable, optional): A function/transform that takes in a\n",
        "            PIL image and returns a transformed version.\n",
        "    \"\"\"\n",
        "\n",
        "    base_folder = 'cifar-100-python'\n",
        "\n",
        "    train_filename = 'train'\n",
        "    test_filename = 'test'\n",
        "    meta_filename = 'meta'\n",
        "\n",
        "    def __init__(self, root, split='train', transform=None):\n",
        "        super(CIFAR100, self).__init__(root, transform=transform)\n",
        "\n",
        "        self.split = split\n",
        "\n",
        "        if split == 'train':\n",
        "            filename = self.train_filename\n",
        "        else:\n",
        "            filename = self.test_filename\n",
        "        \n",
        "        # @todo: add integrity checks\n",
        "        data_path = os.path.join(self.root, self.base_folder, filename)\n",
        "\n",
        "        with open(data_path, 'rb') as f:\n",
        "            entry = pickle.load(f, encoding='latin1')\n",
        "            self.data = entry['data']\n",
        "            self.labels = entry['fine_labels']\n",
        "        \n",
        "        self.data = np.vstack(self.data).reshape(-1, 3, 32, 32)\n",
        "        self.data = self.data.transpose((0, 2, 3, 1))  # Convert to HWC\n",
        "        \n",
        "        self.labels = np.array(self.labels)\n",
        "\n",
        "        meta_path = os.path.join(self.root, self.base_folder, self.meta_filename)\n",
        "        with open(meta_path, 'rb') as f:\n",
        "            meta = pickle.load(f, encoding='latin1')\n",
        "            self.label_names = meta['fine_label_names']\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"Access an element through its index.\n",
        "\n",
        "        Args:\n",
        "            index (int): Index\n",
        "\n",
        "        Returns:\n",
        "            tuple: (image, label) where label is index of the target class.\n",
        "        \"\"\"\n",
        "\n",
        "        image, label = self.data[index], self.labels[index]\n",
        "\n",
        "        image = Image.fromarray(image) # Return a PIL image\n",
        "\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Returns the length of the dataset.\"\"\"\n",
        "        return len(self.data)\n",
        "\n",
        "    def get_class(self, label):\n",
        "        \"\"\"Return the indices of data belonging to the specified label.\"\"\"\n",
        "        return np.where(self.labels==label)[0]\n",
        "\n",
        "    def map_labels(self, label_map):\n",
        "        \"\"\"Change dataset labels with a label map.\n",
        "        \n",
        "        Args:\n",
        "            label_map (dict): dictionary mapping all original CIFAR100 labels\n",
        "                to custom labels.\n",
        "\n",
        "                e.g., {0: custom_label_0, ..., 99: custom_label_99}\n",
        "        \"\"\"\n",
        "\n",
        "        self.label_map = label_map\n",
        "\n",
        "        self.labels = np.vectorize(lambda x: self.label_map[x])(self.labels)\n",
        "\n",
        "        # @todo: also change the order of self.label_names\n",
        "\n",
        "    def class_splits(self, steps=10, random_state=None):\n",
        "        \"\"\"Split the classes in several sets of equal length and return them.\"\"\"\n",
        "\n",
        "        rs = np.random.RandomState(random_state)\n",
        "\n",
        "        idx = np.arange(len(self.label_names))\n",
        "        rs.shuffle(idx)\n",
        "\n",
        "        splits = np.split(idx, steps)\n",
        "\n",
        "        return splits\n",
        "\n",
        "    def train_val_split(self, class_splits, val_size=0.5, random_state=None):\n",
        "        \"\"\"Perform a train and validation split based on given class splits.\n",
        "\n",
        "        Args:\n",
        "            class_splits (list): class split returned by self.class_splits\n",
        "            val_size (int, float or None): size of the validation set.                \n",
        "\n",
        "        Returns:\n",
        "            tuple: (train_indices, val_indices) where each element in the tuple\n",
        "                is a list of lists.\n",
        "\n",
        "                train_indices is a list of len(class_splits) lists. Each inner\n",
        "                list contains the training indices belonging to a class split.\n",
        "                val_indices, analogously, contains the validation indices\n",
        "                belonging to a class split.\n",
        "\n",
        "                e.g., [[0, 1, 2, 3, ..., 99],             <- first class split\n",
        "                       [100, 101, 12, 103, ..., 199],     <- second class split\n",
        "                       [200, 201, 22, 203, ..., 299],\n",
        "                       ...\n",
        "                       [900, 901, 902, 903, ..., 999]]    <- last class split\n",
        "        \"\"\"\n",
        "\n",
        "        train_indices = []\n",
        "        val_indices = []\n",
        "\n",
        "        for i, split in enumerate(class_splits):\n",
        "            train_indices.append([])\n",
        "            val_indices.append([])\n",
        "\n",
        "            for c in split:\n",
        "                # For each class, split the data into train and test\n",
        "                idx = self.get_class(c)\n",
        "                train_idx, val_idx = train_test_split(idx.tolist(), test_size=val_size, random_state=random_state)\n",
        "\n",
        "                train_indices[i].extend(train_idx)\n",
        "                val_indices[i].extend(val_idx)\n",
        "\n",
        "        return train_indices, val_indices\n",
        "\n",
        "    def test_split(self, class_splits):\n",
        "        \"\"\"Perform a train validation split on the dataset.\n",
        "\n",
        "        Args:\n",
        "            class_splits (int): class split returned by self.class_splits\n",
        "            val_size (int, float or None): size of the validation set.                \n",
        "\n",
        "        Returns:\n",
        "            test_indices (list): A list of lists. Analogous to train_test_split.\n",
        "        \"\"\"\n",
        "\n",
        "        test_indices = []\n",
        "\n",
        "        for i, split in enumerate(class_splits):\n",
        "            test_indices.append([])\n",
        "\n",
        "            for c in split:\n",
        "                idx = self.get_class(c)\n",
        "                test_indices[i].extend(idx)\n",
        "\n",
        "        return test_indices\n",
        "\n",
        "    def debug_labels(self):\n",
        "        print(self.labels[:100])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUfYUe_QfVbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load Resnet for CIFAR\n",
        "\n",
        "!git clone https://github.com/akamaster/pytorch_resnet_cifar10.git\n",
        "!mv -v 'pytorch_resnet_cifar10' 'Resnet'\n",
        "\n",
        "from Resnet.resnet import resnet32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j12pgffMR6Qv",
        "colab_type": "text"
      },
      "source": [
        "## Arguments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwE0x8gkSisn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Settings\n",
        "DEVICE = 'cuda'\n",
        "\n",
        "# Dataset\n",
        "DATA_DIR = 'data'       # Directory where the dataset will be downloaded\n",
        "\n",
        "RANDOM_STATE = 42       # For reproducibility of results\n",
        "NUM_CLASSES = 100       # Total number of classes\n",
        "CLASS_BATCH_SIZE = 10   # Size of batch of classes for incremental learning\n",
        "VAL_SIZE = 0.1          # Proportion of validation set with respect to training set (between 0 and 1)\n",
        "\n",
        "# Training\n",
        "BATCH_SIZE = 256        # Icarl uses lr = 128. It slow down the Training, that is already enough time consuming for us\n",
        "LR = 0.1                  # Icarl sets lr = 2. Since they use BinaryCrossEntropy loss it is feasible,\n",
        "                        # in our case it would diverge\n",
        "MOMENTUM = 0.9\n",
        "WEIGHT_DECAY = 1e-5     # From Icarl\n",
        "\n",
        "NUM_RUNS = 3            # Number of runs of every method (at least 3 to have a fair benchmark)\n",
        "\n",
        "NUM_EPOCHS = 70         # Total number of training epochs\n",
        "MILESTONES = [49, 63]   # From Icarl\n",
        "GAMMA = 0.25            # From Icarl\n",
        "# Logging\n",
        "LOG_FREQUENCY = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDDdumxRwbdQ",
        "colab_type": "text"
      },
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ka2RwY0VS8-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download dataset\n",
        "!wget https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
        "!tar -xf 'cifar-100-python.tar.gz'\n",
        "!mv 'cifar-100-python' $DATA_DIR/cifar-100-python\n",
        "!rm -rf 'cifar-100-python.tar.gz'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJVKOqLjVUhp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define transformations for training\n",
        "train_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Define transformations for evaluation\n",
        "eval_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))                                    \n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmQEsuniWjIN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import dataset\n",
        "\n",
        "# train_dataloader, val_dataloader and test_dataloader have the same structure.\n",
        "# Each one is a list of length NUM_RUNS. Each element of each list has length\n",
        "# CLASS_BATCH_SIZE, and contains the DataLoader instances.\n",
        "# e.g., train_dataloader[i][j] is the DataLoader corresponding to the j-th class\n",
        "# batch on the i-th run\n",
        "train_dataloaders = []\n",
        "val_dataloaders = []\n",
        "test_subsets = []\n",
        "\n",
        "# Map original label numbers to ascending order numbers\n",
        "# e.g., [1, 4, 7, 11, 25, ...] to\n",
        "#       {1: 0, 4: 1, 7: 2, 11: 3, 25: 4...}\n",
        "#\n",
        "# label_maps[i]: access the label map of the i-th run\n",
        "label_maps = []\n",
        "\n",
        "for run_i in range(NUM_RUNS): # To have a fair benchmark, we run every method on at least three different random splits.\n",
        "    train_dataset = CIFAR100('', split='train', transform=train_transform)\n",
        "    test_dataset = CIFAR100('', split='test', transform=eval_transform)\n",
        "\n",
        "    class_splits = train_dataset.class_splits(steps=CLASS_BATCH_SIZE, random_state=RANDOM_STATE+run_i)\n",
        "\n",
        "    label_maps.append({})\n",
        "    for split_i in range(len(class_splits)):\n",
        "        label_maps[run_i].update({class_splits[split_i][i]: j for i, j in zip(range(0, 10), range(split_i*10, (split_i+1)*10))})   \n",
        "\n",
        "    train_dataset.map_labels(label_maps[run_i])\n",
        "    test_dataset.map_labels(label_maps[run_i])\n",
        "\n",
        "    class_splits = [list(range(split_i*10, (split_i+1)*10)) for split_i in range(len(class_splits))]\n",
        "\n",
        "    train_indices, val_indices = train_dataset.train_val_split(class_splits, val_size=VAL_SIZE, random_state=RANDOM_STATE+run_i)\n",
        "    test_indices = test_dataset.test_split(class_splits)\n",
        "\n",
        "    train_dataloaders.append([])\n",
        "    val_dataloaders.append([])\n",
        "    test_subsets.append([])\n",
        "\n",
        "    for split_i in range(len(class_splits)): \n",
        "        train_subset = Subset(train_dataset, train_indices[split_i])\n",
        "        val_subset = Subset(train_dataset, val_indices[split_i])\n",
        "        test_subset = Subset(test_dataset, test_indices[split_i])\n",
        "\n",
        "        train_dataloaders[run_i].append(DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4))\n",
        "        val_dataloaders[run_i].append(DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4))\n",
        "        test_subsets[run_i].append(test_subset)\n",
        "\n",
        "# The test set should include all the classes seen in current *and previous* training steps\n",
        "for run_i in range(NUM_RUNS):\n",
        "    for split_i in reversed(range(0, len(class_splits))):\n",
        "        test_subsets[run_i][split_i] = DataLoader(ConcatDataset([test_subsets[run_i][i] for i in range(split_i+1)]),\n",
        "                                                  batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "test_dataloaders = test_subsets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqOQIuaBso79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Helper function to show an image grid\n",
        "\n",
        "def matplotlib_imshow(img, one_channel=False):\n",
        "    if one_channel:\n",
        "        img = img.mean(dim=0)\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    if one_channel:\n",
        "        plt.imshow(npimg, cmap=\"Greys\")\n",
        "    else:\n",
        "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNwcf1fpsvm_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Sanity check: visualize a batch of images\n",
        "dataiter = iter(train_dataloaders[0][0])\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# create grid of images\n",
        "img_grid = torchvision.utils.make_grid(images)\n",
        "\n",
        "# show images\n",
        "matplotlib_imshow(img_grid, one_channel=False)\n",
        "unique_labels = np.unique(labels, return_counts=True)\n",
        "unique_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEX3IV1VUXOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# @todo: put in model package once finished\n",
        "# @todo: funciton to save best model during validation\n",
        "\n",
        "class Manager():\n",
        "\n",
        "    def __init__(self, device, net, criterion, train_dataloader, val_dataloader, test_dataloader):\n",
        "        self.device = device\n",
        "        self.net = net\n",
        "        self.criterion = criterion\n",
        "        self.train_dataloader = train_dataloader\n",
        "        self.val_dataloader = val_dataloader\n",
        "        self.test_dataloader = test_dataloader\n",
        "\n",
        "    def increment_classes(self, n=10):\n",
        "        \"\"\"Add n classes in the final fc layer\"\"\"\n",
        "        in_features = self.net.linear.in_features  # size of each input sample\n",
        "        out_features = self.net.linear.out_features  # size of each output sample\n",
        "        weight = self.net.linear.weight.data\n",
        "\n",
        "        self.net.linear = nn.Linear(in_features, out_features+n)\n",
        "        self.net.linear.weight.data[:out_features] = weight\n",
        "\n",
        "    def do_batch(self, optimizer, batch, labels):\n",
        "        \"\"\"Runs model for one batch.\"\"\"\n",
        "        batch = batch.to(self.device)\n",
        "        labels = labels.to(self.device)\n",
        "\n",
        "        optimizer.zero_grad()  # Zero-ing the gradients\n",
        "        outputs = self.net(batch)\n",
        "\n",
        "        loss = self.criterion(outputs, labels)\n",
        "\n",
        "        # Get predictions\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        running_corrects = torch.sum(\n",
        "            preds == labels.data).data.item()  # number corrects\n",
        "\n",
        "        loss.backward()  # backward pass: computes gradients\n",
        "        optimizer.step()  # update weights based on accumulated gradients\n",
        "\n",
        "        return (loss, running_corrects)\n",
        "\n",
        "    def do_epoch(self, optimizer, scheduler, current_epoch):\n",
        "        \"\"\"Trains model for one epoch.\"\"\"\n",
        "\n",
        "        self.net.train()  # Set network in training mode\n",
        "\n",
        "        running_train_loss = 0\n",
        "        running_corrects = 0\n",
        "        total = 0\n",
        "        batch_idx = 0\n",
        "        for images, labels in tqdm(self.train_dataloader, desc='Epoch: %d ' % (current_epoch)):\n",
        "\n",
        "            loss, corrects = self.do_batch(optimizer, images, labels)\n",
        "\n",
        "            running_train_loss += loss.item()\n",
        "            running_corrects += corrects\n",
        "            total += labels.size(0)\n",
        "            batch_idx += 1\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        # Average Scores\n",
        "        train_loss = running_train_loss / batch_idx  # average over all batches\n",
        "        train_accuracy = running_corrects / \\\n",
        "            float(total)  # average over all samples\n",
        "\n",
        "        print('\\nTrain Loss {}, Train Accuracy {}'\\\n",
        "              .format(train_loss, train_accuracy))\n",
        "\n",
        "        return (train_loss, train_accuracy)\n",
        "\n",
        "    def validate(self):\n",
        "\n",
        "        self.net.train(False)\n",
        "\n",
        "        running_val_loss = 0\n",
        "        running_corrects = 0\n",
        "        total = 0\n",
        "        batch_idx = 0\n",
        "        for images, labels in self.val_dataloader:\n",
        "\n",
        "            images = images.to(self.device)\n",
        "            labels = labels.to(self.device)\n",
        "            total += labels.size(0)\n",
        "\n",
        "            # Forward Pass\n",
        "            outputs = self.net(images)\n",
        "            loss = self.criterion(outputs, labels)\n",
        "            running_val_loss += loss.item()\n",
        "\n",
        "            # Get predictions\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "            # Update Corrects\n",
        "            running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "            batch_idx += 1\n",
        "\n",
        "        # Calcuate Scores\n",
        "        val_loss = running_val_loss / batch_idx\n",
        "        val_accuracy = running_corrects / float(total)\n",
        "\n",
        "        return (val_loss, val_accuracy)\n",
        "\n",
        "    def train(self, optimizer, scheduler, num_epochs):\n",
        "\n",
        "        self.net.to(self.device)\n",
        "        cudnn.benchmark  # Calling this optimizes runtime\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "\n",
        "            train_loss, train_accuracy = self.do_epoch(\n",
        "                optimizer, scheduler, epoch+1)  # Epochs start counting form 1\n",
        "        \n",
        "        # Validate after each batch of classes\n",
        "        val_loss, val_accuracy = self.validate()            \n",
        "\n",
        "        return (train_loss, train_accuracy,\n",
        "                val_loss, val_accuracy)\n",
        "\n",
        "    def test(self):\n",
        "\n",
        "        self.net.train(False)  # Set Network to evaluation mode\n",
        "\n",
        "        running_corrects = 0\n",
        "        total = 0\n",
        "        for images, labels in tqdm(self.test_dataloader):\n",
        "            images = images.to(self.device)\n",
        "            labels = labels.to(self.device)\n",
        "            total += labels.size(0)\n",
        "\n",
        "            # Forward Pass\n",
        "            outputs = self.net(images)\n",
        "            loss = self.criterion(outputs, labels)\n",
        "\n",
        "            # Get predictions\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "            # Update Corrects\n",
        "            running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "        # Calculate Accuracy\n",
        "        accuracy = running_corrects / \\\n",
        "            float(total)  \n",
        "\n",
        "        print('Test Accuracy: {}'.format(accuracy))\n",
        "\n",
        "        return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJqnljCV5gJ5",
        "colab_type": "text"
      },
      "source": [
        "**FINE TUNING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzVPf2KxKci3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loss_history = []\n",
        "train_accuracy_history = []\n",
        "val_loss_history = []\n",
        "val_accuracy_history = []\n",
        "test_accuracy_history = []\n",
        "\n",
        "# Iterate over runs\n",
        "for train_dataloader, val_dataloader, test_dataloader in zip(train_dataloaders, val_dataloaders, test_dataloaders):\n",
        "    train_loss_history.append({})\n",
        "    train_accuracy_history.append({})\n",
        "    val_loss_history.append({})\n",
        "    val_accuracy_history.append({})\n",
        "    test_accuracy_history.append({})\n",
        "\n",
        "    net = resnet32()  # Define the net\n",
        "    criterion = nn.CrossEntropyLoss()  # Define the loss\n",
        "\n",
        "    # In this case we optimize over all the parameters of Resnet\n",
        "    parameters_to_optimize = net.parameters()\n",
        "    optimizer = optim.SGD(parameters_to_optimize, lr=LR,\n",
        "                          momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, \n",
        "                                               milestones=MILESTONES, gamma=GAMMA)\n",
        "        \n",
        "\n",
        "    i = 0\n",
        "    for train_split, val_split, test_split in zip(train_dataloader, val_dataloader, test_dataloader):\n",
        "\n",
        "        current_split = \"Split %i\"%(i)\n",
        "        print(current_split)\n",
        "\n",
        "        # Define Manager Object\n",
        "        manager = Manager(DEVICE, net, criterion,\n",
        "                          train_split, val_split, test_split)\n",
        "\n",
        "        scores = manager.train(optimizer, scheduler,\n",
        "                               NUM_EPOCHS)  # train the model\n",
        "\n",
        "        # score[i] = dictionary with key:epoch, value: score\n",
        "        train_loss_history[-1][current_split] = scores[0]\n",
        "        train_accuracy_history[-1][current_split] = scores[1]\n",
        "        val_loss_history[-1][current_split] = scores[2]\n",
        "        val_accuracy_history[-1][current_split] = scores[3]\n",
        "\n",
        "        # Test the model on classes seen until now\n",
        "        test_accuracy = manager.test()\n",
        "\n",
        "        test_accuracy_history[-1][current_split] = test_accuracy\n",
        "\n",
        "        manager.increment_classes(n=10)  # add 10 nodes to last FC layer\n",
        "\n",
        "        i+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ESzk5gF2c_c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def average_scores(train_loss_history, train_accuracy_history,\n",
        "                   val_loss_history, val_accuracy_history, test_accuracy_history):\n",
        "  '''Note: we decide to lose score informations on epochs, in favor of better comparability\n",
        "  of the scores over the different class splits\n",
        "  '''\n",
        "  avg_train_loss = {k:[] for k in keys}\n",
        "  avg_train_accuracy = {k:[] for k in keys}\n",
        "  avg_val_loss = {k:[] for k in keys}\n",
        "  avg_val_accuracy = {k:[] for k in keys}\n",
        "  avg_test_accuracy = {k:[] for k in keys}\n",
        "  \n",
        "  train_loss = []\n",
        "  train_accuracy = []\n",
        "  val_loss = []\n",
        "  val_accuracy = []\n",
        "  test_accuracy = []\n",
        "\n",
        "  for key in keys:\n",
        "    for run in range(NUM_RUNS):\n",
        "      avg_train_loss[key].append(train_loss_history[run][key])\n",
        "      avg_train_accuracy[key].append(train_accuracy_history[run][key])\n",
        "      avg_val_loss[key].append(val_loss_history[run][key])\n",
        "      avg_val_accuracy[key].append(val_accuracy_history[run][key])\n",
        "      avg_test_accuracy[key].append(test_accuracy_history[run][key])\n",
        "\n",
        "    train_loss.append([np.array(avg_train_loss[key]).mean(), np.array(avg_train_loss[key]).std()])\n",
        "    train_accuracy.append([np.array(avg_train_accuracy[key]).mean(), np.array(avg_train_accuracy[key]).std()])\n",
        "    val_loss.append([np.array(avg_val_loss[key]).mean(), np.array(avg_val_loss[key]).std()])\n",
        "    val_accuracy.append([np.array(avg_val_accuracy[key]).mean(), np.array(avg_val_accuracy[key]).std()])\n",
        "    test_accuracy.append([np.array(avg_test_accuracy[key]).mean(), np.array(avg_test_accuracy[key]).std()])\n",
        "\n",
        "  train_loss = np.array(train_loss)\n",
        "  train_accuracy = np.array(train_accuracy)\n",
        "  val_loss = np.array(val_loss)\n",
        "  val_accuracy = np.array(val_accuracy)\n",
        "  test_accuracy = np.array(test_accuracy)\n",
        "\n",
        "  return(train_loss, train_accuracy, val_loss, val_accuracy, test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKCztHSw7lHB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loss, train_accuracy, val_loss, val_accuracy,\\\n",
        "test_accuracy = average_scores(train_loss_history, train_accuracy_history,\n",
        "                                   val_loss_history, val_accuracy_history, test_accuracy_history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DA9bBfJvBlLo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot Train vs Validation loss and Train vs Validation Accuracy\n",
        "\n",
        "def plot_train_scores(train_loss, train_accuracy, validation_loss, validation_accuracy, save_directory):\n",
        "\n",
        "    # axes[0] = train loss\n",
        "    # axes[1] = train vs validation accuracy\n",
        "    fig, axes = plt.subplots(1, 2, figsize=[15, 5])\n",
        "\n",
        "    x = np.arange(10, 101, 10)\n",
        "\n",
        "    axes[0].plot(x, np.array(train_loss)[:, 0],\n",
        "                 color='#2E84D5', linewidth=2.5, label='Train Loss')\n",
        "    axes[0].plot(x, np.array(validation_loss)[:,0],\n",
        "                 color='#FF9232', linewidth=2.5, label='Validation Loss')\n",
        "    axes[0].set_title(\"Train Loss\")\n",
        "    axes[0].set_xlabel(\"Number of Classes\")\n",
        "    axes[0].set_ylabel(\"Loss\")\n",
        "\n",
        "    axes[1].plot(x, np.array(train_accuracy)[:,0],\n",
        "                 color='#2E84D5', linewidth=2.5, label='Train Accuracy')\n",
        "    axes[1].plot(x, np.array(validation_accuracy)[:,0],\n",
        "                 color='#FF9232', linewidth=2.5, label='Validation Accuracy')\n",
        "    axes[1].set_title(\"Val vs Train Accuracy\")\n",
        "    axes[1].set_xlabel(\"Number of Classes\")\n",
        "    axes[1].set_ylabel(\"Accuracy\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    axes[0].legend()\n",
        "    axes[1].legend()\n",
        "    axes[0].grid(True)\n",
        "    axes[1].grid(True)\n",
        "\n",
        "    if save_directory != None:\n",
        "      fig.savefig(save_directory)\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TAdCtXDEa5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_train_scores(train_loss, train_accuracy, val_loss, val_accuracy, None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwHAycOknrwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_test_scores (test_accuracy, save_directory = None):\n",
        "  fig, axes = plt.subplots(1, 1, figsize=[15, 5])\n",
        "\n",
        "  x = np.arange(10, 101, 10)\n",
        "\n",
        "  axes.errorbar(x, np.array(test_accuracy)[:, 0], np.array(test_accuracy)[:,1],\n",
        "                color='#2E84D5', linewidth=2.5, label='Train Loss')\n",
        "  \n",
        "  axes.set_title(\"Train Accuracy\")\n",
        "  axes.set_xlabel(\"Number of Classes\")\n",
        "  axes.set_ylabel(\"Accuracy\")\n",
        "\n",
        "  plt.tight_layout()\n",
        "  axes.legend()\n",
        "  axes.grid(True)\n",
        "\n",
        "  if save_directory != None:\n",
        "    fig.savefig(save_directory)\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1APlRtTpmkK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "11b6fe5b-6fb8-4b7d-f8ea-45e79207c0cf"
      },
      "source": [
        "plot_test_scores(test_accuracy)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}