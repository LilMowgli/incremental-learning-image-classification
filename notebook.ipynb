{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "notebook.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manuelemacchia/incremental-learning-image-classification/blob/master/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzqxHIh4OCdW",
        "colab_type": "text"
      },
      "source": [
        "# Incremental learning on image classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBHSznCZxpNB",
        "colab_type": "text"
      },
      "source": [
        "## Libraries and packages\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eQ6O12jxMFf",
        "colab_type": "code",
        "outputId": "84e55d83-b1e6-4c40-c207-9866c43a240b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "source": [
        "!pip3 install 'torch==1.5.0'\n",
        "!pip3 install 'torchvision==0.5.0'\n",
        "!pip3 install 'Pillow-SIMD'\n",
        "!pip3 install 'tqdm'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==1.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/70/54e9fb010fe1547bc4774716f11ececb81ae5b306c05f090f4461ee13205/torch-1.5.0-cp36-cp36m-manylinux1_x86_64.whl (752.0MB)\n",
            "\u001b[K     |████████████████████████████████| 752.0MB 23kB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.0) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5.0) (1.18.4)\n",
            "\u001b[31mERROR: torchvision 0.5.0 has requirement torch==1.4.0, but you'll have torch 1.5.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 1.4.0\n",
            "    Uninstalling torch-1.4.0:\n",
            "      Successfully uninstalled torch-1.4.0\n",
            "Successfully installed torch-1.5.0\n",
            "Requirement already satisfied: torchvision==0.5.0 in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Collecting torch==1.4.0\n",
            "  Using cached https://files.pythonhosted.org/packages/24/19/4804aea17cd136f1705a5e98a00618cb8f6ccc375ad8bfa437408e09d058/torch-1.4.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (1.18.4)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (7.0.0)\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 1.5.0\n",
            "    Uninstalling torch-1.5.0:\n",
            "      Successfully uninstalled torch-1.5.0\n",
            "Successfully installed torch-1.4.0\n",
            "Requirement already satisfied: Pillow-SIMD in /usr/local/lib/python3.6/dist-packages (7.0.0.post3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAYXtIdpx0Yy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import urllib\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader, ConcatDataset\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "# from torchvision.models import resnet18\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YFLG4yRVwi9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "username = ''\n",
        "password = ''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09iWc_oCotu2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "password = urllib.parse.quote(password)\n",
        "!git clone https://$username:$password@github.com/manuelemacchia/incremental-learning-image-classification.git\n",
        "!mv -v incremental-learning-image-classification/* .\n",
        "!rm -rf incremental-learning-image-classification README.md\n",
        "\n",
        "from data.cifar100 import CIFAR100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUfYUe_QfVbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load Resnet for CIFAR\n",
        "\n",
        "!git clone https://github.com/akamaster/pytorch_resnet_cifar10.git\n",
        "!mv -v 'pytorch_resnet_cifar10' 'Resnet'\n",
        "\n",
        "from Resnet.resnet import resnet32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j12pgffMR6Qv",
        "colab_type": "text"
      },
      "source": [
        "## Arguments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwE0x8gkSisn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Settings\n",
        "DEVICE = 'cuda'\n",
        "\n",
        "# Dataset\n",
        "DATA_DIR = 'data'       # Directory where the dataset will be downloaded\n",
        "\n",
        "RANDOM_STATE = 42       # For reproducibility of results\n",
        "NUM_CLASSES = 100       # Total number of classes\n",
        "CLASS_BATCH_SIZE = 10   # Size of batch of classes for incremental learning\n",
        "VAL_SIZE = 0.5          # Proportion of validation set with respect to training set (between 0 and 1)\n",
        "\n",
        "# Training\n",
        "BATCH_SIZE = 256\n",
        "LR = 1e-3\n",
        "MOMENTUM = 0.9\n",
        "WEIGHT_DECAY = 5e-5\n",
        "\n",
        "NUM_RUNS = 3            # Number of runs of every method (at least 3 to have a fair benchmark)\n",
        "\n",
        "NUM_EPOCHS = 30         # Total number of training epochs\n",
        "STEP_SIZE = 20          # How many epochs before decreasing learning rate (if using a step-down policy)\n",
        "GAMMA = 0.1             # Multiplicative factor for learning rate step-down\n",
        "\n",
        "# Logging\n",
        "LOG_FREQUENCY = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDDdumxRwbdQ",
        "colab_type": "text"
      },
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ka2RwY0VS8-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download dataset\n",
        "!wget https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
        "!tar -xf 'cifar-100-python.tar.gz'\n",
        "!mv 'cifar-100-python' $DATA_DIR\n",
        "!rm -rf 'cifar-100-python.tar.gz'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJVKOqLjVUhp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define transformations for training\n",
        "train_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Define transformations for evaluation\n",
        "eval_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))                                    \n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmQEsuniWjIN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import dataset\n",
        "train_dataset = CIFAR100(DATA_DIR, split='train', transform=train_transform)\n",
        "test_dataset = CIFAR100(DATA_DIR, split='test', transform=eval_transform)\n",
        "\n",
        "train_dataloaders = []\n",
        "val_dataloaders = []\n",
        "test_dataloaders = []\n",
        "\n",
        "for run_i in range(NUM_RUNS): # To have a fair benchmark, we run every method on at least three different random splits.\n",
        "    class_splits = train_dataset.class_splits(steps=CLASS_BATCH_SIZE, random_state=RANDOM_STATE+run_i)\n",
        "\n",
        "    train_indices, val_indices = train_dataset.train_val_split(class_splits, val_size=VAL_SIZE, random_state=RANDOM_STATE+run_i)\n",
        "    test_indices = test_dataset.test_split(class_splits, random_state=RANDOM_STATE+run_i)\n",
        "\n",
        "    train_dataloaders.append([])\n",
        "    val_dataloaders.append([])\n",
        "    test_dataloaders.append([])\n",
        "\n",
        "    for split_i in range(len(class_splits)):\n",
        "        train_subset = Subset(train_dataset, train_indices[split_i])\n",
        "        val_subset = Subset(train_dataset, val_indices[split_i])\n",
        "        test_subset = Subset(test_dataset, test_indices[split_i])\n",
        "\n",
        "        train_dataloaders[run_i].append(DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4))\n",
        "        val_dataloaders[run_i].append(DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4))\n",
        "        test_dataloaders[run_i].append(DataLoader(test_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4))\n",
        "\n",
        "# The test set should include all the classes seen in current *and previous* training steps\n",
        "for run_i in range(NUM_RUNS):\n",
        "    for split_i in reversed(range(1, len(class_splits))):\n",
        "        test_dataloaders[run_i][split_i] = ConcatDataset([test_dataloaders[run_i][i] for i in range(split_i+1)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqOQIuaBso79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# helper function to show an image grid\n",
        "\n",
        "def matplotlib_imshow(img, one_channel=False):\n",
        "    if one_channel:\n",
        "        img = img.mean(dim=0)\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    if one_channel:\n",
        "        plt.imshow(npimg, cmap=\"Greys\")\n",
        "    else:\n",
        "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNwcf1fpsvm_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sanity check: visualize a batch of images\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(train_dataloaders[0][0])\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# create grid of images\n",
        "img_grid = torchvision.utils.make_grid(images)\n",
        "\n",
        "# show images\n",
        "matplotlib_imshow(img_grid, one_channel=False)\n",
        "unique_labels = np.unique(labels, return_counts=True)\n",
        "unique_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YF58_vvqgn6",
        "colab_type": "text"
      },
      "source": [
        "**Manager Class**\n",
        "\n",
        "Class with methods to train, validate and test the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBjgrsi1v5vt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Manager():\n",
        "\n",
        "  def __init__(self, net, criterion, train_dataloader, val_dataloader, test_dataloader):\n",
        "    self.net = net\n",
        "    self.criterion = criterion\n",
        "    self.train_dataloader = train_dataloader\n",
        "    self.val_dataloader = val_dataloader\n",
        "    self.test_dataloader = test_dataloader\n",
        "\n",
        "\n",
        "  def increment_classes(self, n=10):\n",
        "        \"\"\"Add n classes in the final fc layer\"\"\"\n",
        "        in_features = self.net.fc.in_features # size of each input sample\n",
        "        out_features = self.net.fc.out_features # size of each output sample\n",
        "        weight = self.net.fc.weight.data\n",
        "\n",
        "        self.net.fc = nn.Linear(in_features, out_features+n)\n",
        "        self.net.fc.weight.data[:out_features] = weight\n",
        "        self.net.n_classes += n\n",
        "\n",
        "  \n",
        "  def do_batch(self, optimizer, batch, labels):\n",
        "    \"\"\"Runs model for one batch.\"\"\"\n",
        "    batch = batch.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    optimizer.zero_grad() # Zero-ing the gradients\n",
        "    outputs = self.net(batch)\n",
        "\n",
        "    loss = self.criterion(outputs, labels)\n",
        "\n",
        "    # Get predictions\n",
        "    _, preds = torch.max(outputs.data, 1)\n",
        "    running_corrects = torch.sum(preds == labels.data).data.item() # number corrects\n",
        "\n",
        "    loss.backward()  # backward pass: computes gradients\n",
        "    optimizer.step() # update weights based on accumulated gradients\n",
        "    \n",
        "    return (loss, running_corrects)\n",
        "    \n",
        "\n",
        "  def do_epoch(self, optimizer, scheduler, current_epoch):\n",
        "    \"\"\"Trains model for one epoch.\"\"\"\n",
        "\n",
        "    self.net.train() # Set network in training mode\n",
        "\n",
        "    running_train_loss = 0\n",
        "    running_corrects = 0\n",
        "\n",
        "    batch_idx = 0\n",
        "    for images, labels in tqdm(self.train_dataloader, desc='Epoch: %d ' % (current_epoch)):\n",
        "      loss, corrects = self.do_batch(optimizer, images, labels)\n",
        "      running_train_loss += loss.item()\n",
        "      running_corrects += corrects\n",
        "\n",
        "      batch_idx +=1\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    # Average Scores\n",
        "    train_loss = running_train_loss / batch_idx # average over all batches\n",
        "    train_accuracy = running_corrects / len(self.train_dataloader) # average over all samples\n",
        "\n",
        "    return (train_loss, train_accuracy)\n",
        "\n",
        "\n",
        "  def validate(self):\n",
        "\n",
        "    self.net.train(False)\n",
        "\n",
        "    running_test_loss = 0\n",
        "    running_corrects = 0\n",
        "    \n",
        "    batch_idx = 0\n",
        "    for images, labels in self.val_dataloader:\n",
        "      \n",
        "      images = images.to(DEVICE)\n",
        "      labels = labels.to(DEVICE)\n",
        "\n",
        "      # Forward Pass\n",
        "      outputs = self.net(images)\n",
        "      loss = self.criterion(outputs, labels)\n",
        "      run_val_loss += loss.item()\n",
        "\n",
        "      # Get predictions\n",
        "      _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "      # Update Corrects\n",
        "      running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "      batch_idx += 1\n",
        "\n",
        "    # Calcuate Scores\n",
        "    val_loss = running_test_loss / batch_idx\n",
        "    val_accuracy = running_corrects / float(len(self.val_dataloader)) \n",
        "\n",
        "    return (val_loss, val_accuracy)\n",
        "\n",
        "\n",
        "\n",
        "  def train(self, optimizer, scheduler, num_epochs):\n",
        "    \n",
        "    self.net.to(DEVICE)\n",
        "    cudnn.benchmark # Calling this optimizes runtime\n",
        "\n",
        "    train_loss_history = {}\n",
        "    train_accuracy_history = {}\n",
        "    val_loss_history = {}\n",
        "    val_accuracy_history = {}\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "      train_loss_history[epoch+1], train_accuracy_history[epoch+1] = self.do_epoch(optimizer, scheduler, epoch+1) # Epochs start counting form 1\n",
        "      val_loss_history[epoch+1], val_accuracy_history[epoch+1] = self.validate() # Validate at each epoch\n",
        "\n",
        "    return (train_loss_history, train_accuracy_history, val_loss_history,val_accuracy_history)\n",
        "\n",
        "\n",
        "  def test(self):\n",
        "\n",
        "    self.net.train(False) # Set Network to evaluation mode \n",
        "\n",
        "    running_corrects = 0\n",
        "    for images, labels in tqdm(self.test_dataloader):\n",
        "      images = images.to(DEVICE)\n",
        "      labels = labels.to(DEVICE)\n",
        "\n",
        "      # Forward Pass\n",
        "      outputs = self.net(images)\n",
        "      loss = self.criterion(outputs, labels)\n",
        "\n",
        "      # Get predictions\n",
        "      _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "      # Update Corrects\n",
        "      running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "    # Calculate Accuracy\n",
        "    accuracy = running_corrects / float(len(self.test_dataloader)) #len test dataloader\n",
        "\n",
        "    print('Test Accuracy: {}'.format(accuracy))\n",
        "\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwGDklYJa-N0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot Train vs Validation loss and Train vs Validation Accuracy\n",
        "\n",
        "def plot_scores(train_loss, validation_loss, train_accuracy, validation_accuracy, save_directory):\n",
        "\n",
        "  # axes[0] = train loss\n",
        "  # axes[1] = train vs validation accuracy\n",
        "  fig, axes = plt.subplots(1, 2, figsize = [15, 5])\n",
        "\n",
        "  axes[0].plot(list(train_loss.keys()), list(train_loss.values()), \n",
        "               color = '#2E84D5', linewidth = 2.5, label = 'Train Loss')\n",
        "  axes[0].plot(list(validation_loss.keys()), list(validation_loss.values()), \n",
        "               color = '#FF9232', linewidth = 2.5, label = 'Validation Loss')\n",
        "  axes[0].set_title(\"Train Loss\")\n",
        "  axes[0].set_xlabel(\"epoch\")\n",
        "  axes[0].set_ylabel(\"loss\")\n",
        "\n",
        "  axes[1].plot(list(train_accuracy.keys()), list(train_accuracy.values()), \n",
        "               color = '#2E84D5', linewidth = 2.5, label = 'Train Accuracy')\n",
        "  axes[1].plot(list(validation_accuracy.keys()), list(validation_accuracy.values()), \n",
        "               color = '#FF9232', linewidth = 2.5, label = 'Validation Accuracy')\n",
        "  axes[1].set_title(\"Val vs Train Accuracy\")\n",
        "  axes[1].set_xlabel(\"epoch\")\n",
        "  axes[1].set_ylabel(\"accuracy\")\n",
        "\n",
        "  plt.tight_layout()\n",
        "  axes[0].legend()\n",
        "  axes[1].legend()\n",
        "  axes[0].grid(True)\n",
        "  axes[1].grid(True)\n",
        "\n",
        "  fig.savefig(save_directory)\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJqnljCV5gJ5",
        "colab_type": "text"
      },
      "source": [
        "**FINE TUNING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzVPf2KxKci3",
        "colab_type": "code",
        "outputId": "81e18b4f-0c31-41fd-bb96-e13935ba9dc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        }
      },
      "source": [
        "train_loss_history = []\n",
        "train_accuracy_history = []\n",
        "val_loss_history = []\n",
        "val_accuracy_history = []\n",
        "test_accuracy_history = []\n",
        "\n",
        "for train_dataloader, val_dataloader, test_dataloader in zip(train_dataloaders, val_dataloaders, test_dataloaders):\n",
        "\n",
        "  train_loss_history.append([])\n",
        "  train_accuracy_history.append([])\n",
        "  val_loss_history.append([])\n",
        "  val_accuracy_history.append([])\n",
        "  test_accuracy_history.append([])\n",
        "\n",
        "  net = resnet32() # Define the net\n",
        "  criterion = nn.CrossEntropyLoss() # Define the loss\n",
        "\n",
        "  parameters_to_optimize = net.parameters() # In this case we optimize over all the parameters of Resnet\n",
        "  optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "  scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n",
        "\n",
        "  for train_split, val_split, test_split in zip(train_dataloader, val_dataloader, test_dataloader):\n",
        "\n",
        "    # Define Manager Object\n",
        "    manager = Manager(net, criterion, train_split, val_split, test_split)\n",
        "\n",
        "    scores = manager.train(optimizer, scheduler, NUM_EPOCHS) # train the model\n",
        "\n",
        "    # score[i] = dictionary with key:epoch, value: score\n",
        "    train_loss_history[-1].append(scores[0])\n",
        "    train_accuracy_history[-1].append(scores[1])\n",
        "    val_loss_history[-1].append(scores[2])\n",
        "    val_accuracy_history[-1].append(scores[3])\n",
        "\n",
        "    # Test the model on classes seen until now\n",
        "    test_accuracy = manager.test()\n",
        "\n",
        "    test_accuracy_history[-1].append(test_accuracy)\n",
        "\n",
        "    manager.increment_classes(n=10) # add 10 nodes to last FC layer"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-7c83e26f2d62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mtrain_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_split\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Define Manager Object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        }
      ]
    }
  ]
}