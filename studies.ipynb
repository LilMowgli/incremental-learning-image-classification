{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "studies.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NzqxHIh4OCdW"
      },
      "source": [
        "# Incremental learning on image classification\n",
        "Ablation studies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wBHSznCZxpNB"
      },
      "source": [
        "## Libraries and packages\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4eQ6O12jxMFf",
        "colab": {}
      },
      "source": [
        "!pip3 install 'torch==1.4.0'\n",
        "!pip3 install 'torchvision==0.5.0'\n",
        "!pip3 install 'Pillow-SIMD'\n",
        "!pip3 install 'tqdm'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xAYXtIdpx0Yy",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import urllib\n",
        "import logging\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, Subset, DataLoader, ConcatDataset\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.models import resnet34\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "from copy import deepcopy\n",
        "\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "09iWc_oCotu2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "8200be73-d927-40d0-e45d-33b62c57f710"
      },
      "source": [
        "# GitHub credentials for cloning private repository\n",
        "username = 'xolotl18'\n",
        "password = ''\n",
        "\n",
        "# Download packages from repository\n",
        "password = urllib.parse.quote(password)\n",
        "!git clone https://$username:$password@github.com/manuelemacchia/incremental-learning-image-classification.git\n",
        "password = ''\n",
        "\n",
        "!mv -v incremental-learning-image-classification/* .\n",
        "!rm -rf incremental-learning-image-classification README.md"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'incremental-learning-image-classification'...\n",
            "remote: Enumerating objects: 94, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/94)\u001b[K\rremote: Counting objects:   2% (2/94)\u001b[K\rremote: Counting objects:   3% (3/94)\u001b[K\rremote: Counting objects:   4% (4/94)\u001b[K\rremote: Counting objects:   5% (5/94)\u001b[K\rremote: Counting objects:   6% (6/94)\u001b[K\rremote: Counting objects:   7% (7/94)\u001b[K\rremote: Counting objects:   8% (8/94)\u001b[K\rremote: Counting objects:   9% (9/94)\u001b[K\rremote: Counting objects:  10% (10/94)\u001b[K\rremote: Counting objects:  11% (11/94)\u001b[K\rremote: Counting objects:  12% (12/94)\u001b[K\rremote: Counting objects:  13% (13/94)\u001b[K\rremote: Counting objects:  14% (14/94)\u001b[K\rremote: Counting objects:  15% (15/94)\u001b[K\rremote: Counting objects:  17% (16/94)\u001b[K\rremote: Counting objects:  18% (17/94)\u001b[K\rremote: Counting objects:  19% (18/94)\u001b[K\rremote: Counting objects:  20% (19/94)\u001b[K\rremote: Counting objects:  21% (20/94)\u001b[K\rremote: Counting objects:  22% (21/94)\u001b[K\rremote: Counting objects:  23% (22/94)\u001b[K\rremote: Counting objects:  24% (23/94)\u001b[K\rremote: Counting objects:  25% (24/94)\u001b[K\rremote: Counting objects:  26% (25/94)\u001b[K\rremote: Counting objects:  27% (26/94)\u001b[K\rremote: Counting objects:  28% (27/94)\u001b[K\rremote: Counting objects:  29% (28/94)\u001b[K\rremote: Counting objects:  30% (29/94)\u001b[K\rremote: Counting objects:  31% (30/94)\u001b[K\rremote: Counting objects:  32% (31/94)\u001b[K\rremote: Counting objects:  34% (32/94)\u001b[K\rremote: Counting objects:  35% (33/94)\u001b[K\rremote: Counting objects:  36% (34/94)\u001b[K\rremote: Counting objects:  37% (35/94)\u001b[K\rremote: Counting objects:  38% (36/94)\u001b[K\rremote: Counting objects:  39% (37/94)\u001b[K\rremote: Counting objects:  40% (38/94)\u001b[K\rremote: Counting objects:  41% (39/94)\u001b[K\rremote: Counting objects:  42% (40/94)\u001b[K\rremote: Counting objects:  43% (41/94)\u001b[K\rremote: Counting objects:  44% (42/94)\u001b[K\rremote: Counting objects:  45% (43/94)\u001b[K\rremote: Counting objects:  46% (44/94)\u001b[K\rremote: Counting objects:  47% (45/94)\u001b[K\rremote: Counting objects:  48% (46/94)\u001b[K\rremote: Counting objects:  50% (47/94)\u001b[K\rremote: Counting objects:  51% (48/94)\u001b[K\rremote: Counting objects:  52% (49/94)\u001b[K\rremote: Counting objects:  53% (50/94)\u001b[K\rremote: Counting objects:  54% (51/94)\u001b[K\rremote: Counting objects:  55% (52/94)\u001b[K\rremote: Counting objects:  56% (53/94)\u001b[K\rremote: Counting objects:  57% (54/94)\u001b[K\rremote: Counting objects:  58% (55/94)\u001b[K\rremote: Counting objects:  59% (56/94)\u001b[K\rremote: Counting objects:  60% (57/94)\u001b[K\rremote: Counting objects:  61% (58/94)\u001b[K\rremote: Counting objects:  62% (59/94)\u001b[K\rremote: Counting objects:  63% (60/94)\u001b[K\rremote: Counting objects:  64% (61/94)\u001b[K\rremote: Counting objects:  65% (62/94)\u001b[K\rremote: Counting objects:  67% (63/94)\u001b[K\rremote: Counting objects:  68% (64/94)\u001b[K\rremote: Counting objects:  69% (65/94)\u001b[K\rremote: Counting objects:  70% (66/94)\u001b[K\rremote: Counting objects:  71% (67/94)\u001b[K\rremote: Counting objects:  72% (68/94)\u001b[K\rremote: Counting objects:  73% (69/94)\u001b[K\rremote: Counting objects:  74% (70/94)\u001b[K\rremote: Counting objects:  75% (71/94)\u001b[K\rremote: Counting objects:  76% (72/94)\u001b[K\rremote: Counting objects:  77% (73/94)\u001b[K\rremote: Counting objects:  78% (74/94)\u001b[K\rremote: Counting objects:  79% (75/94)\u001b[K\rremote: Counting objects:  80% (76/94)\u001b[K\rremote: Counting objects:  81% (77/94)\u001b[K\rremote: Counting objects:  82% (78/94)\u001b[K\rremote: Counting objects:  84% (79/94)\u001b[K\rremote: Counting objects:  85% (80/94)\u001b[K\rremote: Counting objects:  86% (81/94)\u001b[K\rremote: Counting objects:  87% (82/94)\u001b[K\rremote: Counting objects:  88% (83/94)\u001b[K\rremote: Counting objects:  89% (84/94)\u001b[K\rremote: Counting objects:  90% (85/94)\u001b[K\rremote: Counting objects:  91% (86/94)\u001b[K\rremote: Counting objects:  92% (87/94)\u001b[K\rremote: Counting objects:  93% (88/94)\u001b[K\rremote: Counting objects:  94% (89/94)\u001b[K\rremote: Counting objects:  95% (90/94)\u001b[K\rremote: Counting objects:  96% (91/94)\u001b[K\rremote: Counting objects:  97% (92/94)\u001b[K\rremote: Counting objects:  98% (93/94)\u001b[K\rremote: Counting objects: 100% (94/94)\u001b[K\rremote: Counting objects: 100% (94/94), done.\u001b[K\n",
            "remote: Compressing objects: 100% (82/82), done.\u001b[K\n",
            "remote: Total 538 (delta 50), reused 11 (delta 4), pack-reused 444\u001b[K\n",
            "Receiving objects: 100% (538/538), 2.55 MiB | 22.94 MiB/s, done.\n",
            "Resolving deltas: 100% (279/279), done.\n",
            "mv: cannot move 'incremental-learning-image-classification/data' to './data': Directory not empty\n",
            "renamed 'incremental-learning-image-classification/joint_training.ipynb' -> './joint_training.ipynb'\n",
            "mv: cannot move 'incremental-learning-image-classification/losses' to './losses': Directory not empty\n",
            "mv: cannot move 'incremental-learning-image-classification/model' to './model': Directory not empty\n",
            "renamed 'incremental-learning-image-classification/notebook.ipynb' -> './notebook.ipynb'\n",
            "renamed 'incremental-learning-image-classification/README.md' -> './README.md'\n",
            "mv: cannot move 'incremental-learning-image-classification/report' to './report': Directory not empty\n",
            "renamed 'incremental-learning-image-classification/studies.ipynb' -> './studies.ipynb'\n",
            "mv: cannot move 'incremental-learning-image-classification/utils' to './utils': Directory not empty\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QPLViftqtC3I",
        "colab": {}
      },
      "source": [
        "from data.cifar100 import Cifar100\n",
        "from model.resnet_cifar import resnet32\n",
        "from model.manager import Manager\n",
        "from model.icarl import Exemplars\n",
        "from model.icarl import iCaRL\n",
        "from utils import plot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j12pgffMR6Qv"
      },
      "source": [
        "## Arguments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JwE0x8gkSisn",
        "colab": {}
      },
      "source": [
        "# Directories\n",
        "DATA_DIR = 'data'       # Directory where the dataset will be downloaded\n",
        "\n",
        "# Settings\n",
        "DEVICE = 'cuda'\n",
        "\n",
        "# Dataset\n",
        "\n",
        "RANDOM_STATE = None\n",
        "\n",
        "RANDOM_STATES = [658, 423, 422]      # For reproducibility of results                        \n",
        "                                     # Note: different random states give very different\n",
        "                                     # splits and therefore very different results.\n",
        "\n",
        "NUM_CLASSES = 100       # Total number of classes\n",
        "NUM_BATCHES = 10\n",
        "CLASS_BATCH_SIZE = 10   # Size of batch of classes for incremental learning\n",
        "\n",
        "VAL_SIZE = 0.1          # Proportion of validation set with respect to training set (between 0 and 1)\n",
        "\n",
        "# Training\n",
        "BATCH_SIZE = 64         # Batch size (iCaRL sets this to 128)\n",
        "LR = 2                  # Initial learning rate\n",
        "                       \n",
        "MOMENTUM = 0.9          # Momentum for stochastic gradient descent (SGD)\n",
        "WEIGHT_DECAY = 1e-5     # Weight decay from iCaRL\n",
        "\n",
        "NUM_RUNS = 3            # Number of runs of every method\n",
        "                        # Note: this should be at least 3 to have a fair benchmark\n",
        "\n",
        "NUM_EPOCHS = 70         # Total number of training epochs\n",
        "MILESTONES = [49, 63]   # Step down policy from iCaRL (MultiStepLR)\n",
        "                        # Decrease the learning rate by gamma at each milestone\n",
        "GAMMA = 0.2             # Gamma factor from iCaRL"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF0ypxGognNR",
        "colab_type": "text"
      },
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4mf04UjEgmPG",
        "colab": {}
      },
      "source": [
        "# Transformations for Learning Without Forgetting\n",
        "train_transform = transforms.Compose([transforms.RandomCrop(32, padding=4),\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.ToTensor(), # Turn PIL Image to torch.Tensor\n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))                                    \n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y9Oq44dxgmPN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "310f8c46-b8f8-4503-bb4f-d7e1accbb8a5"
      },
      "source": [
        "train_subsets = [[] for i in range(NUM_RUNS)]\n",
        "val_subsets = [[] for i in range(NUM_RUNS)]\n",
        "test_subsets = [[] for i in range(NUM_RUNS)]\n",
        "\n",
        "for run_i in range(NUM_RUNS):\n",
        "    for split_i in range(CLASS_BATCH_SIZE):\n",
        "        if run_i+split_i == 0: # Download dataset only at first instantiation\n",
        "            download = True\n",
        "        else:\n",
        "            download = False\n",
        "\n",
        "        # Create CIFAR100 dataset\n",
        "        train_dataset = Cifar100(DATA_DIR, train=True, download=download, random_state=RANDOM_STATES[run_i], transform=train_transform)\n",
        "        test_dataset = Cifar100(DATA_DIR, train=False, download=False, random_state=RANDOM_STATES[run_i], transform=test_transform)\n",
        "    \n",
        "        # Subspace of CIFAR100 of 10 classes\n",
        "        train_dataset.set_classes_batch(train_dataset.batch_splits[split_i]) \n",
        "        test_dataset.set_classes_batch([test_dataset.batch_splits[i] for i in range(0, split_i+1)])\n",
        "\n",
        "        # Define train and validation indices\n",
        "        train_indices, val_indices = train_dataset.train_val_split(VAL_SIZE, RANDOM_STATES[run_i])\n",
        "\n",
        "        # Define subsets\n",
        "        train_subsets[run_i].append(Subset(train_dataset, train_indices))\n",
        "        val_subsets[run_i].append(Subset(train_dataset, val_indices))\n",
        "        test_subsets[run_i].append(test_dataset)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0oEuUQPo2Nb",
        "colab_type": "text"
      },
      "source": [
        "## Classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9tu5eAf7mXF",
        "colab_type": "text"
      },
      "source": [
        "### K-NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fnolqQQ72Gt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class iCaRLwithKNN(iCaRL):\n",
        "    def classifier_fit(self, train_dataset, **clf_args):\n",
        "        \"\"\"Fit classifier on the union of training dataset and exemplars.\"\"\"\n",
        "\n",
        "        # Union of training dataset and exemplars\n",
        "        exemplars_dataset = Exemplars(self.exemplars, self.train_transform)\n",
        "        train_dataset_with_exemplars = ConcatDataset([exemplars_dataset, train_dataset])\n",
        "\n",
        "        # Convert dataset to numpy format\n",
        "        # X contains training samples, y contains labels\n",
        "        X, y = self.dataset_to_numpy(train_dataset_with_exemplars)\n",
        "\n",
        "        # Extract features from the training dataset\n",
        "        X_features = self.extract_features(torch.tensor(X, dtype=torch.float))\n",
        "        for i in range(X_features.size(0)):\n",
        "            X_features[i] = X_features[i]/X_features[i].norm()\n",
        "        X_features = X_features.to('cpu').numpy()\n",
        "\n",
        "        self.clf = KNeighborsClassifier(clf_args['n_neighbors'])\n",
        "        self.clf.fit(X_features, y)\n",
        "\n",
        "    def classifier_predict(self, test_dataset):\n",
        "        \"\"\"Predict labels of test_dataset.\"\"\"\n",
        "\n",
        "        X_test, y_test = self.dataset_to_numpy(test_dataset)\n",
        "\n",
        "        # Extract features from the test set\n",
        "        X_test_features = self.extract_features(torch.tensor(X_test, dtype=torch.float))\n",
        "        for i in range(X_test_features.size(0)):\n",
        "            X_test_features[i] = X_test_features[i]/X_test_features[i].norm()\n",
        "        X_test_features = X_test_features.to('cpu').numpy()\n",
        "        \n",
        "        y_pred = self.clf.predict(X_test_features)\n",
        "\n",
        "        return y_test, y_pred\n",
        "\n",
        "    def dataset_to_numpy(self, dataset):\n",
        "        # Preallocate arrays\n",
        "        X = np.zeros((len(dataset), 3, 32, 32))\n",
        "        y = np.zeros(len(dataset), dtype=int)\n",
        "\n",
        "        dataloader = DataLoader(dataset, batch_size=1)\n",
        "\n",
        "        for idx, (image, labels) in enumerate(dataloader):\n",
        "            X[idx] = image[0].numpy()\n",
        "            y[idx] = labels.numpy()[0]\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def test_knn(self, test_dataset, train_dataset):\n",
        "        \"\"\"Test the model.\n",
        "\n",
        "        Args:\n",
        "            test_dataset: dataset on which to test the network\n",
        "            train_dataset: training set used to train the last split\n",
        "        Returns:\n",
        "            accuracy (float): accuracy of the model on the test set\n",
        "        \"\"\"\n",
        "\n",
        "        self.net.train(False)\n",
        "        if self.best_net is not None: self.best_net.train(False)  # Set Network to evaluation mode\n",
        "        if self.old_net is not None: self.old_net.train(False)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            self.classifier_fit(train_dataset, n_neighbors=3)\n",
        "            y_truth, y_pred = self.classifier_predict(test_dataset)\n",
        "\n",
        "        # Calculate accuracy\n",
        "        accuracy = accuracy_score(y_truth, y_pred)\n",
        "\n",
        "        print(f\"Test accuracy (iCaRL with KNN): {accuracy} \")\n",
        "\n",
        "        return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-t3c4MCBV2jB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LR = 2\n",
        "MOMENTUM = 0.9\n",
        "WEIGHT_DECAY = 0.00001\n",
        "MILESTONES = [49, 63]\n",
        "GAMMA = 0.2\n",
        "NUM_EPOCHS = 70\n",
        "BATCH_SIZE = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zB1mJCwwVwqq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logs_icarl = [[] for _ in range(NUM_RUNS)]\n",
        "logs_icarl_knn = [[] for _ in range(NUM_RUNS)]\n",
        "\n",
        "for run_i in range(NUM_RUNS):\n",
        "    net = resnet32()\n",
        "    icarl_knn = iCaRLwithKNN(DEVICE, net, LR, MOMENTUM, WEIGHT_DECAY, MILESTONES, GAMMA, NUM_EPOCHS, BATCH_SIZE, train_transform, test_transform)\n",
        "\n",
        "    for split_i in range(10):\n",
        "        print(f\"## Split {split_i} of run {run_i} ##\")\n",
        "        \n",
        "        train_logs = icarl_knn.incremental_train(split_i, train_subsets[run_i][split_i], val_subsets[run_i][split_i])\n",
        "\n",
        "        acc, _ = icarl_knn.test(test_subsets[run_i][split_i], train_subsets[run_i][split_i])\n",
        "        logs_icarl[run_i].append(acc)\n",
        "\n",
        "        acc = icarl_knn.test_knn(test_subsets[run_i][split_i], train_subsets[run_i][split_i])\n",
        "        logs_icarl_knn[run_i].append(acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ufG1nvlnrIkP"
      },
      "source": [
        "### Linear SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dswJ5wX2rIkS",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class iCaRLwithSVM(iCaRL):\n",
        "    def classifier_fit(self, train_dataset, **clf_args):\n",
        "        \"\"\"Fit classifier on the union of training dataset and exemplars.\"\"\"\n",
        "\n",
        "        # Union of training dataset and exemplars\n",
        "        exemplars_dataset = Exemplars(self.exemplars, self.train_transform)\n",
        "        train_dataset_with_exemplars = ConcatDataset([exemplars_dataset, train_dataset])\n",
        "\n",
        "        # Convert dataset to numpy format\n",
        "        # X contains training samples, y contains labels\n",
        "        X, y = self.dataset_to_numpy(train_dataset_with_exemplars)\n",
        "\n",
        "        # Extract features from the training dataset\n",
        "        X_features = self.extract_features(torch.tensor(X, dtype=torch.float))\n",
        "        for i in range(X_features.size(0)):\n",
        "            X_features[i] = X_features[i]/X_features[i].norm()\n",
        "        X_features = X_features.to('cpu').numpy()\n",
        "\n",
        "        self.clf = SVC(C=clf_args['C'], kernel=clf_args['kernel'], gamma=clf_args['gamma'])\n",
        "        self.clf.fit(X_features, y)\n",
        "\n",
        "    def classifier_predict(self, test_dataset):\n",
        "        \"\"\"Predict labels of test_dataset.\"\"\"\n",
        "\n",
        "        X_test, y_test = self.dataset_to_numpy(test_dataset)\n",
        "\n",
        "        # Extract features from the test set\n",
        "        X_test_features = self.extract_features(torch.tensor(X_test, dtype=torch.float))\n",
        "        for i in range(X_test_features.size(0)):\n",
        "            X_test_features[i] = X_test_features[i]/X_test_features[i].norm()\n",
        "        X_test_features = X_test_features.to('cpu').numpy()\n",
        "        \n",
        "        y_pred = self.clf.predict(X_test_features)\n",
        "\n",
        "        return y_test, y_pred\n",
        "\n",
        "    def dataset_to_numpy(self, dataset):\n",
        "        # Preallocate arrays\n",
        "        X = np.zeros((len(dataset), 3, 32, 32))\n",
        "        y = np.zeros(len(dataset), dtype=int)\n",
        "\n",
        "        dataloader = DataLoader(dataset, batch_size=1)\n",
        "\n",
        "        for idx, (image, labels) in enumerate(dataloader):\n",
        "            X[idx] = image[0].numpy()\n",
        "            y[idx] = labels.numpy()[0]\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def test_knn(self, test_dataset, train_dataset):\n",
        "        \"\"\"Test the model.\n",
        "\n",
        "        Args:\n",
        "            test_dataset: dataset on which to test the network\n",
        "            train_dataset: training set used to train the last split\n",
        "        Returns:\n",
        "            accuracy (float): accuracy of the model on the test set\n",
        "        \"\"\"\n",
        "\n",
        "        self.net.train(False)\n",
        "        if self.best_net is not None: self.best_net.train(False)  # Set Network to evaluation mode\n",
        "        if self.old_net is not None: self.old_net.train(False)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            self.classifier_fit(train_dataset, C=1, kernel=\"rbf\", gamma=\"auto\")\n",
        "            y_truth, y_pred = self.classifier_predict(test_dataset)\n",
        "\n",
        "        # Calculate accuracy\n",
        "        accuracy = accuracy_score(y_truth, y_pred)\n",
        "\n",
        "        print(f\"Test accuracy (iCaRL with SVC): {accuracy} \")\n",
        "\n",
        "        return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nsmxdNMVrIkV",
        "colab": {}
      },
      "source": [
        "LR = 2\n",
        "MOMENTUM = 0.9\n",
        "WEIGHT_DECAY = 0.00001\n",
        "MILESTONES = [49, 63]\n",
        "GAMMA = 0.2\n",
        "NUM_EPOCHS = 70\n",
        "BATCH_SIZE = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Emgmal00rIkZ",
        "colab": {}
      },
      "source": [
        "logs_icarl = [[] for _ in range(NUM_RUNS)]\n",
        "logs_icarl_svm = [[] for _ in range(NUM_RUNS)]\n",
        "\n",
        "for run_i in range(NUM_RUNS):\n",
        "    net = resnet32()\n",
        "    icarl_svm = iCaRLwithSVM(DEVICE, net, LR, MOMENTUM, WEIGHT_DECAY, MILESTONES, GAMMA, NUM_EPOCHS, BATCH_SIZE, train_transform, test_transform)\n",
        "\n",
        "    for split_i in range(10):\n",
        "        print(f\"## Split {split_i} of run {run_i} ##\")\n",
        "        \n",
        "        train_logs = icarl_svm.incremental_train(split_i, train_subsets[run_i][split_i], val_subsets[run_i][split_i])\n",
        "\n",
        "        acc, _ = icarl_svm.test(test_subsets[run_i][split_i], train_subsets[run_i][split_i])\n",
        "        logs_icarl[run_i].append(acc)\n",
        "\n",
        "        acc = icarl_svm.test_knn(test_subsets[run_i][split_i], train_subsets[run_i][split_i])\n",
        "        logs_icarl_svm[run_i].append(acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUggs5zsz-eu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(logs_icarl)\n",
        "print(logs_icarl_svm)from sklearn.svm import SVC"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzoVUe8wVWUY",
        "colab_type": "text"
      },
      "source": [
        "### All classifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x86Z3l3OViOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NX4SqCBKVjLn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LR = 2\n",
        "MOMENTUM = 0.9\n",
        "WEIGHT_DECAY = 0.00001\n",
        "MILESTONES = [49, 63]\n",
        "GAMMA = 0.2\n",
        "NUM_EPOCHS = 70\n",
        "BATCH_SIZE = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NhDWVFPVmAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class iCaRLwithCLFS(iCaRL):\n",
        "    def classifier_fit(self, train_dataset, split):\n",
        "        \"\"\"Fit classifier on the union of training dataset and exemplars.\"\"\"\n",
        "\n",
        "        # Union of training dataset and exemplars\n",
        "        exemplars_dataset = Exemplars(self.exemplars, self.train_transform)\n",
        "        train_dataset_with_exemplars = ConcatDataset([exemplars_dataset, train_dataset])\n",
        "\n",
        "        # Convert dataset to numpy format\n",
        "        # X contains training samples, y contains labels\n",
        "        X, y = self.dataset_to_numpy(train_dataset_with_exemplars)\n",
        "\n",
        "        # Extract features from the training dataset\n",
        "        X_features = self.extract_features(torch.tensor(X, dtype=torch.float))\n",
        "        for i in range(X_features.size(0)):\n",
        "            X_features[i] = X_features[i]/X_features[i].norm()\n",
        "        X_features = X_features.to('cpu').numpy()\n",
        "\n",
        "        param_grid1 = { \n",
        "          'n_estimators': [100, 200, 500],\n",
        "          'max_features': ['sqrt', 'log2'],\n",
        "          'max_depth' : [5,6,7],\n",
        "          'criterion' :['gini', 'entropy']\n",
        "        }\n",
        "\n",
        "        param_grid2 = {\n",
        "            'n_neighbors': [3, 5, 7, 9],\n",
        "            'leaf_size': [10, 30, 100]\n",
        "        }\n",
        "        param_grid3 = {\n",
        "            'kernel' : ['linear', 'rbf', 'sigmoid'],\n",
        "            'C' : [0.01, 0.1, 1, 10],\n",
        "            'gamma' : [1, 0.1, 0.01, 0.001]\n",
        "        }\n",
        "\n",
        "        print('gridsearch rfc . . .')\n",
        "        self.clf1 = GridSearchCV(estimator=RandomForestClassifier(), param_grid=param_grid1, cv=3, refit=True)\n",
        "        print('gridsearch knn . . .')\n",
        "        self.clf2 = GridSearchCV(estimator=KNeighborsClassifier(), param_grid=param_grid2, cv=3, refit=True)\n",
        "        print('gridsearch svc . . .')\n",
        "        self.clf3 = GridSearchCV(estimator=SVC(), param_grid=param_grid3, cv=3, refit=True)\n",
        "        print('gridsearch done.')\n",
        "        \n",
        "        self.clf1.fit(X_features, y)\n",
        "        self.clf2.fit(X_features, y)\n",
        "        self.clf3.fit(X_features, y)\n",
        "\n",
        "        with open('./params.txt', 'a+') as writefile:\n",
        "          writefile.write(f\"split {split}\")\n",
        "          writefile.write(f\"rfc best parameters:\\n n_estimtors: {self.clf1.best_params_['n_estimators']}\\n max_features : {self.clf1.best_params_['max_features']}\\n max_depth : {self.clf1.best_params_['max_depth']}\\n criterion : {self.clf1.best_params_['criterion']}\\n\")\n",
        "          writefile.write(f\"knn best parameters:\\n knn__n_neighbors : {self.clf2.best_params_['n_neighbors']}\\n leaf_size : {self.clf2.best_params_['leaf_size']}\\n\")\n",
        "          writefile.write(f\"svc best parameters:\\n kernel : {self.clf3.best_params_['kernel']}\\n C : {self.clf3.best_params_['C']}\\n gamma : {self.clf3.best_params_['gamma']}\\n\\n\")\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "    def classifier_predict(self, test_dataset):\n",
        "        \"\"\"Predict labels of test_dataset.\"\"\"\n",
        "\n",
        "        X_test, y_test = self.dataset_to_numpy(test_dataset)\n",
        "\n",
        "        # Extract features from the test set\n",
        "        X_test_features = self.extract_features(torch.tensor(X_test, dtype=torch.float))\n",
        "        for i in range(X_test_features.size(0)):\n",
        "            X_test_features[i] = X_test_features[i]/X_test_features[i].norm()\n",
        "        X_test_features = X_test_features.to('cpu').numpy()\n",
        "        \n",
        "        y_pred1 = self.clf1.predict(X_test_features)\n",
        "        y_pred2 = self.clf2.predict(X_test_features)\n",
        "        y_pred3 = self.clf3.predict(X_test_features)\n",
        "\n",
        "        return y_test, y_pred1, y_pred2, y_pred3\n",
        "\n",
        "    def dataset_to_numpy(self, dataset):\n",
        "        # Preallocate arrays\n",
        "        X = np.zeros((len(dataset), 3, 32, 32))\n",
        "        y = np.zeros(len(dataset), dtype=int)\n",
        "\n",
        "        dataloader = DataLoader(dataset, batch_size=1)\n",
        "\n",
        "        for idx, (image, labels) in enumerate(dataloader):\n",
        "            X[idx] = image[0].numpy()\n",
        "            y[idx] = labels.numpy()[0]\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def test_classifiers(self, test_dataset, train_dataset, split):\n",
        "        \"\"\"Test the model.\n",
        "\n",
        "        Args:\n",
        "            test_dataset: dataset on which to test the network\n",
        "            train_dataset: training set used to train the last split\n",
        "        Returns:\n",
        "            accuracy (float): accuracy of the model on the test set\n",
        "        \"\"\"\n",
        "\n",
        "        self.net.train(False)\n",
        "        if self.best_net is not None: self.best_net.train(False)  # Set Network to evaluation mode\n",
        "        if self.old_net is not None: self.old_net.train(False)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            self.classifier_fit(train_dataset, split)\n",
        "            y_truth, y_pred1, y_pred2, y_pred3 = self.classifier_predict(test_dataset)\n",
        "\n",
        "        # Calculate accuracy\n",
        "        accuracy1 = accuracy_score(y_truth, y_pred1)\n",
        "        accuracy2 = accuracy_score(y_truth, y_pred2)\n",
        "        accuracy3 = accuracy_score(y_truth, y_pred3)\n",
        "\n",
        "        print(f\"Test accuracy (iCaRL with RFC): {accuracy1} \")\n",
        "        print(f\"Test accuracy (iCaRL with KNN): {accuracy2} \")\n",
        "        print(f\"Test accuracy (iCaRL with SVC): {accuracy3} \")\n",
        "\n",
        "        return accuracy1, accuracy2, accuracy3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3F1MQyiGV3bK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c26c1978-d38d-4c7e-95a9-a2d996f201ae"
      },
      "source": [
        "logs_icarl = [[] for _ in range(NUM_RUNS)]\n",
        "logs_icarl_rfc = [[] for _ in range(NUM_RUNS)]\n",
        "logs_icarl_knn = [[] for _ in range(NUM_RUNS)]\n",
        "logs_icarl_svc = [[] for _ in range(NUM_RUNS)]\n",
        "\n",
        "for run_i in range(NUM_RUNS):\n",
        "    net = resnet32()\n",
        "\n",
        "    icarl_CLFS = iCaRLwithCLFS(DEVICE, net, LR, MOMENTUM, WEIGHT_DECAY, MILESTONES, GAMMA, NUM_EPOCHS, BATCH_SIZE, train_transform, test_transform)\n",
        "    \n",
        "    for split_i in range(10):\n",
        "        print(f\"## Split {split_i} of run {run_i} ##\")\n",
        "        \n",
        "        train_logs = icarl_CLFS.incremental_train(split_i, train_subsets[run_i][split_i], val_subsets[run_i][split_i])\n",
        "\n",
        "        acc, _ = icarl_CLFS.test(test_subsets[run_i][split_i], train_subsets[run_i][split_i])\n",
        "        logs_icarl[run_i].append(acc)\n",
        "\n",
        "        acc1, acc2, acc3 = icarl_CLFS.test_classifiers(test_subsets[run_i][split_i], train_subsets[run_i][split_i], split_i)\n",
        "        logs_icarl_rfc[run_i].append(acc1)\n",
        "        logs_icarl_knn[run_i].append(acc2)\n",
        "        logs_icarl_svc[run_i].append(acc3)\n",
        "\n",
        "        with open('./logs.txt', 'a+') as writefile:\n",
        "          writefile.write(f\"split : {split_i} \\n\")\n",
        "          writefile.write(f\" accuracy iCaRL : {acc} \\n\")\n",
        "          writefile.write(f\" accuracy rfc : {acc1} \\n\")\n",
        "          writefile.write(f\" accuracy knn : {acc2} \\n\")\n",
        "          writefile.write(f\" accuracy svc : {acc3} \\n\\n\")\n",
        "\n",
        "from google.colab import files\n",
        "files.download('params.txt')\n",
        "files.download('logs.txt')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "## Split 0 of run 0 ##\n",
            "Length of exemplars set: 0\n",
            "Epoch: 1, LR: [2]\n",
            "Train loss: 0.3807116551058633, Train accuracy: 0.10446428571428572\n",
            "Validation loss: 0.3234121629170009, Validation accuracy: 0.13616071428571427\n",
            "Epoch: 2, LR: [2]\n",
            "Train loss: 0.32078241791043965, Train accuracy: 0.13169642857142858\n",
            "Validation loss: 0.31222453713417053, Validation accuracy: 0.18303571428571427\n",
            "Epoch: 3, LR: [2]\n",
            "Train loss: 0.318192092861448, Train accuracy: 0.1455357142857143\n",
            "Validation loss: 0.3143646333898817, Validation accuracy: 0.14955357142857142\n",
            "Epoch: 4, LR: [2]\n",
            "Train loss: 0.3158152222633362, Train accuracy: 0.15379464285714287\n",
            "Validation loss: 0.31158669931547983, Validation accuracy: 0.17633928571428573\n",
            "Epoch: 5, LR: [2]\n",
            "Train loss: 0.3106324451310294, Train accuracy: 0.1859375\n",
            "Validation loss: 0.3080969623156956, Validation accuracy: 0.171875\n",
            "Epoch: 6, LR: [2]\n",
            "Train loss: 0.30680064644132343, Train accuracy: 0.20223214285714286\n",
            "Validation loss: 0.3035589967455183, Validation accuracy: 0.22098214285714285\n",
            "Epoch: 7, LR: [2]\n",
            "Train loss: 0.3016605364424842, Train accuracy: 0.22455357142857144\n",
            "Validation loss: 0.30568791713033405, Validation accuracy: 0.20758928571428573\n",
            "Epoch: 8, LR: [2]\n",
            "Train loss: 0.29399904012680056, Train accuracy: 0.265625\n",
            "Validation loss: 0.29637952361788067, Validation accuracy: 0.2611607142857143\n",
            "Epoch: 9, LR: [2]\n",
            "Train loss: 0.28328081539699007, Train accuracy: 0.2988839285714286\n",
            "Validation loss: 0.2732068725994655, Validation accuracy: 0.35267857142857145\n",
            "Epoch: 10, LR: [2]\n",
            "Train loss: 0.2727282813617161, Train accuracy: 0.3502232142857143\n",
            "Validation loss: 0.26378490243639263, Validation accuracy: 0.3950892857142857\n",
            "Epoch: 11, LR: [2]\n",
            "Train loss: 0.26107706895896365, Train accuracy: 0.3854910714285714\n",
            "Validation loss: 0.2999403050967625, Validation accuracy: 0.2544642857142857\n",
            "Epoch: 12, LR: [2]\n",
            "Train loss: 0.2513979251895632, Train accuracy: 0.42410714285714285\n",
            "Validation loss: 0.23377832983221328, Validation accuracy: 0.45535714285714285\n",
            "Epoch: 13, LR: [2]\n",
            "Train loss: 0.23354131260088512, Train accuracy: 0.478125\n",
            "Validation loss: 0.257660557116781, Validation accuracy: 0.40625\n",
            "Epoch: 14, LR: [2]\n",
            "Train loss: 0.2205077629004206, Train accuracy: 0.5149553571428571\n",
            "Validation loss: 0.24537925209317887, Validation accuracy: 0.41964285714285715\n",
            "Epoch: 15, LR: [2]\n",
            "Train loss: 0.20947130556617463, Train accuracy: 0.5529017857142857\n",
            "Validation loss: 0.20902483378137862, Validation accuracy: 0.5535714285714286\n",
            "Epoch: 16, LR: [2]\n",
            "Train loss: 0.20115447427545274, Train accuracy: 0.5662946428571428\n",
            "Validation loss: 0.2090265303850174, Validation accuracy: 0.5535714285714286\n",
            "Epoch: 17, LR: [2]\n",
            "Train loss: 0.1942220988018172, Train accuracy: 0.5805803571428572\n",
            "Validation loss: 0.2225188229765211, Validation accuracy: 0.546875\n",
            "Epoch: 18, LR: [2]\n",
            "Train loss: 0.17930288868291036, Train accuracy: 0.6314732142857142\n",
            "Validation loss: 0.1645422535283225, Validation accuracy: 0.6383928571428571\n",
            "Epoch: 19, LR: [2]\n",
            "Train loss: 0.16853529555456978, Train accuracy: 0.6571428571428571\n",
            "Validation loss: 0.18759120787893022, Validation accuracy: 0.6183035714285714\n",
            "Epoch: 20, LR: [2]\n",
            "Train loss: 0.1644712191607271, Train accuracy: 0.6620535714285715\n",
            "Validation loss: 0.19005491052355086, Validation accuracy: 0.6026785714285714\n",
            "Epoch: 21, LR: [2]\n",
            "Train loss: 0.15660153520958764, Train accuracy: 0.6808035714285714\n",
            "Validation loss: 0.24002609934125627, Validation accuracy: 0.5\n",
            "Epoch: 22, LR: [2]\n",
            "Train loss: 0.14963885716029576, Train accuracy: 0.6962053571428571\n",
            "Validation loss: 0.15389188698359899, Validation accuracy: 0.7053571428571429\n",
            "Epoch: 23, LR: [2]\n",
            "Train loss: 0.13976782368762153, Train accuracy: 0.7216517857142857\n",
            "Validation loss: 0.21352423301764897, Validation accuracy: 0.5625\n",
            "Epoch: 24, LR: [2]\n",
            "Train loss: 0.1351336928350585, Train accuracy: 0.7308035714285714\n",
            "Validation loss: 0.19841053869043077, Validation accuracy: 0.65625\n",
            "Epoch: 25, LR: [2]\n",
            "Train loss: 0.12831227066261428, Train accuracy: 0.7408482142857142\n",
            "Validation loss: 0.15992035397461482, Validation accuracy: 0.7254464285714286\n",
            "Epoch: 26, LR: [2]\n",
            "Train loss: 0.13146952337452344, Train accuracy: 0.7381696428571428\n",
            "Validation loss: 0.15018067402499063, Validation accuracy: 0.7254464285714286\n",
            "Epoch: 27, LR: [2]\n",
            "Train loss: 0.11875753221767289, Train accuracy: 0.7642857142857142\n",
            "Validation loss: 0.12485342472791672, Validation accuracy: 0.7589285714285714\n",
            "Epoch: 28, LR: [2]\n",
            "Train loss: 0.11361038493258613, Train accuracy: 0.7785714285714286\n",
            "Validation loss: 0.16480432557208197, Validation accuracy: 0.6830357142857143\n",
            "Epoch: 29, LR: [2]\n",
            "Train loss: 0.11001238535557474, Train accuracy: 0.7901785714285714\n",
            "Validation loss: 0.15145213795559748, Validation accuracy: 0.6919642857142857\n",
            "Epoch: 30, LR: [2]\n",
            "Train loss: 0.1109066038259438, Train accuracy: 0.7832589285714285\n",
            "Validation loss: 0.11601747678858894, Validation accuracy: 0.7723214285714286\n",
            "Epoch: 31, LR: [2]\n",
            "Train loss: 0.10155822485685348, Train accuracy: 0.8035714285714286\n",
            "Validation loss: 0.11875121614762715, Validation accuracy: 0.7790178571428571\n",
            "Epoch: 32, LR: [2]\n",
            "Train loss: 0.09431913324764797, Train accuracy: 0.8167410714285714\n",
            "Validation loss: 0.14380777840103423, Validation accuracy: 0.7276785714285714\n",
            "Epoch: 33, LR: [2]\n",
            "Train loss: 0.09330099310193743, Train accuracy: 0.8236607142857143\n",
            "Validation loss: 0.1123864512358393, Validation accuracy: 0.7834821428571429\n",
            "Epoch: 34, LR: [2]\n",
            "Train loss: 0.08935870432427952, Train accuracy: 0.8314732142857143\n",
            "Validation loss: 0.1055649391242436, Validation accuracy: 0.8080357142857143\n",
            "Epoch: 35, LR: [2]\n",
            "Train loss: 0.08789821224553244, Train accuracy: 0.8294642857142858\n",
            "Validation loss: 0.1012953690120152, Validation accuracy: 0.8370535714285714\n",
            "Epoch: 36, LR: [2]\n",
            "Train loss: 0.08565783378268992, Train accuracy: 0.8386160714285714\n",
            "Validation loss: 0.10550780700785774, Validation accuracy: 0.7924107142857143\n",
            "Epoch: 37, LR: [2]\n",
            "Train loss: 0.08156046127634389, Train accuracy: 0.8508928571428571\n",
            "Validation loss: 0.10541322188717979, Validation accuracy: 0.7946428571428571\n",
            "Epoch: 38, LR: [2]\n",
            "Train loss: 0.08096052764781884, Train accuracy: 0.8486607142857143\n",
            "Validation loss: 0.08872738001602036, Validation accuracy: 0.8236607142857143\n",
            "Epoch: 39, LR: [2]\n",
            "Train loss: 0.07486510963312216, Train accuracy: 0.8631696428571428\n",
            "Validation loss: 0.09297219078455653, Validation accuracy: 0.8236607142857143\n",
            "Epoch: 40, LR: [2]\n",
            "Train loss: 0.07600769326090813, Train accuracy: 0.8598214285714286\n",
            "Validation loss: 0.08814046851226262, Validation accuracy: 0.828125\n",
            "Epoch: 41, LR: [2]\n",
            "Train loss: 0.07450390713555473, Train accuracy: 0.865625\n",
            "Validation loss: 0.11113368932689939, Validation accuracy: 0.7946428571428571\n",
            "Epoch: 42, LR: [2]\n",
            "Train loss: 0.06982088999024459, Train accuracy: 0.8694196428571429\n",
            "Validation loss: 0.09365035167762212, Validation accuracy: 0.8191964285714286\n",
            "Epoch: 43, LR: [2]\n",
            "Train loss: 0.0672588230243751, Train accuracy: 0.8745535714285714\n",
            "Validation loss: 0.11983515641519002, Validation accuracy: 0.7700892857142857\n",
            "Epoch: 44, LR: [2]\n",
            "Train loss: 0.06629962388958249, Train accuracy: 0.8796875\n",
            "Validation loss: 0.095639987715653, Validation accuracy: 0.8236607142857143\n",
            "Epoch: 45, LR: [2]\n",
            "Train loss: 0.06126875520816871, Train accuracy: 0.8930803571428572\n",
            "Validation loss: 0.1269177943468094, Validation accuracy: 0.7767857142857143\n",
            "Epoch: 46, LR: [2]\n",
            "Train loss: 0.06200047635606357, Train accuracy: 0.8805803571428571\n",
            "Validation loss: 0.10134240772042956, Validation accuracy: 0.8258928571428571\n",
            "Epoch: 47, LR: [2]\n",
            "Train loss: 0.06533551221447331, Train accuracy: 0.8816964285714286\n",
            "Validation loss: 0.08443596426929746, Validation accuracy: 0.8482142857142857\n",
            "Epoch: 48, LR: [2]\n",
            "Train loss: 0.061847794641341484, Train accuracy: 0.8892857142857142\n",
            "Validation loss: 0.10478686754192625, Validation accuracy: 0.8236607142857143\n",
            "Epoch: 49, LR: [2]\n",
            "Train loss: 0.05563611630350351, Train accuracy: 0.9055803571428571\n",
            "Validation loss: 0.09685582241841725, Validation accuracy: 0.8258928571428571\n",
            "Epoch: 50, LR: [0.4]\n",
            "Train loss: 0.03974803912320307, Train accuracy: 0.9316964285714285\n",
            "Validation loss: 0.05511641449161938, Validation accuracy: 0.8995535714285714\n",
            "Epoch: 51, LR: [0.4]\n",
            "Train loss: 0.03260511000241552, Train accuracy: 0.9479910714285714\n",
            "Validation loss: 0.060807217710784504, Validation accuracy: 0.9129464285714286\n",
            "Epoch: 52, LR: [0.4]\n",
            "Train loss: 0.030140412412583827, Train accuracy: 0.9511160714285715\n",
            "Validation loss: 0.05932416394352913, Validation accuracy: 0.9017857142857143\n",
            "Epoch: 53, LR: [0.4]\n",
            "Train loss: 0.028035709833992378, Train accuracy: 0.9564732142857143\n",
            "Validation loss: 0.0631713510624, Validation accuracy: 0.8816964285714286\n",
            "Epoch: 54, LR: [0.4]\n",
            "Train loss: 0.02656954617372581, Train accuracy: 0.9558035714285714\n",
            "Validation loss: 0.05707556168947901, Validation accuracy: 0.9040178571428571\n",
            "Epoch: 55, LR: [0.4]\n",
            "Train loss: 0.026071138999291827, Train accuracy: 0.959375\n",
            "Validation loss: 0.06223341662968908, Validation accuracy: 0.8839285714285714\n",
            "Epoch: 56, LR: [0.4]\n",
            "Train loss: 0.024683417180286986, Train accuracy: 0.9622767857142858\n",
            "Validation loss: 0.05630036709564073, Validation accuracy: 0.8973214285714286\n",
            "Epoch: 57, LR: [0.4]\n",
            "Train loss: 0.025458894576877354, Train accuracy: 0.9582589285714286\n",
            "Validation loss: 0.06192030731056418, Validation accuracy: 0.8883928571428571\n",
            "Epoch: 58, LR: [0.4]\n",
            "Train loss: 0.023171250781576547, Train accuracy: 0.9633928571428572\n",
            "Validation loss: 0.05903460245047297, Validation accuracy: 0.8995535714285714\n",
            "Epoch: 59, LR: [0.4]\n",
            "Train loss: 0.022093087428116373, Train accuracy: 0.9674107142857142\n",
            "Validation loss: 0.064982625788876, Validation accuracy: 0.8950892857142857\n",
            "Epoch: 60, LR: [0.4]\n",
            "Train loss: 0.018621511830549154, Train accuracy: 0.9712053571428572\n",
            "Validation loss: 0.06705078748720032, Validation accuracy: 0.8772321428571429\n",
            "Epoch: 61, LR: [0.4]\n",
            "Train loss: 0.019574840692803262, Train accuracy: 0.9680803571428571\n",
            "Validation loss: 0.05545720803950514, Validation accuracy: 0.9017857142857143\n",
            "Epoch: 62, LR: [0.4]\n",
            "Train loss: 0.017120924665193472, Train accuracy: 0.975\n",
            "Validation loss: 0.05841202741222722, Validation accuracy: 0.8995535714285714\n",
            "Epoch: 63, LR: [0.4]\n",
            "Train loss: 0.017379810927169663, Train accuracy: 0.9763392857142857\n",
            "Validation loss: 0.06375848954277379, Validation accuracy: 0.890625\n",
            "Epoch: 64, LR: [0.08000000000000002]\n",
            "Train loss: 0.01611153572199068, Train accuracy: 0.9772321428571429\n",
            "Validation loss: 0.04742895119956562, Validation accuracy: 0.9129464285714286\n",
            "Epoch: 65, LR: [0.08000000000000002]\n",
            "Train loss: 0.014434184722735414, Train accuracy: 0.9774553571428571\n",
            "Validation loss: 0.05146268914852824, Validation accuracy: 0.9129464285714286\n",
            "Epoch: 66, LR: [0.08000000000000002]\n",
            "Train loss: 0.013298125242415283, Train accuracy: 0.9808035714285714\n",
            "Validation loss: 0.05964639091065952, Validation accuracy: 0.8950892857142857\n",
            "Epoch: 67, LR: [0.08000000000000002]\n",
            "Train loss: 0.013304086718043047, Train accuracy: 0.9816964285714286\n",
            "Validation loss: 0.0602809273238693, Validation accuracy: 0.9084821428571429\n",
            "Epoch: 68, LR: [0.08000000000000002]\n",
            "Train loss: 0.012757294944354467, Train accuracy: 0.9816964285714286\n",
            "Validation loss: 0.05928797860230718, Validation accuracy: 0.9129464285714286\n",
            "Epoch: 69, LR: [0.08000000000000002]\n",
            "Train loss: 0.012621388860446002, Train accuracy: 0.9830357142857142\n",
            "Validation loss: 0.059115562587976456, Validation accuracy: 0.8995535714285714\n",
            "Epoch: 70, LR: [0.08000000000000002]\n",
            "Train loss: 0.012609729393651443, Train accuracy: 0.9841517857142857\n",
            "Validation loss: 0.06719532529158252, Validation accuracy: 0.890625\n",
            "Target number of exemplars per class: 200\n",
            "Target total number of exemplars: 2000\n",
            "Randomly extracting exemplars from class 0 of current split... Extracted 200 exemplars.\n",
            "Randomly extracting exemplars from class 1 of current split... Extracted 200 exemplars.\n",
            "Randomly extracting exemplars from class 2 of current split... Extracted 200 exemplars.\n",
            "Randomly extracting exemplars from class 3 of current split... Extracted 200 exemplars.\n",
            "Randomly extracting exemplars from class 4 of current split... Extracted 200 exemplars.\n",
            "Randomly extracting exemplars from class 5 of current split... Extracted 200 exemplars.\n",
            "Randomly extracting exemplars from class 6 of current split... Extracted 200 exemplars.\n",
            "Randomly extracting exemplars from class 7 of current split... Extracted 200 exemplars.\n",
            "Randomly extracting exemplars from class 8 of current split... Extracted 200 exemplars.\n",
            "Randomly extracting exemplars from class 9 of current split... Extracted 200 exemplars.\n",
            "Computing mean of exemplars... done\n",
            "Test accuracy (iCaRL): 0.91 (exemplars and training data)\n",
            "gridsearch rfc . . .\n",
            "gridsearch knn . . .\n",
            "gridsearch svc . . .\n",
            "gridsearch done.\n",
            "Test accuracy (iCaRL with RFC): 0.908 \n",
            "Test accuracy (iCaRL with KNN): 0.908 \n",
            "Test accuracy (iCaRL with SVC): 0.908 \n",
            "## Split 1 of run 0 ##\n",
            "Length of exemplars set: 2000\n",
            "Epoch: 1, LR: [2]\n",
            "Train loss: 0.1567344726017206, Train accuracy: 0.3129641089108911\n",
            "Validation loss: 0.22406002240521566, Validation accuracy: 0.08258928571428571\n",
            "Epoch: 2, LR: [2]\n",
            "Train loss: 0.12894227724559237, Train accuracy: 0.39913366336633666\n",
            "Validation loss: 0.1996407530137471, Validation accuracy: 0.22767857142857142\n",
            "Epoch: 3, LR: [2]\n",
            "Train loss: 0.12014215476442092, Train accuracy: 0.4681311881188119\n",
            "Validation loss: 0.18562286240713938, Validation accuracy: 0.28125\n",
            "Epoch: 4, LR: [2]\n",
            "Train loss: 0.1131931335324108, Train accuracy: 0.5163985148514851\n",
            "Validation loss: 0.19232061292443955, Validation accuracy: 0.296875\n",
            "Epoch: 5, LR: [2]\n",
            "Train loss: 0.1100723681473496, Train accuracy: 0.5474938118811881\n",
            "Validation loss: 0.17058315021651133, Validation accuracy: 0.36160714285714285\n",
            "Epoch: 6, LR: [2]\n",
            "Train loss: 0.10661656534907842, Train accuracy: 0.5802908415841584\n",
            "Validation loss: 0.17462407052516937, Validation accuracy: 0.35714285714285715\n",
            "Epoch: 7, LR: [2]\n",
            "Train loss: 0.10249327875600003, Train accuracy: 0.6017945544554455\n",
            "Validation loss: 0.16982909824166978, Validation accuracy: 0.40401785714285715\n",
            "Epoch: 8, LR: [2]\n",
            "Train loss: 0.09931569819403167, Train accuracy: 0.6163366336633663\n",
            "Validation loss: 0.16249831446579524, Validation accuracy: 0.45535714285714285\n",
            "Epoch: 9, LR: [2]\n",
            "Train loss: 0.09850783889541531, Train accuracy: 0.6273205445544554\n",
            "Validation loss: 0.17031050792762212, Validation accuracy: 0.45982142857142855\n",
            "Epoch: 10, LR: [2]\n",
            "Train loss: 0.09613778331492207, Train accuracy: 0.645884900990099\n",
            "Validation loss: 0.15833111320223128, Validation accuracy: 0.5334821428571429\n",
            "Epoch: 11, LR: [2]\n",
            "Train loss: 0.09460292918847339, Train accuracy: 0.6579517326732673\n",
            "Validation loss: 0.18017044876302993, Validation accuracy: 0.5066964285714286\n",
            "Epoch: 12, LR: [2]\n",
            "Train loss: 0.09463207571223231, Train accuracy: 0.661509900990099\n",
            "Validation loss: 0.18030500411987305, Validation accuracy: 0.4575892857142857\n",
            "Epoch: 13, LR: [2]\n",
            "Train loss: 0.09348117833090301, Train accuracy: 0.6748143564356436\n",
            "Validation loss: 0.17082781663962773, Validation accuracy: 0.4642857142857143\n",
            "Epoch: 14, LR: [2]\n",
            "Train loss: 0.09043665370433637, Train accuracy: 0.682394801980198\n",
            "Validation loss: 0.16764264873095922, Validation accuracy: 0.48214285714285715\n",
            "Epoch: 15, LR: [2]\n",
            "Train loss: 0.09096082204049176, Train accuracy: 0.6892017326732673\n",
            "Validation loss: 0.16899370082787105, Validation accuracy: 0.5223214285714286\n",
            "Epoch: 16, LR: [2]\n",
            "Train loss: 0.08926204201018456, Train accuracy: 0.6986386138613861\n",
            "Validation loss: 0.15459622016974858, Validation accuracy: 0.53125\n",
            "Epoch: 17, LR: [2]\n",
            "Train loss: 0.08878214391741422, Train accuracy: 0.6950804455445545\n",
            "Validation loss: 0.16470876336097717, Validation accuracy: 0.5513392857142857\n",
            "Epoch: 18, LR: [2]\n",
            "Train loss: 0.08726834195970308, Train accuracy: 0.7120977722772277\n",
            "Validation loss: 0.1591762112719672, Validation accuracy: 0.59375\n",
            "Epoch: 19, LR: [2]\n",
            "Train loss: 0.08712831360868889, Train accuracy: 0.7122524752475248\n",
            "Validation loss: 0.17772580896105086, Validation accuracy: 0.44642857142857145\n",
            "Epoch: 20, LR: [2]\n",
            "Train loss: 0.08449240154263997, Train accuracy: 0.728805693069307\n",
            "Validation loss: 0.15392603618758066, Validation accuracy: 0.5580357142857143\n",
            "Epoch: 21, LR: [2]\n",
            "Train loss: 0.0845272962999816, Train accuracy: 0.7212252475247525\n",
            "Validation loss: 0.17342597671917506, Validation accuracy: 0.5580357142857143\n",
            "Epoch: 22, LR: [2]\n",
            "Train loss: 0.08452520910466071, Train accuracy: 0.7311262376237624\n",
            "Validation loss: 0.17238503055913107, Validation accuracy: 0.5267857142857143\n",
            "Epoch: 23, LR: [2]\n",
            "Train loss: 0.08169647402102405, Train accuracy: 0.7306621287128713\n",
            "Validation loss: 0.16252351658684866, Validation accuracy: 0.5736607142857143\n",
            "Epoch: 24, LR: [2]\n",
            "Train loss: 0.08138663576233506, Train accuracy: 0.739634900990099\n",
            "Validation loss: 0.15711957003389085, Validation accuracy: 0.5758928571428571\n",
            "Epoch: 25, LR: [2]\n",
            "Train loss: 0.0822457987999562, Train accuracy: 0.7391707920792079\n",
            "Validation loss: 0.15534799226692744, Validation accuracy: 0.5513392857142857\n",
            "Epoch: 26, LR: [2]\n",
            "Train loss: 0.08182424933898567, Train accuracy: 0.7390160891089109\n",
            "Validation loss: 0.16411854326725006, Validation accuracy: 0.5491071428571429\n",
            "Epoch: 27, LR: [2]\n",
            "Train loss: 0.08045386438175003, Train accuracy: 0.7592821782178217\n",
            "Validation loss: 0.15642438190323965, Validation accuracy: 0.5803571428571429\n",
            "Epoch: 28, LR: [2]\n",
            "Train loss: 0.08047238796359242, Train accuracy: 0.7459777227722773\n",
            "Validation loss: 0.15972754039934703, Validation accuracy: 0.5558035714285714\n",
            "Epoch: 29, LR: [2]\n",
            "Train loss: 0.07928673698022815, Train accuracy: 0.7501547029702971\n",
            "Validation loss: 0.1651474812201091, Validation accuracy: 0.5736607142857143\n",
            "Epoch: 30, LR: [2]\n",
            "Train loss: 0.08041505530329034, Train accuracy: 0.755105198019802\n",
            "Validation loss: 0.16599042926515853, Validation accuracy: 0.5200892857142857\n",
            "Epoch: 31, LR: [2]\n",
            "Train loss: 0.0778181615589869, Train accuracy: 0.770884900990099\n",
            "Validation loss: 0.14503732110772813, Validation accuracy: 0.6361607142857143\n",
            "Epoch: 32, LR: [2]\n",
            "Train loss: 0.07888496272487215, Train accuracy: 0.7745977722772277\n",
            "Validation loss: 0.15977240886007035, Validation accuracy: 0.6049107142857143\n",
            "Epoch: 33, LR: [2]\n",
            "Train loss: 0.0777917858028766, Train accuracy: 0.7679455445544554\n",
            "Validation loss: 0.16364820088659013, Validation accuracy: 0.578125\n",
            "Epoch: 34, LR: [2]\n",
            "Train loss: 0.07838950627068482, Train accuracy: 0.7667079207920792\n",
            "Validation loss: 0.18147375328200205, Validation accuracy: 0.53125\n",
            "Epoch: 35, LR: [2]\n",
            "Train loss: 0.07856593553972717, Train accuracy: 0.7687190594059405\n",
            "Validation loss: 0.15719175977366312, Validation accuracy: 0.5803571428571429\n",
            "Epoch: 36, LR: [2]\n",
            "Train loss: 0.07643277231271904, Train accuracy: 0.7770730198019802\n",
            "Validation loss: 0.16960637271404266, Validation accuracy: 0.5669642857142857\n",
            "Epoch: 37, LR: [2]\n",
            "Train loss: 0.0755154009502713, Train accuracy: 0.781559405940594\n",
            "Validation loss: 0.15924835417951858, Validation accuracy: 0.5870535714285714\n",
            "Epoch: 38, LR: [2]\n",
            "Train loss: 0.07569679699026712, Train accuracy: 0.7894492574257426\n",
            "Validation loss: 0.14985987969807216, Validation accuracy: 0.640625\n",
            "Epoch: 39, LR: [2]\n",
            "Train loss: 0.07398357419389309, Train accuracy: 0.7942450495049505\n",
            "Validation loss: 0.14794754769120896, Validation accuracy: 0.6383928571428571\n",
            "Epoch: 40, LR: [2]\n",
            "Train loss: 0.07625181939784843, Train accuracy: 0.7781559405940595\n",
            "Validation loss: 0.17585022108895437, Validation accuracy: 0.5982142857142857\n",
            "Epoch: 41, LR: [2]\n",
            "Train loss: 0.07618639562832247, Train accuracy: 0.786509900990099\n",
            "Validation loss: 0.1447528749704361, Validation accuracy: 0.6227678571428571\n",
            "Epoch: 42, LR: [2]\n",
            "Train loss: 0.07281290466832642, Train accuracy: 0.7954826732673267\n",
            "Validation loss: 0.16159679634230478, Validation accuracy: 0.6071428571428571\n",
            "Epoch: 43, LR: [2]\n",
            "Train loss: 0.07290339492040106, Train accuracy: 0.7908415841584159\n",
            "Validation loss: 0.1757462216275079, Validation accuracy: 0.6071428571428571\n",
            "Epoch: 44, LR: [2]\n",
            "Train loss: 0.07400189067172531, Train accuracy: 0.7925433168316832\n",
            "Validation loss: 0.16179012400763376, Validation accuracy: 0.6183035714285714\n",
            "Epoch: 45, LR: [2]\n",
            "Train loss: 0.07319265072888667, Train accuracy: 0.7953279702970297\n",
            "Validation loss: 0.15984632500580379, Validation accuracy: 0.5870535714285714\n",
            "Epoch: 46, LR: [2]\n",
            "Train loss: 0.07392611498437306, Train accuracy: 0.8015160891089109\n",
            "Validation loss: 0.17020637009825026, Validation accuracy: 0.6138392857142857\n",
            "Epoch: 47, LR: [2]\n",
            "Train loss: 0.07201624595292724, Train accuracy: 0.8032178217821783\n",
            "Validation loss: 0.1633213460445404, Validation accuracy: 0.6339285714285714\n",
            "Epoch: 48, LR: [2]\n",
            "Train loss: 0.07237256742497482, Train accuracy: 0.7990408415841584\n",
            "Validation loss: 0.17165757502828324, Validation accuracy: 0.5825892857142857\n",
            "Epoch: 49, LR: [2]\n",
            "Train loss: 0.07316388883213006, Train accuracy: 0.8049195544554455\n",
            "Validation loss: 0.18537133506366185, Validation accuracy: 0.546875\n",
            "Epoch: 50, LR: [0.4]\n",
            "Train loss: 0.06086421459175573, Train accuracy: 0.8392636138613861\n",
            "Validation loss: 0.14621526428631373, Validation accuracy: 0.6651785714285714\n",
            "Epoch: 51, LR: [0.4]\n",
            "Train loss: 0.05594951069295997, Train accuracy: 0.8626237623762376\n",
            "Validation loss: 0.14676568337849208, Validation accuracy: 0.6785714285714286\n",
            "Epoch: 52, LR: [0.4]\n",
            "Train loss: 0.05400483575787875, Train accuracy: 0.869740099009901\n",
            "Validation loss: 0.15953647877488816, Validation accuracy: 0.6540178571428571\n",
            "Epoch: 53, LR: [0.4]\n",
            "Train loss: 0.053836754052945884, Train accuracy: 0.8734529702970297\n",
            "Validation loss: 0.15742915868759155, Validation accuracy: 0.6540178571428571\n",
            "Epoch: 54, LR: [0.4]\n",
            "Train loss: 0.0514452493205519, Train accuracy: 0.8833539603960396\n",
            "Validation loss: 0.15080967119761876, Validation accuracy: 0.6897321428571429\n",
            "Epoch: 55, LR: [0.4]\n",
            "Train loss: 0.052344712069129, Train accuracy: 0.8876856435643564\n",
            "Validation loss: 0.16452257335186005, Validation accuracy: 0.671875\n",
            "Epoch: 56, LR: [0.4]\n",
            "Train loss: 0.05074140956938857, Train accuracy: 0.8924814356435643\n",
            "Validation loss: 0.15826401540211268, Validation accuracy: 0.6830357142857143\n",
            "Epoch: 57, LR: [0.4]\n",
            "Train loss: 0.050890695598751014, Train accuracy: 0.8940284653465347\n",
            "Validation loss: 0.17003739093031203, Validation accuracy: 0.6540178571428571\n",
            "Epoch: 58, LR: [0.4]\n",
            "Train loss: 0.050395737190057736, Train accuracy: 0.896194306930693\n",
            "Validation loss: 0.1564794374363763, Validation accuracy: 0.671875\n",
            "Epoch: 59, LR: [0.4]\n",
            "Train loss: 0.04997673730301385, Train accuracy: 0.8946472772277227\n",
            "Validation loss: 0.14920478846345628, Validation accuracy: 0.7098214285714286\n",
            "Epoch: 60, LR: [0.4]\n",
            "Train loss: 0.049465162255386316, Train accuracy: 0.9020730198019802\n",
            "Validation loss: 0.16494345664978027, Validation accuracy: 0.6763392857142857\n",
            "Epoch: 61, LR: [0.4]\n",
            "Train loss: 0.04997774715175723, Train accuracy: 0.901299504950495\n",
            "Validation loss: 0.17003525154931204, Validation accuracy: 0.6428571428571429\n",
            "Epoch: 62, LR: [0.4]\n",
            "Train loss: 0.04877162094015886, Train accuracy: 0.9033106435643564\n",
            "Validation loss: 0.16527155680315836, Validation accuracy: 0.6852678571428571\n",
            "Epoch: 63, LR: [0.4]\n",
            "Train loss: 0.048649012784261515, Train accuracy: 0.9067141089108911\n",
            "Validation loss: 0.16843577793666295, Validation accuracy: 0.6629464285714286\n",
            "Epoch: 64, LR: [0.08000000000000002]\n",
            "Train loss: 0.04726677288365836, Train accuracy: 0.9133663366336634\n",
            "Validation loss: 0.16967477117265975, Validation accuracy: 0.6830357142857143\n",
            "Epoch: 65, LR: [0.08000000000000002]\n",
            "Train loss: 0.046778558873304045, Train accuracy: 0.9124381188118812\n",
            "Validation loss: 0.16796086728572845, Validation accuracy: 0.6830357142857143\n",
            "Epoch: 66, LR: [0.08000000000000002]\n",
            "Train loss: 0.047245664724914156, Train accuracy: 0.9110457920792079\n",
            "Validation loss: 0.16628547864300863, Validation accuracy: 0.6808035714285714\n",
            "Epoch: 67, LR: [0.08000000000000002]\n",
            "Train loss: 0.04715580054291404, Train accuracy: 0.9186262376237624\n",
            "Validation loss: 0.1571281382015773, Validation accuracy: 0.7098214285714286\n",
            "Epoch: 68, LR: [0.08000000000000002]\n",
            "Train loss: 0.04709173860673857, Train accuracy: 0.9189356435643564\n",
            "Validation loss: 0.16886637892041886, Validation accuracy: 0.671875\n",
            "Epoch: 69, LR: [0.08000000000000002]\n",
            "Train loss: 0.04671767394584004, Train accuracy: 0.9190903465346535\n",
            "Validation loss: 0.16062583455017634, Validation accuracy: 0.6808035714285714\n",
            "Epoch: 70, LR: [0.08000000000000002]\n",
            "Train loss: 0.045950747012059284, Train accuracy: 0.9133663366336634\n",
            "Validation loss: 0.16580048203468323, Validation accuracy: 0.6830357142857143\n",
            "Target number of exemplars per class: 100\n",
            "Target total number of exemplars: 2000\n",
            "Randomly extracting exemplars from class 0 of current split... Extracted 100 exemplars.\n",
            "Randomly extracting exemplars from class 1 of current split... Extracted 100 exemplars.\n",
            "Randomly extracting exemplars from class 2 of current split... Extracted 100 exemplars.\n",
            "Randomly extracting exemplars from class 3 of current split... Extracted 100 exemplars.\n",
            "Randomly extracting exemplars from class 4 of current split... Extracted 100 exemplars.\n",
            "Randomly extracting exemplars from class 5 of current split... Extracted 100 exemplars.\n",
            "Randomly extracting exemplars from class 6 of current split... Extracted 100 exemplars.\n",
            "Randomly extracting exemplars from class 7 of current split... Extracted 100 exemplars.\n",
            "Randomly extracting exemplars from class 8 of current split... Extracted 100 exemplars.\n",
            "Randomly extracting exemplars from class 9 of current split... Extracted 100 exemplars.\n",
            "Computing mean of exemplars... done\n",
            "Test accuracy (iCaRL): 0.807 (exemplars and training data)\n",
            "gridsearch rfc . . .\n",
            "gridsearch knn . . .\n",
            "gridsearch svc . . .\n",
            "gridsearch done.\n",
            "Test accuracy (iCaRL with RFC): 0.752 \n",
            "Test accuracy (iCaRL with KNN): 0.79 \n",
            "Test accuracy (iCaRL with SVC): 0.796 \n",
            "## Split 2 of run 0 ##\n",
            "Length of exemplars set: 2000\n",
            "Epoch: 1, LR: [2]\n",
            "Train loss: 0.1404568032905607, Train accuracy: 0.30708539603960394\n",
            "Validation loss: 0.15106127304690226, Validation accuracy: 0.16071428571428573\n",
            "Epoch: 2, LR: [2]\n",
            "Train loss: 0.11849905823421951, Train accuracy: 0.39495668316831684\n",
            "Validation loss: 0.1436714998313359, Validation accuracy: 0.22544642857142858\n",
            "Epoch: 3, LR: [2]\n",
            "Train loss: 0.11337494200999194, Train accuracy: 0.45792079207920794\n",
            "Validation loss: 0.15146130323410034, Validation accuracy: 0.2767857142857143\n",
            "Epoch: 4, LR: [2]\n",
            "Train loss: 0.10942641121916252, Train accuracy: 0.5004641089108911\n",
            "Validation loss: 0.1395902442080634, Validation accuracy: 0.31919642857142855\n",
            "Epoch: 5, LR: [2]\n",
            "Train loss: 0.10672386285692158, Train accuracy: 0.5324876237623762\n",
            "Validation loss: 0.1414289421268872, Validation accuracy: 0.31026785714285715\n",
            "Epoch: 6, LR: [2]\n",
            "Train loss: 0.10513109367082615, Train accuracy: 0.5577042079207921\n",
            "Validation loss: 0.13471253961324692, Validation accuracy: 0.36830357142857145\n",
            "Epoch: 7, LR: [2]\n",
            "Train loss: 0.10358319379905663, Train accuracy: 0.5635829207920792\n",
            "Validation loss: 0.12425662257841655, Validation accuracy: 0.41964285714285715\n",
            "Epoch: 8, LR: [2]\n",
            "Train loss: 0.10297440995674322, Train accuracy: 0.5748762376237624\n",
            "Validation loss: 0.13493542586054122, Validation accuracy: 0.41964285714285715\n",
            "Epoch: 9, LR: [2]\n",
            "Train loss: 0.1003994659179508, Train accuracy: 0.6010210396039604\n",
            "Validation loss: 0.11554378164666039, Validation accuracy: 0.48214285714285715\n",
            "Epoch: 10, LR: [2]\n",
            "Train loss: 0.10047660701640762, Train accuracy: 0.6104579207920792\n",
            "Validation loss: 0.12481846128191267, Validation accuracy: 0.4375\n",
            "Epoch: 11, LR: [2]\n",
            "Train loss: 0.09965786559156853, Train accuracy: 0.6141707920792079\n",
            "Validation loss: 0.13557840032236917, Validation accuracy: 0.421875\n",
            "Epoch: 12, LR: [2]\n",
            "Train loss: 0.09840309575642689, Train accuracy: 0.6321163366336634\n",
            "Validation loss: 0.12536683359316417, Validation accuracy: 0.48660714285714285\n",
            "Epoch: 13, LR: [2]\n",
            "Train loss: 0.09711852883643443, Train accuracy: 0.6478960396039604\n",
            "Validation loss: 0.12719084322452545, Validation accuracy: 0.4888392857142857\n",
            "Epoch: 14, LR: [2]\n",
            "Train loss: 0.09796155133459827, Train accuracy: 0.6485148514851485\n",
            "Validation loss: 0.1277525829417365, Validation accuracy: 0.4330357142857143\n",
            "Epoch: 15, LR: [2]\n",
            "Train loss: 0.09733835356955481, Train accuracy: 0.6599628712871287\n",
            "Validation loss: 0.11990963986941747, Validation accuracy: 0.53125\n",
            "Epoch: 16, LR: [2]\n",
            "Train loss: 0.09711229697902604, Train accuracy: 0.6675433168316832\n",
            "Validation loss: 0.12578890366213663, Validation accuracy: 0.49776785714285715\n",
            "Epoch: 17, LR: [2]\n",
            "Train loss: 0.09516746410638979, Train accuracy: 0.6850247524752475\n",
            "Validation loss: 0.12111199115003858, Validation accuracy: 0.5133928571428571\n",
            "Epoch: 18, LR: [2]\n",
            "Train loss: 0.09532128532629201, Train accuracy: 0.6817759900990099\n",
            "Validation loss: 0.12528342753648758, Validation accuracy: 0.49107142857142855\n",
            "Epoch: 19, LR: [2]\n",
            "Train loss: 0.09411376345865798, Train accuracy: 0.6884282178217822\n",
            "Validation loss: 0.1303578998361315, Validation accuracy: 0.46875\n",
            "Epoch: 20, LR: [2]\n",
            "Train loss: 0.09240879590558533, Train accuracy: 0.7003403465346535\n",
            "Validation loss: 0.13028689048119954, Validation accuracy: 0.5357142857142857\n",
            "Epoch: 21, LR: [2]\n",
            "Train loss: 0.0938147901013346, Train accuracy: 0.6961633663366337\n",
            "Validation loss: 0.14106502277510508, Validation accuracy: 0.49107142857142855\n",
            "Epoch: 22, LR: [2]\n",
            "Train loss: 0.09326407261709176, Train accuracy: 0.7021967821782178\n",
            "Validation loss: 0.10385094370160784, Validation accuracy: 0.5602678571428571\n",
            "Epoch: 23, LR: [2]\n",
            "Train loss: 0.0925841777041407, Train accuracy: 0.7105507425742574\n",
            "Validation loss: 0.12752806395292282, Validation accuracy: 0.5223214285714286\n",
            "Epoch: 24, LR: [2]\n",
            "Train loss: 0.09219461812241243, Train accuracy: 0.7189047029702971\n",
            "Validation loss: 0.13641543899263656, Validation accuracy: 0.5491071428571429\n",
            "Epoch: 25, LR: [2]\n",
            "Train loss: 0.09043046153417908, Train accuracy: 0.7283415841584159\n",
            "Validation loss: 0.13184369781187602, Validation accuracy: 0.53125\n",
            "Epoch: 26, LR: [2]\n",
            "Train loss: 0.09184777412084069, Train accuracy: 0.7230816831683168\n",
            "Validation loss: 0.11441817560366221, Validation accuracy: 0.5401785714285714\n",
            "Epoch: 27, LR: [2]\n",
            "Train loss: 0.08938527387557643, Train accuracy: 0.7342202970297029\n",
            "Validation loss: 0.11122586258820125, Validation accuracy: 0.5758928571428571\n",
            "Epoch: 28, LR: [2]\n",
            "Train loss: 0.08992702159846183, Train accuracy: 0.7377784653465347\n",
            "Validation loss: 0.11515658455235618, Validation accuracy: 0.5602678571428571\n",
            "Epoch: 29, LR: [2]\n",
            "Train loss: 0.09031279694915999, Train accuracy: 0.7349938118811881\n",
            "Validation loss: 0.1330308041402272, Validation accuracy: 0.5022321428571429\n",
            "Epoch: 30, LR: [2]\n",
            "Train loss: 0.09004744326714242, Train accuracy: 0.7470606435643564\n",
            "Validation loss: 0.11532087730509895, Validation accuracy: 0.5915178571428571\n",
            "Epoch: 31, LR: [2]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-9384877f8fa8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"## Split {split_i} of run {run_i} ##\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mtrain_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0micarl_CLFS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mincremental_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_subsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrun_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_subsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrun_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0micarl_CLFS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_subsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrun_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_subsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrun_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/model/icarl.py\u001b[0m in \u001b[0;36mincremental_train\u001b[0;34m(self, split, train_dataset, val_dataset)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;31m# Improve network parameters upon receiving new classes. Effectively\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;31m# train a new network starting from the current network parameters.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mtrain_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_representation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;31m# Compute the number of exemplars per class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/model/icarl.py\u001b[0m in \u001b[0;36mupdate_representation\u001b[0;34m(self, train_dataset, val_dataset)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;31m# Train the network on combined dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0mtrain_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset_with_exemplars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# @todo: include exemplars in validation set?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;31m# Keep a copy of the current network in order to compute its outputs for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/model/icarl.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataset, val_dataset)\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0;31m# Run an epoch (start counting form 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;31m# Validate after each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/model/icarl.py\u001b[0m in \u001b[0;36mdo_epoch\u001b[0;34m(self, current_epoch)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m             \u001b[0mrunning_train_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/model/icarl.py\u001b[0m in \u001b[0;36mdo_batch\u001b[0;34m(self, batch, labels)\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0;31m# loss. We discard the output of the new neurons, as they are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m             \u001b[0;31m# considered in the distillation loss.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             \u001b[0mold_net_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mold_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0;31m# Concatenate the outputs of the old network and the one-hot encoded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/model/resnet_cifar.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/model/resnet_cifar.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m                 \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}